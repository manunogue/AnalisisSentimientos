[1] "DATASET NAME: Carmela_Bi_IR_0"
[1] "TRAIN INSTANCES: 308"
[1] "TEST INSTANCES: 103"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 1.91894698143005"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

308 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 247, 246, 246, 246, 247 
Resampling results:

  ROC       Sens  Spec
  0.750614  0.08  1   

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.6      0.0
  positive      6.8     92.5
                            
 Accuracy (average) : 0.9318

[1] "TEST accuracy: 0.931818181818182"
[1] "TEST +precision: 0.931372549019608"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.0869565217391304"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        0
            positive       11       87
[1] "TEST accuracy: 0.893203883495146"
[1] "TEST +precision: 0.887755102040816"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.3125"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.18253663380941"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

308 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 246, 246, 247, 246, 247 
Resampling results across tuning parameters:

  C      M  ROC  Sens  Spec
  0.010  1  0.5  0     1   
  0.010  2  0.5  0     1   
  0.010  3  0.5  0     1   
  0.255  1  0.5  0     1   
  0.255  2  0.5  0     1   
  0.255  3  0.5  0     1   
  0.500  1  0.5  0     1   
  0.500  2  0.5  0     1   
  0.500  3  0.5  0     1   

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.01 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.0
  positive      7.5     92.5
                            
 Accuracy (average) : 0.9253

[1] "TEST accuracy: 0.925324675324675"
[1] "TEST +precision: 0.925324675324675"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       16       87
[1] "TEST accuracy: 0.844660194174757"
[1] "TEST +precision: 0.844660194174757"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 1.49727930227915"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

308 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 247, 246, 247, 246, 246 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens  Spec     
  0.3  1          0.6               0.50        50      0.5669298  0     1.0000000
  0.3  1          0.6               0.50       100      0.5809649  0     1.0000000
  0.3  1          0.6               0.50       150      0.5946491  0     1.0000000
  0.3  1          0.6               0.75        50      0.5971930  0     1.0000000
  0.3  1          0.6               0.75       100      0.6182456  0     1.0000000
  0.3  1          0.6               0.75       150      0.6250877  0     1.0000000
  0.3  1          0.6               1.00        50      0.6178947  0     1.0000000
  0.3  1          0.6               1.00       100      0.6187719  0     1.0000000
  0.3  1          0.6               1.00       150      0.6187719  0     1.0000000
  0.3  1          0.8               0.50        50      0.5589474  0     1.0000000
  0.3  1          0.8               0.50       100      0.5620175  0     1.0000000
  0.3  1          0.8               0.50       150      0.5604386  0     1.0000000
  0.3  1          0.8               0.75        50      0.6080702  0     1.0000000
  0.3  1          0.8               0.75       100      0.6059649  0     1.0000000
  0.3  1          0.8               0.75       150      0.6188596  0     1.0000000
  0.3  1          0.8               1.00        50      0.6052632  0     1.0000000
  0.3  1          0.8               1.00       100      0.6052632  0     1.0000000
  0.3  1          0.8               1.00       150      0.6052632  0     1.0000000
  0.3  2          0.6               0.50        50      0.5712281  0     1.0000000
  0.3  2          0.6               0.50       100      0.5964912  0     1.0000000
  0.3  2          0.6               0.50       150      0.6017544  0     1.0000000
  0.3  2          0.6               0.75        50      0.5633333  0     1.0000000
  0.3  2          0.6               0.75       100      0.5703509  0     1.0000000
  0.3  2          0.6               0.75       150      0.5610526  0     1.0000000
  0.3  2          0.6               1.00        50      0.5963158  0     1.0000000
  0.3  2          0.6               1.00       100      0.5903509  0     1.0000000
  0.3  2          0.6               1.00       150      0.5903509  0     1.0000000
  0.3  2          0.8               0.50        50      0.5799123  0     1.0000000
  0.3  2          0.8               0.50       100      0.5814912  0     1.0000000
  0.3  2          0.8               0.50       150      0.5850000  0     1.0000000
  0.3  2          0.8               0.75        50      0.5953509  0     1.0000000
  0.3  2          0.8               0.75       100      0.6098246  0     1.0000000
  0.3  2          0.8               0.75       150      0.6098246  0     1.0000000
  0.3  2          0.8               1.00        50      0.5837719  0     1.0000000
  0.3  2          0.8               1.00       100      0.5758772  0     1.0000000
  0.3  2          0.8               1.00       150      0.5792105  0     1.0000000
  0.3  3          0.6               0.50        50      0.5773684  0     1.0000000
  0.3  3          0.6               0.50       100      0.5899123  0     1.0000000
  0.3  3          0.6               0.50       150      0.5951754  0     1.0000000
  0.3  3          0.6               0.75        50      0.6170175  0     1.0000000
  0.3  3          0.6               0.75       100      0.6194737  0     1.0000000
  0.3  3          0.6               0.75       150      0.6222807  0     1.0000000
  0.3  3          0.6               1.00        50      0.5942105  0     1.0000000
  0.3  3          0.6               1.00       100      0.5957895  0     1.0000000
  0.3  3          0.6               1.00       150      0.5957895  0     1.0000000
  0.3  3          0.8               0.50        50      0.5697368  0     1.0000000
  0.3  3          0.8               0.50       100      0.5877193  0     1.0000000
  0.3  3          0.8               0.50       150      0.5896491  0     1.0000000
  0.3  3          0.8               0.75        50      0.6089474  0     1.0000000
  0.3  3          0.8               0.75       100      0.6031579  0     1.0000000
  0.3  3          0.8               0.75       150      0.5995614  0     1.0000000
  0.3  3          0.8               1.00        50      0.5836842  0     1.0000000
  0.3  3          0.8               1.00       100      0.5836842  0     1.0000000
  0.3  3          0.8               1.00       150      0.5836842  0     1.0000000
  0.4  1          0.6               0.50        50      0.5757895  0     1.0000000
  0.4  1          0.6               0.50       100      0.5972807  0     1.0000000
  0.4  1          0.6               0.50       150      0.5972807  0     1.0000000
  0.4  1          0.6               0.75        50      0.5877193  0     1.0000000
  0.4  1          0.6               0.75       100      0.6014035  0     1.0000000
  0.4  1          0.6               0.75       150      0.5906140  0     1.0000000
  0.4  1          0.6               1.00        50      0.6049123  0     1.0000000
  0.4  1          0.6               1.00       100      0.6049123  0     1.0000000
  0.4  1          0.6               1.00       150      0.6049123  0     1.0000000
  0.4  1          0.8               0.50        50      0.5856140  0     1.0000000
  0.4  1          0.8               0.50       100      0.5702632  0     1.0000000
  0.4  1          0.8               0.50       150      0.5702632  0     1.0000000
  0.4  1          0.8               0.75        50      0.5942105  0     1.0000000
  0.4  1          0.8               0.75       100      0.6152632  0     1.0000000
  0.4  1          0.8               0.75       150      0.6194737  0     1.0000000
  0.4  1          0.8               1.00        50      0.6035088  0     1.0000000
  0.4  1          0.8               1.00       100      0.6035088  0     1.0000000
  0.4  1          0.8               1.00       150      0.6035088  0     1.0000000
  0.4  2          0.6               0.50        50      0.6249123  0     1.0000000
  0.4  2          0.6               0.50       100      0.6529825  0     1.0000000
  0.4  2          0.6               0.50       150      0.6564912  0     1.0000000
  0.4  2          0.6               0.75        50      0.5679825  0     1.0000000
  0.4  2          0.6               0.75       100      0.5753509  0     1.0000000
  0.4  2          0.6               0.75       150      0.5902632  0     1.0000000
  0.4  2          0.6               1.00        50      0.5902632  0     0.9964912
  0.4  2          0.6               1.00       100      0.5895614  0     0.9964912
  0.4  2          0.6               1.00       150      0.5895614  0     0.9964912
  0.4  2          0.8               0.50        50      0.5799123  0     1.0000000
  0.4  2          0.8               0.50       100      0.5834211  0     1.0000000
  0.4  2          0.8               0.50       150      0.5799123  0     1.0000000
  0.4  2          0.8               0.75        50      0.6044737  0     1.0000000
  0.4  2          0.8               0.75       100      0.6048246  0     1.0000000
  0.4  2          0.8               0.75       150      0.6012281  0     1.0000000
  0.4  2          0.8               1.00        50      0.5862281  0     1.0000000
  0.4  2          0.8               1.00       100      0.5809649  0     1.0000000
  0.4  2          0.8               1.00       150      0.5818421  0     0.9964912
  0.4  3          0.6               0.50        50      0.5780702  0     1.0000000
  0.4  3          0.6               0.50       100      0.5503509  0     1.0000000
  0.4  3          0.6               0.50       150      0.5571930  0     1.0000000
  0.4  3          0.6               0.75        50      0.5750000  0     1.0000000
  0.4  3          0.6               0.75       100      0.6013158  0     1.0000000
  0.4  3          0.6               0.75       150      0.6000877  0     1.0000000
  0.4  3          0.6               1.00        50      0.5907018  0     0.9964912
  0.4  3          0.6               1.00       100      0.5922807  0     0.9964912
  0.4  3          0.6               1.00       150      0.5922807  0     0.9964912
  0.4  3          0.8               0.50        50      0.5634211  0     1.0000000
  0.4  3          0.8               0.50       100      0.5658772  0     1.0000000
  0.4  3          0.8               0.50       150      0.5756140  0     1.0000000
  0.4  3          0.8               0.75        50      0.6339474  0     1.0000000
  0.4  3          0.8               0.75       100      0.6332456  0     1.0000000
  0.4  3          0.8               0.75       150      0.6386842  0     1.0000000
  0.4  3          0.8               1.00        50      0.5679825  0     1.0000000
  0.4  3          0.8               1.00       100      0.5688596  0     1.0000000
  0.4  3          0.8               1.00       150      0.5688596  0     1.0000000

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 2, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.5.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.0
  positive      7.5     92.5
                            
 Accuracy (average) : 0.9253

[1] "TEST accuracy: 0.925324675324675"
[1] "TEST +precision: 0.925324675324675"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       16       87
[1] "TEST accuracy: 0.844660194174757"
[1] "TEST +precision: 0.844660194174757"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
