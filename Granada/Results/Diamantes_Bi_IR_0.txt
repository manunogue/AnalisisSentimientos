[1] "DATASET NAME: Diamantes_Bi_IR_0"
[1] "TRAIN INSTANCES: 390"
[1] "TEST INSTANCES: 131"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.03954482078552"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

390 samples
947 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 313, 312, 312, 311, 312 
Resampling results:

  ROC        Sens        Spec
  0.7797703  0.06666667  1   

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.3      0.0
  positive      4.6     95.1
                            
 Accuracy (average) : 0.9538

[1] "TEST accuracy: 0.953846153846154"
[1] "TEST +precision: 0.953727506426735"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.0526315789473684"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        2
            positive        6      123
[1] "TEST accuracy: 0.938931297709924"
[1] "TEST +precision: 0.953488372093023"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.984"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.28795491456985"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

390 samples
947 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 312, 311, 312, 312, 313 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec
  0.010  1  0.5000000  0     1   
  0.010  2  0.5000000  0     1   
  0.010  3  0.5000000  0     1   
  0.255  1  0.5000000  0     1   
  0.255  2  0.5000000  0     1   
  0.255  3  0.5000000  0     1   
  0.500  1  0.5477207  0     1   
  0.500  2  0.5121441  0     1   
  0.500  3  0.5000000  0     1   

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.0
  positive      4.9     95.1
                            
 Accuracy (average) : 0.9513

[1] "TEST accuracy: 0.951282051282051"
[1] "TEST +precision: 0.951282051282051"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        6      125
[1] "TEST accuracy: 0.954198473282443"
[1] "TEST +precision: 0.954198473282443"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 1.8415042479833"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

390 samples
947 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 312, 312, 313, 312, 311 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens  Spec     
  0.3  1          0.6               0.50        50      0.5048153  0     1.0000000
  0.3  1          0.6               0.50       100      0.5427748  0     1.0000000
  0.3  1          0.6               0.50       150      0.5198018  0     1.0000000
  0.3  1          0.6               0.75        50      0.5544054  0     1.0000000
  0.3  1          0.6               0.75       100      0.5558018  0     1.0000000
  0.3  1          0.6               0.75       150      0.5557568  0     1.0000000
  0.3  1          0.6               1.00        50      0.5628514  0     1.0000000
  0.3  1          0.6               1.00       100      0.5756622  0     1.0000000
  0.3  1          0.6               1.00       150      0.5756622  0     1.0000000
  0.3  1          0.8               0.50        50      0.5354189  0     1.0000000
  0.3  1          0.8               0.50       100      0.5337207  0     1.0000000
  0.3  1          0.8               0.50       150      0.5465586  0     1.0000000
  0.3  1          0.8               0.75        50      0.5916937  0     1.0000000
  0.3  1          0.8               0.75       100      0.5761847  0     1.0000000
  0.3  1          0.8               0.75       150      0.5910315  0     1.0000000
  0.3  1          0.8               1.00        50      0.5625045  0     1.0000000
  0.3  1          0.8               1.00       100      0.5756802  0     0.9946667
  0.3  1          0.8               1.00       150      0.5736802  0     0.9946667
  0.3  2          0.6               0.50        50      0.5791441  0     1.0000000
  0.3  2          0.6               0.50       100      0.5406306  0     1.0000000
  0.3  2          0.6               0.50       150      0.5521171  0     1.0000000
  0.3  2          0.6               0.75        50      0.5630495  0     1.0000000
  0.3  2          0.6               0.75       100      0.5738514  0     1.0000000
  0.3  2          0.6               0.75       150      0.5866982  0     1.0000000
  0.3  2          0.6               1.00        50      0.6113198  0     1.0000000
  0.3  2          0.6               1.00       100      0.6146712  0     0.9973333
  0.3  2          0.6               1.00       150      0.6133378  0     0.9973333
  0.3  2          0.8               0.50        50      0.5119414  0     1.0000000
  0.3  2          0.8               0.50       100      0.5476892  0     1.0000000
  0.3  2          0.8               0.50       150      0.5267883  0     1.0000000
  0.3  2          0.8               0.75        50      0.6033649  0     1.0000000
  0.3  2          0.8               0.75       100      0.5969910  0     1.0000000
  0.3  2          0.8               0.75       150      0.6057748  0     1.0000000
  0.3  2          0.8               1.00        50      0.5551126  0     0.9973333
  0.3  2          0.8               1.00       100      0.5801306  0     0.9973333
  0.3  2          0.8               1.00       150      0.5874910  0     0.9973333
  0.3  3          0.6               0.50        50      0.5054414  0     1.0000000
  0.3  3          0.6               0.50       100      0.5512793  0     1.0000000
  0.3  3          0.6               0.50       150      0.5321306  0     1.0000000
  0.3  3          0.6               0.75        50      0.5852162  0     1.0000000
  0.3  3          0.6               0.75       100      0.5595315  0     1.0000000
  0.3  3          0.6               0.75       150      0.5642523  0     1.0000000
  0.3  3          0.6               1.00        50      0.6004144  0     0.9973333
  0.3  3          0.6               1.00       100      0.6044955  0     0.9973333
  0.3  3          0.6               1.00       150      0.6044955  0     0.9973333
  0.3  3          0.8               0.50        50      0.5752117  0     1.0000000
  0.3  3          0.8               0.50       100      0.5928333  0     1.0000000
  0.3  3          0.8               0.50       150      0.6305541  0     1.0000000
  0.3  3          0.8               0.75        50      0.6027027  0     1.0000000
  0.3  3          0.8               0.75       100      0.5952432  0     1.0000000
  0.3  3          0.8               0.75       150      0.6188739  0     1.0000000
  0.3  3          0.8               1.00        50      0.6088378  0     0.9973333
  0.3  3          0.8               1.00       100      0.6047297  0     0.9973333
  0.3  3          0.8               1.00       150      0.6040901  0     0.9946667
  0.4  1          0.6               0.50        50      0.5458604  0     1.0000000
  0.4  1          0.6               0.50       100      0.5831216  0     1.0000000
  0.4  1          0.6               0.50       150      0.5424279  0     1.0000000
  0.4  1          0.6               0.75        50      0.5131892  0     1.0000000
  0.4  1          0.6               0.75       100      0.5301081  0     1.0000000
  0.4  1          0.6               0.75       150      0.5422162  0     1.0000000
  0.4  1          0.6               1.00        50      0.5604414  0     1.0000000
  0.4  1          0.6               1.00       100      0.5584414  0     1.0000000
  0.4  1          0.6               1.00       150      0.5584414  0     1.0000000
  0.4  1          0.8               0.50        50      0.5748739  0     1.0000000
  0.4  1          0.8               0.50       100      0.5828739  0     1.0000000
  0.4  1          0.8               0.50       150      0.5663198  0     1.0000000
  0.4  1          0.8               0.75        50      0.5942568  0     1.0000000
  0.4  1          0.8               0.75       100      0.6081667  0     1.0000000
  0.4  1          0.8               0.75       150      0.5895541  0     1.0000000
  0.4  1          0.8               1.00        50      0.5560856  0     1.0000000
  0.4  1          0.8               1.00       100      0.5550450  0     1.0000000
  0.4  1          0.8               1.00       150      0.5550450  0     1.0000000
  0.4  2          0.6               0.50        50      0.5543964  0     1.0000000
  0.4  2          0.6               0.50       100      0.5412613  0     1.0000000
  0.4  2          0.6               0.50       150      0.5493694  0     1.0000000
  0.4  2          0.6               0.75        50      0.5967883  0     1.0000000
  0.4  2          0.6               0.75       100      0.5872658  0     1.0000000
  0.4  2          0.6               0.75       150      0.6107703  0     1.0000000
  0.4  2          0.6               1.00        50      0.5966261  0     0.9973333
  0.4  2          0.6               1.00       100      0.6026892  0     0.9973333
  0.4  2          0.6               1.00       150      0.6033559  0     0.9973333
  0.4  2          0.8               0.50        50      0.5627477  0     1.0000000
  0.4  2          0.8               0.50       100      0.5565766  0     1.0000000
  0.4  2          0.8               0.50       150      0.5729685  0     1.0000000
  0.4  2          0.8               0.75        50      0.6139820  0     1.0000000
  0.4  2          0.8               0.75       100      0.6163153  0     1.0000000
  0.4  2          0.8               0.75       150      0.6123063  0     1.0000000
  0.4  2          0.8               1.00        50      0.6006982  0     0.9973333
  0.4  2          0.8               1.00       100      0.5959685  0     0.9973333
  0.4  2          0.8               1.00       150      0.5986712  0     0.9973333
  0.4  3          0.6               0.50        50      0.5166712  0     1.0000000
  0.4  3          0.6               0.50       100      0.5372793  0     1.0000000
  0.4  3          0.6               0.50       150      0.5318739  0     1.0000000
  0.4  3          0.6               0.75        50      0.6272748  0     1.0000000
  0.4  3          0.6               0.75       100      0.6259144  0     1.0000000
  0.4  3          0.6               0.75       150      0.6313198  0     1.0000000
  0.4  3          0.6               1.00        50      0.6052838  0     0.9973333
  0.4  3          0.6               1.00       100      0.6032117  0     0.9946667
  0.4  3          0.6               1.00       150      0.6018604  0     0.9946667
  0.4  3          0.8               0.50        50      0.4694505  0     1.0000000
  0.4  3          0.8               0.50       100      0.4850901  0     1.0000000
  0.4  3          0.8               0.50       150      0.5120180  0     1.0000000
  0.4  3          0.8               0.75        50      0.5529144  0     1.0000000
  0.4  3          0.8               0.75       100      0.5596892  0     1.0000000
  0.4  3          0.8               0.75       150      0.5816396  0     1.0000000
  0.4  3          0.8               1.00        50      0.6064369  0     0.9973333
  0.4  3          0.8               1.00       100      0.6003559  0     0.9973333
  0.4  3          0.8               1.00       150      0.6003559  0     0.9973333

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.0
  positive      4.9     95.1
                            
 Accuracy (average) : 0.9513

[1] "TEST accuracy: 0.951282051282051"
[1] "TEST +precision: 0.951282051282051"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        6      125
[1] "TEST accuracy: 0.954198473282443"
[1] "TEST +precision: 0.954198473282443"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
