[1] "DATASET NAME: Estrellas_Bi_IR_5"
[1] "TRAIN INSTANCES: 482"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.62614893913269"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

482 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 385, 385, 385, 387, 386 
Resampling results:

  ROC        Sens       Spec     
  0.9877424  0.9028571  0.9973684

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     19.5      0.2
  positive      2.1     78.2
                            
 Accuracy (average) : 0.9772

[1] "TEST accuracy: 0.977178423236514"
[1] "TEST +precision: 0.974160206718346"
[1] "TEST -precision: 0.989473684210526"
[1] "TEST specifity: 0.903846153846154"
[1] "TEST sensitivity: 0.997354497354497"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        1
            positive        8      127
[1] "TEST accuracy: 0.934782608695652"
[1] "TEST +precision: 0.940740740740741"
[1] "TEST -precision: 0.666666666666667"
[1] "TEST specifity: 0.2"
[1] "TEST sensitivity: 0.9921875"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.553160516421"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

482 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 386, 385, 385, 387, 385 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7341649  0.4914286  0.9762105
  0.010  2  0.7427556  0.5104762  0.9709474
  0.010  3  0.7163880  0.4528571  0.9683158
  0.255  1  0.8658376  0.7419048  0.9602456
  0.255  2  0.8628503  0.7223810  0.9602456
  0.255  3  0.8282037  0.6076190  0.9735439
  0.500  1  0.9133500  0.8561905  0.9417895
  0.500  2  0.9030563  0.7800000  0.9496842
  0.500  3  0.8867910  0.6461905  0.9524211

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.5      4.6
  positive      3.1     73.9
                            
 Accuracy (average) : 0.9232

[1] "TEST accuracy: 0.923236514522822"
[1] "TEST +precision: 0.959568733153639"
[1] "TEST -precision: 0.801801801801802"
[1] "TEST specifity: 0.855769230769231"
[1] "TEST sensitivity: 0.941798941798942"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        4
            positive        9      124
[1] "TEST accuracy: 0.905797101449275"
[1] "TEST +precision: 0.932330827067669"
[1] "TEST -precision: 0.2"
[1] "TEST specifity: 0.1"
[1] "TEST sensitivity: 0.96875"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.91084333260854"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

482 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 385, 386, 385, 386, 386 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8638647  0.3947619  0.9761404
  0.3  1          0.6               0.50       100      0.8965242  0.4619048  0.9788070
  0.3  1          0.6               0.50       150      0.9126771  0.4904762  0.9787719
  0.3  1          0.6               0.75        50      0.8892686  0.4519048  0.9920000
  0.3  1          0.6               0.75       100      0.9245359  0.5280952  0.9867368
  0.3  1          0.6               0.75       150      0.9318152  0.5380952  0.9761404
  0.3  1          0.6               1.00        50      0.8977970  0.4038095  0.9868070
  0.3  1          0.6               1.00       100      0.9317901  0.5285714  0.9920702
  0.3  1          0.6               1.00       150      0.9403480  0.5385714  0.9894386
  0.3  1          0.8               0.50        50      0.8650909  0.3838095  0.9788421
  0.3  1          0.8               0.50       100      0.8982571  0.4719048  0.9788421
  0.3  1          0.8               0.50       150      0.9201802  0.5285714  0.9761754
  0.3  1          0.8               0.75        50      0.8929557  0.3942857  0.9867368
  0.3  1          0.8               0.75       100      0.9198839  0.5285714  0.9761404
  0.3  1          0.8               0.75       150      0.9266986  0.5571429  0.9788070
  0.3  1          0.8               1.00        50      0.8946299  0.4133333  0.9894386
  0.3  1          0.8               1.00       100      0.9301295  0.5285714  0.9921053
  0.3  1          0.8               1.00       150      0.9417698  0.5385714  0.9841053
  0.3  2          0.6               0.50        50      0.9048782  0.4414286  0.9788070
  0.3  2          0.6               0.50       100      0.9196424  0.5185714  0.9735088
  0.3  2          0.6               0.50       150      0.9223563  0.5280952  0.9735088
  0.3  2          0.6               0.75        50      0.9245042  0.5571429  0.9867719
  0.3  2          0.6               0.75       100      0.9368022  0.5861905  0.9841404
  0.3  2          0.6               0.75       150      0.9285194  0.5952381  0.9788421
  0.3  2          0.6               1.00        50      0.9294294  0.5285714  0.9814737
  0.3  2          0.6               1.00       100      0.9449998  0.5671429  0.9788070
  0.3  2          0.6               1.00       150      0.9379879  0.5961905  0.9682105
  0.3  2          0.8               0.50        50      0.8911502  0.4419048  0.9761404
  0.3  2          0.8               0.50       100      0.9152607  0.4995238  0.9681754
  0.3  2          0.8               0.50       150      0.9272180  0.5280952  0.9734737
  0.3  2          0.8               0.75        50      0.9201276  0.5385714  0.9788421
  0.3  2          0.8               0.75       100      0.9382861  0.5857143  0.9761754
  0.3  2          0.8               0.75       150      0.9400255  0.5957143  0.9761754
  0.3  2          0.8               1.00        50      0.9313239  0.5190476  0.9894386
  0.3  2          0.8               1.00       100      0.9472485  0.5671429  0.9761754
  0.3  2          0.8               1.00       150      0.9438555  0.5961905  0.9761754
  0.3  3          0.6               0.50        50      0.9113442  0.4609524  0.9841404
  0.3  3          0.6               0.50       100      0.9270309  0.5095238  0.9814737
  0.3  3          0.6               0.50       150      0.9303680  0.5385714  0.9761754
  0.3  3          0.6               0.75        50      0.9309501  0.5576190  0.9814737
  0.3  3          0.6               0.75       100      0.9367542  0.5671429  0.9708421
  0.3  3          0.6               0.75       150      0.9401723  0.6338095  0.9681754
  0.3  3          0.6               1.00        50      0.9544340  0.6147619  0.9841053
  0.3  3          0.6               1.00       100      0.9505589  0.6533333  0.9708772
  0.3  3          0.6               1.00       150      0.9488918  0.6823810  0.9682105
  0.3  3          0.8               0.50        50      0.9170142  0.4704762  0.9762105
  0.3  3          0.8               0.50       100      0.9371842  0.5185714  0.9735439
  0.3  3          0.8               0.50       150      0.9515894  0.5857143  0.9735088
  0.3  3          0.8               0.75        50      0.9403668  0.5571429  0.9814737
  0.3  3          0.8               0.75       100      0.9445368  0.6152381  0.9761404
  0.3  3          0.8               0.75       150      0.9489689  0.6533333  0.9788070
  0.3  3          0.8               1.00        50      0.9482132  0.6338095  0.9841053
  0.3  3          0.8               1.00       100      0.9462749  0.6528571  0.9735088
  0.3  3          0.8               1.00       150      0.9478897  0.6919048  0.9682105
  0.4  1          0.6               0.50        50      0.8634390  0.4119048  0.9788421
  0.4  1          0.6               0.50       100      0.9031389  0.4690476  0.9788421
  0.4  1          0.6               0.50       150      0.9151880  0.5180952  0.9682105
  0.4  1          0.6               0.75        50      0.9000497  0.5090476  0.9867719
  0.4  1          0.6               0.75       100      0.9269023  0.5380952  0.9787719
  0.4  1          0.6               0.75       150      0.9246475  0.5576190  0.9788070
  0.4  1          0.6               1.00        50      0.9242222  0.4995238  0.9868070
  0.4  1          0.6               1.00       100      0.9381013  0.5671429  0.9867719
  0.4  1          0.6               1.00       150      0.9419724  0.5671429  0.9814386
  0.4  1          0.8               0.50        50      0.8756731  0.4228571  0.9788070
  0.4  1          0.8               0.50       100      0.9120854  0.5385714  0.9761754
  0.4  1          0.8               0.50       150      0.9150731  0.5666667  0.9762105
  0.4  1          0.8               0.75        50      0.8923154  0.5000000  0.9841404
  0.4  1          0.8               0.75       100      0.9248563  0.5476190  0.9761404
  0.4  1          0.8               0.75       150      0.9295631  0.6047619  0.9788070
  0.4  1          0.8               1.00        50      0.9176107  0.4995238  0.9894386
  0.4  1          0.8               1.00       100      0.9393208  0.5385714  0.9867719
  0.4  1          0.8               1.00       150      0.9434816  0.5671429  0.9814386
  0.4  2          0.6               0.50        50      0.9061057  0.4709524  0.9788421
  0.4  2          0.6               0.50       100      0.9165744  0.5566667  0.9735439
  0.4  2          0.6               0.50       150      0.9272398  0.5857143  0.9708772
  0.4  2          0.6               0.75        50      0.9287329  0.5476190  0.9788421
  0.4  2          0.6               0.75       100      0.9349271  0.5957143  0.9735439
  0.4  2          0.6               0.75       150      0.9345165  0.6342857  0.9761754
  0.4  2          0.6               1.00        50      0.9382588  0.5380952  0.9814386
  0.4  2          0.6               1.00       100      0.9390827  0.5861905  0.9788070
  0.4  2          0.6               1.00       150      0.9350464  0.5961905  0.9708421
  0.4  2          0.8               0.50        50      0.8997427  0.5000000  0.9681404
  0.4  2          0.8               0.50       100      0.9140911  0.5571429  0.9708421
  0.4  2          0.8               0.50       150      0.9145971  0.5385714  0.9655439
  0.4  2          0.8               0.75        50      0.9404783  0.5666667  0.9867368
  0.4  2          0.8               0.75       100      0.9409678  0.6147619  0.9761754
  0.4  2          0.8               0.75       150      0.9380489  0.6342857  0.9708421
  0.4  2          0.8               1.00        50      0.9356441  0.5671429  0.9867719
  0.4  2          0.8               1.00       100      0.9385125  0.5766667  0.9761754
  0.4  2          0.8               1.00       150      0.9345378  0.6057143  0.9682105
  0.4  3          0.6               0.50        50      0.9302049  0.4895238  0.9761754
  0.4  3          0.6               0.50       100      0.9264365  0.4990476  0.9734737
  0.4  3          0.6               0.50       150      0.9311650  0.5571429  0.9761404
  0.4  3          0.6               0.75        50      0.9376520  0.5857143  0.9814737
  0.4  3          0.6               0.75       100      0.9439866  0.6442857  0.9814737
  0.4  3          0.6               0.75       150      0.9438145  0.6633333  0.9708421
  0.4  3          0.6               1.00        50      0.9432684  0.5861905  0.9814737
  0.4  3          0.6               1.00       100      0.9457874  0.6533333  0.9735088
  0.4  3          0.6               1.00       150      0.9505846  0.6723810  0.9682105
  0.4  3          0.8               0.50        50      0.9195815  0.5376190  0.9788070
  0.4  3          0.8               0.50       100      0.9247790  0.5280952  0.9814737
  0.4  3          0.8               0.50       150      0.9313513  0.5857143  0.9788070
  0.4  3          0.8               0.75        50      0.9408889  0.5871429  0.9814737
  0.4  3          0.8               0.75       100      0.9454591  0.6442857  0.9735088
  0.4  3          0.8               0.75       150      0.9501721  0.6733333  0.9761404
  0.4  3          0.8               1.00        50      0.9547174  0.6242857  0.9761754
  0.4  3          0.8               1.00       100      0.9535691  0.6823810  0.9708421
  0.4  3          0.8               1.00       150      0.9568269  0.7014286  0.9708421

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     15.1      2.3
  positive      6.4     76.1
                            
 Accuracy (average) : 0.9129

[1] "TEST accuracy: 0.912863070539419"
[1] "TEST +precision: 0.922110552763819"
[1] "TEST -precision: 0.869047619047619"
[1] "TEST specifity: 0.701923076923077"
[1] "TEST sensitivity: 0.970899470899471"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        4
            positive        6      124
[1] "TEST accuracy: 0.927536231884058"
[1] "TEST +precision: 0.953846153846154"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.4"
[1] "TEST sensitivity: 0.96875"
