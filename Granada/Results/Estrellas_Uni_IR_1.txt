[1] "DATASET NAME: Estrellas_Uni_IR_1"
[1] "TRAIN INSTANCES: 768"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.96320486068726"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

768 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 614, 614, 614, 615, 615 
Resampling results:

  ROC  Sens  Spec
  1    1     1   

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative       50        0
  positive        0       50
                       
 Accuracy (average) : 1

[1] "TEST accuracy: 1"
[1] "TEST +precision: 1"
[1] "TEST -precision: 1"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        7        0
            positive        9      122
[1] "TEST accuracy: 0.934782608695652"
[1] "TEST +precision: 0.931297709923664"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.4375"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.28081944783529"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

768 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 614, 614, 614, 615, 615 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9636481  0.9895079  0.9295625
  0.010  2  0.9636481  0.9895079  0.9295625
  0.010  3  0.9602485  0.9895079  0.9269310
  0.255  1  0.9624999  0.9921053  0.9269993
  0.255  2  0.9639167  0.9921053  0.9269993
  0.255  3  0.9588519  0.9921053  0.9191729
  0.500  1  0.9679315  0.9921053  0.9373889
  0.500  2  0.9693483  0.9921053  0.9373889
  0.500  3  0.9642322  0.9921053  0.9269651

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     49.6      3.1
  positive      0.4     46.9
                            
 Accuracy (average) : 0.9648

[1] "TEST accuracy: 0.96484375"
[1] "TEST +precision: 0.991735537190083"
[1] "TEST -precision: 0.940740740740741"
[1] "TEST specifity: 0.9921875"
[1] "TEST sensitivity: 0.9375"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        7
            positive       11      115
[1] "TEST accuracy: 0.869565217391304"
[1] "TEST +precision: 0.912698412698413"
[1] "TEST -precision: 0.416666666666667"
[1] "TEST specifity: 0.3125"
[1] "TEST sensitivity: 0.942622950819672"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.14925700028737"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

768 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 614, 615, 614, 615, 614 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9901603  0.9765892  0.9505126
  0.3  1          0.6               0.50       100      0.9939699  0.9921736  0.9687970
  0.3  1          0.6               0.50       150      0.9964181  1.0000000  0.9765892
  0.3  1          0.6               0.75        50      0.9910946  0.9895762  0.9374915
  0.3  1          0.6               0.75       100      0.9955003  0.9895762  0.9661996
  0.3  1          0.6               0.75       150      0.9963174  1.0000000  0.9687970
  0.3  1          0.6               1.00        50      0.9905846  0.9895762  0.9505468
  0.3  1          0.6               1.00       100      0.9958305  0.9895762  0.9609364
  0.3  1          0.6               1.00       150      0.9970577  1.0000000  0.9687628
  0.3  1          0.8               0.50        50      0.9906912  0.9895762  0.9531442
  0.3  1          0.8               0.50       100      0.9962078  0.9921736  0.9661654
  0.3  1          0.8               0.50       150      0.9965801  0.9973684  0.9739576
  0.3  1          0.8               0.75        50      0.9897207  0.9895762  0.9504785
  0.3  1          0.8               0.75       100      0.9953254  0.9921736  0.9635680
  0.3  1          0.8               0.75       150      0.9958389  1.0000000  0.9713944
  0.3  1          0.8               1.00        50      0.9909894  0.9895762  0.9609364
  0.3  1          0.8               1.00       100      0.9949894  0.9895762  0.9661654
  0.3  1          0.8               1.00       150      0.9963431  1.0000000  0.9687286
  0.3  2          0.6               0.50        50      0.9960839  0.9974026  0.9713602
  0.3  2          0.6               0.50       100      0.9983804  1.0000000  0.9739576
  0.3  2          0.6               0.50       150      0.9966929  1.0000000  0.9713260
  0.3  2          0.6               0.75        50      0.9987173  1.0000000  0.9713602
  0.3  2          0.6               0.75       100      0.9997976  1.0000000  0.9843814
  0.3  2          0.6               0.75       150      0.9993253  1.0000000  0.9843814
  0.3  2          0.6               1.00        50      0.9972601  1.0000000  0.9687628
  0.3  2          0.6               1.00       100      0.9981438  1.0000000  0.9791866
  0.3  2          0.6               1.00       150      0.9978744  1.0000000  0.9843814
  0.3  2          0.8               0.50        50      0.9988163  0.9974026  0.9713260
  0.3  2          0.8               0.50       100      0.9990213  1.0000000  0.9791866
  0.3  2          0.8               0.50       150      0.9984146  1.0000000  0.9844156
  0.3  2          0.8               0.75        50      0.9987510  1.0000000  0.9713944
  0.3  2          0.8               0.75       100      0.9987177  1.0000000  0.9791524
  0.3  2          0.8               0.75       150      0.9990857  1.0000000  0.9791524
  0.3  2          0.8               1.00        50      0.9985131  0.9947710  0.9739918
  0.3  2          0.8               1.00       100      0.9988163  1.0000000  0.9713602
  0.3  2          0.8               1.00       150      0.9992206  1.0000000  0.9739576
  0.3  3          0.6               0.50        50      0.9998642  1.0000000  0.9791866
  0.3  3          0.6               0.50       100      0.9999321  1.0000000  0.9817840
  0.3  3          0.6               0.50       150      0.9997972  1.0000000  0.9817840
  0.3  3          0.6               0.75        50      0.9998984  1.0000000  0.9792208
  0.3  3          0.6               0.75       100      0.9998984  1.0000000  0.9818182
  0.3  3          0.6               0.75       150      0.9999321  1.0000000  0.9844156
  0.3  3          0.6               1.00        50      0.9998984  1.0000000  0.9818182
  0.3  3          0.6               1.00       100      1.0000000  1.0000000  0.9844156
  0.3  3          0.6               1.00       150      0.9999658  1.0000000  0.9844156
  0.3  3          0.8               0.50        50      0.9997972  1.0000000  0.9791866
  0.3  3          0.8               0.50       100      0.9999321  1.0000000  0.9817840
  0.3  3          0.8               0.50       150      0.9988460  1.0000000  0.9817840
  0.3  3          0.8               0.75        50      0.9986170  1.0000000  0.9765892
  0.3  3          0.8               0.75       100      0.9993586  1.0000000  0.9739918
  0.3  3          0.8               0.75       150      0.9991225  1.0000000  0.9792208
  0.3  3          0.8               1.00        50      0.9999663  1.0000000  0.9818182
  0.3  3          0.8               1.00       100      0.9999663  1.0000000  0.9870130
  0.3  3          0.8               1.00       150      0.9999658  1.0000000  0.9844156
  0.4  1          0.6               0.50        50      0.9932788  0.9895762  0.9661996
  0.4  1          0.6               0.50       100      0.9959343  0.9973684  0.9765892
  0.4  1          0.6               0.50       150      0.9982069  1.0000000  0.9739918
  0.4  1          0.6               0.75        50      0.9941465  0.9895762  0.9713944
  0.4  1          0.6               0.75       100      0.9974692  1.0000000  0.9791866
  0.4  1          0.6               0.75       150      0.9986835  1.0000000  0.9713602
  0.4  1          0.6               1.00        50      0.9928855  0.9895762  0.9583732
  0.4  1          0.6               1.00       100      0.9959361  0.9973684  0.9687628
  0.4  1          0.6               1.00       150      0.9964789  1.0000000  0.9687628
  0.4  1          0.8               0.50        50      0.9923813  0.9922078  0.9531442
  0.4  1          0.8               0.50       100      0.9935997  0.9974026  0.9687970
  0.4  1          0.8               0.50       150      0.9956423  1.0000000  0.9791866
  0.4  1          0.8               0.75        50      0.9925425  0.9895762  0.9531442
  0.4  1          0.8               0.75       100      0.9964465  1.0000000  0.9661654
  0.4  1          0.8               0.75       150      0.9970591  1.0000000  0.9713602
  0.4  1          0.8               1.00        50      0.9938989  0.9895762  0.9609706
  0.4  1          0.8               1.00       100      0.9962717  0.9973684  0.9609364
  0.4  1          0.8               1.00       150      0.9972970  1.0000000  0.9687628
  0.4  2          0.6               0.50        50      0.9990209  1.0000000  0.9817840
  0.4  2          0.6               0.50       100      0.9998313  1.0000000  0.9817498
  0.4  2          0.6               0.50       150      0.9999321  1.0000000  0.9791183
  0.4  2          0.6               0.75        50      0.9975366  1.0000000  0.9713602
  0.4  2          0.6               0.75       100      0.9975038  1.0000000  0.9739576
  0.4  2          0.6               0.75       150      0.9969951  1.0000000  0.9713602
  0.4  2          0.6               1.00        50      0.9989197  1.0000000  0.9765892
  0.4  2          0.6               1.00       100      0.9990888  1.0000000  0.9817840
  0.4  2          0.6               1.00       150      0.9995579  1.0000000  0.9870130
  0.4  2          0.8               0.50        50      0.9996276  1.0000000  0.9687628
  0.4  2          0.8               0.50       100      0.9988145  1.0000000  0.9765550
  0.4  2          0.8               0.50       150      0.9983733  1.0000000  0.9765550
  0.4  2          0.8               0.75        50      0.9984141  1.0000000  0.9765892
  0.4  2          0.8               0.75       100      0.9991562  1.0000000  0.9818182
  0.4  2          0.8               0.75       150      0.9990506  1.0000000  0.9818182
  0.4  2          0.8               1.00        50      0.9994598  1.0000000  0.9792208
  0.4  2          0.8               1.00       100      0.9999321  1.0000000  0.9870130
  0.4  2          0.8               1.00       150      0.9996929  1.0000000  0.9844156
  0.4  3          0.6               0.50        50      0.9999325  1.0000000  0.9791524
  0.4  3          0.6               0.50       100      0.9995952  1.0000000  0.9817498
  0.4  3          0.6               0.50       150      0.9997972  1.0000000  0.9791524
  0.4  3          0.6               0.75        50      0.9999321  1.0000000  0.9895762
  0.4  3          0.6               0.75       100      1.0000000  1.0000000  0.9817840
  0.4  3          0.6               0.75       150      1.0000000  1.0000000  0.9817840
  0.4  3          0.6               1.00        50      0.9999321  1.0000000  0.9740260
  0.4  3          0.6               1.00       100      0.9996582  1.0000000  0.9766234
  0.4  3          0.6               1.00       150      0.9995557  1.0000000  0.9792208
  0.4  3          0.8               0.50        50      0.9998988  1.0000000  0.9844156
  0.4  3          0.8               0.50       100      0.9997972  1.0000000  0.9844156
  0.4  3          0.8               0.50       150      0.9991225  1.0000000  0.9844156
  0.4  3          0.8               0.75        50      0.9997639  1.0000000  0.9713260
  0.4  3          0.8               0.75       100      0.9999321  1.0000000  0.9739576
  0.4  3          0.8               0.75       150      0.9999658  1.0000000  0.9739576
  0.4  3          0.8               1.00        50      0.9993928  1.0000000  0.9765892
  0.4  3          0.8               1.00       100      0.9998313  1.0000000  0.9818182
  0.4  3          0.8               1.00       150      0.9999663  1.0000000  0.9818182

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.8
  positive      0.0     49.2
                            
 Accuracy (average) : 0.9922

[1] "TEST accuracy: 0.9921875"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.984615384615385"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.984375"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        8        2
            positive        8      120
[1] "TEST accuracy: 0.927536231884058"
[1] "TEST +precision: 0.9375"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 0.983606557377049"
