[1] "DATASET NAME: Estrellas_Uni_IR_5"
[1] "TRAIN INSTANCES: 485"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.32381701469421"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

485 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 389, 388, 387, 388, 388 
Resampling results:

  ROC        Sens  Spec    
  0.9977922  0.97  0.994771

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     20.2      0.4
  positive      0.6     78.8
                            
 Accuracy (average) : 0.9897

[1] "TEST accuracy: 0.989690721649485"
[1] "TEST +precision: 0.992207792207792"
[1] "TEST -precision: 0.98"
[1] "TEST specifity: 0.97029702970297"
[1] "TEST sensitivity: 0.994791666666667"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        8        0
            positive        8      122
[1] "TEST accuracy: 0.942028985507246"
[1] "TEST +precision: 0.938461538461538"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.10839908520381"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

485 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 387, 388, 388, 389, 388 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8310543  0.6628571  0.9505810
  0.010  2  0.8272541  0.6628571  0.9453862
  0.010  3  0.8133460  0.6333333  0.9453520
  0.255  1  0.9070533  0.8309524  0.9505468
  0.255  2  0.9116822  0.8119048  0.9583390
  0.255  3  0.8959052  0.7919048  0.9322967
  0.500  1  0.9240951  0.9000000  0.9479152
  0.500  2  0.9201590  0.8419048  0.9583390
  0.500  3  0.8959052  0.7919048  0.9322967

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.8      4.1
  positive      2.1     75.1
                            
 Accuracy (average) : 0.9381

[1] "TEST accuracy: 0.938144329896907"
[1] "TEST +precision: 0.973262032085562"
[1] "TEST -precision: 0.81981981981982"
[1] "TEST specifity: 0.900990099009901"
[1] "TEST sensitivity: 0.947916666666667"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        3        4
            positive       13      118
[1] "TEST accuracy: 0.876811594202899"
[1] "TEST +precision: 0.900763358778626"
[1] "TEST -precision: 0.428571428571429"
[1] "TEST specifity: 0.1875"
[1] "TEST sensitivity: 0.967213114754098"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.22349135080973"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

485 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 388, 387, 388, 389, 388 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9852135  0.8019048  0.9843472
  0.3  1          0.6               0.50       100      0.9934269  0.9109524  0.9869446
  0.3  1          0.6               0.50       150      0.9919431  0.9209524  0.9869446
  0.3  1          0.6               0.75        50      0.9801431  0.8014286  0.9791524
  0.3  1          0.6               0.75       100      0.9908577  0.9109524  0.9817498
  0.3  1          0.6               0.75       150      0.9930164  0.9409524  0.9817498
  0.3  1          0.6               1.00        50      0.9832973  0.7823810  0.9843472
  0.3  1          0.6               1.00       100      0.9896483  0.9014286  0.9869446
  0.3  1          0.6               1.00       150      0.9904135  0.9409524  0.9869446
  0.3  1          0.8               0.50        50      0.9773247  0.8023810  0.9843814
  0.3  1          0.8               0.50       100      0.9901588  0.9009524  0.9869788
  0.3  1          0.8               0.50       150      0.9898682  0.9209524  0.9869446
  0.3  1          0.8               0.75        50      0.9803866  0.8514286  0.9843472
  0.3  1          0.8               0.75       100      0.9903169  0.9209524  0.9869446
  0.3  1          0.8               0.75       150      0.9908542  0.9409524  0.9843472
  0.3  1          0.8               1.00        50      0.9849056  0.7523810  0.9843472
  0.3  1          0.8               1.00       100      0.9885076  0.9014286  0.9869446
  0.3  1          0.8               1.00       150      0.9905467  0.9409524  0.9843472
  0.3  2          0.6               0.50        50      0.9926020  0.9009524  0.9869105
  0.3  2          0.6               0.50       100      0.9948359  0.9209524  0.9895420
  0.3  2          0.6               0.50       150      0.9936657  0.9409524  0.9869105
  0.3  2          0.6               0.75        50      0.9932634  0.9209524  0.9895420
  0.3  2          0.6               0.75       100      0.9953379  0.9409524  0.9895420
  0.3  2          0.6               0.75       150      0.9948133  0.9409524  0.9843472
  0.3  2          0.6               1.00        50      0.9917228  0.9409524  0.9869446
  0.3  2          0.6               1.00       100      0.9944236  0.9409524  0.9895420
  0.3  2          0.6               1.00       150      0.9946834  0.9409524  0.9869446
  0.3  2          0.8               0.50        50      0.9904162  0.8909524  0.9869446
  0.3  2          0.8               0.50       100      0.9926848  0.9409524  0.9921394
  0.3  2          0.8               0.50       150      0.9921529  0.9409524  0.9869788
  0.3  2          0.8               0.75        50      0.9940618  0.9209524  0.9869446
  0.3  2          0.8               0.75       100      0.9944446  0.9409524  0.9895420
  0.3  2          0.8               0.75       150      0.9938323  0.9409524  0.9895420
  0.3  2          0.8               1.00        50      0.9910782  0.9409524  0.9843472
  0.3  2          0.8               1.00       100      0.9935598  0.9409524  0.9843472
  0.3  2          0.8               1.00       150      0.9939076  0.9409524  0.9869446
  0.3  3          0.6               0.50        50      0.9888104  0.9209524  0.9921394
  0.3  3          0.6               0.50       100      0.9892069  0.9409524  0.9895420
  0.3  3          0.6               0.50       150      0.9903561  0.9409524  0.9869446
  0.3  3          0.6               0.75        50      0.9956113  0.9509524  0.9895420
  0.3  3          0.6               0.75       100      0.9956151  0.9409524  0.9895420
  0.3  3          0.6               0.75       150      0.9941938  0.9409524  0.9895420
  0.3  3          0.6               1.00        50      0.9933864  0.9409524  0.9895420
  0.3  3          0.6               1.00       100      0.9923581  0.9409524  0.9895420
  0.3  3          0.6               1.00       150      0.9917070  0.9409524  0.9869446
  0.3  3          0.8               0.50        50      0.9916865  0.9309524  0.9895420
  0.3  3          0.8               0.50       100      0.9933919  0.9409524  0.9765208
  0.3  3          0.8               0.50       150      0.9925199  0.9409524  0.9817498
  0.3  3          0.8               0.75        50      0.9929882  0.9409524  0.9843472
  0.3  3          0.8               0.75       100      0.9923564  0.9409524  0.9869446
  0.3  3          0.8               0.75       150      0.9919651  0.9409524  0.9869446
  0.3  3          0.8               1.00        50      0.9966588  0.9409524  0.9895420
  0.3  3          0.8               1.00       100      0.9962448  0.9409524  0.9869446
  0.3  3          0.8               1.00       150      0.9954677  0.9409524  0.9843472
  0.4  1          0.6               0.50        50      0.9893948  0.8709524  0.9843472
  0.4  1          0.6               0.50       100      0.9914938  0.9309524  0.9869446
  0.4  1          0.6               0.50       150      0.9922760  0.9409524  0.9869446
  0.4  1          0.6               0.75        50      0.9846109  0.8423810  0.9843472
  0.4  1          0.6               0.75       100      0.9915823  0.9409524  0.9843472
  0.4  1          0.6               0.75       150      0.9929985  0.9409524  0.9869446
  0.4  1          0.6               1.00        50      0.9846527  0.8714286  0.9791524
  0.4  1          0.6               1.00       100      0.9899132  0.9409524  0.9843472
  0.4  1          0.6               1.00       150      0.9910611  0.9409524  0.9843472
  0.4  1          0.8               0.50        50      0.9828353  0.8323810  0.9843472
  0.4  1          0.8               0.50       100      0.9900352  0.9009524  0.9869446
  0.4  1          0.8               0.50       150      0.9919214  0.9409524  0.9869446
  0.4  1          0.8               0.75        50      0.9864898  0.9009524  0.9869446
  0.4  1          0.8               0.75       100      0.9908752  0.9409524  0.9869446
  0.4  1          0.8               0.75       150      0.9944672  0.9409524  0.9895420
  0.4  1          0.8               1.00        50      0.9843624  0.8523810  0.9843472
  0.4  1          0.8               1.00       100      0.9891322  0.9409524  0.9869446
  0.4  1          0.8               1.00       150      0.9905557  0.9409524  0.9843472
  0.4  2          0.6               0.50        50      0.9907794  0.9009524  0.9895420
  0.4  2          0.6               0.50       100      0.9916603  0.9409524  0.9895420
  0.4  2          0.6               0.50       150      0.9905286  0.9409524  0.9869446
  0.4  2          0.6               0.75        50      0.9936342  0.9409524  0.9869446
  0.4  2          0.6               0.75       100      0.9941746  0.9409524  0.9869105
  0.4  2          0.6               0.75       150      0.9920162  0.9409524  0.9869105
  0.4  2          0.6               1.00        50      0.9940737  0.9409524  0.9869446
  0.4  2          0.6               1.00       100      0.9941951  0.9409524  0.9895420
  0.4  2          0.6               1.00       150      0.9934073  0.9409524  0.9869446
  0.4  2          0.8               0.50        50      0.9917636  0.8909524  0.9869446
  0.4  2          0.8               0.50       100      0.9923741  0.9009524  0.9895420
  0.4  2          0.8               0.50       150      0.9930949  0.9409524  0.9921736
  0.4  2          0.8               0.75        50      0.9936692  0.9409524  0.9869446
  0.4  2          0.8               0.75       100      0.9931497  0.9409524  0.9869446
  0.4  2          0.8               0.75       150      0.9924880  0.9409524  0.9843131
  0.4  2          0.8               1.00        50      0.9919860  0.9409524  0.9843472
  0.4  2          0.8               1.00       100      0.9937781  0.9409524  0.9843472
  0.4  2          0.8               1.00       150      0.9928690  0.9409524  0.9817157
  0.4  3          0.6               0.50        50      0.9899620  0.9209524  0.9895420
  0.4  3          0.6               0.50       100      0.9897146  0.9409524  0.9791183
  0.4  3          0.6               0.50       150      0.9898181  0.9409524  0.9843472
  0.4  3          0.6               0.75        50      0.9955027  0.9409524  0.9973684
  0.4  3          0.6               0.75       100      0.9954959  0.9609524  0.9947710
  0.4  3          0.6               0.75       150      0.9951011  0.9409524  0.9947710
  0.4  3          0.6               1.00        50      0.9964080  0.9409524  0.9843472
  0.4  3          0.6               1.00       100      0.9950781  0.9409524  0.9843472
  0.4  3          0.6               1.00       150      0.9944394  0.9409524  0.9843472
  0.4  3          0.8               0.50        50      0.9924720  0.9409524  0.9921736
  0.4  3          0.8               0.50       100      0.9909140  0.9409524  0.9817840
  0.4  3          0.8               0.50       150      0.9893841  0.9409524  0.9843814
  0.4  3          0.8               0.75        50      0.9944424  0.9409524  0.9869446
  0.4  3          0.8               0.75       100      0.9922351  0.9409524  0.9921736
  0.4  3          0.8               0.75       150      0.9919489  0.9409524  0.9921736
  0.4  3          0.8               1.00        50      0.9954797  0.9409524  0.9895420
  0.4  3          0.8               1.00       100      0.9942972  0.9409524  0.9869446
  0.4  3          0.8               1.00       150      0.9931480  0.9409524  0.9869446

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     19.6      0.8
  positive      1.2     78.4
                            
 Accuracy (average) : 0.9794

[1] "TEST accuracy: 0.979381443298969"
[1] "TEST +precision: 0.984455958549223"
[1] "TEST -precision: 0.95959595959596"
[1] "TEST specifity: 0.940594059405941"
[1] "TEST sensitivity: 0.989583333333333"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        1
            positive       10      121
[1] "TEST accuracy: 0.920289855072464"
[1] "TEST +precision: 0.923664122137405"
[1] "TEST -precision: 0.857142857142857"
[1] "TEST specifity: 0.375"
[1] "TEST sensitivity: 0.991803278688525"
