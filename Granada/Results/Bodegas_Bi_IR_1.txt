[1] "DATASET NAME: Bodegas_Bi_IR_1"
[1] "TRAIN INSTANCES: 818"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 4.0458869934082"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

818 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 654, 655, 655, 654, 654 
Resampling results:

  ROC        Sens       Spec     
  0.9975426  0.9755194  0.9853056

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     48.8      0.7
  positive      1.2     49.3
                            
 Accuracy (average) : 0.9804

[1] "TEST accuracy: 0.980440097799511"
[1] "TEST +precision: 0.975786924939467"
[1] "TEST -precision: 0.985185185185185"
[1] "TEST specifity: 0.975550122249389"
[1] "TEST sensitivity: 0.985330073349633"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        2
            positive       12      132
[1] "TEST accuracy: 0.91304347826087"
[1] "TEST +precision: 0.916666666666667"
[1] "TEST -precision: 0.882352941176471"
[1] "TEST specifity: 0.555555555555556"
[1] "TEST sensitivity: 0.985074626865672"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.9560760140419"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

818 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 654, 656, 654, 654, 654 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7346446  1.0000000  0.3937669
  0.010  2  0.7347190  0.9951220  0.3937669
  0.010  3  0.7331426  0.9926829  0.3937669
  0.255  1  0.7391494  0.9951220  0.3912978
  0.255  2  0.7414115  0.9951220  0.3962060
  0.255  3  0.7377827  0.9926829  0.3937669
  0.500  1  0.7551518  0.9951220  0.3961759
  0.500  2  0.7564969  0.9951220  0.4010539
  0.500  3  0.7626972  0.9926829  0.4059922

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     49.6     29.7
  positive      0.4     20.3
                            
 Accuracy (average) : 0.6993

[1] "TEST accuracy: 0.699266503667482"
[1] "TEST +precision: 0.982248520710059"
[1] "TEST -precision: 0.62557781201849"
[1] "TEST specifity: 0.992665036674817"
[1] "TEST sensitivity: 0.405867970660147"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       22       71
            positive        5       63
[1] "TEST accuracy: 0.527950310559006"
[1] "TEST +precision: 0.926470588235294"
[1] "TEST -precision: 0.236559139784946"
[1] "TEST specifity: 0.814814814814815"
[1] "TEST sensitivity: 0.470149253731343"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.01593376795451"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

818 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 654, 654, 655, 654, 655 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8887703  0.8609756  0.6966275
  0.3  1          0.6               0.50       100      0.9442551  0.7971093  0.8992472
  0.3  1          0.6               0.50       150      0.9625710  0.8654622  0.9486299
  0.3  1          0.6               0.75        50      0.8948172  0.7112014  0.8283951
  0.3  1          0.6               0.75       100      0.9495649  0.7897320  0.9560072
  0.3  1          0.6               0.75       150      0.9650372  0.8556760  0.9559470
  0.3  1          0.6               1.00        50      0.8977875  0.6698585  0.9211081
  0.3  1          0.6               1.00       100      0.9552113  0.7946402  0.9780187
  0.3  1          0.6               1.00       150      0.9658215  0.8092743  0.9853357
  0.3  1          0.8               0.50        50      0.8679145  0.6843120  0.8160795
  0.3  1          0.8               0.50       100      0.9357973  0.7750979  0.9388738
  0.3  1          0.8               0.50       150      0.9567633  0.8679012  0.9363746
  0.3  1          0.8               0.75        50      0.8921229  0.7186691  0.8381813
  0.3  1          0.8               0.75       100      0.9492535  0.7897621  0.9632641
  0.3  1          0.8               0.75       150      0.9625557  0.8580849  0.9608552
  0.3  1          0.8               1.00        50      0.8932343  0.5918097  0.9853659
  0.3  1          0.8               1.00       100      0.9542301  0.7897621  0.9780187
  0.3  1          0.8               1.00       150      0.9658149  0.7995182  0.9804276
  0.3  2          0.6               0.50        50      0.9459408  0.7898525  0.9584161
  0.3  2          0.6               0.50       100      0.9735919  0.8923818  0.9412827
  0.3  2          0.6               0.50       150      0.9739059  0.9070160  0.9510991
  0.3  2          0.6               0.75        50      0.9518803  0.8068353  0.9535682
  0.3  2          0.6               0.75       100      0.9706972  0.8801566  0.9510991
  0.3  2          0.6               0.75       150      0.9746078  0.9070160  0.9486299
  0.3  2          0.6               1.00        50      0.9495140  0.7726889  0.9755796
  0.3  2          0.6               1.00       100      0.9730108  0.8483890  0.9755495
  0.3  2          0.6               1.00       150      0.9765098  0.8776874  0.9779886
  0.3  2          0.8               0.50        50      0.9440361  0.8213490  0.8724782
  0.3  2          0.8               0.50       100      0.9674352  0.9143631  0.9046974
  0.3  2          0.8               0.50       150      0.9729427  0.9119241  0.9364047
  0.3  2          0.8               0.75        50      0.9499012  0.7775369  0.9535080
  0.3  2          0.8               0.75       100      0.9706709  0.8752484  0.9535080
  0.3  2          0.8               0.75       150      0.9745044  0.8947907  0.9608853
  0.3  2          0.8               1.00        50      0.9549278  0.7921409  0.9731105
  0.3  2          0.8               1.00       100      0.9729352  0.8361638  0.9755194
  0.3  2          0.8               1.00       150      0.9786453  0.8752183  0.9755194
  0.3  3          0.6               0.50        50      0.9625515  0.8508281  0.9413129
  0.3  3          0.6               0.50       100      0.9726893  0.8947606  0.9461909
  0.3  3          0.6               0.50       150      0.9736215  0.9118639  0.9437218
  0.3  3          0.6               0.75        50      0.9677450  0.8581451  0.9461909
  0.3  3          0.6               0.75       100      0.9781176  0.9045468  0.9608552
  0.3  3          0.6               0.75       150      0.9789147  0.9167721  0.9632942
  0.3  3          0.6               1.00        50      0.9669511  0.8435110  0.9804276
  0.3  3          0.6               1.00       100      0.9781571  0.8752785  0.9731105
  0.3  3          0.6               1.00       150      0.9797383  0.9094851  0.9706414
  0.3  3          0.8               0.50        50      0.9640622  0.8874435  0.9116832
  0.3  3          0.8               0.50       100      0.9712410  0.9119241  0.9388437
  0.3  3          0.8               0.50       150      0.9743207  0.9216501  0.9339958
  0.3  3          0.8               0.75        50      0.9652283  0.8704005  0.9511292
  0.3  3          0.8               0.75       100      0.9776733  0.9045468  0.9559470
  0.3  3          0.8               0.75       150      0.9780984  0.9167721  0.9583860
  0.3  3          0.8               1.00        50      0.9659748  0.8287865  0.9779886
  0.3  3          0.8               1.00       100      0.9774675  0.8728094  0.9730804
  0.3  3          0.8               1.00       150      0.9793884  0.9119241  0.9706414
  0.4  1          0.6               0.50        50      0.9105305  0.7633845  0.8536585
  0.4  1          0.6               0.50       100      0.9538168  0.8336646  0.9487203
  0.4  1          0.6               0.50       150      0.9646072  0.8801566  0.9388437
  0.4  1          0.6               0.75        50      0.9174723  0.6406504  0.9829268
  0.4  1          0.6               0.75       100      0.9603491  0.8336947  0.9682023
  0.4  1          0.6               0.75       150      0.9692025  0.8605239  0.9559771
  0.4  1          0.6               1.00        50      0.9049467  0.6358025  0.9804878
  0.4  1          0.6               1.00       100      0.9591155  0.8264077  0.9755495
  0.4  1          0.6               1.00       150      0.9717149  0.8336947  0.9779886
  0.4  1          0.8               0.50        50      0.9004357  0.7211984  0.8504366
  0.4  1          0.8               0.50       100      0.9423332  0.8068353  0.9364047
  0.4  1          0.8               0.50       150      0.9665139  0.9045769  0.9339356
  0.4  1          0.8               0.75        50      0.9050628  0.6968684  0.8877447
  0.4  1          0.8               0.75       100      0.9567282  0.8434207  0.9535381
  0.4  1          0.8               0.75       150      0.9693310  0.8874737  0.9412827
  0.4  1          0.8               1.00        50      0.9078716  0.6455285  0.9804878
  0.4  1          0.8               1.00       100      0.9599680  0.8264077  0.9755495
  0.4  1          0.8               1.00       150      0.9706401  0.8312556  0.9755194
  0.4  2          0.6               0.50        50      0.9567033  0.8092743  0.9535381
  0.4  2          0.6               0.50       100      0.9736685  0.8972298  0.9437218
  0.4  2          0.6               0.50       150      0.9769132  0.9118639  0.9486600
  0.4  2          0.6               0.75        50      0.9584007  0.8263475  0.9608853
  0.4  2          0.6               0.75       100      0.9766728  0.9021379  0.9633243
  0.4  2          0.6               0.75       150      0.9784448  0.9143330  0.9559771
  0.4  2          0.6               1.00        50      0.9574654  0.8264077  0.9755495
  0.4  2          0.6               1.00       100      0.9743467  0.8752785  0.9755495
  0.4  2          0.6               1.00       150      0.9791809  0.9070160  0.9779886
  0.4  2          0.8               0.50        50      0.9593973  0.8410117  0.9608552
  0.4  2          0.8               0.50       100      0.9699156  0.8972298  0.9412827
  0.4  2          0.8               0.50       150      0.9737203  0.9094249  0.9510991
  0.4  2          0.8               0.75        50      0.9551702  0.8410419  0.9511292
  0.4  2          0.8               0.75       100      0.9763477  0.9118940  0.9584161
  0.4  2          0.8               0.75       150      0.9777715  0.9168022  0.9559771
  0.4  2          0.8               1.00        50      0.9594926  0.8312858  0.9706715
  0.4  2          0.8               1.00       100      0.9756621  0.8752484  0.9755495
  0.4  2          0.8               1.00       150      0.9792679  0.9094550  0.9730804
  0.4  3          0.6               0.50        50      0.9683705  0.8800662  0.9437519
  0.4  3          0.6               0.50       100      0.9762179  0.9118940  0.9413129
  0.4  3          0.6               0.50       150      0.9757045  0.9118639  0.9412827
  0.4  3          0.6               0.75        50      0.9681752  0.8899729  0.9535381
  0.4  3          0.6               0.75       100      0.9773503  0.9143330  0.9559771
  0.4  3          0.6               0.75       150      0.9760269  0.9241192  0.9559470
  0.4  3          0.6               1.00        50      0.9709496  0.8655224  0.9682023
  0.4  3          0.6               1.00       100      0.9807823  0.9094550  0.9731105
  0.4  3          0.6               1.00       150      0.9786336  0.9265583  0.9657332
  0.4  3          0.8               0.50        50      0.9680437  0.8899428  0.9510991
  0.4  3          0.8               0.50       100      0.9737682  0.9094550  0.9461909
  0.4  3          0.8               0.50       150      0.9761229  0.9143330  0.9486299
  0.4  3          0.8               0.75        50      0.9704148  0.8850647  0.9437519
  0.4  3          0.8               0.75       100      0.9782383  0.9167721  0.9609154
  0.4  3          0.8               0.75       150      0.9786398  0.9240891  0.9584161
  0.4  3          0.8               1.00        50      0.9718023  0.8678711  0.9731105
  0.4  3          0.8               1.00       100      0.9791041  0.9167721  0.9682023
  0.4  3          0.8               1.00       150      0.9781259  0.9289973  0.9608552

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     45.5      1.3
  positive      4.5     48.7
                            
 Accuracy (average) : 0.9413

[1] "TEST accuracy: 0.941320293398533"
[1] "TEST +precision: 0.914942528735632"
[1] "TEST -precision: 0.971279373368146"
[1] "TEST specifity: 0.909535452322738"
[1] "TEST sensitivity: 0.973105134474328"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       13        6
            positive       14      128
[1] "TEST accuracy: 0.875776397515528"
[1] "TEST +precision: 0.901408450704225"
[1] "TEST -precision: 0.684210526315789"
[1] "TEST specifity: 0.481481481481481"
[1] "TEST sensitivity: 0.955223880597015"
