[1] "DATASET NAME: Carmela_Uni_IR_1"
[1] "TRAIN INSTANCES: 554"
[1] "TEST INSTANCES: 103"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.19393610954285"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

554 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 444, 444, 444, 442, 442 
Resampling results:

  ROC  Sens  Spec     
  1    1     0.9856494

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.7
  positive      0.0     49.3
                            
 Accuracy (average) : 0.9928

[1] "TEST accuracy: 0.992779783393502"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.98576512455516"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.985559566787004"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        2
            positive        6       93
[1] "TEST accuracy: 0.922330097087379"
[1] "TEST +precision: 0.939393939393939"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.25"
[1] "TEST sensitivity: 0.978947368421053"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.08576409816742"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

554 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 443, 443, 443, 443, 444 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9516128  0.9781818  0.9172727
  0.010  2  0.9549244  0.9781818  0.9172727
  0.010  3  0.9552763  0.9781818  0.9136364
  0.255  1  0.9575543  1.0000000  0.9101299
  0.255  2  0.9669699  1.0000000  0.9101299
  0.255  3  0.9634262  0.9927273  0.9137662
  0.500  1  0.9585986  1.0000000  0.9209091
  0.500  2  0.9693182  1.0000000  0.9245455
  0.500  3  0.9666883  0.9927273  0.9318182

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      3.8
  positive      0.0     46.2
                            
 Accuracy (average) : 0.9621

[1] "TEST accuracy: 0.962093862815884"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.929530201342282"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.924187725631769"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        3        7
            positive        5       88
[1] "TEST accuracy: 0.883495145631068"
[1] "TEST +precision: 0.946236559139785"
[1] "TEST -precision: 0.3"
[1] "TEST specifity: 0.375"
[1] "TEST sensitivity: 0.926315789473684"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.37107918262482"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

554 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 442, 444, 443, 444, 443 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9868542  0.9566883  0.9496753
  0.3  1          0.6               0.50       100      0.9970195  1.0000000  0.9568182
  0.3  1          0.6               0.50       150      0.9994120  1.0000000  0.9603896
  0.3  1          0.6               0.75        50      0.9883454  0.9459091  0.9459740
  0.3  1          0.6               0.75       100      0.9950285  1.0000000  0.9604545
  0.3  1          0.6               0.75       150      0.9968539  1.0000000  0.9675974
  0.3  1          0.6               1.00        50      0.9824003  0.9458442  0.9461039
  0.3  1          0.6               1.00       100      0.9942702  0.9892857  0.9568182
  0.3  1          0.6               1.00       150      0.9949834  1.0000000  0.9675974
  0.3  1          0.8               0.50        50      0.9870596  0.9494156  0.9387662
  0.3  1          0.8               0.50       100      0.9976239  1.0000000  0.9640260
  0.3  1          0.8               0.50       150      0.9981341  1.0000000  0.9675974
  0.3  1          0.8               0.75        50      0.9878972  0.9422078  0.9460390
  0.3  1          0.8               0.75       100      0.9955767  1.0000000  0.9604545
  0.3  1          0.8               0.75       150      0.9980727  1.0000000  0.9640260
  0.3  1          0.8               1.00        50      0.9847052  0.9458442  0.9459740
  0.3  1          0.8               1.00       100      0.9943977  1.0000000  0.9568182
  0.3  1          0.8               1.00       150      0.9958950  1.0000000  0.9675325
  0.3  2          0.6               0.50        50      0.9996173  1.0000000  0.9676623
  0.3  2          0.6               0.50       100      1.0000000  1.0000000  0.9820130
  0.3  2          0.6               0.50       150      1.0000000  1.0000000  0.9820130
  0.3  2          0.6               0.75        50      0.9982430  1.0000000  0.9531818
  0.3  2          0.6               0.75       100      0.9996764  1.0000000  0.9640260
  0.3  2          0.6               0.75       150      0.9998724  1.0000000  0.9675974
  0.3  2          0.6               1.00        50      0.9985215  1.0000000  0.9675325
  0.3  2          0.6               1.00       100      0.9990434  1.0000000  0.9712338
  0.3  2          0.6               1.00       150      1.0000000  1.0000000  0.9676623
  0.3  2          0.8               0.50        50      0.9980833  1.0000000  0.9639610
  0.3  2          0.8               0.50       100      1.0000000  1.0000000  0.9711688
  0.3  2          0.8               0.50       150      1.0000000  1.0000000  0.9711688
  0.3  2          0.8               0.75        50      0.9969189  1.0000000  0.9640260
  0.3  2          0.8               0.75       100      0.9998087  1.0000000  0.9604545
  0.3  2          0.8               0.75       150      0.9998724  1.0000000  0.9712338
  0.3  2          0.8               1.00        50      0.9968563  1.0000000  0.9640260
  0.3  2          0.8               1.00       100      0.9977679  1.0000000  0.9711688
  0.3  2          0.8               1.00       150      0.9992985  1.0000000  0.9675974
  0.3  3          0.6               0.50        50      0.9984460  1.0000000  0.9783117
  0.3  3          0.6               0.50       100      0.9992985  1.0000000  0.9748052
  0.3  3          0.6               0.50       150      0.9998724  1.0000000  0.9675974
  0.3  3          0.6               0.75        50      0.9987789  1.0000000  0.9747403
  0.3  3          0.6               0.75       100      0.9997402  1.0000000  0.9784416
  0.3  3          0.6               0.75       150      1.0000000  1.0000000  0.9784416
  0.3  3          0.6               1.00        50      0.9994898  1.0000000  0.9748052
  0.3  3          0.6               1.00       100      1.0000000  1.0000000  0.9748701
  0.3  3          0.6               1.00       150      1.0000000  1.0000000  0.9785065
  0.3  3          0.8               0.50        50      0.9989796  1.0000000  0.9747403
  0.3  3          0.8               0.50       100      0.9993622  1.0000000  0.9748052
  0.3  3          0.8               0.50       150      0.9998724  1.0000000  0.9711688
  0.3  3          0.8               0.75        50      0.9994260  1.0000000  0.9639610
  0.3  3          0.8               0.75       100      0.9993622  1.0000000  0.9748701
  0.3  3          0.8               0.75       150      0.9995536  1.0000000  0.9711688
  0.3  3          0.8               1.00        50      0.9998087  1.0000000  0.9711688
  0.3  3          0.8               1.00       100      1.0000000  1.0000000  0.9748701
  0.3  3          0.8               1.00       150      1.0000000  1.0000000  0.9748701
  0.4  1          0.6               0.50        50      0.9898876  0.9712338  0.9568831
  0.4  1          0.6               0.50       100      0.9981921  1.0000000  0.9604545
  0.4  1          0.6               0.50       150      0.9995442  1.0000000  0.9639610
  0.4  1          0.6               0.75        50      0.9931960  0.9711039  0.9567532
  0.4  1          0.6               0.75       100      0.9950993  1.0000000  0.9603896
  0.4  1          0.6               0.75       150      0.9975011  1.0000000  0.9675974
  0.4  1          0.6               1.00        50      0.9899618  0.9422078  0.9532468
  0.4  1          0.6               1.00       100      0.9951075  1.0000000  0.9640260
  0.4  1          0.6               1.00       150      0.9965397  1.0000000  0.9675974
  0.4  1          0.8               0.50        50      0.9882388  0.9566883  0.9532468
  0.4  1          0.8               0.50       100      0.9967714  1.0000000  0.9640260
  0.4  1          0.8               0.50       150      1.0000000  1.0000000  0.9639610
  0.4  1          0.8               0.75        50      0.9910609  0.9565584  0.9568182
  0.4  1          0.8               0.75       100      0.9958312  1.0000000  0.9639610
  0.4  1          0.8               0.75       150      0.9993552  1.0000000  0.9675974
  0.4  1          0.8               1.00        50      0.9904352  0.9603896  0.9532468
  0.4  1          0.8               1.00       100      0.9949834  1.0000000  0.9639610
  0.4  1          0.8               1.00       150      0.9963437  1.0000000  0.9711688
  0.4  2          0.6               0.50        50      0.9987883  1.0000000  0.9712987
  0.4  2          0.6               0.50       100      0.9977041  1.0000000  0.9748701
  0.4  2          0.6               0.50       150      0.9980867  1.0000000  0.9748701
  0.4  2          0.6               0.75        50      0.9977644  1.0000000  0.9675974
  0.4  2          0.6               0.75       100      0.9993622  1.0000000  0.9748701
  0.4  2          0.6               0.75       150      0.9996811  1.0000000  0.9675974
  0.4  2          0.6               1.00        50      0.9989749  1.0000000  0.9711039
  0.4  2          0.6               1.00       100      1.0000000  1.0000000  0.9820130
  0.4  2          0.6               1.00       150      1.0000000  1.0000000  0.9784416
  0.4  2          0.8               0.50        50      0.9996800  1.0000000  0.9675974
  0.4  2          0.8               0.50       100      0.9998724  1.0000000  0.9711039
  0.4  2          0.8               0.50       150      0.9996811  1.0000000  0.9711039
  0.4  2          0.8               0.75        50      0.9977679  1.0000000  0.9603896
  0.4  2          0.8               0.75       100      1.0000000  1.0000000  0.9784416
  0.4  2          0.8               0.75       150      0.9998724  1.0000000  0.9676623
  0.4  2          0.8               1.00        50      0.9974256  1.0000000  0.9747403
  0.4  2          0.8               1.00       100      0.9998678  1.0000000  0.9675974
  0.4  2          0.8               1.00       150      1.0000000  1.0000000  0.9675974
  0.4  3          0.6               0.50        50      1.0000000  1.0000000  0.9748701
  0.4  3          0.6               0.50       100      1.0000000  1.0000000  0.9712338
  0.4  3          0.6               0.50       150      1.0000000  1.0000000  0.9748701
  0.4  3          0.6               0.75        50      1.0000000  1.0000000  0.9748701
  0.4  3          0.6               0.75       100      0.9998724  1.0000000  0.9820779
  0.4  3          0.6               0.75       150      0.9998724  1.0000000  0.9820779
  0.4  3          0.6               1.00        50      0.9998678  1.0000000  0.9784416
  0.4  3          0.6               1.00       100      1.0000000  1.0000000  0.9748701
  0.4  3          0.6               1.00       150      1.0000000  1.0000000  0.9712338
  0.4  3          0.8               0.50        50      0.9993622  1.0000000  0.9712338
  0.4  3          0.8               0.50       100      0.9990434  1.0000000  0.9711688
  0.4  3          0.8               0.50       150      0.9995536  1.0000000  0.9675974
  0.4  3          0.8               0.75        50      0.9984056  1.0000000  0.9820779
  0.4  3          0.8               0.75       100      0.9984694  1.0000000  0.9820779
  0.4  3          0.8               0.75       150      0.9987883  1.0000000  0.9748701
  0.4  3          0.8               1.00        50      0.9998087  1.0000000  0.9712338
  0.4  3          0.8               1.00       100      1.0000000  1.0000000  0.9712987
  0.4  3          0.8               1.00       150      1.0000000  1.0000000  0.9712987

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.5.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      1.3
  positive      0.0     48.7
                            
 Accuracy (average) : 0.9874

[1] "TEST accuracy: 0.987364620938628"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.975352112676056"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.974729241877256"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        4
            positive        4       91
[1] "TEST accuracy: 0.922330097087379"
[1] "TEST +precision: 0.957894736842105"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 0.957894736842105"
