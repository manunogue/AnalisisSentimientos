[1] "DATASET NAME: Bodegas_Bi_IR_10"
[1] "TRAIN INSTANCES: 515"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.3713321685791"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

515 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 412, 412, 412, 412, 412 
Resampling results:

  ROC        Sens       Spec     
  0.9563361  0.6510823  0.9779886

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     13.4      1.7
  positive      7.2     77.7
                            
 Accuracy (average) : 0.9107

[1] "TEST accuracy: 0.910679611650485"
[1] "TEST +precision: 0.91533180778032"
[1] "TEST -precision: 0.884615384615385"
[1] "TEST specifity: 0.650943396226415"
[1] "TEST sensitivity: 0.97799511002445"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       17        4
            positive       10      130
[1] "TEST accuracy: 0.91304347826087"
[1] "TEST +precision: 0.928571428571429"
[1] "TEST -precision: 0.80952380952381"
[1] "TEST specifity: 0.62962962962963"
[1] "TEST sensitivity: 0.970149253731343"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.37179691791534"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

515 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 412, 412, 412, 412, 412 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec    
  0.010  1  0.5000000  0.00000000  1.000000
  0.010  2  0.5000000  0.00000000  1.000000
  0.010  3  0.5000000  0.00000000  1.000000
  0.255  1  0.5616322  0.03809524  1.000000
  0.255  2  0.5630259  0.02857143  1.000000
  0.255  3  0.5446752  0.01904762  1.000000
  0.500  1  0.6494077  0.05714286  0.997561
  0.500  2  0.6162162  0.03809524  1.000000
  0.500  3  0.5852685  0.01904762  0.997561

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.2      0.2
  positive     19.4     79.2
                            
 Accuracy (average) : 0.8039

[1] "TEST accuracy: 0.803883495145631"
[1] "TEST +precision: 0.803149606299213"
[1] "TEST -precision: 0.857142857142857"
[1] "TEST specifity: 0.0566037735849057"
[1] "TEST sensitivity: 0.997555012224939"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        3
            positive       26      131
[1] "TEST accuracy: 0.819875776397516"
[1] "TEST +precision: 0.834394904458599"
[1] "TEST -precision: 0.25"
[1] "TEST specifity: 0.037037037037037"
[1] "TEST sensitivity: 0.977611940298508"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.52946731646856"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

515 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 411, 412, 413, 412, 412 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7253167  0.07575758  0.9951220
  0.3  1          0.6               0.50       100      0.7697328  0.13160173  0.9951220
  0.3  1          0.6               0.50       150      0.7835156  0.13203463  0.9829268
  0.3  1          0.6               0.75        50      0.7524185  0.13246753  0.9951220
  0.3  1          0.6               0.75       100      0.7985416  0.13246753  0.9926829
  0.3  1          0.6               0.75       150      0.7902730  0.18961039  0.9828967
  0.3  1          0.6               1.00        50      0.7420685  0.13246753  0.9975610
  0.3  1          0.6               1.00       100      0.7956940  0.17012987  0.9951220
  0.3  1          0.6               1.00       150      0.8130496  0.17012987  0.9951220
  0.3  1          0.8               0.50        50      0.7159073  0.10389610  0.9950918
  0.3  1          0.8               0.50       100      0.7638486  0.14199134  0.9926528
  0.3  1          0.8               0.50       150      0.7701082  0.18008658  0.9828666
  0.3  1          0.8               0.75        50      0.7618074  0.14199134  0.9975610
  0.3  1          0.8               0.75       100      0.7979311  0.17965368  0.9926829
  0.3  1          0.8               0.75       150      0.7981124  0.21774892  0.9878049
  0.3  1          0.8               1.00        50      0.7401824  0.13246753  0.9975610
  0.3  1          0.8               1.00       100      0.7957499  0.16060606  0.9951220
  0.3  1          0.8               1.00       150      0.8139986  0.17965368  0.9951220
  0.3  2          0.6               0.50        50      0.7701631  0.12294372  0.9902439
  0.3  2          0.6               0.50       100      0.7860663  0.18917749  0.9853659
  0.3  2          0.6               0.50       150      0.7956127  0.19783550  0.9853357
  0.3  2          0.6               0.75        50      0.7940249  0.16103896  0.9902138
  0.3  2          0.6               0.75       100      0.8087121  0.26406926  0.9731105
  0.3  2          0.6               0.75       150      0.8033016  0.25454545  0.9657633
  0.3  2          0.6               1.00        50      0.8054775  0.16060606  0.9951220
  0.3  2          0.6               1.00       100      0.8209077  0.22683983  0.9804577
  0.3  2          0.6               1.00       150      0.8177665  0.23636364  0.9706414
  0.3  2          0.8               0.50        50      0.7809250  0.12294372  0.9853357
  0.3  2          0.8               0.50       100      0.7874308  0.20822511  0.9804577
  0.3  2          0.8               0.50       150      0.7897532  0.17922078  0.9779584
  0.3  2          0.8               0.75        50      0.7970523  0.17012987  0.9926829
  0.3  2          0.8               0.75       100      0.8098375  0.23593074  0.9779886
  0.3  2          0.8               0.75       150      0.8073720  0.23593074  0.9682023
  0.3  2          0.8               1.00        50      0.8049335  0.16103896  0.9951220
  0.3  2          0.8               1.00       100      0.8157211  0.23636364  0.9780187
  0.3  2          0.8               1.00       150      0.8102763  0.25541126  0.9731105
  0.3  3          0.6               0.50        50      0.7903383  0.17012987  0.9902439
  0.3  3          0.6               0.50       100      0.7966966  0.20779221  0.9853357
  0.3  3          0.6               0.50       150      0.8064771  0.23636364  0.9731406
  0.3  3          0.6               0.75        50      0.8024047  0.22597403  0.9878049
  0.3  3          0.6               0.75       100      0.8050250  0.22640693  0.9731105
  0.3  3          0.6               0.75       150      0.8051044  0.25497835  0.9682325
  0.3  3          0.6               1.00        50      0.8135719  0.19783550  0.9926829
  0.3  3          0.6               1.00       100      0.8127315  0.24545455  0.9706715
  0.3  3          0.6               1.00       150      0.8097648  0.25541126  0.9657332
  0.3  3          0.8               0.50        50      0.7753526  0.17012987  0.9878049
  0.3  3          0.8               0.50       100      0.7843180  0.24588745  0.9780187
  0.3  3          0.8               0.50       150      0.7899348  0.22640693  0.9682023
  0.3  3          0.8               0.75        50      0.8243176  0.21731602  0.9804276
  0.3  3          0.8               0.75       100      0.8184674  0.25541126  0.9681421
  0.3  3          0.8               0.75       150      0.8239684  0.26493506  0.9657031
  0.3  3          0.8               1.00        50      0.8135382  0.20735931  0.9951220
  0.3  3          0.8               1.00       100      0.8165948  0.24545455  0.9682325
  0.3  3          0.8               1.00       150      0.8157449  0.25497835  0.9559169
  0.4  1          0.6               0.50        50      0.7369952  0.12294372  0.9926829
  0.4  1          0.6               0.50       100      0.7889027  0.15151515  0.9853659
  0.4  1          0.6               0.50       150      0.7911696  0.20865801  0.9829268
  0.4  1          0.6               0.75        50      0.7692751  0.13246753  0.9902138
  0.4  1          0.6               0.75       100      0.7977979  0.19870130  0.9902439
  0.4  1          0.6               0.75       150      0.7979632  0.25541126  0.9804878
  0.4  1          0.6               1.00        50      0.7608528  0.14199134  0.9975610
  0.4  1          0.6               1.00       100      0.8084962  0.17056277  0.9951220
  0.4  1          0.6               1.00       150      0.8185338  0.20822511  0.9853659
  0.4  1          0.8               0.50        50      0.7208679  0.12337662  0.9951220
  0.4  1          0.8               0.50       100      0.7667449  0.17965368  0.9853659
  0.4  1          0.8               0.50       150      0.7808076  0.19826840  0.9829268
  0.4  1          0.8               0.75        50      0.7667382  0.14155844  0.9902439
  0.4  1          0.8               0.75       100      0.7988166  0.18961039  0.9902439
  0.4  1          0.8               0.75       150      0.7963491  0.24588745  0.9755194
  0.4  1          0.8               1.00        50      0.7538923  0.14199134  0.9975610
  0.4  1          0.8               1.00       100      0.7968290  0.18008658  0.9951220
  0.4  1          0.8               1.00       150      0.8083518  0.21774892  0.9853659
  0.4  2          0.6               0.50        50      0.7762112  0.13246753  0.9779886
  0.4  2          0.6               0.50       100      0.7972957  0.19783550  0.9780187
  0.4  2          0.6               0.50       150      0.8035003  0.21688312  0.9731406
  0.4  2          0.6               0.75        50      0.8144314  0.21645022  0.9902439
  0.4  2          0.6               0.75       100      0.8083216  0.27316017  0.9828666
  0.4  2          0.6               0.75       150      0.8078273  0.27316017  0.9755495
  0.4  2          0.6               1.00        50      0.8037957  0.18008658  0.9951220
  0.4  2          0.6               1.00       100      0.8148259  0.23636364  0.9780488
  0.4  2          0.6               1.00       150      0.8034706  0.21731602  0.9633243
  0.4  2          0.8               0.50        50      0.7867716  0.18831169  0.9804577
  0.4  2          0.8               0.50       100      0.7940832  0.22727273  0.9828967
  0.4  2          0.8               0.50       150      0.7937835  0.20735931  0.9755194
  0.4  2          0.8               0.75        50      0.7883581  0.17965368  0.9878049
  0.4  2          0.8               0.75       100      0.7896880  0.21774892  0.9681722
  0.4  2          0.8               0.75       150      0.7959462  0.21774892  0.9608251
  0.4  2          0.8               1.00        50      0.8025301  0.16060606  0.9951220
  0.4  2          0.8               1.00       100      0.8086090  0.25497835  0.9755796
  0.4  2          0.8               1.00       150      0.8075967  0.23636364  0.9584161
  0.4  3          0.6               0.50        50      0.7814712  0.16017316  0.9853357
  0.4  3          0.6               0.50       100      0.7866068  0.17878788  0.9804878
  0.4  3          0.6               0.50       150      0.7934926  0.20779221  0.9657332
  0.4  3          0.6               0.75        50      0.7982309  0.24458874  0.9853357
  0.4  3          0.6               0.75       100      0.8018788  0.23549784  0.9584161
  0.4  3          0.6               0.75       150      0.7982414  0.24502165  0.9559771
  0.4  3          0.6               1.00        50      0.8179913  0.23506494  0.9779886
  0.4  3          0.6               1.00       100      0.8177315  0.27316017  0.9657934
  0.4  3          0.6               1.00       150      0.8146449  0.27359307  0.9584161
  0.4  3          0.8               0.50        50      0.8071970  0.14199134  0.9902439
  0.4  3          0.8               0.50       100      0.7909651  0.23593074  0.9828666
  0.4  3          0.8               0.50       150      0.8070068  0.25497835  0.9779886
  0.4  3          0.8               0.75        50      0.8122517  0.24588745  0.9853357
  0.4  3          0.8               0.75       100      0.8230754  0.26493506  0.9706414
  0.4  3          0.8               0.75       150      0.8230679  0.30216450  0.9682023
  0.4  3          0.8               1.00        50      0.8179756  0.25454545  0.9829268
  0.4  3          0.8               1.00       100      0.8048021  0.27316017  0.9657332
  0.4  3          0.8               1.00       150      0.8092056  0.27316017  0.9608251

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      4.5      1.6
  positive     16.1     77.9
                            
 Accuracy (average) : 0.8233

[1] "TEST accuracy: 0.823300970873786"
[1] "TEST +precision: 0.828512396694215"
[1] "TEST -precision: 0.741935483870968"
[1] "TEST specifity: 0.216981132075472"
[1] "TEST sensitivity: 0.980440097799511"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        7        0
            positive       20      134
[1] "TEST accuracy: 0.875776397515528"
[1] "TEST +precision: 0.87012987012987"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.259259259259259"
[1] "TEST sensitivity: 1"
