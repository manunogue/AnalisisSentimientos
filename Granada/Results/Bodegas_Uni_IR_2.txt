[1] "DATASET NAME: Bodegas_Uni_IR_2"
[1] "TRAIN INSTANCES: 645"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.40187311172485"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

645 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 516, 516, 516, 516, 516 
Resampling results:

  ROC        Sens       Spec     
  0.9955247  0.9791667  0.9876543

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     36.4      0.8
  positive      0.8     62.0
                            
 Accuracy (average) : 0.9845

[1] "TEST accuracy: 0.984496124031008"
[1] "TEST +precision: 0.987654320987654"
[1] "TEST -precision: 0.979166666666667"
[1] "TEST specifity: 0.979166666666667"
[1] "TEST sensitivity: 0.987654320987654"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        2
            positive        8      136
[1] "TEST accuracy: 0.937888198757764"
[1] "TEST +precision: 0.944444444444444"
[1] "TEST -precision: 0.882352941176471"
[1] "TEST specifity: 0.652173913043478"
[1] "TEST sensitivity: 0.985507246376812"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.11805055141449"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

645 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 516, 516, 516, 516, 516 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8911523  0.8500000  0.9185185
  0.010  2  0.8939815  0.8500000  0.9160494
  0.010  3  0.9108282  0.8500000  0.9209877
  0.255  1  0.9323045  0.9291667  0.9185185
  0.255  2  0.9352881  0.9291667  0.9209877
  0.255  3  0.9514918  0.9166667  0.9308642
  0.500  1  0.9400463  0.9416667  0.9234568
  0.500  2  0.9384259  0.9291667  0.9234568
  0.500  3  0.9554270  0.9208333  0.9333333

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.3      4.2
  positive      2.9     58.6
                            
 Accuracy (average) : 0.9287

[1] "TEST accuracy: 0.928682170542636"
[1] "TEST +precision: 0.952141057934509"
[1] "TEST -precision: 0.891129032258065"
[1] "TEST specifity: 0.920833333333333"
[1] "TEST sensitivity: 0.933333333333333"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       10        8
            positive       13      130
[1] "TEST accuracy: 0.869565217391304"
[1] "TEST +precision: 0.909090909090909"
[1] "TEST -precision: 0.555555555555556"
[1] "TEST specifity: 0.434782608695652"
[1] "TEST sensitivity: 0.942028985507246"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.49320426781972"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

645 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 516, 516, 516, 516, 516 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9784208  0.8458333  0.9851852
  0.3  1          0.6               0.50       100      0.9867798  0.9375000  0.9827160
  0.3  1          0.6               0.50       150      0.9861626  0.9541667  0.9753086
  0.3  1          0.6               0.75        50      0.9804012  0.8458333  0.9777778
  0.3  1          0.6               0.75       100      0.9880658  0.9333333  0.9753086
  0.3  1          0.6               0.75       150      0.9890432  0.9291667  0.9777778
  0.3  1          0.6               1.00        50      0.9768261  0.8208333  0.9851852
  0.3  1          0.6               1.00       100      0.9869856  0.9083333  0.9827160
  0.3  1          0.6               1.00       150      0.9871142  0.9125000  0.9777778
  0.3  1          0.8               0.50        50      0.9760545  0.8250000  0.9679012
  0.3  1          0.8               0.50       100      0.9871399  0.9208333  0.9876543
  0.3  1          0.8               0.50       150      0.9866770  0.9458333  0.9777778
  0.3  1          0.8               0.75        50      0.9789352  0.8291667  0.9802469
  0.3  1          0.8               0.75       100      0.9852623  0.8958333  0.9777778
  0.3  1          0.8               0.75       150      0.9871914  0.9291667  0.9802469
  0.3  1          0.8               1.00        50      0.9771348  0.8250000  0.9876543
  0.3  1          0.8               1.00       100      0.9858796  0.8958333  0.9802469
  0.3  1          0.8               1.00       150      0.9880658  0.9166667  0.9728395
  0.3  2          0.6               0.50        50      0.9854938  0.9333333  0.9629630
  0.3  2          0.6               0.50       100      0.9875514  0.9500000  0.9703704
  0.3  2          0.6               0.50       150      0.9896605  0.9500000  0.9703704
  0.3  2          0.6               0.75        50      0.9869342  0.9375000  0.9728395
  0.3  2          0.6               0.75       100      0.9902778  0.9541667  0.9753086
  0.3  2          0.6               0.75       150      0.9922325  0.9583333  0.9753086
  0.3  2          0.6               1.00        50      0.9854424  0.9166667  0.9728395
  0.3  2          0.6               1.00       100      0.9894033  0.9416667  0.9802469
  0.3  2          0.6               1.00       150      0.9903807  0.9583333  0.9851852
  0.3  2          0.8               0.50        50      0.9877572  0.9458333  0.9777778
  0.3  2          0.8               0.50       100      0.9902778  0.9583333  0.9728395
  0.3  2          0.8               0.50       150      0.9909465  0.9541667  0.9753086
  0.3  2          0.8               0.75        50      0.9839506  0.9208333  0.9876543
  0.3  2          0.8               0.75       100      0.9870370  0.9500000  0.9827160
  0.3  2          0.8               0.75       150      0.9880144  0.9583333  0.9753086
  0.3  2          0.8               1.00        50      0.9839506  0.9125000  0.9777778
  0.3  2          0.8               1.00       100      0.9890432  0.9500000  0.9802469
  0.3  2          0.8               1.00       150      0.9900206  0.9583333  0.9851852
  0.3  3          0.6               0.50        50      0.9842593  0.9416667  0.9753086
  0.3  3          0.6               0.50       100      0.9873971  0.9500000  0.9728395
  0.3  3          0.6               0.50       150      0.9890432  0.9708333  0.9753086
  0.3  3          0.6               0.75        50      0.9859568  0.9458333  0.9851852
  0.3  3          0.6               0.75       100      0.9902263  0.9708333  0.9728395
  0.3  3          0.6               0.75       150      0.9922325  0.9750000  0.9753086
  0.3  3          0.6               1.00        50      0.9890947  0.9458333  0.9827160
  0.3  3          0.6               1.00       100      0.9915123  0.9750000  0.9827160
  0.3  3          0.6               1.00       150      0.9916667  0.9750000  0.9802469
  0.3  3          0.8               0.50        50      0.9895062  0.9458333  0.9827160
  0.3  3          0.8               0.50       100      0.9900720  0.9583333  0.9802469
  0.3  3          0.8               0.50       150      0.9912037  0.9708333  0.9728395
  0.3  3          0.8               0.75        50      0.9901235  0.9375000  0.9827160
  0.3  3          0.8               0.75       100      0.9927469  0.9750000  0.9777778
  0.3  3          0.8               0.75       150      0.9924383  0.9750000  0.9777778
  0.3  3          0.8               1.00        50      0.9878086  0.9250000  0.9802469
  0.3  3          0.8               1.00       100      0.9924897  0.9750000  0.9777778
  0.3  3          0.8               1.00       150      0.9935185  0.9750000  0.9777778
  0.4  1          0.6               0.50        50      0.9848765  0.8791667  0.9802469
  0.4  1          0.6               0.50       100      0.9880144  0.9416667  0.9753086
  0.4  1          0.6               0.50       150      0.9885802  0.9458333  0.9802469
  0.4  1          0.6               0.75        50      0.9833076  0.8875000  0.9777778
  0.4  1          0.6               0.75       100      0.9884774  0.9375000  0.9703704
  0.4  1          0.6               0.75       150      0.9902263  0.9458333  0.9777778
  0.4  1          0.6               1.00        50      0.9825617  0.8458333  0.9802469
  0.4  1          0.6               1.00       100      0.9895833  0.9083333  0.9802469
  0.4  1          0.6               1.00       150      0.9888889  0.9291667  0.9802469
  0.4  1          0.8               0.50        50      0.9787037  0.8666667  0.9703704
  0.4  1          0.8               0.50       100      0.9870885  0.9416667  0.9728395
  0.4  1          0.8               0.50       150      0.9889918  0.9458333  0.9802469
  0.4  1          0.8               0.75        50      0.9842593  0.8708333  0.9827160
  0.4  1          0.8               0.75       100      0.9867798  0.9291667  0.9802469
  0.4  1          0.8               0.75       150      0.9898148  0.9458333  0.9777778
  0.4  1          0.8               1.00        50      0.9831533  0.8458333  0.9827160
  0.4  1          0.8               1.00       100      0.9869342  0.9166667  0.9802469
  0.4  1          0.8               1.00       150      0.9879115  0.9291667  0.9802469
  0.4  2          0.6               0.50        50      0.9884259  0.9500000  0.9703704
  0.4  2          0.6               0.50       100      0.9897634  0.9541667  0.9703704
  0.4  2          0.6               0.50       150      0.9908436  0.9541667  0.9728395
  0.4  2          0.6               0.75        50      0.9878601  0.9250000  0.9777778
  0.4  2          0.6               0.75       100      0.9906893  0.9541667  0.9802469
  0.4  2          0.6               0.75       150      0.9912037  0.9750000  0.9777778
  0.4  2          0.6               1.00        50      0.9889918  0.9416667  0.9802469
  0.4  2          0.6               1.00       100      0.9922840  0.9500000  0.9851852
  0.4  2          0.6               1.00       150      0.9916667  0.9750000  0.9802469
  0.4  2          0.8               0.50        50      0.9879115  0.9375000  0.9753086
  0.4  2          0.8               0.50       100      0.9933128  0.9583333  0.9802469
  0.4  2          0.8               0.50       150      0.9909465  0.9750000  0.9654321
  0.4  2          0.8               0.75        50      0.9884259  0.9250000  0.9753086
  0.4  2          0.8               0.75       100      0.9915123  0.9500000  0.9777778
  0.4  2          0.8               0.75       150      0.9911523  0.9750000  0.9753086
  0.4  2          0.8               1.00        50      0.9872428  0.9125000  0.9802469
  0.4  2          0.8               1.00       100      0.9926955  0.9583333  0.9802469
  0.4  2          0.8               1.00       150      0.9908951  0.9750000  0.9753086
  0.4  3          0.6               0.50        50      0.9926440  0.9500000  0.9753086
  0.4  3          0.6               0.50       100      0.9922325  0.9708333  0.9753086
  0.4  3          0.6               0.50       150      0.9934671  0.9750000  0.9703704
  0.4  3          0.6               0.75        50      0.9917695  0.9541667  0.9654321
  0.4  3          0.6               0.75       100      0.9925412  0.9708333  0.9703704
  0.4  3          0.6               0.75       150      0.9923868  0.9708333  0.9753086
  0.4  3          0.6               1.00        50      0.9940329  0.9500000  0.9753086
  0.4  3          0.6               1.00       100      0.9946502  0.9708333  0.9827160
  0.4  3          0.6               1.00       150      0.9950617  0.9750000  0.9802469
  0.4  3          0.8               0.50        50      0.9895062  0.9541667  0.9703704
  0.4  3          0.8               0.50       100      0.9917181  0.9750000  0.9777778
  0.4  3          0.8               0.50       150      0.9927984  0.9708333  0.9777778
  0.4  3          0.8               0.75        50      0.9937243  0.9500000  0.9802469
  0.4  3          0.8               0.75       100      0.9937243  0.9750000  0.9777778
  0.4  3          0.8               0.75       150      0.9938272  0.9750000  0.9802469
  0.4  3          0.8               1.00        50      0.9895062  0.9500000  0.9802469
  0.4  3          0.8               1.00       100      0.9904835  0.9750000  0.9753086
  0.4  3          0.8               1.00       150      0.9918724  0.9750000  0.9753086

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     36.3      1.2
  positive      0.9     61.6
                            
 Accuracy (average) : 0.9783

[1] "TEST accuracy: 0.978294573643411"
[1] "TEST +precision: 0.985111662531017"
[1] "TEST -precision: 0.966942148760331"
[1] "TEST specifity: 0.975"
[1] "TEST sensitivity: 0.980246913580247"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        5
            positive        8      133
[1] "TEST accuracy: 0.919254658385093"
[1] "TEST +precision: 0.943262411347518"
[1] "TEST -precision: 0.75"
[1] "TEST specifity: 0.652173913043478"
[1] "TEST sensitivity: 0.963768115942029"
