[1] "DATASET NAME: Diamantes_Bi_IR_10"
[1] "TRAIN INSTANCES: 425"
[1] "TEST INSTANCES: 131"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.3347589969635"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

425 samples
947 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 340, 341, 339, 340, 340 
Resampling results:

  ROC        Sens       Spec
  0.9843014  0.9272727  1   

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.8      0.0
  positive      0.9     87.3
                            
 Accuracy (average) : 0.9906

[1] "TEST accuracy: 0.990588235294118"
[1] "TEST +precision: 0.989333333333333"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.925925925925926"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        6      125
[1] "TEST accuracy: 0.954198473282443"
[1] "TEST +precision: 0.954198473282443"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.33752516905467"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

425 samples
947 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 340, 340, 341, 340, 339 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5000000  0.00000000  1.0000000
  0.010  2  0.5000000  0.00000000  1.0000000
  0.010  3  0.5000000  0.00000000  1.0000000
  0.255  1  0.5981712  0.09272727  0.9972973
  0.255  2  0.5969550  0.09272727  0.9972973
  0.255  3  0.5775446  0.07454545  0.9945946
  0.500  1  0.6779189  0.14727273  0.9972973
  0.500  2  0.6379975  0.11090909  0.9972973
  0.500  3  0.5787609  0.07454545  0.9945946

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.9      0.2
  positive     10.8     87.1
                            
 Accuracy (average) : 0.8894

[1] "TEST accuracy: 0.889411764705882"
[1] "TEST +precision: 0.889423076923077"
[1] "TEST -precision: 0.888888888888889"
[1] "TEST specifity: 0.148148148148148"
[1] "TEST sensitivity: 0.997304582210243"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        6      125
[1] "TEST accuracy: 0.954198473282443"
[1] "TEST +precision: 0.954198473282443"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.21373159885407"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

425 samples
947 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 340, 341, 340, 339, 340 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7099984  0.03818182  1.0000000
  0.3  1          0.6               0.50       100      0.7166699  0.11090909  0.9973333
  0.3  1          0.6               0.50       150      0.7228288  0.11090909  0.9973333
  0.3  1          0.6               0.75        50      0.7731466  0.14909091  0.9945946
  0.3  1          0.6               0.75       100      0.7639918  0.25818182  0.9918919
  0.3  1          0.6               0.75       150      0.7565749  0.29636364  0.9918919
  0.3  1          0.6               1.00        50      0.7765848  0.24000000  0.9945946
  0.3  1          0.6               1.00       100      0.7789091  0.24000000  0.9945946
  0.3  1          0.6               1.00       150      0.7727862  0.29636364  0.9918919
  0.3  1          0.8               0.50        50      0.7354914  0.13090909  1.0000000
  0.3  1          0.8               0.50       100      0.7493726  0.13090909  1.0000000
  0.3  1          0.8               0.50       150      0.7361990  0.14909091  1.0000000
  0.3  1          0.8               0.75        50      0.7634382  0.25818182  0.9945946
  0.3  1          0.8               0.75       100      0.7537903  0.27636364  0.9945946
  0.3  1          0.8               0.75       150      0.7576020  0.29636364  0.9945946
  0.3  1          0.8               1.00        50      0.7828075  0.25818182  0.9945946
  0.3  1          0.8               1.00       100      0.7722948  0.25818182  0.9945946
  0.3  1          0.8               1.00       150      0.7749730  0.31454545  0.9945946
  0.3  2          0.6               0.50        50      0.7794464  0.14909091  1.0000000
  0.3  2          0.6               0.50       100      0.7846732  0.20363636  1.0000000
  0.3  2          0.6               0.50       150      0.7973366  0.22181818  0.9972973
  0.3  2          0.6               0.75        50      0.7980139  0.27818182  0.9892252
  0.3  2          0.6               0.75       100      0.8335160  0.33272727  0.9892252
  0.3  2          0.6               0.75       150      0.8370049  0.33272727  0.9892252
  0.3  2          0.6               1.00        50      0.8110434  0.33636364  0.9918919
  0.3  2          0.6               1.00       100      0.8112563  0.39272727  0.9918919
  0.3  2          0.6               1.00       150      0.8487813  0.41090909  0.9918919
  0.3  2          0.8               0.50        50      0.7786306  0.18363636  0.9918919
  0.3  2          0.8               0.50       100      0.8107551  0.20181818  0.9918919
  0.3  2          0.8               0.50       150      0.8163898  0.25636364  0.9918919
  0.3  2          0.8               0.75        50      0.7971900  0.33454545  0.9891892
  0.3  2          0.8               0.75       100      0.8196175  0.37090909  0.9918919
  0.3  2          0.8               0.75       150      0.8217371  0.37090909  0.9891892
  0.3  2          0.8               1.00        50      0.7990639  0.35454545  0.9919279
  0.3  2          0.8               1.00       100      0.8288165  0.42909091  0.9892252
  0.3  2          0.8               1.00       150      0.8553686  0.44727273  0.9918919
  0.3  3          0.6               0.50        50      0.7692318  0.20363636  0.9945946
  0.3  3          0.6               0.50       100      0.7903554  0.25818182  0.9918919
  0.3  3          0.6               0.50       150      0.8056396  0.29636364  0.9892252
  0.3  3          0.6               0.75        50      0.8226274  0.27818182  0.9945946
  0.3  3          0.6               0.75       100      0.8576642  0.33272727  0.9918919
  0.3  3          0.6               0.75       150      0.8584079  0.36909091  0.9891892
  0.3  3          0.6               1.00        50      0.8242588  0.31454545  0.9919279
  0.3  3          0.6               1.00       100      0.8551761  0.40727273  0.9918919
  0.3  3          0.6               1.00       150      0.8577035  0.40727273  0.9918919
  0.3  3          0.8               0.50        50      0.7853808  0.22000000  0.9918919
  0.3  3          0.8               0.50       100      0.7879607  0.23818182  0.9918919
  0.3  3          0.8               0.50       150      0.7912498  0.27454545  0.9891892
  0.3  3          0.8               0.75        50      0.8388370  0.36909091  0.9891892
  0.3  3          0.8               0.75       100      0.8432957  0.38727273  0.9918919
  0.3  3          0.8               0.75       150      0.8488206  0.38727273  0.9891892
  0.3  3          0.8               1.00        50      0.8431400  0.35454545  0.9919279
  0.3  3          0.8               1.00       100      0.8670794  0.44727273  0.9918919
  0.3  3          0.8               1.00       150      0.8686519  0.44727273  0.9918919
  0.4  1          0.6               0.50        50      0.7014832  0.09454545  1.0000000
  0.4  1          0.6               0.50       100      0.7309050  0.13090909  0.9972973
  0.4  1          0.6               0.50       150      0.7350147  0.18545455  1.0000000
  0.4  1          0.6               0.75        50      0.7525463  0.20363636  0.9945946
  0.4  1          0.6               0.75       100      0.7609975  0.24000000  0.9972973
  0.4  1          0.6               0.75       150      0.7596167  0.22181818  0.9972973
  0.4  1          0.6               1.00        50      0.7939656  0.20363636  0.9945946
  0.4  1          0.6               1.00       100      0.7701949  0.26000000  0.9945946
  0.4  1          0.6               1.00       150      0.7634070  0.27818182  0.9972973
  0.4  1          0.8               0.50        50      0.7130262  0.14727273  0.9946306
  0.4  1          0.8               0.50       100      0.7502490  0.18363636  0.9973333
  0.4  1          0.8               0.50       150      0.7534267  0.24000000  0.9973333
  0.4  1          0.8               0.75        50      0.7457952  0.18545455  1.0000000
  0.4  1          0.8               0.75       100      0.7594529  0.24000000  0.9972973
  0.4  1          0.8               0.75       150      0.7691466  0.25818182  0.9945946
  0.4  1          0.8               1.00        50      0.7945799  0.25818182  0.9945946
  0.4  1          0.8               1.00       100      0.7755479  0.31454545  0.9945946
  0.4  1          0.8               1.00       150      0.7678575  0.31454545  0.9918919
  0.4  2          0.6               0.50        50      0.7787060  0.16909091  0.9918919
  0.4  2          0.6               0.50       100      0.7915381  0.27818182  0.9892252
  0.4  2          0.6               0.50       150      0.7987109  0.27818182  0.9865225
  0.4  2          0.6               0.75        50      0.8113038  0.35454545  0.9945946
  0.4  2          0.6               0.75       100      0.8179181  0.37272727  0.9918919
  0.4  2          0.6               0.75       150      0.8174758  0.37272727  0.9918919
  0.4  2          0.6               1.00        50      0.7880188  0.39272727  0.9892252
  0.4  2          0.6               1.00       100      0.8298583  0.42909091  0.9918919
  0.4  2          0.6               1.00       150      0.8367592  0.42909091  0.9918919
  0.4  2          0.8               0.50        50      0.7849025  0.16545455  0.9891892
  0.4  2          0.8               0.50       100      0.8010319  0.27818182  0.9865225
  0.4  2          0.8               0.50       150      0.7989255  0.31454545  0.9838198
  0.4  2          0.8               0.75        50      0.8033595  0.29636364  0.9945946
  0.4  2          0.8               0.75       100      0.8325405  0.33272727  0.9891892
  0.4  2          0.8               0.75       150      0.8321638  0.33272727  0.9891892
  0.4  2          0.8               1.00        50      0.8094537  0.33454545  0.9919279
  0.4  2          0.8               1.00       100      0.8345725  0.37090909  0.9918919
  0.4  2          0.8               1.00       150      0.8542531  0.38909091  0.9891892
  0.4  3          0.6               0.50        50      0.7980147  0.20363636  0.9891892
  0.4  3          0.6               0.50       100      0.8067207  0.24000000  0.9918919
  0.4  3          0.6               0.50       150      0.8139689  0.25818182  0.9918919
  0.4  3          0.6               0.75        50      0.8131704  0.35272727  0.9945946
  0.4  3          0.6               0.75       100      0.8316339  0.37090909  0.9891892
  0.4  3          0.6               0.75       150      0.8207363  0.37090909  0.9891892
  0.4  3          0.6               1.00        50      0.8238337  0.42909091  0.9919279
  0.4  3          0.6               1.00       100      0.8498796  0.46545455  0.9918919
  0.4  3          0.6               1.00       150      0.8501253  0.48363636  0.9891892
  0.4  3          0.8               0.50        50      0.7821556  0.27818182  0.9918919
  0.4  3          0.8               0.50       100      0.7893366  0.27818182  0.9891892
  0.4  3          0.8               0.50       150      0.7847830  0.27818182  0.9891892
  0.4  3          0.8               0.75        50      0.8536233  0.35272727  0.9892252
  0.4  3          0.8               0.75       100      0.8600721  0.37090909  0.9865225
  0.4  3          0.8               0.75       150      0.8588534  0.38909091  0.9865225
  0.4  3          0.8               1.00        50      0.8559902  0.44727273  0.9918919
  0.4  3          0.8               1.00       100      0.8612989  0.46545455  0.9918919
  0.4  3          0.8               1.00       150      0.8620328  0.46545455  0.9918919

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      5.6      0.7
  positive      7.1     86.6
                            
 Accuracy (average) : 0.9224

[1] "TEST accuracy: 0.922352941176471"
[1] "TEST +precision: 0.924623115577889"
[1] "TEST -precision: 0.888888888888889"
[1] "TEST specifity: 0.444444444444444"
[1] "TEST sensitivity: 0.991913746630728"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        2
            positive        6      123
[1] "TEST accuracy: 0.938931297709924"
[1] "TEST +precision: 0.953488372093023"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.984"
