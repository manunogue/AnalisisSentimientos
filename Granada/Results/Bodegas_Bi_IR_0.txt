[1] "DATASET NAME: Bodegas_Bi_IR_0"
[1] "TRAIN INSTANCES: 481"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.26224780082703"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

481 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 384, 384, 386, 385, 385 
Resampling results:

  ROC        Sens      Spec     
  0.8686187  0.332381  0.9780488

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      5.0      1.9
  positive     10.0     83.2
                            
 Accuracy (average) : 0.8815

[1] "TEST accuracy: 0.881496881496881"
[1] "TEST +precision: 0.892857142857143"
[1] "TEST -precision: 0.727272727272727"
[1] "TEST specifity: 0.333333333333333"
[1] "TEST sensitivity: 0.97799511002445"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       18        6
            positive        9      128
[1] "TEST accuracy: 0.906832298136646"
[1] "TEST +precision: 0.934306569343066"
[1] "TEST -precision: 0.75"
[1] "TEST specifity: 0.666666666666667"
[1] "TEST sensitivity: 0.955223880597015"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.46618822018305"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

481 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 386, 384, 385, 384, 385 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec    
  0.010  1  0.5000000  0     1.000000
  0.010  2  0.5000000  0     1.000000
  0.010  3  0.5000000  0     1.000000
  0.255  1  0.5000000  0     1.000000
  0.255  2  0.5000000  0     1.000000
  0.255  3  0.5000000  0     1.000000
  0.500  1  0.5657631  0     0.995122
  0.500  2  0.5064374  0     1.000000
  0.500  3  0.5000000  0     1.000000

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.4
  positive     15.0     84.6
                            
 Accuracy (average) : 0.8462

[1] "TEST accuracy: 0.846153846153846"
[1] "TEST +precision: 0.849686847599165"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.995110024449878"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       27      134
[1] "TEST accuracy: 0.832298136645963"
[1] "TEST +precision: 0.832298136645963"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.57138593196869"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

481 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 385, 385, 385, 385, 384 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.6798806  0.00000000  1.0000000
  0.3  1          0.6               0.50       100      0.7000812  0.00000000  0.9925926
  0.3  1          0.6               0.50       150      0.7209106  0.01333333  0.9925926
  0.3  1          0.6               0.75        50      0.7077140  0.02857143  0.9975610
  0.3  1          0.6               0.75       100      0.7169122  0.05714286  0.9950918
  0.3  1          0.6               0.75       150      0.7271193  0.07047619  0.9901837
  0.3  1          0.6               1.00        50      0.7185480  0.05714286  0.9975610
  0.3  1          0.6               1.00       100      0.7481978  0.07047619  0.9975610
  0.3  1          0.6               1.00       150      0.7480519  0.07047619  0.9950918
  0.3  1          0.8               0.50        50      0.6990757  0.00000000  1.0000000
  0.3  1          0.8               0.50       100      0.6998179  0.01333333  0.9901536
  0.3  1          0.8               0.50       150      0.7020524  0.02761905  0.9901536
  0.3  1          0.8               0.75        50      0.6959697  0.05714286  0.9975610
  0.3  1          0.8               0.75       100      0.7258072  0.05714286  0.9901837
  0.3  1          0.8               0.75       150      0.7303346  0.08476190  0.9877145
  0.3  1          0.8               1.00        50      0.7088584  0.05714286  0.9975610
  0.3  1          0.8               1.00       100      0.7346989  0.07047619  0.9951220
  0.3  1          0.8               1.00       150      0.7403448  0.07047619  0.9926528
  0.3  2          0.6               0.50        50      0.7065922  0.01428571  0.9901536
  0.3  2          0.6               0.50       100      0.7050548  0.02761905  0.9877145
  0.3  2          0.6               0.50       150      0.7108778  0.02761905  0.9877145
  0.3  2          0.6               0.75        50      0.7329058  0.05619048  0.9926227
  0.3  2          0.6               0.75       100      0.7317487  0.06952381  0.9901536
  0.3  2          0.6               0.75       150      0.7225130  0.07047619  0.9877145
  0.3  2          0.6               1.00        50      0.7480468  0.08476190  0.9951220
  0.3  2          0.6               1.00       100      0.7497619  0.09809524  0.9902138
  0.3  2          0.6               1.00       150      0.7443472  0.08476190  0.9853056
  0.3  2          0.8               0.50        50      0.6958551  0.01333333  0.9950918
  0.3  2          0.8               0.50       100      0.7037375  0.01333333  0.9877145
  0.3  2          0.8               0.50       150      0.6898401  0.02761905  0.9852755
  0.3  2          0.8               0.75        50      0.7084485  0.00000000  0.9901837
  0.3  2          0.8               0.75       100      0.7106484  0.04190476  0.9901837
  0.3  2          0.8               0.75       150      0.7122465  0.04190476  0.9853056
  0.3  2          0.8               1.00        50      0.7416829  0.02857143  0.9951220
  0.3  2          0.8               1.00       100      0.7379730  0.05619048  0.9877447
  0.3  2          0.8               1.00       150      0.7416599  0.08476190  0.9853056
  0.3  3          0.6               0.50        50      0.7127510  0.00000000  0.9950617
  0.3  3          0.6               0.50       100      0.7345692  0.01428571  0.9925926
  0.3  3          0.6               0.50       150      0.7204986  0.01428571  0.9876844
  0.3  3          0.6               0.75        50      0.7186311  0.02761905  0.9926227
  0.3  3          0.6               0.75       100      0.7182262  0.04190476  0.9901837
  0.3  3          0.6               0.75       150      0.7205670  0.05619048  0.9877145
  0.3  3          0.6               1.00        50      0.7243580  0.04285714  0.9950918
  0.3  3          0.6               1.00       100      0.7234372  0.05619048  0.9901837
  0.3  3          0.6               1.00       150      0.7215753  0.05619048  0.9877447
  0.3  3          0.8               0.50        50      0.6869534  0.01333333  0.9950617
  0.3  3          0.8               0.50       100      0.6856128  0.01333333  0.9901837
  0.3  3          0.8               0.50       150      0.7063425  0.05619048  0.9828365
  0.3  3          0.8               0.75        50      0.7107837  0.06952381  0.9853056
  0.3  3          0.8               0.75       100      0.7107736  0.08285714  0.9828666
  0.3  3          0.8               0.75       150      0.7152776  0.08285714  0.9828666
  0.3  3          0.8               1.00        50      0.7393482  0.04285714  0.9951220
  0.3  3          0.8               1.00       100      0.7393403  0.05619048  0.9852755
  0.3  3          0.8               1.00       150      0.7414175  0.09809524  0.9803975
  0.4  1          0.6               0.50        50      0.6993630  0.00000000  1.0000000
  0.4  1          0.6               0.50       100      0.7098235  0.00000000  0.9950617
  0.4  1          0.6               0.50       150      0.7063491  0.01428571  0.9975309
  0.4  1          0.6               0.75        50      0.7132444  0.05714286  0.9975610
  0.4  1          0.6               0.75       100      0.7474664  0.07047619  0.9877145
  0.4  1          0.6               0.75       150      0.7397299  0.08476190  0.9877447
  0.4  1          0.6               1.00        50      0.6919517  0.05714286  1.0000000
  0.4  1          0.6               1.00       100      0.7214749  0.07047619  0.9975610
  0.4  1          0.6               1.00       150      0.7293131  0.07047619  0.9926528
  0.4  1          0.8               0.50        50      0.6915739  0.01333333  0.9975610
  0.4  1          0.8               0.50       100      0.7013509  0.02761905  0.9951220
  0.4  1          0.8               0.50       150      0.6937660  0.02761905  0.9877447
  0.4  1          0.8               0.75        50      0.7161690  0.01333333  0.9950918
  0.4  1          0.8               0.75       100      0.7215499  0.04095238  0.9901536
  0.4  1          0.8               0.75       150      0.7210697  0.02666667  0.9852755
  0.4  1          0.8               1.00        50      0.7146894  0.07047619  0.9975610
  0.4  1          0.8               1.00       100      0.7285016  0.07047619  0.9951220
  0.4  1          0.8               1.00       150      0.7338369  0.07047619  0.9902138
  0.4  2          0.6               0.50        50      0.7112756  0.00000000  1.0000000
  0.4  2          0.6               0.50       100      0.7019005  0.00000000  0.9877145
  0.4  2          0.6               0.50       150      0.6987198  0.01333333  0.9852755
  0.4  2          0.6               0.75        50      0.7216780  0.02761905  0.9975610
  0.4  2          0.6               0.75       100      0.7236261  0.02761905  0.9901837
  0.4  2          0.6               0.75       150      0.7229657  0.02761905  0.9828365
  0.4  2          0.6               1.00        50      0.7558029  0.07142857  0.9926829
  0.4  2          0.6               1.00       100      0.7485359  0.08476190  0.9877447
  0.4  2          0.6               1.00       150      0.7444059  0.08476190  0.9828365
  0.4  2          0.8               0.50        50      0.7190486  0.02761905  0.9926227
  0.4  2          0.8               0.50       100      0.7169066  0.04190476  0.9926227
  0.4  2          0.8               0.50       150      0.7125161  0.06857143  0.9877447
  0.4  2          0.8               0.75        50      0.7336398  0.04285714  0.9975610
  0.4  2          0.8               0.75       100      0.7312691  0.05619048  0.9901837
  0.4  2          0.8               0.75       150      0.7260149  0.08476190  0.9828365
  0.4  2          0.8               1.00        50      0.7461351  0.07142857  0.9926528
  0.4  2          0.8               1.00       100      0.7476132  0.08476190  0.9828365
  0.4  2          0.8               1.00       150      0.7439935  0.08476190  0.9828365
  0.4  3          0.6               0.50        50      0.6938001  0.01333333  0.9901536
  0.4  3          0.6               0.50       100      0.7074321  0.01333333  0.9877447
  0.4  3          0.6               0.50       150      0.7203002  0.05619048  0.9852755
  0.4  3          0.6               0.75        50      0.7111076  0.04190476  0.9926528
  0.4  3          0.6               0.75       100      0.7117960  0.04190476  0.9877748
  0.4  3          0.6               0.75       150      0.7116024  0.09904762  0.9828666
  0.4  3          0.6               1.00        50      0.7383351  0.08476190  0.9902138
  0.4  3          0.6               1.00       100      0.7389238  0.08476190  0.9828666
  0.4  3          0.6               1.00       150      0.7319780  0.08476190  0.9828666
  0.4  3          0.8               0.50        50      0.7095810  0.02761905  0.9852454
  0.4  3          0.8               0.50       100      0.7047265  0.02761905  0.9950617
  0.4  3          0.8               0.50       150      0.7012017  0.02761905  0.9828064
  0.4  3          0.8               0.75        50      0.7326052  0.09809524  0.9901837
  0.4  3          0.8               0.75       100      0.7293101  0.11238095  0.9852755
  0.4  3          0.8               0.75       150      0.7373184  0.11238095  0.9852755
  0.4  3          0.8               1.00        50      0.7439186  0.08476190  0.9926528
  0.4  3          0.8               1.00       100      0.7425169  0.08476190  0.9877447
  0.4  3          0.8               1.00       150      0.7368815  0.08476190  0.9853056

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 2, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.0      0.6
  positive     13.9     84.4
                            
 Accuracy (average) : 0.8545

[1] "TEST accuracy: 0.854469854469854"
[1] "TEST +precision: 0.858350951374207"
[1] "TEST -precision: 0.625"
[1] "TEST specifity: 0.0694444444444444"
[1] "TEST sensitivity: 0.992665036674817"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9        0
            positive       18      134
[1] "TEST accuracy: 0.888198757763975"
[1] "TEST +precision: 0.881578947368421"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.333333333333333"
[1] "TEST sensitivity: 1"
