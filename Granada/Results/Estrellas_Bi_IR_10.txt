[1] "DATASET NAME: Estrellas_Bi_IR_10"
[1] "TRAIN INSTANCES: 448"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.34601211547852"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

448 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 358, 358, 358, 359, 359 
Resampling results:

  ROC        Sens       Spec     
  0.9745539  0.7571429  0.9946667

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.8      0.4
  positive      3.8     83.9
                            
 Accuracy (average) : 0.9576

[1] "TEST accuracy: 0.957589285714286"
[1] "TEST +precision: 0.956743002544529"
[1] "TEST -precision: 0.963636363636364"
[1] "TEST specifity: 0.757142857142857"
[1] "TEST sensitivity: 0.994708994708995"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        3
            positive        6      125
[1] "TEST accuracy: 0.934782608695652"
[1] "TEST +precision: 0.954198473282443"
[1] "TEST -precision: 0.571428571428571"
[1] "TEST specifity: 0.4"
[1] "TEST sensitivity: 0.9765625"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.3550753513972"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

448 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 358, 359, 358, 358, 359 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.6512005  0.3142857  0.9866667
  0.010  2  0.5620000  0.1285714  0.9946667
  0.010  3  0.5592381  0.1142857  1.0000000
  0.255  1  0.7912657  0.6000000  0.9840702
  0.255  2  0.7059073  0.3571429  0.9947018
  0.255  3  0.6602393  0.2857143  0.9894035
  0.500  1  0.8461078  0.6428571  0.9709123
  0.500  2  0.8109887  0.4285714  0.9867719
  0.500  3  0.8203797  0.4571429  0.9524912

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.0      2.5
  positive      5.6     81.9
                            
 Accuracy (average) : 0.9196

[1] "TEST accuracy: 0.919642857142857"
[1] "TEST +precision: 0.936224489795918"
[1] "TEST -precision: 0.803571428571429"
[1] "TEST specifity: 0.642857142857143"
[1] "TEST sensitivity: 0.970899470899471"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        2
            positive        9      126
[1] "TEST accuracy: 0.920289855072464"
[1] "TEST +precision: 0.933333333333333"
[1] "TEST -precision: 0.333333333333333"
[1] "TEST specifity: 0.1"
[1] "TEST sensitivity: 0.984375"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.31967658201853"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

448 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 359, 358, 358, 358, 359 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8449273  0.2714286  0.9920702
  0.3  1          0.6               0.50       100      0.8831830  0.3571429  0.9841404
  0.3  1          0.6               0.50       150      0.8942406  0.3857143  0.9762456
  0.3  1          0.6               0.75        50      0.8773784  0.3428571  0.9947018
  0.3  1          0.6               0.75       100      0.9002556  0.4428571  0.9867719
  0.3  1          0.6               0.75       150      0.8974900  0.4428571  0.9787719
  0.3  1          0.6               1.00        50      0.8874524  0.3428571  1.0000000
  0.3  1          0.6               1.00       100      0.9238772  0.4142857  0.9867368
  0.3  1          0.6               1.00       150      0.9265113  0.4857143  0.9867368
  0.3  1          0.8               0.50        50      0.8557381  0.3285714  0.9867368
  0.3  1          0.8               0.50       100      0.8953195  0.3714286  0.9867719
  0.3  1          0.8               0.50       150      0.9001103  0.3857143  0.9709123
  0.3  1          0.8               0.75        50      0.8682531  0.3285714  0.9920702
  0.3  1          0.8               0.75       100      0.8853058  0.4428571  0.9894035
  0.3  1          0.8               0.75       150      0.9046241  0.4428571  0.9761404
  0.3  1          0.8               1.00        50      0.8894023  0.3000000  0.9973333
  0.3  1          0.8               1.00       100      0.9278784  0.3857143  0.9920702
  0.3  1          0.8               1.00       150      0.9290251  0.4428571  0.9840702
  0.3  2          0.6               0.50        50      0.8702143  0.4285714  0.9840702
  0.3  2          0.6               0.50       100      0.8827669  0.4142857  0.9788772
  0.3  2          0.6               0.50       150      0.8812757  0.4142857  0.9762105
  0.3  2          0.6               0.75        50      0.9005714  0.4714286  0.9867368
  0.3  2          0.6               0.75       100      0.9061228  0.4857143  0.9761404
  0.3  2          0.6               0.75       150      0.9073033  0.4857143  0.9708421
  0.3  2          0.6               1.00        50      0.9127882  0.4857143  0.9867368
  0.3  2          0.6               1.00       100      0.9220827  0.5000000  0.9841053
  0.3  2          0.6               1.00       150      0.9221880  0.5142857  0.9761404
  0.3  2          0.8               0.50        50      0.8726441  0.3428571  0.9867719
  0.3  2          0.8               0.50       100      0.8724035  0.4000000  0.9867719
  0.3  2          0.8               0.50       150      0.8750714  0.4000000  0.9867719
  0.3  2          0.8               0.75        50      0.8985489  0.4428571  0.9814737
  0.3  2          0.8               0.75       100      0.9087043  0.4714286  0.9734737
  0.3  2          0.8               0.75       150      0.9078922  0.4714286  0.9761404
  0.3  2          0.8               1.00        50      0.9216040  0.4714286  0.9867368
  0.3  2          0.8               1.00       100      0.9264737  0.5000000  0.9841053
  0.3  2          0.8               1.00       150      0.9212832  0.5142857  0.9761404
  0.3  3          0.6               0.50        50      0.8716654  0.3857143  0.9814737
  0.3  3          0.6               0.50       100      0.8808296  0.4000000  0.9788421
  0.3  3          0.6               0.50       150      0.8758070  0.4571429  0.9709123
  0.3  3          0.6               0.75        50      0.9001266  0.4571429  0.9788070
  0.3  3          0.6               0.75       100      0.8976504  0.4714286  0.9708772
  0.3  3          0.6               0.75       150      0.9038070  0.4857143  0.9735088
  0.3  3          0.6               1.00        50      0.9284624  0.5285714  0.9840702
  0.3  3          0.6               1.00       100      0.9256441  0.5428571  0.9761754
  0.3  3          0.6               1.00       150      0.9240476  0.5428571  0.9735439
  0.3  3          0.8               0.50        50      0.8805840  0.4000000  0.9815088
  0.3  3          0.8               0.50       100      0.8844799  0.4285714  0.9815088
  0.3  3          0.8               0.50       150      0.8814875  0.4571429  0.9815088
  0.3  3          0.8               0.75        50      0.9017130  0.4714286  0.9841053
  0.3  3          0.8               0.75       100      0.9019511  0.4714286  0.9788070
  0.3  3          0.8               0.75       150      0.9050589  0.4714286  0.9735088
  0.3  3          0.8               1.00        50      0.9258033  0.5285714  0.9841053
  0.3  3          0.8               1.00       100      0.9182694  0.5714286  0.9735088
  0.3  3          0.8               1.00       150      0.9158383  0.5714286  0.9708772
  0.4  1          0.6               0.50        50      0.8547757  0.3285714  0.9867368
  0.4  1          0.6               0.50       100      0.8996053  0.3571429  0.9761404
  0.4  1          0.6               0.50       150      0.8921115  0.3714286  0.9761404
  0.4  1          0.6               0.75        50      0.8757995  0.3714286  0.9867368
  0.4  1          0.6               0.75       100      0.8965188  0.4285714  0.9787719
  0.4  1          0.6               0.75       150      0.8997444  0.4571429  0.9734737
  0.4  1          0.6               1.00        50      0.9082068  0.3857143  0.9947368
  0.4  1          0.6               1.00       100      0.9235915  0.4285714  0.9814386
  0.4  1          0.6               1.00       150      0.9205689  0.4714286  0.9814386
  0.4  1          0.8               0.50        50      0.8547043  0.3142857  0.9788070
  0.4  1          0.8               0.50       100      0.8696090  0.3857143  0.9761754
  0.4  1          0.8               0.50       150      0.8811729  0.4285714  0.9682105
  0.4  1          0.8               0.75        50      0.8798559  0.3857143  0.9867719
  0.4  1          0.8               0.75       100      0.8974010  0.4714286  0.9761053
  0.4  1          0.8               0.75       150      0.9045802  0.4142857  0.9735088
  0.4  1          0.8               1.00        50      0.9089486  0.3571429  0.9973333
  0.4  1          0.8               1.00       100      0.9288446  0.4428571  0.9867018
  0.4  1          0.8               1.00       150      0.9289524  0.4571429  0.9840702
  0.4  2          0.6               0.50        50      0.8790639  0.3571429  0.9814386
  0.4  2          0.6               0.50       100      0.8926303  0.4571429  0.9735789
  0.4  2          0.6               0.50       150      0.8870602  0.4714286  0.9656140
  0.4  2          0.6               0.75        50      0.9103722  0.5142857  0.9867719
  0.4  2          0.6               0.75       100      0.9105426  0.5000000  0.9787719
  0.4  2          0.6               0.75       150      0.9011216  0.5000000  0.9708421
  0.4  2          0.6               1.00        50      0.9216316  0.5285714  0.9841053
  0.4  2          0.6               1.00       100      0.9242155  0.5285714  0.9788070
  0.4  2          0.6               1.00       150      0.9228822  0.5428571  0.9788070
  0.4  2          0.8               0.50        50      0.8677406  0.3142857  0.9867368
  0.4  2          0.8               0.50       100      0.8845990  0.4142857  0.9814737
  0.4  2          0.8               0.50       150      0.8817494  0.4000000  0.9762105
  0.4  2          0.8               0.75        50      0.9006867  0.4285714  0.9840702
  0.4  2          0.8               0.75       100      0.9035627  0.4714286  0.9708421
  0.4  2          0.8               0.75       150      0.9032268  0.4857143  0.9735088
  0.4  2          0.8               1.00        50      0.9231028  0.5000000  0.9867368
  0.4  2          0.8               1.00       100      0.9243421  0.5000000  0.9761754
  0.4  2          0.8               1.00       150      0.9223997  0.5142857  0.9735439
  0.4  3          0.6               0.50        50      0.8724211  0.3571429  0.9814386
  0.4  3          0.6               0.50       100      0.8727356  0.4285714  0.9762105
  0.4  3          0.6               0.50       150      0.8688108  0.4428571  0.9788421
  0.4  3          0.6               0.75        50      0.8964524  0.4714286  0.9814386
  0.4  3          0.6               0.75       100      0.9003985  0.4857143  0.9735439
  0.4  3          0.6               0.75       150      0.8994461  0.5000000  0.9735088
  0.4  3          0.6               1.00        50      0.9321416  0.5571429  0.9841404
  0.4  3          0.6               1.00       100      0.9292130  0.5714286  0.9761754
  0.4  3          0.6               1.00       150      0.9262895  0.5571429  0.9735088
  0.4  3          0.8               0.50        50      0.8700739  0.4142857  0.9708772
  0.4  3          0.8               0.50       100      0.8884850  0.4714286  0.9761404
  0.4  3          0.8               0.50       150      0.8793847  0.4714286  0.9603158
  0.4  3          0.8               0.75        50      0.8999298  0.4857143  0.9682105
  0.4  3          0.8               0.75       100      0.8917506  0.4857143  0.9655789
  0.4  3          0.8               0.75       150      0.8915602  0.4857143  0.9682105
  0.4  3          0.8               1.00        50      0.9260489  0.5428571  0.9841053
  0.4  3          0.8               1.00       100      0.9246416  0.5714286  0.9788070
  0.4  3          0.8               1.00       150      0.9244612  0.5714286  0.9735088

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      8.7      1.3
  positive      6.9     83.0
                            
 Accuracy (average) : 0.9174

[1] "TEST accuracy: 0.917410714285714"
[1] "TEST +precision: 0.923076923076923"
[1] "TEST -precision: 0.866666666666667"
[1] "TEST specifity: 0.557142857142857"
[1] "TEST sensitivity: 0.984126984126984"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        2
            positive        8      126
[1] "TEST accuracy: 0.927536231884058"
[1] "TEST +precision: 0.940298507462687"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.2"
[1] "TEST sensitivity: 0.984375"
