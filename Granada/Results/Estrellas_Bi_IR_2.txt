[1] "DATASET NAME: Estrellas_Bi_IR_2"
[1] "TRAIN INSTANCES: 585"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.63152503967285"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

585 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 468, 467, 468, 468, 469 
Resampling results:

  ROC        Sens       Spec     
  0.9976492  0.9808362  0.9947368

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.7      0.3
  positive      0.7     64.3
                            
 Accuracy (average) : 0.9897

[1] "TEST accuracy: 0.98974358974359"
[1] "TEST +precision: 0.989473684210526"
[1] "TEST -precision: 0.990243902439024"
[1] "TEST specifity: 0.980676328502415"
[1] "TEST sensitivity: 0.994708994708995"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        1
            positive        9      127
[1] "TEST accuracy: 0.927536231884058"
[1] "TEST +precision: 0.933823529411765"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.1"
[1] "TEST sensitivity: 0.9921875"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.56854318380356"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

585 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 468, 469, 467, 469, 467 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9450532  0.9377468  0.9074386
  0.010  2  0.9344961  0.8987224  0.9154737
  0.010  3  0.9382599  0.8794425  0.9178947
  0.255  1  0.9659398  0.9808362  0.9287368
  0.255  2  0.9759038  0.9662021  0.9420000
  0.255  3  0.9668329  0.9375145  0.9365965
  0.500  1  0.9671299  0.9903600  0.9392632
  0.500  2  0.9843060  0.9806039  0.9657193
  0.500  3  0.9803844  0.9566783  0.9524211

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.7      2.2
  positive      0.7     62.4
                            
 Accuracy (average) : 0.9709

[1] "TEST accuracy: 0.970940170940171"
[1] "TEST +precision: 0.989159891598916"
[1] "TEST -precision: 0.939814814814815"
[1] "TEST specifity: 0.980676328502415"
[1] "TEST sensitivity: 0.965608465608466"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        5
            positive        9      123
[1] "TEST accuracy: 0.898550724637681"
[1] "TEST +precision: 0.931818181818182"
[1] "TEST -precision: 0.166666666666667"
[1] "TEST specifity: 0.1"
[1] "TEST sensitivity: 0.9609375"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.97500866651535"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

585 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 468, 468, 469, 467, 468 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9467448  0.5751452  0.9762807
  0.3  1          0.6               0.50       100      0.9644543  0.7346109  0.9709825
  0.3  1          0.6               0.50       150      0.9702116  0.8650407  0.9604211
  0.3  1          0.6               0.75        50      0.9501941  0.6331010  0.9709474
  0.3  1          0.6               0.75       100      0.9750102  0.8265970  0.9709474
  0.3  1          0.6               0.75       150      0.9776294  0.8845528  0.9709123
  0.3  1          0.6               1.00        50      0.9538222  0.6478513  0.9656842
  0.3  1          0.6               1.00       100      0.9748593  0.8509872  0.9683158
  0.3  1          0.6               1.00       150      0.9774739  0.9040650  0.9603860
  0.3  1          0.8               0.50        50      0.9396697  0.6039489  0.9683158
  0.3  1          0.8               0.50       100      0.9623995  0.7590012  0.9709474
  0.3  1          0.8               0.50       150      0.9695211  0.8797909  0.9577544
  0.3  1          0.8               0.75        50      0.9506380  0.6185830  0.9683509
  0.3  1          0.8               0.75       100      0.9687068  0.7830430  0.9683158
  0.3  1          0.8               0.75       150      0.9740147  0.9040650  0.9630526
  0.3  1          0.8               1.00        50      0.9525027  0.6332172  0.9709825
  0.3  1          0.8               1.00       100      0.9742475  0.8314750  0.9656842
  0.3  1          0.8               1.00       150      0.9779369  0.8944251  0.9656842
  0.3  2          0.6               0.50        50      0.9571057  0.7980256  0.9709825
  0.3  2          0.6               0.50       100      0.9673231  0.8800232  0.9603860
  0.3  2          0.6               0.50       150      0.9683100  0.8897793  0.9577895
  0.3  2          0.6               0.75        50      0.9734492  0.8607433  0.9736140
  0.3  2          0.6               0.75       100      0.9786526  0.8897793  0.9710175
  0.3  2          0.6               0.75       150      0.9763935  0.8993031  0.9683158
  0.3  2          0.6               1.00        50      0.9772246  0.8168409  0.9762456
  0.3  2          0.6               1.00       100      0.9783277  0.9040650  0.9709474
  0.3  2          0.6               1.00       150      0.9774698  0.9135889  0.9788772
  0.3  2          0.8               0.50        50      0.9651504  0.8123113  0.9657193
  0.3  2          0.8               0.50       100      0.9718101  0.8556330  0.9683158
  0.3  2          0.8               0.50       150      0.9712248  0.9040650  0.9577895
  0.3  2          0.8               0.75        50      0.9741025  0.8318235  0.9762456
  0.3  2          0.8               0.75       100      0.9748414  0.9040650  0.9683158
  0.3  2          0.8               0.75       150      0.9748522  0.9135889  0.9656491
  0.3  2          0.8               1.00        50      0.9700168  0.8557491  0.9630175
  0.3  2          0.8               1.00       100      0.9771122  0.9040650  0.9656842
  0.3  2          0.8               1.00       150      0.9773966  0.9135889  0.9709825
  0.3  3          0.6               0.50        50      0.9685831  0.8123113  0.9709825
  0.3  3          0.6               0.50       100      0.9742569  0.8801394  0.9657193
  0.3  3          0.6               0.50       150      0.9741759  0.8897793  0.9604211
  0.3  3          0.6               0.75        50      0.9787874  0.8754936  0.9736140
  0.3  3          0.6               0.75       100      0.9794387  0.8897793  0.9656842
  0.3  3          0.6               0.75       150      0.9773668  0.8946574  0.9630526
  0.3  3          0.6               1.00        50      0.9782213  0.9040650  0.9735789
  0.3  3          0.6               1.00       100      0.9783631  0.8993031  0.9736140
  0.3  3          0.6               1.00       150      0.9772495  0.9184669  0.9683158
  0.3  3          0.8               0.50        50      0.9670196  0.8606272  0.9577544
  0.3  3          0.8               0.50       100      0.9675385  0.8849013  0.9577544
  0.3  3          0.8               0.50       150      0.9692690  0.8897793  0.9577544
  0.3  3          0.8               0.75        50      0.9757444  0.9040650  0.9709825
  0.3  3          0.8               0.75       100      0.9744073  0.9041812  0.9736140
  0.3  3          0.8               0.75       150      0.9742395  0.9184669  0.9656842
  0.3  3          0.8               1.00        50      0.9751557  0.9040650  0.9656842
  0.3  3          0.8               1.00       100      0.9774915  0.9135889  0.9709825
  0.3  3          0.8               1.00       150      0.9788021  0.9184669  0.9683158
  0.4  1          0.6               0.50        50      0.9469792  0.7108014  0.9709474
  0.4  1          0.6               0.50       100      0.9698523  0.8655052  0.9683509
  0.4  1          0.6               0.50       150      0.9715691  0.8991870  0.9630175
  0.4  1          0.6               0.75        50      0.9629522  0.7299652  0.9736140
  0.4  1          0.6               0.75       100      0.9739916  0.8507549  0.9683158
  0.4  1          0.6               0.75       150      0.9744642  0.9040650  0.9656842
  0.4  1          0.6               1.00        50      0.9623307  0.7397213  0.9709474
  0.4  1          0.6               1.00       100      0.9780980  0.8943089  0.9656842
  0.4  1          0.6               1.00       150      0.9805478  0.9040650  0.9683509
  0.4  1          0.8               0.50        50      0.9510036  0.6526132  0.9683509
  0.4  1          0.8               0.50       100      0.9624122  0.8367015  0.9551228
  0.4  1          0.8               0.50       150      0.9666396  0.8944251  0.9656842
  0.4  1          0.8               0.75        50      0.9592599  0.7637631  0.9736140
  0.4  1          0.8               0.75       100      0.9729712  0.8849013  0.9656491
  0.4  1          0.8               0.75       150      0.9767463  0.8897793  0.9736140
  0.4  1          0.8               1.00        50      0.9598335  0.7204413  0.9736140
  0.4  1          0.8               1.00       100      0.9762068  0.8991870  0.9630175
  0.4  1          0.8               1.00       150      0.9790379  0.9040650  0.9683509
  0.4  2          0.6               0.50        50      0.9653649  0.8412311  0.9709474
  0.4  2          0.6               0.50       100      0.9711714  0.8849013  0.9656842
  0.4  2          0.6               0.50       150      0.9729402  0.8897793  0.9656140
  0.4  2          0.6               0.75        50      0.9758357  0.8897793  0.9682456
  0.4  2          0.6               0.75       100      0.9750897  0.8993031  0.9682807
  0.4  2          0.6               0.75       150      0.9741912  0.8993031  0.9577193
  0.4  2          0.6               1.00        50      0.9752491  0.8944251  0.9683158
  0.4  2          0.6               1.00       100      0.9784138  0.9135889  0.9709825
  0.4  2          0.6               1.00       150      0.9777431  0.9184669  0.9656842
  0.4  2          0.8               0.50        50      0.9675529  0.8363531  0.9577895
  0.4  2          0.8               0.50       100      0.9705360  0.8850174  0.9498596
  0.4  2          0.8               0.50       150      0.9710440  0.8897793  0.9524561
  0.4  2          0.8               0.75        50      0.9759643  0.8846690  0.9656491
  0.4  2          0.8               0.75       100      0.9770656  0.8993031  0.9630175
  0.4  2          0.8               0.75       150      0.9765849  0.9041812  0.9577544
  0.4  2          0.8               1.00        50      0.9741514  0.9040650  0.9683158
  0.4  2          0.8               1.00       100      0.9792699  0.9135889  0.9762456
  0.4  2          0.8               1.00       150      0.9781558  0.9184669  0.9735789
  0.4  3          0.6               0.50        50      0.9732950  0.8800232  0.9629825
  0.4  3          0.6               0.50       100      0.9742752  0.8897793  0.9629825
  0.4  3          0.6               0.50       150      0.9767295  0.8946574  0.9524561
  0.4  3          0.6               0.75        50      0.9773010  0.8897793  0.9656842
  0.4  3          0.6               0.75       100      0.9747360  0.9041812  0.9577544
  0.4  3          0.6               0.75       150      0.9762685  0.9041812  0.9577544
  0.4  3          0.6               1.00        50      0.9757608  0.9040650  0.9762456
  0.4  3          0.6               1.00       100      0.9774083  0.9184669  0.9709474
  0.4  3          0.6               1.00       150      0.9772266  0.9184669  0.9656842
  0.4  3          0.8               0.50        50      0.9670521  0.8847851  0.9577544
  0.4  3          0.8               0.50       100      0.9736056  0.9040650  0.9551228
  0.4  3          0.8               0.50       150      0.9731322  0.9089431  0.9498596
  0.4  3          0.8               0.75        50      0.9790512  0.9040650  0.9656842
  0.4  3          0.8               0.75       100      0.9760787  0.9089431  0.9577895
  0.4  3          0.8               0.75       150      0.9779037  0.9089431  0.9630526
  0.4  3          0.8               1.00        50      0.9779246  0.9040650  0.9762456
  0.4  3          0.8               1.00       100      0.9772984  0.9038328  0.9709474
  0.4  3          0.8               1.00       150      0.9766825  0.9038328  0.9683158

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 1, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     32.0      2.1
  positive      3.4     62.6
                            
 Accuracy (average) : 0.9453

[1] "TEST accuracy: 0.945299145299145"
[1] "TEST +precision: 0.948186528497409"
[1] "TEST -precision: 0.939698492462312"
[1] "TEST specifity: 0.903381642512077"
[1] "TEST sensitivity: 0.968253968253968"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        4
            positive        8      124
[1] "TEST accuracy: 0.91304347826087"
[1] "TEST +precision: 0.939393939393939"
[1] "TEST -precision: 0.333333333333333"
[1] "TEST specifity: 0.2"
[1] "TEST sensitivity: 0.96875"
