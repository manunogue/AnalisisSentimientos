[1] "DATASET NAME: Diamantes_Uni_IR_0"
[1] "TRAIN INSTANCES: 390"
[1] "TEST INSTANCES: 131"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 1.9268491268158"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

390 samples
797 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 311, 312, 313, 312, 312 
Resampling results:

  ROC        Sens       Spec     
  0.9005465  0.1333333  0.9946667

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.5      0.5
  positive      3.6     95.4
                           
 Accuracy (average) : 0.959

[1] "TEST accuracy: 0.958974358974359"
[1] "TEST +precision: 0.963730569948187"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.125"
[1] "TEST sensitivity: 0.994652406417112"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        0
            positive        7      122
[1] "TEST accuracy: 0.946564885496183"
[1] "TEST +precision: 0.945736434108527"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.222222222222222"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.00515431960424"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

390 samples
797 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 313, 312, 311, 312, 312 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5000000  0.00000000  1.0000000
  0.010  2  0.5000000  0.00000000  1.0000000
  0.010  3  0.5000000  0.00000000  1.0000000
  0.255  1  0.4591832  0.00000000  0.9973333
  0.255  2  0.4893333  0.00000000  0.9973333
  0.255  3  0.5000000  0.00000000  1.0000000
  0.500  1  0.4046577  0.00000000  0.9920000
  0.500  2  0.4780541  0.06666667  0.9865946
  0.500  3  0.6062943  0.06666667  0.9813333

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.3      1.8
  positive      3.8     94.1
                            
 Accuracy (average) : 0.9436

[1] "TEST accuracy: 0.943589743589744"
[1] "TEST +precision: 0.960732984293194"
[1] "TEST -precision: 0.125"
[1] "TEST specifity: 0.0625"
[1] "TEST sensitivity: 0.981283422459893"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        3
            positive        9      119
[1] "TEST accuracy: 0.908396946564885"
[1] "TEST +precision: 0.9296875"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.975409836065574"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 1.93863088289897"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

390 samples
797 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 312, 312, 312, 312, 312 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7994565  0.00000000  1.0000000
  0.3  1          0.6               0.50       100      0.7559339  0.06666667  0.9973333
  0.3  1          0.6               0.50       150      0.7121652  0.06666667  0.9946667
  0.3  1          0.6               0.75        50      0.8007192  0.06666667  0.9973333
  0.3  1          0.6               0.75       100      0.8013393  0.13333333  0.9946667
  0.3  1          0.6               0.75       150      0.7785105  0.13333333  0.9920000
  0.3  1          0.6               1.00        50      0.8316547  0.06666667  0.9973333
  0.3  1          0.6               1.00       100      0.8041862  0.06666667  0.9946306
  0.3  1          0.6               1.00       150      0.7888784  0.06666667  0.9919640
  0.3  1          0.8               0.50        50      0.7289489  0.00000000  0.9946667
  0.3  1          0.8               0.50       100      0.7228679  0.00000000  0.9919640
  0.3  1          0.8               0.50       150      0.7417808  0.00000000  0.9919640
  0.3  1          0.8               0.75        50      0.7981937  0.06666667  0.9973333
  0.3  1          0.8               0.75       100      0.7923784  0.13333333  0.9920000
  0.3  1          0.8               0.75       150      0.7781201  0.13333333  0.9892973
  0.3  1          0.8               1.00        50      0.8384474  0.06666667  0.9973333
  0.3  1          0.8               1.00       100      0.8263919  0.06666667  0.9946306
  0.3  1          0.8               1.00       150      0.8013949  0.06666667  0.9892973
  0.3  2          0.6               0.50        50      0.7763453  0.00000000  0.9946667
  0.3  2          0.6               0.50       100      0.7367688  0.00000000  0.9919640
  0.3  2          0.6               0.50       150      0.7245015  0.06666667  0.9946306
  0.3  2          0.6               0.75        50      0.8368949  0.06666667  0.9973333
  0.3  2          0.6               0.75       100      0.7792192  0.13333333  0.9946667
  0.3  2          0.6               0.75       150      0.7760901  0.13333333  0.9946667
  0.3  2          0.6               1.00        50      0.8511892  0.13333333  0.9946306
  0.3  2          0.6               1.00       100      0.7992042  0.13333333  0.9919640
  0.3  2          0.6               1.00       150      0.7695856  0.13333333  0.9919640
  0.3  2          0.8               0.50        50      0.7524084  0.00000000  0.9973333
  0.3  2          0.8               0.50       100      0.7583123  0.06666667  0.9946667
  0.3  2          0.8               0.50       150      0.7505255  0.06666667  0.9946667
  0.3  2          0.8               0.75        50      0.7955766  0.06666667  0.9946306
  0.3  2          0.8               0.75       100      0.7599489  0.13333333  0.9919640
  0.3  2          0.8               0.75       150      0.7448018  0.13333333  0.9919640
  0.3  2          0.8               1.00        50      0.8585856  0.20000000  0.9919640
  0.3  2          0.8               1.00       100      0.8197568  0.20000000  0.9919640
  0.3  2          0.8               1.00       150      0.7949730  0.20000000  0.9919640
  0.3  3          0.6               0.50        50      0.7370541  0.06666667  0.9973333
  0.3  3          0.6               0.50       100      0.6667598  0.06666667  0.9946667
  0.3  3          0.6               0.50       150      0.6832222  0.06666667  0.9973333
  0.3  3          0.6               0.75        50      0.7898559  0.13333333  0.9919640
  0.3  3          0.6               0.75       100      0.7656757  0.06666667  0.9919640
  0.3  3          0.6               0.75       150      0.7259940  0.13333333  0.9919640
  0.3  3          0.6               1.00        50      0.8435465  0.20000000  0.9946667
  0.3  3          0.6               1.00       100      0.8057838  0.13333333  0.9920000
  0.3  3          0.6               1.00       150      0.7787598  0.13333333  0.9920000
  0.3  3          0.8               0.50        50      0.8201336  0.00000000  1.0000000
  0.3  3          0.8               0.50       100      0.7802222  0.06666667  0.9946667
  0.3  3          0.8               0.50       150      0.7417477  0.13333333  0.9946667
  0.3  3          0.8               0.75        50      0.8104414  0.13333333  0.9946306
  0.3  3          0.8               0.75       100      0.7703333  0.13333333  0.9946306
  0.3  3          0.8               0.75       150      0.7626877  0.13333333  0.9919640
  0.3  3          0.8               1.00        50      0.8475285  0.06666667  0.9919640
  0.3  3          0.8               1.00       100      0.7992072  0.06666667  0.9892973
  0.3  3          0.8               1.00       150      0.7877928  0.06666667  0.9892973
  0.4  1          0.6               0.50        50      0.7872583  0.20000000  0.9920000
  0.4  1          0.6               0.50       100      0.7598078  0.20000000  0.9893333
  0.4  1          0.6               0.50       150      0.7474685  0.26666667  0.9839640
  0.4  1          0.6               0.75        50      0.8365931  0.06666667  0.9946306
  0.4  1          0.6               0.75       100      0.7967147  0.06666667  0.9919640
  0.4  1          0.6               0.75       150      0.8083784  0.20000000  0.9892973
  0.4  1          0.6               1.00        50      0.8371832  0.00000000  0.9973333
  0.4  1          0.6               1.00       100      0.8070826  0.06666667  0.9946667
  0.4  1          0.6               1.00       150      0.7883078  0.06666667  0.9892973
  0.4  1          0.8               0.50        50      0.7816231  0.06666667  0.9973333
  0.4  1          0.8               0.50       100      0.7445916  0.06666667  0.9893333
  0.4  1          0.8               0.50       150      0.7250000  0.06666667  0.9893333
  0.4  1          0.8               0.75        50      0.7801111  0.06666667  0.9973333
  0.4  1          0.8               0.75       100      0.7824565  0.13333333  0.9946306
  0.4  1          0.8               0.75       150      0.7701532  0.06666667  0.9892973
  0.4  1          0.8               1.00        50      0.8406306  0.00000000  0.9973333
  0.4  1          0.8               1.00       100      0.8227613  0.06666667  0.9946667
  0.4  1          0.8               1.00       150      0.8081817  0.06666667  0.9892973
  0.4  2          0.6               0.50        50      0.7551171  0.06666667  0.9946667
  0.4  2          0.6               0.50       100      0.7080030  0.06666667  0.9946306
  0.4  2          0.6               0.50       150      0.6868108  0.06666667  0.9946667
  0.4  2          0.6               0.75        50      0.7812523  0.06666667  0.9946667
  0.4  2          0.6               0.75       100      0.7633303  0.06666667  0.9919640
  0.4  2          0.6               0.75       150      0.7455495  0.06666667  0.9919640
  0.4  2          0.6               1.00        50      0.8385676  0.13333333  0.9919640
  0.4  2          0.6               1.00       100      0.7967508  0.13333333  0.9919640
  0.4  2          0.6               1.00       150      0.7924474  0.20000000  0.9919640
  0.4  2          0.8               0.50        50      0.7849129  0.00000000  0.9920000
  0.4  2          0.8               0.50       100      0.7913844  0.06666667  0.9920000
  0.4  2          0.8               0.50       150      0.7683453  0.06666667  0.9920000
  0.4  2          0.8               0.75        50      0.7598799  0.06666667  0.9919640
  0.4  2          0.8               0.75       100      0.7375856  0.06666667  0.9919640
  0.4  2          0.8               0.75       150      0.7163213  0.06666667  0.9919640
  0.4  2          0.8               1.00        50      0.8653063  0.13333333  0.9919640
  0.4  2          0.8               1.00       100      0.8217117  0.13333333  0.9919640
  0.4  2          0.8               1.00       150      0.7994174  0.20000000  0.9919640
  0.4  3          0.6               0.50        50      0.7841321  0.06666667  0.9920000
  0.4  3          0.6               0.50       100      0.7836667  0.06666667  1.0000000
  0.4  3          0.6               0.50       150      0.8001652  0.13333333  1.0000000
  0.4  3          0.6               0.75        50      0.7775495  0.06666667  0.9946667
  0.4  3          0.6               0.75       100      0.7423123  0.06666667  0.9946667
  0.4  3          0.6               0.75       150      0.7135105  0.06666667  0.9946667
  0.4  3          0.6               1.00        50      0.8333393  0.13333333  0.9919640
  0.4  3          0.6               1.00       100      0.8072042  0.06666667  0.9919640
  0.4  3          0.6               1.00       150      0.7877898  0.06666667  0.9919640
  0.4  3          0.8               0.50        50      0.7342793  0.13333333  0.9920000
  0.4  3          0.8               0.50       100      0.7149700  0.06666667  0.9920000
  0.4  3          0.8               0.50       150      0.6949159  0.13333333  0.9920000
  0.4  3          0.8               0.75        50      0.7687688  0.13333333  0.9920000
  0.4  3          0.8               0.75       100      0.7456186  0.13333333  0.9920000
  0.4  3          0.8               0.75       150      0.7467568  0.13333333  0.9920000
  0.4  3          0.8               1.00        50      0.8237057  0.06666667  0.9973333
  0.4  3          0.8               1.00       100      0.7642553  0.06666667  0.9973333
  0.4  3          0.8               1.00       150      0.7563964  0.06666667  0.9973333

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 2, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.5      0.8
  positive      3.6     95.1
                            
 Accuracy (average) : 0.9564

[1] "TEST accuracy: 0.956410256410256"
[1] "TEST +precision: 0.963636363636364"
[1] "TEST -precision: 0.4"
[1] "TEST specifity: 0.125"
[1] "TEST sensitivity: 0.991978609625668"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        9      122
[1] "TEST accuracy: 0.931297709923664"
[1] "TEST +precision: 0.931297709923664"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
