[1] "DATASET NAME: Bodegas_Uni_IR_0"
[1] "TRAIN INSTANCES: 481"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.16116905212402"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

481 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 385, 385, 385, 385, 384 
Resampling results:

  ROC        Sens       Spec     
  0.9783333  0.8041667  0.9876543

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     12.7      1.0
  positive      3.1     83.2
                            
 Accuracy (average) : 0.9584

[1] "TEST accuracy: 0.958419958419958"
[1] "TEST +precision: 0.963855421686747"
[1] "TEST -precision: 0.924242424242424"
[1] "TEST specifity: 0.802631578947368"
[1] "TEST sensitivity: 0.987654320987654"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       17        2
            positive        6      136
[1] "TEST accuracy: 0.950310559006211"
[1] "TEST +precision: 0.957746478873239"
[1] "TEST -precision: 0.894736842105263"
[1] "TEST specifity: 0.739130434782609"
[1] "TEST sensitivity: 0.985507246376812"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.00582613150279"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

481 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 385, 385, 385, 384, 385 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.6533128  0.4191667  0.9679012
  0.010  2  0.7033128  0.4841667  0.9679012
  0.010  3  0.7281173  0.4975000  0.9703704
  0.255  1  0.7484774  0.5750000  0.9308642
  0.255  2  0.7532665  0.5750000  0.9333333
  0.255  3  0.7316924  0.5108333  0.9703704
  0.500  1  0.7409053  0.5883333  0.9283951
  0.500  2  0.8032253  0.6016667  0.9259259
  0.500  3  0.8110854  0.5358333  0.9506173

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      8.5      4.2
  positive      7.3     80.0
                            
 Accuracy (average) : 0.8857

[1] "TEST accuracy: 0.885654885654886"
[1] "TEST +precision: 0.916666666666667"
[1] "TEST -precision: 0.672131147540984"
[1] "TEST specifity: 0.539473684210526"
[1] "TEST sensitivity: 0.950617283950617"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       12        9
            positive       11      129
[1] "TEST accuracy: 0.875776397515528"
[1] "TEST +precision: 0.921428571428571"
[1] "TEST -precision: 0.571428571428571"
[1] "TEST specifity: 0.521739130434783"
[1] "TEST sensitivity: 0.934782608695652"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.13619246880213"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

481 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 385, 384, 385, 385, 385 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9366821  0.5133333  0.9950617
  0.3  1          0.6               0.50       100      0.9518210  0.6325000  0.9925926
  0.3  1          0.6               0.50       150      0.9452366  0.6725000  0.9851852
  0.3  1          0.6               0.75        50      0.9462037  0.5516667  0.9950617
  0.3  1          0.6               0.75       100      0.9526029  0.6316667  0.9925926
  0.3  1          0.6               0.75       150      0.9540947  0.6716667  0.9901235
  0.3  1          0.6               1.00        50      0.9418570  0.5258333  0.9950617
  0.3  1          0.6               1.00       100      0.9551029  0.6058333  0.9925926
  0.3  1          0.6               1.00       150      0.9575514  0.6450000  0.9901235
  0.3  1          0.8               0.50        50      0.9370370  0.5275000  0.9950617
  0.3  1          0.8               0.50       100      0.9433333  0.6333333  0.9851852
  0.3  1          0.8               0.50       150      0.9404012  0.6466667  0.9827160
  0.3  1          0.8               0.75        50      0.9394444  0.5258333  0.9876543
  0.3  1          0.8               0.75       100      0.9494239  0.6450000  0.9950617
  0.3  1          0.8               0.75       150      0.9542593  0.6716667  0.9876543
  0.3  1          0.8               1.00        50      0.9408385  0.5258333  0.9950617
  0.3  1          0.8               1.00       100      0.9541049  0.6050000  0.9925926
  0.3  1          0.8               1.00       150      0.9569856  0.6450000  0.9925926
  0.3  2          0.6               0.50        50      0.9527263  0.5941667  0.9950617
  0.3  2          0.6               0.50       100      0.9479938  0.6466667  0.9827160
  0.3  2          0.6               0.50       150      0.9430967  0.6458333  0.9802469
  0.3  2          0.6               0.75        50      0.9504218  0.6583333  0.9925926
  0.3  2          0.6               0.75       100      0.9499074  0.6716667  0.9827160
  0.3  2          0.6               0.75       150      0.9474794  0.6983333  0.9851852
  0.3  2          0.6               1.00        50      0.9528601  0.6575000  0.9950617
  0.3  2          0.6               1.00       100      0.9566461  0.6708333  0.9925926
  0.3  2          0.6               1.00       150      0.9588786  0.6708333  0.9851852
  0.3  2          0.8               0.50        50      0.9426132  0.6591667  0.9950617
  0.3  2          0.8               0.50       100      0.9493313  0.6325000  0.9876543
  0.3  2          0.8               0.50       150      0.9421502  0.6458333  0.9827160
  0.3  2          0.8               0.75        50      0.9479115  0.6316667  0.9901235
  0.3  2          0.8               0.75       100      0.9487654  0.6966667  0.9851852
  0.3  2          0.8               0.75       150      0.9460391  0.7100000  0.9851852
  0.3  2          0.8               1.00        50      0.9504835  0.5916667  0.9950617
  0.3  2          0.8               1.00       100      0.9582922  0.6441667  0.9925926
  0.3  2          0.8               1.00       150      0.9541152  0.6700000  0.9827160
  0.3  3          0.6               0.50        50      0.9383333  0.6325000  0.9802469
  0.3  3          0.6               0.50       100      0.9360494  0.6591667  0.9777778
  0.3  3          0.6               0.50       150      0.9367593  0.6716667  0.9802469
  0.3  3          0.6               0.75        50      0.9564815  0.6850000  0.9901235
  0.3  3          0.6               0.75       100      0.9503086  0.6850000  0.9802469
  0.3  3          0.6               0.75       150      0.9488889  0.7108333  0.9827160
  0.3  3          0.6               1.00        50      0.9508539  0.6450000  0.9925926
  0.3  3          0.6               1.00       100      0.9517387  0.6575000  0.9901235
  0.3  3          0.6               1.00       150      0.9507510  0.6708333  0.9851852
  0.3  3          0.8               0.50        50      0.9591049  0.6450000  0.9876543
  0.3  3          0.8               0.50       100      0.9462243  0.6191667  0.9827160
  0.3  3          0.8               0.50       150      0.9418107  0.6841667  0.9851852
  0.3  3          0.8               0.75        50      0.9541770  0.6458333  0.9876543
  0.3  3          0.8               0.75       100      0.9463992  0.6583333  0.9802469
  0.3  3          0.8               0.75       150      0.9463477  0.6850000  0.9827160
  0.3  3          0.8               1.00        50      0.9467798  0.6058333  0.9975309
  0.3  3          0.8               1.00       100      0.9467078  0.6716667  0.9901235
  0.3  3          0.8               1.00       150      0.9439506  0.6583333  0.9851852
  0.4  1          0.6               0.50        50      0.9434774  0.5650000  0.9950617
  0.4  1          0.6               0.50       100      0.9421502  0.6058333  0.9851852
  0.4  1          0.6               0.50       150      0.9450206  0.6725000  0.9802469
  0.4  1          0.6               0.75        50      0.9539198  0.5783333  0.9950617
  0.4  1          0.6               0.75       100      0.9495885  0.6450000  0.9925926
  0.4  1          0.6               0.75       150      0.9498457  0.6975000  0.9901235
  0.4  1          0.6               1.00        50      0.9454372  0.5391667  0.9950617
  0.4  1          0.6               1.00       100      0.9569650  0.6316667  0.9925926
  0.4  1          0.6               1.00       150      0.9578189  0.6575000  0.9876543
  0.4  1          0.8               0.50        50      0.9432099  0.6050000  0.9925926
  0.4  1          0.8               0.50       100      0.9524280  0.6316667  0.9876543
  0.4  1          0.8               0.50       150      0.9468724  0.6983333  0.9728395
  0.4  1          0.8               0.75        50      0.9518004  0.6316667  0.9950617
  0.4  1          0.8               0.75       100      0.9519753  0.6983333  0.9925926
  0.4  1          0.8               0.75       150      0.9484877  0.6983333  0.9851852
  0.4  1          0.8               1.00        50      0.9416512  0.5525000  0.9925926
  0.4  1          0.8               1.00       100      0.9577572  0.6183333  0.9901235
  0.4  1          0.8               1.00       150      0.9563066  0.6450000  0.9876543
  0.4  2          0.6               0.50        50      0.9420370  0.6441667  0.9950617
  0.4  2          0.6               0.50       100      0.9322119  0.6575000  0.9827160
  0.4  2          0.6               0.50       150      0.9326132  0.6575000  0.9851852
  0.4  2          0.6               0.75        50      0.9530761  0.6575000  0.9950617
  0.4  2          0.6               0.75       100      0.9522016  0.7383333  0.9876543
  0.4  2          0.6               0.75       150      0.9504527  0.7508333  0.9802469
  0.4  2          0.6               1.00        50      0.9501440  0.6450000  0.9950617
  0.4  2          0.6               1.00       100      0.9587346  0.6575000  0.9901235
  0.4  2          0.6               1.00       150      0.9556379  0.7108333  0.9851852
  0.4  2          0.8               0.50        50      0.9450514  0.6583333  0.9876543
  0.4  2          0.8               0.50       100      0.9345165  0.6716667  0.9851852
  0.4  2          0.8               0.50       150      0.9325309  0.6708333  0.9827160
  0.4  2          0.8               0.75        50      0.9574486  0.6075000  0.9950617
  0.4  2          0.8               0.75       100      0.9510905  0.6716667  0.9827160
  0.4  2          0.8               0.75       150      0.9492284  0.6458333  0.9851852
  0.4  2          0.8               1.00        50      0.9478704  0.6191667  0.9950617
  0.4  2          0.8               1.00       100      0.9553498  0.6450000  0.9876543
  0.4  2          0.8               1.00       150      0.9536523  0.6716667  0.9876543
  0.4  3          0.6               0.50        50      0.9501235  0.6325000  0.9827160
  0.4  3          0.6               0.50       100      0.9506996  0.6850000  0.9827160
  0.4  3          0.6               0.50       150      0.9469959  0.7108333  0.9827160
  0.4  3          0.6               0.75        50      0.9507407  0.6450000  0.9876543
  0.4  3          0.6               0.75       100      0.9449897  0.6850000  0.9827160
  0.4  3          0.6               0.75       150      0.9492593  0.6716667  0.9802469
  0.4  3          0.6               1.00        50      0.9612037  0.6441667  0.9950617
  0.4  3          0.6               1.00       100      0.9592695  0.6716667  0.9901235
  0.4  3          0.6               1.00       150      0.9582922  0.6850000  0.9876543
  0.4  3          0.8               0.50        50      0.9430864  0.6716667  0.9802469
  0.4  3          0.8               0.50       100      0.9408848  0.6466667  0.9851852
  0.4  3          0.8               0.50       150      0.9396193  0.6725000  0.9851852
  0.4  3          0.8               0.75        50      0.9574177  0.6316667  0.9901235
  0.4  3          0.8               0.75       100      0.9526543  0.6841667  0.9851852
  0.4  3          0.8               0.75       150      0.9490947  0.6716667  0.9827160
  0.4  3          0.8               1.00        50      0.9561111  0.6308333  0.9901235
  0.4  3          0.8               1.00       100      0.9512140  0.6841667  0.9876543
  0.4  3          0.8               1.00       150      0.9509362  0.6316667  0.9851852

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.2      0.4
  positive      5.6     83.8
                            
 Accuracy (average) : 0.9397

[1] "TEST accuracy: 0.93970893970894"
[1] "TEST +precision: 0.937209302325581"
[1] "TEST -precision: 0.96078431372549"
[1] "TEST specifity: 0.644736842105263"
[1] "TEST sensitivity: 0.995061728395062"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       14        3
            positive        9      135
[1] "TEST accuracy: 0.925465838509317"
[1] "TEST +precision: 0.9375"
[1] "TEST -precision: 0.823529411764706"
[1] "TEST specifity: 0.608695652173913"
[1] "TEST sensitivity: 0.978260869565217"
