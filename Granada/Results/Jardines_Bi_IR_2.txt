[1] "DATASET NAME: Jardines_Bi_IR_2"
[1] "TRAIN INSTANCES: 989"
[1] "TEST INSTANCES: 223"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 4.52392792701721"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

989 samples
959 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 791, 791, 791, 791, 792 
Resampling results:

  ROC  Sens  Spec
  1    1     1   

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.9      0.0
  positive      0.0     66.1
                       
 Accuracy (average) : 1

[1] "TEST accuracy: 1"
[1] "TEST +precision: 1"
[1] "TEST -precision: 1"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        5      218
[1] "TEST accuracy: 0.977578475336323"
[1] "TEST +precision: 0.977578475336323"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.41827796697617"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

989 samples
959 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 791, 791, 791, 791, 792 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.9971373  1     0.9892543
  0.010  2  0.9971373  1     0.9892543
  0.010  3  0.9970347  1     0.9877275
  0.255  1  0.9971373  1     0.9892543
  0.255  2  0.9971373  1     0.9892543
  0.255  3  0.9970347  1     0.9877275
  0.500  1  0.9973537  1     0.9907810
  0.500  2  0.9973537  1     0.9907810
  0.500  3  0.9970347  1     0.9877275

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.9      0.6
  positive      0.0     65.5
                            
 Accuracy (average) : 0.9939

[1] "TEST accuracy: 0.993933265925177"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.982404692082111"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.990825688073395"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        5      218
[1] "TEST accuracy: 0.977578475336323"
[1] "TEST +precision: 0.977578475336323"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.8397811015447"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

989 samples
959 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 791, 791, 791, 791, 792 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9992594  0.9761194  0.9877745
  0.3  1          0.6               0.50       100      1.0000000  1.0000000  0.9893012
  0.3  1          0.6               0.50       150      1.0000000  1.0000000  0.9984733
  0.3  1          0.6               0.75        50      0.9996924  0.9731343  0.9984733
  0.3  1          0.6               0.75       100      1.0000000  1.0000000  0.9954198
  0.3  1          0.6               0.75       150      1.0000000  1.0000000  0.9954198
  0.3  1          0.6               1.00        50      0.9989860  1.0000000  0.9938931
  0.3  1          0.6               1.00       100      0.9998177  1.0000000  0.9954198
  0.3  1          0.6               1.00       150      1.0000000  1.0000000  0.9969466
  0.3  1          0.8               0.50        50      0.9947135  0.9522388  0.9801292
  0.3  1          0.8               0.50       100      1.0000000  1.0000000  0.9893130
  0.3  1          0.8               0.50       150      1.0000000  1.0000000  0.9954198
  0.3  1          0.8               0.75        50      0.9993164  0.9761194  0.9893130
  0.3  1          0.8               0.75       100      1.0000000  1.0000000  0.9969466
  0.3  1          0.8               0.75       150      1.0000000  1.0000000  0.9969466
  0.3  1          0.8               1.00        50      0.9989404  1.0000000  0.9938931
  0.3  1          0.8               1.00       100      0.9998177  1.0000000  0.9954198
  0.3  1          0.8               1.00       150      1.0000000  1.0000000  0.9969466
  0.3  2          0.6               0.50        50      1.0000000  1.0000000  0.9984733
  0.3  2          0.6               0.50       100      1.0000000  1.0000000  1.0000000
  0.3  2          0.6               0.50       150      1.0000000  1.0000000  1.0000000
  0.3  2          0.6               0.75        50      1.0000000  1.0000000  0.9969466
  0.3  2          0.6               0.75       100      1.0000000  1.0000000  0.9969466
  0.3  2          0.6               0.75       150      1.0000000  1.0000000  0.9984733
  0.3  2          0.6               1.00        50      1.0000000  1.0000000  0.9938931
  0.3  2          0.6               1.00       100      1.0000000  1.0000000  0.9969466
  0.3  2          0.6               1.00       150      1.0000000  1.0000000  0.9969466
  0.3  2          0.8               0.50        50      1.0000000  1.0000000  0.9969466
  0.3  2          0.8               0.50       100      1.0000000  1.0000000  0.9984733
  0.3  2          0.8               0.50       150      1.0000000  1.0000000  1.0000000
  0.3  2          0.8               0.75        50      1.0000000  1.0000000  0.9969466
  0.3  2          0.8               0.75       100      1.0000000  1.0000000  0.9954198
  0.3  2          0.8               0.75       150      1.0000000  1.0000000  0.9984733
  0.3  2          0.8               1.00        50      0.9998177  1.0000000  0.9969466
  0.3  2          0.8               1.00       100      1.0000000  1.0000000  0.9969466
  0.3  2          0.8               1.00       150      1.0000000  1.0000000  0.9969466
  0.3  3          0.6               0.50        50      1.0000000  1.0000000  1.0000000
  0.3  3          0.6               0.50       100      1.0000000  1.0000000  1.0000000
  0.3  3          0.6               0.50       150      1.0000000  1.0000000  1.0000000
  0.3  3          0.6               0.75        50      1.0000000  1.0000000  0.9984733
  0.3  3          0.6               0.75       100      1.0000000  1.0000000  0.9984733
  0.3  3          0.6               0.75       150      1.0000000  1.0000000  0.9984733
  0.3  3          0.6               1.00        50      1.0000000  1.0000000  0.9969466
  0.3  3          0.6               1.00       100      1.0000000  1.0000000  0.9984733
  0.3  3          0.6               1.00       150      1.0000000  1.0000000  0.9984733
  0.3  3          0.8               0.50        50      1.0000000  1.0000000  0.9938814
  0.3  3          0.8               0.50       100      1.0000000  1.0000000  0.9953964
  0.3  3          0.8               0.50       150      1.0000000  1.0000000  0.9969231
  0.3  3          0.8               0.75        50      1.0000000  1.0000000  0.9969466
  0.3  3          0.8               0.75       100      1.0000000  1.0000000  0.9984733
  0.3  3          0.8               0.75       150      1.0000000  1.0000000  0.9984733
  0.3  3          0.8               1.00        50      1.0000000  1.0000000  0.9969466
  0.3  3          0.8               1.00       100      1.0000000  1.0000000  0.9969466
  0.3  3          0.8               1.00       150      1.0000000  1.0000000  0.9984733
  0.4  1          0.6               0.50        50      0.9991455  1.0000000  0.9893130
  0.4  1          0.6               0.50       100      1.0000000  1.0000000  0.9969466
  0.4  1          0.6               0.50       150      1.0000000  1.0000000  0.9969466
  0.4  1          0.6               0.75        50      0.9995215  1.0000000  0.9938931
  0.4  1          0.6               0.75       100      1.0000000  1.0000000  0.9969466
  0.4  1          0.6               0.75       150      1.0000000  1.0000000  0.9954198
  0.4  1          0.6               1.00        50      0.9998177  1.0000000  0.9954198
  0.4  1          0.6               1.00       100      1.0000000  1.0000000  0.9969466
  0.4  1          0.6               1.00       150      1.0000000  1.0000000  0.9969466
  0.4  1          0.8               0.50        50      1.0000000  1.0000000  0.9954198
  0.4  1          0.8               0.50       100      1.0000000  1.0000000  0.9954198
  0.4  1          0.8               0.50       150      1.0000000  1.0000000  0.9954198
  0.4  1          0.8               0.75        50      1.0000000  1.0000000  0.9969466
  0.4  1          0.8               0.75       100      1.0000000  1.0000000  0.9954198
  0.4  1          0.8               0.75       150      1.0000000  1.0000000  0.9938931
  0.4  1          0.8               1.00        50      1.0000000  1.0000000  0.9938931
  0.4  1          0.8               1.00       100      1.0000000  1.0000000  0.9954198
  0.4  1          0.8               1.00       150      1.0000000  1.0000000  0.9969466
  0.4  2          0.6               0.50        50      1.0000000  1.0000000  0.9984733
  0.4  2          0.6               0.50       100      1.0000000  1.0000000  0.9984733
  0.4  2          0.6               0.50       150      1.0000000  1.0000000  0.9984733
  0.4  2          0.6               0.75        50      1.0000000  1.0000000  0.9938931
  0.4  2          0.6               0.75       100      1.0000000  1.0000000  0.9984733
  0.4  2          0.6               0.75       150      1.0000000  1.0000000  0.9984733
  0.4  2          0.6               1.00        50      1.0000000  1.0000000  0.9969466
  0.4  2          0.6               1.00       100      1.0000000  1.0000000  0.9969466
  0.4  2          0.6               1.00       150      1.0000000  1.0000000  0.9984733
  0.4  2          0.8               0.50        50      1.0000000  1.0000000  0.9984733
  0.4  2          0.8               0.50       100      1.0000000  1.0000000  0.9984733
  0.4  2          0.8               0.50       150      1.0000000  1.0000000  0.9984733
  0.4  2          0.8               0.75        50      1.0000000  1.0000000  0.9969466
  0.4  2          0.8               0.75       100      1.0000000  1.0000000  0.9984733
  0.4  2          0.8               0.75       150      1.0000000  1.0000000  0.9984733
  0.4  2          0.8               1.00        50      1.0000000  1.0000000  0.9969466
  0.4  2          0.8               1.00       100      1.0000000  1.0000000  0.9969466
  0.4  2          0.8               1.00       150      1.0000000  1.0000000  0.9984733
  0.4  3          0.6               0.50        50      1.0000000  1.0000000  1.0000000
  0.4  3          0.6               0.50       100      1.0000000  1.0000000  1.0000000
  0.4  3          0.6               0.50       150      1.0000000  1.0000000  1.0000000
  0.4  3          0.6               0.75        50      1.0000000  1.0000000  0.9984733
  0.4  3          0.6               0.75       100      1.0000000  1.0000000  1.0000000
  0.4  3          0.6               0.75       150      1.0000000  1.0000000  1.0000000
  0.4  3          0.6               1.00        50      1.0000000  1.0000000  0.9984733
  0.4  3          0.6               1.00       100      1.0000000  1.0000000  0.9984733
  0.4  3          0.6               1.00       150      1.0000000  1.0000000  0.9984733
  0.4  3          0.8               0.50        50      1.0000000  1.0000000  0.9984615
  0.4  3          0.8               0.50       100      1.0000000  1.0000000  0.9984615
  0.4  3          0.8               0.50       150      1.0000000  1.0000000  0.9984615
  0.4  3          0.8               0.75        50      1.0000000  1.0000000  0.9969466
  0.4  3          0.8               0.75       100      1.0000000  1.0000000  0.9984733
  0.4  3          0.8               0.75       150      1.0000000  1.0000000  0.9984733
  0.4  3          0.8               1.00        50      1.0000000  1.0000000  0.9984733
  0.4  3          0.8               1.00       100      1.0000000  1.0000000  1.0000000
  0.4  3          0.8               1.00       150      1.0000000  1.0000000  1.0000000

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 1, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.5.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.9      0.3
  positive      0.0     65.8
                           
 Accuracy (average) : 0.997

[1] "TEST accuracy: 0.996966632962588"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.99112426035503"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.995412844036697"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        2
            positive        5      216
[1] "TEST accuracy: 0.968609865470852"
[1] "TEST +precision: 0.97737556561086"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.990825688073395"
