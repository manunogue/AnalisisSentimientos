[1] "DATASET NAME: Estrellas_Uni_IR_0"
[1] "TRAIN INSTANCES: 414"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.20368504524231"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

414 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 331, 331, 332, 331, 331 
Resampling results:

  ROC        Sens       Spec     
  0.9612953  0.6666667  0.9843814

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      4.8      1.4
  positive      2.4     91.3
                            
 Accuracy (average) : 0.9614

[1] "TEST accuracy: 0.961352657004831"
[1] "TEST +precision: 0.974226804123711"
[1] "TEST -precision: 0.769230769230769"
[1] "TEST specifity: 0.666666666666667"
[1] "TEST sensitivity: 0.984375"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9        1
            positive        7      121
[1] "TEST accuracy: 0.942028985507246"
[1] "TEST +precision: 0.9453125"
[1] "TEST -precision: 0.9"
[1] "TEST specifity: 0.5625"
[1] "TEST sensitivity: 0.991803278688525"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.06841684977214"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

414 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 331, 332, 331, 331, 331 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.5000000  0.0000000  1.0000000
  0.010  2  0.5000000  0.0000000  1.0000000
  0.010  3  0.5000000  0.0000000  1.0000000
  0.255  1  0.5582935  0.1666667  0.9635680
  0.255  2  0.5766917  0.1000000  0.9583732
  0.255  3  0.5275604  0.1000000  0.9557758
  0.500  1  0.5709615  0.1666667  0.9609706
  0.500  2  0.5709643  0.1000000  0.9557758
  0.500  3  0.5297249  0.1333333  0.9479836

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.7      3.9
  positive      6.5     88.9
                            
 Accuracy (average) : 0.8961

[1] "TEST accuracy: 0.896135265700483"
[1] "TEST +precision: 0.931645569620253"
[1] "TEST -precision: 0.157894736842105"
[1] "TEST specifity: 0.1"
[1] "TEST sensitivity: 0.958333333333333"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        0
            positive       15      122
[1] "TEST accuracy: 0.891304347826087"
[1] "TEST +precision: 0.89051094890511"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.0625"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 1.94435441493988"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

414 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 332, 331, 331, 331, 331 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8738437  0.1666667  0.9870130
  0.3  1          0.6               0.50       100      0.8747722  0.2666667  0.9896104
  0.3  1          0.6               0.50       150      0.8595637  0.2333333  0.9896104
  0.3  1          0.6               0.75        50      0.8879756  0.1666667  0.9922078
  0.3  1          0.6               0.75       100      0.8914445  0.2666667  0.9896104
  0.3  1          0.6               0.75       150      0.8890465  0.2666667  0.9843814
  0.3  1          0.6               1.00        50      0.8882547  0.1666667  0.9974026
  0.3  1          0.6               1.00       100      0.9025177  0.2333333  0.9922078
  0.3  1          0.6               1.00       150      0.8926920  0.2333333  0.9843814
  0.3  1          0.8               0.50        50      0.8480349  0.2000000  0.9948052
  0.3  1          0.8               0.50       100      0.8609023  0.3000000  0.9896104
  0.3  1          0.8               0.50       150      0.8608339  0.3333333  0.9843814
  0.3  1          0.8               0.75        50      0.8543518  0.2333333  0.9922078
  0.3  1          0.8               0.75       100      0.8676236  0.2000000  0.9869788
  0.3  1          0.8               0.75       150      0.8842561  0.3000000  0.9869788
  0.3  1          0.8               1.00        50      0.8784803  0.1666667  0.9948052
  0.3  1          0.8               1.00       100      0.8916496  0.2333333  0.9896104
  0.3  1          0.8               1.00       150      0.8852700  0.2333333  0.9843814
  0.3  2          0.6               0.50        50      0.8815277  0.3000000  0.9896104
  0.3  2          0.6               0.50       100      0.8676749  0.2666667  0.9870130
  0.3  2          0.6               0.50       150      0.8528993  0.3666667  0.9844156
  0.3  2          0.6               0.75        50      0.9101105  0.1666667  0.9896104
  0.3  2          0.6               0.75       100      0.8875826  0.2666667  0.9922078
  0.3  2          0.6               0.75       150      0.8741570  0.2666667  0.9922078
  0.3  2          0.6               1.00        50      0.9127820  0.1666667  0.9922078
  0.3  2          0.6               1.00       100      0.9062315  0.2666667  0.9869788
  0.3  2          0.6               1.00       150      0.8872180  0.2666667  0.9895762
  0.3  2          0.8               0.50        50      0.8739348  0.2333333  0.9896104
  0.3  2          0.8               0.50       100      0.8539303  0.2333333  0.9870130
  0.3  2          0.8               0.50       150      0.8525803  0.2666667  0.9844156
  0.3  2          0.8               0.75        50      0.8845409  0.2333333  0.9922078
  0.3  2          0.8               0.75       100      0.8745215  0.2666667  0.9869788
  0.3  2          0.8               0.75       150      0.8615117  0.2666667  0.9895762
  0.3  2          0.8               1.00        50      0.9028594  0.2000000  0.9922078
  0.3  2          0.8               1.00       100      0.8948052  0.2333333  0.9896104
  0.3  2          0.8               1.00       150      0.8775177  0.2333333  0.9895762
  0.3  3          0.6               0.50        50      0.9020335  0.2333333  0.9922078
  0.3  3          0.6               0.50       100      0.8864548  0.2333333  0.9895762
  0.3  3          0.6               0.50       150      0.8682502  0.2666667  0.9895762
  0.3  3          0.6               0.75        50      0.9046936  0.3333333  0.9948052
  0.3  3          0.6               0.75       100      0.8838460  0.3000000  0.9922078
  0.3  3          0.6               0.75       150      0.8686660  0.3333333  0.9922078
  0.3  3          0.6               1.00        50      0.8957052  0.2000000  0.9896104
  0.3  3          0.6               1.00       100      0.8979209  0.2000000  0.9896104
  0.3  3          0.6               1.00       150      0.8805935  0.2000000  0.9896104
  0.3  3          0.8               0.50        50      0.8535373  0.2333333  0.9869788
  0.3  3          0.8               0.50       100      0.8404762  0.2666667  0.9870130
  0.3  3          0.8               0.50       150      0.8248291  0.2666667  0.9870130
  0.3  3          0.8               0.75        50      0.8701868  0.2333333  0.9948052
  0.3  3          0.8               0.75       100      0.8533151  0.1666667  0.9948052
  0.3  3          0.8               0.75       150      0.8294201  0.2000000  0.9922078
  0.3  3          0.8               1.00        50      0.8961495  0.2333333  0.9922078
  0.3  3          0.8               1.00       100      0.8779790  0.2666667  0.9922078
  0.3  3          0.8               1.00       150      0.8632604  0.3000000  0.9922078
  0.4  1          0.6               0.50        50      0.8837947  0.3000000  0.9921736
  0.4  1          0.6               0.50       100      0.8902370  0.3666667  0.9843814
  0.4  1          0.6               0.50       150      0.8863238  0.3333333  0.9817840
  0.4  1          0.6               0.75        50      0.9053087  0.3000000  0.9922078
  0.4  1          0.6               0.75       100      0.8976190  0.3000000  0.9869788
  0.4  1          0.6               0.75       150      0.9007348  0.3666667  0.9921736
  0.4  1          0.6               1.00        50      0.8851390  0.1666667  0.9948052
  0.4  1          0.6               1.00       100      0.8914103  0.2666667  0.9843814
  0.4  1          0.6               1.00       150      0.8769708  0.2666667  0.9843814
  0.4  1          0.8               0.50        50      0.8389724  0.3000000  0.9922078
  0.4  1          0.8               0.50       100      0.8608054  0.2666667  0.9896104
  0.4  1          0.8               0.50       150      0.8477330  0.3000000  0.9843814
  0.4  1          0.8               0.75        50      0.8785828  0.3000000  0.9896104
  0.4  1          0.8               0.75       100      0.8746070  0.3333333  0.9870130
  0.4  1          0.8               0.75       150      0.8559866  0.3333333  0.9869788
  0.4  1          0.8               1.00        50      0.8969070  0.2000000  0.9948052
  0.4  1          0.8               1.00       100      0.8809695  0.2000000  0.9843814
  0.4  1          0.8               1.00       150      0.8679141  0.2333333  0.9843814
  0.4  2          0.6               0.50        50      0.8544144  0.2000000  0.9870130
  0.4  2          0.6               0.50       100      0.8379471  0.2666667  0.9870130
  0.4  2          0.6               0.50       150      0.8526601  0.2333333  0.9870130
  0.4  2          0.6               0.75        50      0.8976589  0.2666667  0.9922078
  0.4  2          0.6               0.75       100      0.8773012  0.3000000  0.9922078
  0.4  2          0.6               0.75       150      0.8417293  0.3000000  0.9922078
  0.4  2          0.6               1.00        50      0.8970950  0.1666667  0.9896104
  0.4  2          0.6               1.00       100      0.8854010  0.2333333  0.9895762
  0.4  2          0.6               1.00       150      0.8702495  0.2000000  0.9895762
  0.4  2          0.8               0.50        50      0.8852016  0.3000000  0.9843814
  0.4  2          0.8               0.50       100      0.8752051  0.3000000  0.9869788
  0.4  2          0.8               0.50       150      0.8461950  0.3000000  0.9870130
  0.4  2          0.8               0.75        50      0.8556733  0.3000000  0.9870130
  0.4  2          0.8               0.75       100      0.8317555  0.2666667  0.9869788
  0.4  2          0.8               0.75       150      0.8079175  0.2666667  0.9895762
  0.4  2          0.8               1.00        50      0.8885111  0.2666667  0.9922078
  0.4  2          0.8               1.00       100      0.8771018  0.2333333  0.9922078
  0.4  2          0.8               1.00       150      0.8584757  0.2000000  0.9896104
  0.4  3          0.6               0.50        50      0.8839200  0.2333333  0.9843814
  0.4  3          0.6               0.50       100      0.8665812  0.2666667  0.9869788
  0.4  3          0.6               0.50       150      0.8514240  0.2666667  0.9869788
  0.4  3          0.6               0.75        50      0.8756209  0.2666667  0.9896104
  0.4  3          0.6               0.75       100      0.8522101  0.2333333  0.9896104
  0.4  3          0.6               0.75       150      0.8370244  0.2000000  0.9896104
  0.4  3          0.6               1.00        50      0.8810321  0.2333333  0.9896104
  0.4  3          0.6               1.00       100      0.8485532  0.2666667  0.9896104
  0.4  3          0.6               1.00       150      0.8377136  0.2666667  0.9922078
  0.4  3          0.8               0.50        50      0.8404648  0.3333333  0.9895762
  0.4  3          0.8               0.50       100      0.8197084  0.3000000  0.9870130
  0.4  3          0.8               0.50       150      0.8201470  0.3000000  0.9896104
  0.4  3          0.8               0.75        50      0.8707393  0.1666667  0.9895762
  0.4  3          0.8               0.75       100      0.8468786  0.2333333  0.9895762
  0.4  3          0.8               0.75       150      0.8308612  0.2000000  0.9895762
  0.4  3          0.8               1.00        50      0.8991969  0.2000000  0.9895762
  0.4  3          0.8               1.00       100      0.8849054  0.2000000  0.9896104
  0.4  3          0.8               1.00       150      0.8818694  0.2000000  0.9896104

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 2, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.2      0.7
  positive      6.0     92.0
                            
 Accuracy (average) : 0.9324

[1] "TEST accuracy: 0.932367149758454"
[1] "TEST +precision: 0.938423645320197"
[1] "TEST -precision: 0.625"
[1] "TEST specifity: 0.166666666666667"
[1] "TEST sensitivity: 0.9921875"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        0
            positive       12      122
[1] "TEST accuracy: 0.91304347826087"
[1] "TEST +precision: 0.91044776119403"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.25"
[1] "TEST sensitivity: 1"
