[1] "DATASET NAME: Carmela_Bi_IR_1"
[1] "TRAIN INSTANCES: 570"
[1] "TEST INSTANCES: 103"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.76183795928955"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

570 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 456, 456, 456, 456, 456 
Resampling results:

  ROC  Sens  Spec
  1    1     1   

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative       50        0
  positive        0       50
                       
 Accuracy (average) : 1

[1] "TEST accuracy: 1"
[1] "TEST +precision: 1"
[1] "TEST -precision: 1"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        0
            positive       15       87
[1] "TEST accuracy: 0.854368932038835"
[1] "TEST +precision: 0.852941176470588"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.0625"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.61095546483994"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

570 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 456, 456, 456, 456, 456 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.9904586  1     0.9578947
  0.010  2  0.9939366  1     0.9508772
  0.010  3  0.9923053  1     0.9473684
  0.255  1  0.9923977  1     0.9754386
  0.255  2  0.9975685  1     0.9824561
  0.255  3  0.9953524  1     0.9684211
  0.500  1  0.9873807  1     0.9754386
  0.500  2  0.9968606  1     0.9824561
  0.500  3  0.9954448  1     0.9719298

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.9
  positive      0.0     49.1
                            
 Accuracy (average) : 0.9912

[1] "TEST accuracy: 0.991228070175439"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.982758620689655"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.982456140350877"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        0
            positive       15       87
[1] "TEST accuracy: 0.854368932038835"
[1] "TEST +precision: 0.852941176470588"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.0625"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.90216610034307"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

570 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 456, 456, 456, 456, 456 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9841797  0.8701754  0.9754386
  0.3  1          0.6               0.50       100      0.9978763  1.0000000  0.9754386
  0.3  1          0.6               0.50       150      0.9977532  1.0000000  0.9754386
  0.3  1          0.6               0.75        50      0.9911050  0.8947368  0.9719298
  0.3  1          0.6               0.75       100      0.9926439  0.9824561  0.9754386
  0.3  1          0.6               0.75       150      0.9977532  1.0000000  0.9754386
  0.3  1          0.6               1.00        50      0.9942136  0.8561404  0.9964912
  0.3  1          0.6               1.00       100      0.9977532  0.9824561  0.9894737
  0.3  1          0.6               1.00       150      0.9977532  1.0000000  0.9894737
  0.3  1          0.8               0.50        50      0.9820560  0.8701754  0.9684211
  0.3  1          0.8               0.50       100      0.9904894  0.9859649  0.9649123
  0.3  1          0.8               0.50       150      0.9938443  1.0000000  0.9649123
  0.3  1          0.8               0.75        50      0.9901508  0.8771930  0.9754386
  0.3  1          0.8               0.75       100      0.9968914  1.0000000  0.9754386
  0.3  1          0.8               0.75       150      0.9977532  1.0000000  0.9754386
  0.3  1          0.8               1.00        50      0.9946445  0.8561404  0.9964912
  0.3  1          0.8               1.00       100      0.9975685  0.9824561  0.9894737
  0.3  1          0.8               1.00       150      0.9977532  1.0000000  0.9929825
  0.3  2          0.6               0.50        50      0.9959680  0.9403509  0.9859649
  0.3  2          0.6               0.50       100      0.9975993  0.9929825  0.9684211
  0.3  2          0.6               0.50       150      0.9983380  1.0000000  0.9684211
  0.3  2          0.6               0.75        50      0.9918436  1.0000000  0.9754386
  0.3  2          0.6               0.75       100      0.9971991  1.0000000  0.9789474
  0.3  2          0.6               0.75       150      0.9971068  1.0000000  0.9789474
  0.3  2          0.6               1.00        50      0.9965220  0.9824561  0.9754386
  0.3  2          0.6               1.00       100      0.9977532  1.0000000  0.9929825
  0.3  2          0.6               1.00       150      0.9977839  1.0000000  0.9929825
  0.3  2          0.8               0.50        50      0.9895352  0.9543860  0.9684211
  0.3  2          0.8               0.50       100      0.9961219  1.0000000  0.9649123
  0.3  2          0.8               0.50       150      0.9984611  1.0000000  0.9614035
  0.3  2          0.8               0.75        50      0.9938135  0.9824561  0.9824561
  0.3  2          0.8               0.75       100      0.9960911  1.0000000  0.9789474
  0.3  2          0.8               0.75       150      0.9983995  1.0000000  0.9754386
  0.3  2          0.8               1.00        50      0.9970145  1.0000000  0.9754386
  0.3  2          0.8               1.00       100      0.9977532  1.0000000  0.9929825
  0.3  2          0.8               1.00       150      0.9977839  1.0000000  0.9894737
  0.3  3          0.6               0.50        50      0.9974761  0.9649123  0.9719298
  0.3  3          0.6               0.50       100      0.9977839  1.0000000  0.9614035
  0.3  3          0.6               0.50       150      0.9980917  1.0000000  0.9649123
  0.3  3          0.6               0.75        50      0.9974761  1.0000000  0.9754386
  0.3  3          0.6               0.75       100      0.9984611  1.0000000  0.9719298
  0.3  3          0.6               0.75       150      0.9985842  1.0000000  0.9684211
  0.3  3          0.6               1.00        50      0.9983687  1.0000000  0.9894737
  0.3  3          0.6               1.00       100      0.9983995  1.0000000  0.9894737
  0.3  3          0.6               1.00       150      0.9984611  1.0000000  0.9754386
  0.3  3          0.8               0.50        50      0.9924900  0.9719298  0.9789474
  0.3  3          0.8               0.50       100      0.9929825  0.9929825  0.9649123
  0.3  3          0.8               0.50       150      0.9951370  0.9929825  0.9684211
  0.3  3          0.8               0.75        50      0.9955371  1.0000000  0.9754386
  0.3  3          0.8               0.75       100      0.9983995  1.0000000  0.9754386
  0.3  3          0.8               0.75       150      0.9983380  1.0000000  0.9719298
  0.3  3          0.8               1.00        50      0.9983687  1.0000000  0.9789474
  0.3  3          0.8               1.00       100      0.9985226  1.0000000  0.9789474
  0.3  3          0.8               1.00       150      0.9987073  1.0000000  0.9754386
  0.4  1          0.6               0.50        50      0.9778086  0.8877193  0.9719298
  0.4  1          0.6               0.50       100      0.9948600  0.9929825  0.9719298
  0.4  1          0.6               0.50       150      0.9962758  0.9929825  0.9719298
  0.4  1          0.6               0.75        50      0.9957525  0.9719298  0.9719298
  0.4  1          0.6               0.75       100      0.9986457  1.0000000  0.9894737
  0.4  1          0.6               0.75       150      0.9980302  1.0000000  0.9929825
  0.4  1          0.6               1.00        50      0.9964604  0.9473684  0.9894737
  0.4  1          0.6               1.00       100      0.9977532  1.0000000  0.9929825
  0.4  1          0.6               1.00       150      0.9977532  1.0000000  0.9929825
  0.4  1          0.8               0.50        50      0.9937827  0.9368421  0.9824561
  0.4  1          0.8               0.50       100      0.9952601  0.9824561  0.9754386
  0.4  1          0.8               0.50       150      0.9963681  1.0000000  0.9719298
  0.4  1          0.8               0.75        50      0.9911050  0.9543860  0.9719298
  0.4  1          0.8               0.75       100      0.9982148  1.0000000  0.9754386
  0.4  1          0.8               0.75       150      0.9983995  1.0000000  0.9754386
  0.4  1          0.8               1.00        50      0.9931979  0.9438596  0.9824561
  0.4  1          0.8               1.00       100      0.9977532  1.0000000  0.9894737
  0.4  1          0.8               1.00       150      0.9977532  1.0000000  0.9929825
  0.4  2          0.6               0.50        50      0.9957525  0.9684211  0.9754386
  0.4  2          0.6               0.50       100      0.9967375  1.0000000  0.9684211
  0.4  2          0.6               0.50       150      0.9966759  1.0000000  0.9614035
  0.4  2          0.6               0.75        50      0.9977532  1.0000000  0.9789474
  0.4  2          0.6               0.75       100      0.9983380  1.0000000  0.9754386
  0.4  2          0.6               0.75       150      0.9964912  1.0000000  0.9719298
  0.4  2          0.6               1.00        50      0.9983687  1.0000000  0.9929825
  0.4  2          0.6               1.00       100      0.9983687  1.0000000  0.9929825
  0.4  2          0.6               1.00       150      0.9983380  1.0000000  0.9859649
  0.4  2          0.8               0.50        50      0.9845183  0.9754386  0.9649123
  0.4  2          0.8               0.50       100      0.9865189  0.9754386  0.9614035
  0.4  2          0.8               0.50       150      0.9891043  0.9754386  0.9614035
  0.4  2          0.8               0.75        50      0.9945522  1.0000000  0.9719298
  0.4  2          0.8               0.75       100      0.9983995  1.0000000  0.9754386
  0.4  2          0.8               0.75       150      0.9981533  1.0000000  0.9719298
  0.4  2          0.8               1.00        50      0.9977532  1.0000000  0.9894737
  0.4  2          0.8               1.00       100      0.9977532  1.0000000  0.9929825
  0.4  2          0.8               1.00       150      0.9983995  1.0000000  0.9789474
  0.4  3          0.6               0.50        50      0.9952601  0.9929825  0.9719298
  0.4  3          0.6               0.50       100      0.9934749  1.0000000  0.9614035
  0.4  3          0.6               0.50       150      0.9943367  1.0000000  0.9614035
  0.4  3          0.6               0.75        50      0.9977532  1.0000000  0.9894737
  0.4  3          0.6               0.75       100      0.9983995  1.0000000  0.9684211
  0.4  3          0.6               0.75       150      0.9983380  1.0000000  0.9684211
  0.4  3          0.6               1.00        50      0.9986457  1.0000000  0.9929825
  0.4  3          0.6               1.00       100      0.9990766  1.0000000  0.9754386
  0.4  3          0.6               1.00       150      0.9980917  1.0000000  0.9719298
  0.4  3          0.8               0.50        50      0.9881810  0.9859649  0.9649123
  0.4  3          0.8               0.50       100      0.9908895  0.9859649  0.9578947
  0.4  3          0.8               0.50       150      0.9884272  0.9859649  0.9614035
  0.4  3          0.8               0.75        50      0.9977839  1.0000000  0.9754386
  0.4  3          0.8               0.75       100      0.9983380  1.0000000  0.9719298
  0.4  3          0.8               0.75       150      0.9984611  1.0000000  0.9719298
  0.4  3          0.8               1.00        50      0.9977532  1.0000000  0.9929825
  0.4  3          0.8               1.00       100      0.9985226  1.0000000  0.9754386
  0.4  3          0.8               1.00       150      0.9983995  1.0000000  0.9754386

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      1.2
  positive      0.0     48.8
                            
 Accuracy (average) : 0.9877

[1] "TEST accuracy: 0.987719298245614"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.976027397260274"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.975438596491228"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        0
            positive       15       87
[1] "TEST accuracy: 0.854368932038835"
[1] "TEST +precision: 0.852941176470588"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.0625"
[1] "TEST sensitivity: 1"
