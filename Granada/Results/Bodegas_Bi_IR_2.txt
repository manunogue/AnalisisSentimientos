[1] "DATASET NAME: Bodegas_Bi_IR_2"
[1] "TRAIN INSTANCES: 649"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.87048006057739"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

649 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 519, 519, 519, 520, 519 
Resampling results:

  ROC        Sens       Spec     
  0.9907445  0.9541667  0.9828666

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     35.3      1.1
  positive      1.7     61.9
                            
 Accuracy (average) : 0.9723

[1] "TEST accuracy: 0.972265023112481"
[1] "TEST +precision: 0.973365617433414"
[1] "TEST -precision: 0.970338983050847"
[1] "TEST specifity: 0.954166666666667"
[1] "TEST sensitivity: 0.982885085574572"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       13        2
            positive       14      132
[1] "TEST accuracy: 0.900621118012422"
[1] "TEST +precision: 0.904109589041096"
[1] "TEST -precision: 0.866666666666667"
[1] "TEST specifity: 0.481481481481481"
[1] "TEST sensitivity: 0.985074626865672"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.53314509789149"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

649 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 519, 519, 519, 520, 519 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5666770  0.11250000  0.9950918
  0.010  2  0.5668549  0.11250000  0.9950918
  0.010  3  0.5466821  0.09583333  0.9975309
  0.255  1  0.7433711  0.22083333  0.9926227
  0.255  2  0.7101287  0.20833333  0.9877447
  0.255  3  0.6810138  0.19166667  0.9902138
  0.500  1  0.7446668  0.22083333  0.9926227
  0.500  2  0.7205435  0.20833333  0.9901837
  0.500  3  0.6954447  0.19583333  0.9902138

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      8.2      0.5
  positive     28.8     62.6
                            
 Accuracy (average) : 0.7072

[1] "TEST accuracy: 0.707241910631741"
[1] "TEST +precision: 0.684654300168634"
[1] "TEST -precision: 0.946428571428571"
[1] "TEST specifity: 0.220833333333333"
[1] "TEST sensitivity: 0.992665036674817"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        4
            positive       21      130
[1] "TEST accuracy: 0.84472049689441"
[1] "TEST +precision: 0.860927152317881"
[1] "TEST -precision: 0.6"
[1] "TEST specifity: 0.222222222222222"
[1] "TEST sensitivity: 0.970149253731343"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.07662824789683"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

649 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 519, 519, 519, 520, 519 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8607789  0.4166667  0.9878049
  0.3  1          0.6               0.50       100      0.9010856  0.5083333  0.9731406
  0.3  1          0.6               0.50       150      0.9186045  0.6041667  0.9755495
  0.3  1          0.6               0.75        50      0.8760586  0.4500000  0.9853357
  0.3  1          0.6               0.75       100      0.9202960  0.6125000  0.9877748
  0.3  1          0.6               0.75       150      0.9339905  0.6791667  0.9828666
  0.3  1          0.6               1.00        50      0.8813962  0.4250000  0.9878049
  0.3  1          0.6               1.00       100      0.9246145  0.5666667  0.9878049
  0.3  1          0.6               1.00       150      0.9431810  0.6750000  0.9779886
  0.3  1          0.8               0.50        50      0.8779089  0.4250000  0.9853357
  0.3  1          0.8               0.50       100      0.9165632  0.5708333  0.9828967
  0.3  1          0.8               0.50       150      0.9291256  0.6375000  0.9803975
  0.3  1          0.8               0.75        50      0.8792837  0.4166667  0.9902439
  0.3  1          0.8               0.75       100      0.9258939  0.5791667  0.9878049
  0.3  1          0.8               0.75       150      0.9384560  0.6833333  0.9779886
  0.3  1          0.8               1.00        50      0.8817945  0.4375000  0.9902439
  0.3  1          0.8               1.00       100      0.9271276  0.5833333  0.9878049
  0.3  1          0.8               1.00       150      0.9436136  0.6791667  0.9804276
  0.3  2          0.6               0.50        50      0.9078418  0.5625000  0.9877748
  0.3  2          0.6               0.50       100      0.9342997  0.6666667  0.9828666
  0.3  2          0.6               0.50       150      0.9381916  0.6875000  0.9584463
  0.3  2          0.6               0.75        50      0.9263208  0.5916667  0.9853056
  0.3  2          0.6               0.75       100      0.9443067  0.6958333  0.9682325
  0.3  2          0.6               0.75       150      0.9502437  0.7333333  0.9657633
  0.3  2          0.6               1.00        50      0.9269601  0.5875000  0.9878049
  0.3  2          0.6               1.00       100      0.9438036  0.6958333  0.9804276
  0.3  2          0.6               1.00       150      0.9547745  0.7375000  0.9730804
  0.3  2          0.8               0.50        50      0.9089293  0.5833333  0.9779886
  0.3  2          0.8               0.50       100      0.9304009  0.6583333  0.9681722
  0.3  2          0.8               0.50       150      0.9375129  0.6916667  0.9608552
  0.3  2          0.8               0.75        50      0.9289010  0.6000000  0.9828967
  0.3  2          0.8               0.75       100      0.9421726  0.7041667  0.9755194
  0.3  2          0.8               0.75       150      0.9503830  0.7375000  0.9608251
  0.3  2          0.8               1.00        50      0.9273324  0.6000000  0.9828666
  0.3  2          0.8               1.00       100      0.9455953  0.6958333  0.9779886
  0.3  2          0.8               1.00       150      0.9543687  0.7416667  0.9706414
  0.3  3          0.6               0.50        50      0.9192942  0.6041667  0.9731105
  0.3  3          0.6               0.50       100      0.9313058  0.6958333  0.9681421
  0.3  3          0.6               0.50       150      0.9375458  0.7208333  0.9510690
  0.3  3          0.6               0.75        50      0.9424602  0.6833333  0.9730804
  0.3  3          0.6               0.75       100      0.9549919  0.7708333  0.9657633
  0.3  3          0.6               0.75       150      0.9524400  0.7791667  0.9560072
  0.3  3          0.6               1.00        50      0.9453308  0.6750000  0.9828967
  0.3  3          0.6               1.00       100      0.9586413  0.7458333  0.9779886
  0.3  3          0.6               1.00       150      0.9564495  0.7958333  0.9608853
  0.3  3          0.8               0.50        50      0.9228941  0.6416667  0.9828666
  0.3  3          0.8               0.50       100      0.9387364  0.6958333  0.9730503
  0.3  3          0.8               0.50       150      0.9391734  0.7375000  0.9632942
  0.3  3          0.8               0.75        50      0.9347492  0.6791667  0.9779886
  0.3  3          0.8               0.75       100      0.9502657  0.7375000  0.9633243
  0.3  3          0.8               0.75       150      0.9496230  0.7833333  0.9510991
  0.3  3          0.8               1.00        50      0.9442842  0.6833333  0.9804276
  0.3  3          0.8               1.00       100      0.9572136  0.7500000  0.9730804
  0.3  3          0.8               1.00       150      0.9566289  0.8125000  0.9608853
  0.4  1          0.6               0.50        50      0.8786134  0.4250000  0.9902138
  0.4  1          0.6               0.50       100      0.9206906  0.6333333  0.9706715
  0.4  1          0.6               0.50       150      0.9379542  0.6708333  0.9559771
  0.4  1          0.6               0.75        50      0.8977611  0.4916667  0.9853357
  0.4  1          0.6               0.75       100      0.9244906  0.6541667  0.9779886
  0.4  1          0.6               0.75       150      0.9338659  0.6791667  0.9730503
  0.4  1          0.6               1.00        50      0.9021498  0.4458333  0.9926829
  0.4  1          0.6               1.00       100      0.9356033  0.6666667  0.9755495
  0.4  1          0.6               1.00       150      0.9462674  0.6916667  0.9804276
  0.4  1          0.8               0.50        50      0.8759626  0.4625000  0.9804878
  0.4  1          0.8               0.50       100      0.9167868  0.6250000  0.9657633
  0.4  1          0.8               0.50       150      0.9245311  0.6625000  0.9608552
  0.4  1          0.8               0.75        50      0.8898292  0.4875000  0.9853357
  0.4  1          0.8               0.75       100      0.9273280  0.6291667  0.9828666
  0.4  1          0.8               0.75       150      0.9388635  0.7041667  0.9608552
  0.4  1          0.8               1.00        50      0.8945577  0.4500000  0.9878049
  0.4  1          0.8               1.00       100      0.9351962  0.6583333  0.9828666
  0.4  1          0.8               1.00       150      0.9469785  0.7000000  0.9804276
  0.4  2          0.6               0.50        50      0.9100450  0.6083333  0.9706715
  0.4  2          0.6               0.50       100      0.9331793  0.7083333  0.9632942
  0.4  2          0.6               0.50       150      0.9372466  0.7250000  0.9560072
  0.4  2          0.6               0.75        50      0.9250060  0.6666667  0.9804577
  0.4  2          0.6               0.75       100      0.9412843  0.7208333  0.9681722
  0.4  2          0.6               0.75       150      0.9462963  0.7500000  0.9608853
  0.4  2          0.6               1.00        50      0.9400814  0.6875000  0.9804276
  0.4  2          0.6               1.00       100      0.9565251  0.7250000  0.9755194
  0.4  2          0.6               1.00       150      0.9549994  0.7958333  0.9657332
  0.4  2          0.8               0.50        50      0.9185420  0.6250000  0.9804276
  0.4  2          0.8               0.50       100      0.9369414  0.6791667  0.9681722
  0.4  2          0.8               0.50       150      0.9392659  0.7208333  0.9535381
  0.4  2          0.8               0.75        50      0.9332236  0.6416667  0.9828666
  0.4  2          0.8               0.75       100      0.9490647  0.7250000  0.9657633
  0.4  2          0.8               0.75       150      0.9499793  0.7625000  0.9682023
  0.4  2          0.8               1.00        50      0.9343483  0.6708333  0.9828967
  0.4  2          0.8               1.00       100      0.9533163  0.7291667  0.9755194
  0.4  2          0.8               1.00       150      0.9513124  0.7750000  0.9706414
  0.4  3          0.6               0.50        50      0.9314947  0.6333333  0.9681722
  0.4  3          0.6               0.50       100      0.9448299  0.7208333  0.9583860
  0.4  3          0.6               0.50       150      0.9442359  0.7541667  0.9511292
  0.4  3          0.6               0.75        50      0.9462282  0.7041667  0.9706414
  0.4  3          0.6               0.75       100      0.9504002  0.7791667  0.9584161
  0.4  3          0.6               0.75       150      0.9490575  0.7791667  0.9511292
  0.4  3          0.6               1.00        50      0.9509717  0.6958333  0.9828666
  0.4  3          0.6               1.00       100      0.9575671  0.7833333  0.9633544
  0.4  3          0.6               1.00       150      0.9543291  0.8125000  0.9609154
  0.4  3          0.8               0.50        50      0.9216815  0.6625000  0.9657633
  0.4  3          0.8               0.50       100      0.9341435  0.7083333  0.9462511
  0.4  3          0.8               0.50       150      0.9396624  0.7416667  0.9437820
  0.4  3          0.8               0.75        50      0.9418549  0.7041667  0.9731105
  0.4  3          0.8               0.75       100      0.9497400  0.7791667  0.9559771
  0.4  3          0.8               0.75       150      0.9503375  0.7833333  0.9559771
  0.4  3          0.8               1.00        50      0.9459230  0.7000000  0.9779886
  0.4  3          0.8               1.00       100      0.9554313  0.7958333  0.9608853
  0.4  3          0.8               1.00       150      0.9549599  0.8250000  0.9608853

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     27.6      1.4
  positive      9.4     61.6
                            
 Accuracy (average) : 0.8921

[1] "TEST accuracy: 0.892141756548536"
[1] "TEST +precision: 0.867678958785249"
[1] "TEST -precision: 0.952127659574468"
[1] "TEST specifity: 0.745833333333333"
[1] "TEST sensitivity: 0.97799511002445"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       11        4
            positive       16      130
[1] "TEST accuracy: 0.875776397515528"
[1] "TEST +precision: 0.89041095890411"
[1] "TEST -precision: 0.733333333333333"
[1] "TEST specifity: 0.407407407407407"
[1] "TEST sensitivity: 0.970149253731343"
