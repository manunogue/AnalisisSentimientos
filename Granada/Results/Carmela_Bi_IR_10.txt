[1] "DATASET NAME: Carmela_Bi_IR_10"
[1] "TRAIN INSTANCES: 334"
[1] "TEST INSTANCES: 103"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.02615904808044"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

334 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 267, 267, 268, 267, 267 
Resampling results:

  ROC        Sens       Spec
  0.9559454  0.8111111  1   

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     12.0      0.0
  positive      2.7     85.3
                            
 Accuracy (average) : 0.9731

[1] "TEST accuracy: 0.973053892215569"
[1] "TEST +precision: 0.969387755102041"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.816326530612245"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        0
            positive       14       87
[1] "TEST accuracy: 0.864077669902913"
[1] "TEST +precision: 0.861386138613861"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.125"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.22684658368429"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

334 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 268, 267, 267, 267, 267 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec
  0.010  1  0.5000000  0.00  1   
  0.010  2  0.5000000  0.00  1   
  0.010  3  0.5000000  0.00  1   
  0.255  1  0.5157895  0.00  1   
  0.255  2  0.5157895  0.00  1   
  0.255  3  0.5157895  0.00  1   
  0.500  1  0.5638596  0.04  1   
  0.500  2  0.5638596  0.04  1   
  0.500  3  0.5157895  0.00  1   

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.6      0.0
  positive     14.1     85.3
                            
 Accuracy (average) : 0.8593

[1] "TEST accuracy: 0.859281437125748"
[1] "TEST +precision: 0.858433734939759"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.0408163265306122"
[1] "TEST sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       16       87
[1] "TEST accuracy: 0.844660194174757"
[1] "TEST +precision: 0.844660194174757"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 1.89785613218943"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

334 samples
967 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 267, 268, 267, 267, 267 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7174659  0.02000000  1.0000000
  0.3  1          0.6               0.50       100      0.6933333  0.06000000  1.0000000
  0.3  1          0.6               0.50       150      0.7165692  0.06000000  1.0000000
  0.3  1          0.6               0.75        50      0.7168031  0.12000000  1.0000000
  0.3  1          0.6               0.75       100      0.7634503  0.18000000  0.9964912
  0.3  1          0.6               0.75       150      0.7637427  0.18000000  0.9964912
  0.3  1          0.6               1.00        50      0.7683431  0.28444444  1.0000000
  0.3  1          0.6               1.00       100      0.7919493  0.28444444  1.0000000
  0.3  1          0.6               1.00       150      0.7921832  0.30444444  0.9894737
  0.3  1          0.8               0.50        50      0.6674464  0.04000000  1.0000000
  0.3  1          0.8               0.50       100      0.7015205  0.06000000  1.0000000
  0.3  1          0.8               0.50       150      0.6980117  0.06000000  1.0000000
  0.3  1          0.8               0.75        50      0.7195712  0.22000000  1.0000000
  0.3  1          0.8               0.75       100      0.7675439  0.24000000  1.0000000
  0.3  1          0.8               0.75       150      0.7723002  0.24000000  0.9964912
  0.3  1          0.8               1.00        50      0.7684211  0.24000000  1.0000000
  0.3  1          0.8               1.00       100      0.7795517  0.24000000  1.0000000
  0.3  1          0.8               1.00       150      0.7794347  0.24000000  1.0000000
  0.3  2          0.6               0.50        50      0.6685380  0.08000000  0.9964912
  0.3  2          0.6               0.50       100      0.6821053  0.10000000  0.9964912
  0.3  2          0.6               0.50       150      0.6879142  0.10000000  0.9964912
  0.3  2          0.6               0.75        50      0.7984990  0.26000000  0.9894737
  0.3  2          0.6               0.75       100      0.7993762  0.26000000  0.9894737
  0.3  2          0.6               0.75       150      0.8027680  0.24000000  1.0000000
  0.3  2          0.6               1.00        50      0.7988889  0.28444444  0.9964912
  0.3  2          0.6               1.00       100      0.7995322  0.30444444  0.9859649
  0.3  2          0.6               1.00       150      0.7946199  0.30444444  0.9859649
  0.3  2          0.8               0.50        50      0.7345809  0.06000000  0.9859649
  0.3  2          0.8               0.50       100      0.7511501  0.08000000  0.9929825
  0.3  2          0.8               0.50       150      0.7625341  0.06000000  0.9964912
  0.3  2          0.8               0.75        50      0.7979727  0.26444444  1.0000000
  0.3  2          0.8               0.75       100      0.8158674  0.26444444  0.9964912
  0.3  2          0.8               0.75       150      0.8140936  0.26444444  1.0000000
  0.3  2          0.8               1.00        50      0.8032749  0.28444444  1.0000000
  0.3  2          0.8               1.00       100      0.8026121  0.30444444  0.9894737
  0.3  2          0.8               1.00       150      0.8027290  0.30444444  0.9859649
  0.3  3          0.6               0.50        50      0.6915400  0.04000000  0.9894737
  0.3  3          0.6               0.50       100      0.6932943  0.04000000  0.9964912
  0.3  3          0.6               0.50       150      0.6982066  0.08000000  0.9964912
  0.3  3          0.6               0.75        50      0.7769006  0.22000000  1.0000000
  0.3  3          0.6               0.75       100      0.7802924  0.24000000  0.9894737
  0.3  3          0.6               0.75       150      0.7867251  0.22000000  0.9894737
  0.3  3          0.6               1.00        50      0.8208577  0.32444444  0.9789474
  0.3  3          0.6               1.00       100      0.8165302  0.32444444  0.9754386
  0.3  3          0.6               1.00       150      0.8141910  0.32444444  0.9754386
  0.3  3          0.8               0.50        50      0.7485965  0.14000000  0.9964912
  0.3  3          0.8               0.50       100      0.7556140  0.14000000  1.0000000
  0.3  3          0.8               0.50       150      0.7604483  0.14000000  1.0000000
  0.3  3          0.8               0.75        50      0.7773684  0.20000000  1.0000000
  0.3  3          0.8               0.75       100      0.7776023  0.20000000  0.9964912
  0.3  3          0.8               0.75       150      0.7845419  0.22000000  0.9824561
  0.3  3          0.8               1.00        50      0.8058285  0.30444444  0.9754386
  0.3  3          0.8               1.00       100      0.7974074  0.30444444  0.9719298
  0.3  3          0.8               1.00       150      0.8016179  0.30444444  0.9684211
  0.4  1          0.6               0.50        50      0.7042300  0.12000000  1.0000000
  0.4  1          0.6               0.50       100      0.7368616  0.14000000  0.9964912
  0.4  1          0.6               0.50       150      0.7330019  0.14000000  1.0000000
  0.4  1          0.6               0.75        50      0.7601559  0.10000000  1.0000000
  0.4  1          0.6               0.75       100      0.7718908  0.10000000  1.0000000
  0.4  1          0.6               0.75       150      0.7714230  0.10000000  1.0000000
  0.4  1          0.6               1.00        50      0.7813255  0.24000000  1.0000000
  0.4  1          0.6               1.00       100      0.7815205  0.22000000  0.9964912
  0.4  1          0.6               1.00       150      0.7797661  0.22000000  0.9964912
  0.4  1          0.8               0.50        50      0.7285770  0.08000000  1.0000000
  0.4  1          0.8               0.50       100      0.7250292  0.14000000  1.0000000
  0.4  1          0.8               0.50       150      0.7233138  0.14000000  1.0000000
  0.4  1          0.8               0.75        50      0.7621053  0.20000000  1.0000000
  0.4  1          0.8               0.75       100      0.7685575  0.22000000  0.9894737
  0.4  1          0.8               0.75       150      0.7671540  0.22000000  0.9859649
  0.4  1          0.8               1.00        50      0.7792788  0.24000000  1.0000000
  0.4  1          0.8               1.00       100      0.7783041  0.24000000  1.0000000
  0.4  1          0.8               1.00       150      0.7760234  0.24000000  1.0000000
  0.4  2          0.6               0.50        50      0.7596881  0.04222222  0.9929825
  0.4  2          0.6               0.50       100      0.7631384  0.08444444  0.9929825
  0.4  2          0.6               0.50       150      0.7742105  0.12444444  0.9964912
  0.4  2          0.6               0.75        50      0.7914620  0.22444444  0.9964912
  0.4  2          0.6               0.75       100      0.7939766  0.22444444  0.9929825
  0.4  2          0.6               0.75       150      0.7814620  0.22444444  0.9929825
  0.4  2          0.6               1.00        50      0.8047953  0.28444444  0.9894737
  0.4  2          0.6               1.00       100      0.8030799  0.28444444  0.9859649
  0.4  2          0.6               1.00       150      0.7999220  0.28444444  0.9859649
  0.4  2          0.8               0.50        50      0.7502924  0.08000000  1.0000000
  0.4  2          0.8               0.50       100      0.7481871  0.08000000  1.0000000
  0.4  2          0.8               0.50       150      0.7505263  0.08000000  1.0000000
  0.4  2          0.8               0.75        50      0.7628460  0.22000000  1.0000000
  0.4  2          0.8               0.75       100      0.7684795  0.22000000  0.9964912
  0.4  2          0.8               0.75       150      0.7705848  0.22000000  0.9964912
  0.4  2          0.8               1.00        50      0.8009357  0.28444444  1.0000000
  0.4  2          0.8               1.00       100      0.8053411  0.28444444  0.9964912
  0.4  2          0.8               1.00       150      0.8052242  0.28444444  0.9929825
  0.4  3          0.6               0.50        50      0.7172125  0.04000000  0.9929825
  0.4  3          0.6               0.50       100      0.7556725  0.06000000  0.9929825
  0.4  3          0.6               0.50       150      0.7546394  0.14222222  0.9859649
  0.4  3          0.6               0.75        50      0.7722222  0.12000000  1.0000000
  0.4  3          0.6               0.75       100      0.7789474  0.14000000  0.9894737
  0.4  3          0.6               0.75       150      0.7816374  0.12000000  0.9964912
  0.4  3          0.6               1.00        50      0.7914230  0.32444444  0.9789474
  0.4  3          0.6               1.00       100      0.7902534  0.32444444  0.9789474
  0.4  3          0.6               1.00       150      0.7947368  0.32444444  0.9789474
  0.4  3          0.8               0.50        50      0.7331774  0.08000000  1.0000000
  0.4  3          0.8               0.50       100      0.7507212  0.12000000  1.0000000
  0.4  3          0.8               0.50       150      0.7458090  0.14000000  1.0000000
  0.4  3          0.8               0.75        50      0.7489669  0.20000000  1.0000000
  0.4  3          0.8               0.75       100      0.7591033  0.20000000  1.0000000
  0.4  3          0.8               0.75       150      0.7623392  0.20000000  1.0000000
  0.4  3          0.8               1.00        50      0.8048343  0.30444444  0.9964912
  0.4  3          0.8               1.00       100      0.8037817  0.30444444  0.9929825
  0.4  3          0.8               1.00       150      0.8020273  0.30444444  0.9964912

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      4.8      1.8
  positive      9.9     83.5
                            
 Accuracy (average) : 0.8832

[1] "TEST accuracy: 0.883233532934132"
[1] "TEST +precision: 0.894230769230769"
[1] "TEST -precision: 0.727272727272727"
[1] "TEST specifity: 0.326530612244898"
[1] "TEST sensitivity: 0.978947368421053"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        0
            positive       14       87
[1] "TEST accuracy: 0.864077669902913"
[1] "TEST +precision: 0.861386138613861"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.125"
[1] "TEST sensitivity: 1"
