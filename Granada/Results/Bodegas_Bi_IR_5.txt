[1] "DATASET NAME: Bodegas_Bi_IR_5"
[1] "TRAIN INSTANCES: 548"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.85752105712891"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

548 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 438, 438, 438, 438, 440 
Resampling results:

  ROC        Sens       Spec     
  0.9690295  0.7989418  0.9804878

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     20.3      1.5
  positive      5.1     73.2
                            
 Accuracy (average) : 0.9343

[1] "TEST accuracy: 0.934306569343066"
[1] "TEST +precision: 0.934731934731935"
[1] "TEST -precision: 0.932773109243697"
[1] "TEST specifity: 0.798561151079137"
[1] "TEST sensitivity: 0.980440097799511"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        3
            positive       12      131
[1] "TEST accuracy: 0.906832298136646"
[1] "TEST +precision: 0.916083916083916"
[1] "TEST -precision: 0.833333333333333"
[1] "TEST specifity: 0.555555555555556"
[1] "TEST sensitivity: 0.977611940298508"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.43999816974004"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

548 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 438, 438, 439, 438, 439 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5012195  0.00000000  1.0000000
  0.010  2  0.5012195  0.00000000  1.0000000
  0.010  3  0.5012195  0.00000000  1.0000000
  0.255  1  0.6354046  0.05740741  0.9975610
  0.255  2  0.6228546  0.05740741  0.9975610
  0.255  3  0.6150584  0.05026455  0.9975610
  0.500  1  0.6492219  0.06481481  0.9950918
  0.500  2  0.6338700  0.05740741  0.9975610
  0.500  3  0.6317831  0.05740741  0.9975610

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.6      0.4
  positive     23.7     74.3
                            
 Accuracy (average) : 0.7591

[1] "TEST accuracy: 0.759124087591241"
[1] "TEST +precision: 0.757914338919926"
[1] "TEST -precision: 0.818181818181818"
[1] "TEST specifity: 0.0647482014388489"
[1] "TEST sensitivity: 0.995110024449878"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        3
            positive       26      131
[1] "TEST accuracy: 0.819875776397516"
[1] "TEST +precision: 0.834394904458599"
[1] "TEST -precision: 0.25"
[1] "TEST specifity: 0.037037037037037"
[1] "TEST sensitivity: 0.977611940298508"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.87708736658096"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

548 samples
925 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 439, 438, 438, 439, 438 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.7620354  0.1645503  0.9975610
  0.3  1          0.6               0.50       100      0.8129076  0.3169312  0.9902138
  0.3  1          0.6               0.50       150      0.8332801  0.3460317  0.9828365
  0.3  1          0.6               0.75        50      0.7754850  0.2444444  0.9975610
  0.3  1          0.6               0.75       100      0.8301775  0.3603175  0.9951220
  0.3  1          0.6               0.75       150      0.8415677  0.3746032  0.9804276
  0.3  1          0.6               1.00        50      0.7744247  0.2595238  0.9951220
  0.3  1          0.6               1.00       100      0.8318724  0.3314815  0.9951220
  0.3  1          0.6               1.00       150      0.8547479  0.3674603  0.9902138
  0.3  1          0.8               0.50        50      0.7805722  0.2161376  0.9951220
  0.3  1          0.8               0.50       100      0.8079435  0.2952381  0.9902439
  0.3  1          0.8               0.50       150      0.8400380  0.3460317  0.9853357
  0.3  1          0.8               0.75        50      0.7742198  0.2523810  0.9951220
  0.3  1          0.8               0.75       100      0.8207731  0.3457672  0.9902439
  0.3  1          0.8               0.75       150      0.8508071  0.3677249  0.9804276
  0.3  1          0.8               1.00        50      0.7624618  0.2740741  0.9951220
  0.3  1          0.8               1.00       100      0.8377527  0.3386243  0.9951220
  0.3  1          0.8               1.00       150      0.8634652  0.3817460  0.9902138
  0.3  2          0.6               0.50        50      0.8097330  0.2804233  0.9926829
  0.3  2          0.6               0.50       100      0.8378764  0.3679894  0.9853357
  0.3  2          0.6               0.50       150      0.8513884  0.4108466  0.9755495
  0.3  2          0.6               0.75        50      0.8161435  0.3529101  0.9951220
  0.3  2          0.6               0.75       100      0.8603223  0.4179894  0.9779886
  0.3  2          0.6               0.75       150      0.8626941  0.4248677  0.9755495
  0.3  2          0.6               1.00        50      0.8311976  0.3388889  0.9951220
  0.3  2          0.6               1.00       100      0.8698563  0.4037037  0.9828967
  0.3  2          0.6               1.00       150      0.8680378  0.4394180  0.9731105
  0.3  2          0.8               0.50        50      0.8186976  0.3169312  0.9779584
  0.3  2          0.8               0.50       100      0.8411053  0.3531746  0.9828365
  0.3  2          0.8               0.50       150      0.8469405  0.3888889  0.9730503
  0.3  2          0.8               0.75        50      0.8211377  0.3097884  0.9926829
  0.3  2          0.8               0.75       100      0.8575252  0.3671958  0.9803975
  0.3  2          0.8               0.75       150      0.8592571  0.4394180  0.9681722
  0.3  2          0.8               1.00        50      0.8372489  0.3388889  0.9926829
  0.3  2          0.8               1.00       100      0.8679846  0.4037037  0.9804577
  0.3  2          0.8               1.00       150      0.8614450  0.4465608  0.9731105
  0.3  3          0.6               0.50        50      0.8337280  0.3531746  0.9779584
  0.3  3          0.6               0.50       100      0.8508856  0.3674603  0.9828365
  0.3  3          0.6               0.50       150      0.8462441  0.3894180  0.9755194
  0.3  3          0.6               0.75        50      0.8620231  0.3600529  0.9803975
  0.3  3          0.6               0.75       100      0.8554663  0.4322751  0.9681722
  0.3  3          0.6               0.75       150      0.8556131  0.4394180  0.9681722
  0.3  3          0.6               1.00        50      0.8607718  0.3746032  0.9853357
  0.3  3          0.6               1.00       100      0.8650374  0.4465608  0.9755796
  0.3  3          0.6               1.00       150      0.8596529  0.4537037  0.9681722
  0.3  3          0.8               0.50        50      0.8376452  0.2944444  0.9828666
  0.3  3          0.8               0.50       100      0.8384695  0.3664021  0.9730804
  0.3  3          0.8               0.50       150      0.8361375  0.4103175  0.9657633
  0.3  3          0.8               0.75        50      0.8598523  0.3671958  0.9853056
  0.3  3          0.8               0.75       100      0.8631915  0.4391534  0.9730503
  0.3  3          0.8               0.75       150      0.8614956  0.4462963  0.9632641
  0.3  3          0.8               1.00        50      0.8587253  0.3746032  0.9828967
  0.3  3          0.8               1.00       100      0.8669726  0.4465608  0.9706715
  0.3  3          0.8               1.00       150      0.8608428  0.4537037  0.9682023
  0.4  1          0.6               0.50        50      0.7795490  0.2735450  0.9902138
  0.4  1          0.6               0.50       100      0.8298297  0.3386243  0.9828967
  0.4  1          0.6               0.50       150      0.8442928  0.3386243  0.9755194
  0.4  1          0.6               0.75        50      0.7749790  0.3171958  0.9926829
  0.4  1          0.6               0.75       100      0.8313772  0.3603175  0.9828967
  0.4  1          0.6               0.75       150      0.8475486  0.3894180  0.9755194
  0.4  1          0.6               1.00        50      0.7822009  0.2814815  0.9951220
  0.4  1          0.6               1.00       100      0.8493284  0.3531746  0.9902439
  0.4  1          0.6               1.00       150      0.8673280  0.3674603  0.9853357
  0.4  1          0.8               0.50        50      0.7697273  0.2595238  0.9853659
  0.4  1          0.8               0.50       100      0.8284730  0.2880952  0.9853357
  0.4  1          0.8               0.50       150      0.8384835  0.3595238  0.9804276
  0.4  1          0.8               0.75        50      0.7796054  0.2955026  0.9902439
  0.4  1          0.8               0.75       100      0.8370064  0.3817460  0.9828967
  0.4  1          0.8               0.75       150      0.8582349  0.4179894  0.9804276
  0.4  1          0.8               1.00        50      0.7881737  0.2955026  0.9951220
  0.4  1          0.8               1.00       100      0.8506732  0.3600529  0.9926829
  0.4  1          0.8               1.00       150      0.8696025  0.3960317  0.9853357
  0.4  2          0.6               0.50        50      0.8292640  0.3103175  0.9804276
  0.4  2          0.6               0.50       100      0.8501269  0.3817460  0.9828967
  0.4  2          0.6               0.50       150      0.8560094  0.3965608  0.9804276
  0.4  2          0.6               0.75        50      0.8308534  0.3603175  0.9779886
  0.4  2          0.6               0.75       100      0.8503839  0.4108466  0.9730804
  0.4  2          0.6               0.75       150      0.8505657  0.4179894  0.9681722
  0.4  2          0.6               1.00        50      0.8528358  0.3674603  0.9902138
  0.4  2          0.6               1.00       100      0.8650573  0.4537037  0.9755796
  0.4  2          0.6               1.00       150      0.8634055  0.4679894  0.9706414
  0.4  2          0.8               0.50        50      0.8337807  0.3531746  0.9853056
  0.4  2          0.8               0.50       100      0.8482379  0.4037037  0.9803674
  0.4  2          0.8               0.50       150      0.8481584  0.3965608  0.9779584
  0.4  2          0.8               0.75        50      0.8464624  0.3600529  0.9755495
  0.4  2          0.8               0.75       100      0.8610401  0.4322751  0.9779886
  0.4  2          0.8               0.75       150      0.8603669  0.4537037  0.9584161
  0.4  2          0.8               1.00        50      0.8483191  0.3600529  0.9853357
  0.4  2          0.8               1.00       100      0.8699838  0.4537037  0.9731406
  0.4  2          0.8               1.00       150      0.8678577  0.4608466  0.9682023
  0.4  3          0.6               0.50        50      0.8454994  0.2947090  0.9705510
  0.4  3          0.6               0.50       100      0.8555642  0.4177249  0.9656429
  0.4  3          0.6               0.50       150      0.8564444  0.4174603  0.9656429
  0.4  3          0.6               0.75        50      0.8605342  0.3891534  0.9828666
  0.4  3          0.6               0.75       100      0.8531445  0.4248677  0.9681722
  0.4  3          0.6               0.75       150      0.8620580  0.4248677  0.9730503
  0.4  3          0.6               1.00        50      0.8642486  0.4251323  0.9828967
  0.4  3          0.6               1.00       100      0.8615472  0.4608466  0.9731105
  0.4  3          0.6               1.00       150      0.8600572  0.4608466  0.9657332
  0.4  3          0.8               0.50        50      0.8367445  0.3457672  0.9755495
  0.4  3          0.8               0.50       100      0.8465173  0.3886243  0.9706715
  0.4  3          0.8               0.50       150      0.8411021  0.4322751  0.9730804
  0.4  3          0.8               0.75        50      0.8510362  0.4177249  0.9853056
  0.4  3          0.8               0.75       100      0.8571633  0.4320106  0.9779584
  0.4  3          0.8               0.75       150      0.8546415  0.4534392  0.9706715
  0.4  3          0.8               1.00        50      0.8729863  0.4465608  0.9828967
  0.4  3          0.8               1.00       100      0.8656187  0.4608466  0.9682023
  0.4  3          0.8               1.00       150      0.8638260  0.4894180  0.9682023

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.3      1.3
  positive     14.1     73.4
                            
 Accuracy (average) : 0.8467

[1] "TEST accuracy: 0.846715328467153"
[1] "TEST +precision: 0.839248434237996"
[1] "TEST -precision: 0.898550724637681"
[1] "TEST specifity: 0.446043165467626"
[1] "TEST sensitivity: 0.982885085574572"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        8        3
            positive       19      131
[1] "TEST accuracy: 0.863354037267081"
[1] "TEST +precision: 0.873333333333333"
[1] "TEST -precision: 0.727272727272727"
[1] "TEST specifity: 0.296296296296296"
[1] "TEST sensitivity: 0.977611940298508"
