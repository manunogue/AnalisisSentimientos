[1] "DATASET NAME: Estrellas_Uni_IR_10"
[1] "TRAIN INSTANCES: 449"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.88059592247009"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

449 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 359, 359, 360, 359, 359 
Resampling results:

  ROC        Sens       Spec    
  0.9917845  0.9076923  0.994771

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     13.1      0.4
  positive      1.3     85.1
                            
 Accuracy (average) : 0.9822

[1] "TEST accuracy: 0.982182628062361"
[1] "TEST +precision: 0.984536082474227"
[1] "TEST -precision: 0.967213114754098"
[1] "TEST specifity: 0.907692307692308"
[1] "TEST sensitivity: 0.994791666666667"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        8        0
            positive        8      122
[1] "TEST accuracy: 0.942028985507246"
[1] "TEST +precision: 0.938461538461538"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.38342291514079"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

449 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 359, 360, 359, 359, 359 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7151559  0.4461538  0.9766234
  0.010  2  0.7146564  0.4153846  0.9766234
  0.010  3  0.7028458  0.4153846  0.9792208
  0.255  1  0.8210185  0.6615385  0.9636364
  0.255  2  0.8063331  0.5846154  0.9636364
  0.255  3  0.8211473  0.6307692  0.9557758
  0.500  1  0.8249224  0.6923077  0.9636364
  0.500  2  0.8069404  0.5846154  0.9636364
  0.500  3  0.8090594  0.6307692  0.9557758

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.0      3.1
  positive      4.5     82.4
                            
 Accuracy (average) : 0.9243

[1] "TEST accuracy: 0.924276169265033"
[1] "TEST +precision: 0.948717948717949"
[1] "TEST -precision: 0.76271186440678"
[1] "TEST specifity: 0.692307692307692"
[1] "TEST sensitivity: 0.963541666666667"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        3
            positive       15      119
[1] "TEST accuracy: 0.869565217391304"
[1] "TEST +precision: 0.888059701492537"
[1] "TEST -precision: 0.25"
[1] "TEST specifity: 0.0625"
[1] "TEST sensitivity: 0.975409836065574"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.24937296708425"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

449 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 359, 359, 359, 359, 360 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9753036  0.6153846  0.9921394
  0.3  1          0.6               0.50       100      0.9819365  0.7692308  0.9869446
  0.3  1          0.6               0.50       150      0.9859246  0.9076923  0.9843472
  0.3  1          0.6               0.75        50      0.9746648  0.5692308  0.9895420
  0.3  1          0.6               0.75       100      0.9861297  0.8000000  0.9817157
  0.3  1          0.6               0.75       150      0.9873337  0.8307692  0.9843472
  0.3  1          0.6               1.00        50      0.9812319  0.6307692  0.9895420
  0.3  1          0.6               1.00       100      0.9837531  0.7538462  0.9869446
  0.3  1          0.6               1.00       150      0.9849650  0.8461538  0.9869446
  0.3  1          0.8               0.50        50      0.9708160  0.5846154  0.9843131
  0.3  1          0.8               0.50       100      0.9841264  0.8461538  0.9869446
  0.3  1          0.8               0.50       150      0.9859272  0.8769231  0.9791183
  0.3  1          0.8               0.75        50      0.9742652  0.6153846  0.9895420
  0.3  1          0.8               0.75       100      0.9853383  0.8461538  0.9843472
  0.3  1          0.8               0.75       150      0.9889321  0.9076923  0.9817157
  0.3  1          0.8               1.00        50      0.9781245  0.6461538  0.9869446
  0.3  1          0.8               1.00       100      0.9847573  0.7692308  0.9843472
  0.3  1          0.8               1.00       150      0.9851596  0.8461538  0.9843472
  0.3  2          0.6               0.50        50      0.9829145  0.7538462  0.9843472
  0.3  2          0.6               0.50       100      0.9818944  0.8307692  0.9843131
  0.3  2          0.6               0.50       150      0.9818892  0.8461538  0.9843131
  0.3  2          0.6               0.75        50      0.9861481  0.7846154  0.9791183
  0.3  2          0.6               0.75       100      0.9881461  0.8615385  0.9843131
  0.3  2          0.6               0.75       150      0.9889453  0.8769231  0.9843131
  0.3  2          0.6               1.00        50      0.9841763  0.7384615  0.9765550
  0.3  2          0.6               1.00       100      0.9859483  0.8461538  0.9817157
  0.3  2          0.6               1.00       150      0.9883564  0.8461538  0.9817157
  0.3  2          0.8               0.50        50      0.9808928  0.7538462  0.9843472
  0.3  2          0.8               0.50       100      0.9796887  0.8615385  0.9817498
  0.3  2          0.8               0.50       150      0.9784820  0.8307692  0.9869446
  0.3  2          0.8               0.75        50      0.9895736  0.8615385  0.9817498
  0.3  2          0.8               0.75       100      0.9881461  0.8923077  0.9817157
  0.3  2          0.8               0.75       150      0.9877438  0.8769231  0.9817157
  0.3  2          0.8               1.00        50      0.9847600  0.8307692  0.9765208
  0.3  2          0.8               1.00       100      0.9871471  0.8923077  0.9765208
  0.3  2          0.8               1.00       150      0.9875388  0.9076923  0.9817157
  0.3  3          0.6               0.50        50      0.9873258  0.8615385  0.9869788
  0.3  3          0.6               0.50       100      0.9857011  0.9230769  0.9791183
  0.3  3          0.6               0.50       150      0.9854961  0.9230769  0.9791183
  0.3  3          0.6               0.75        50      0.9857327  0.8923077  0.9869446
  0.3  3          0.6               0.75       100      0.9873285  0.8923077  0.9790841
  0.3  3          0.6               0.75       150      0.9875204  0.8923077  0.9842789
  0.3  3          0.6               1.00        50      0.9879699  0.8461538  0.9869446
  0.3  3          0.6               1.00       100      0.9887639  0.8615385  0.9843131
  0.3  3          0.6               1.00       150      0.9877517  0.8769231  0.9843131
  0.3  3          0.8               0.50        50      0.9796914  0.8615385  0.9817498
  0.3  3          0.8               0.50       100      0.9794837  0.8615385  0.9817498
  0.3  3          0.8               0.50       150      0.9782849  0.8615385  0.9817498
  0.3  3          0.8               0.75        50      0.9871418  0.8923077  0.9869446
  0.3  3          0.8               0.75       100      0.9855276  0.8769231  0.9843131
  0.3  3          0.8               0.75       150      0.9841159  0.8769231  0.9869105
  0.3  3          0.8               1.00        50      0.9903780  0.8615385  0.9895762
  0.3  3          0.8               1.00       100      0.9897629  0.8769231  0.9947710
  0.3  3          0.8               1.00       150      0.9899574  0.9076923  0.9921736
  0.4  1          0.6               0.50        50      0.9637731  0.6461538  0.9843472
  0.4  1          0.6               0.50       100      0.9821074  0.7538462  0.9895420
  0.4  1          0.6               0.50       150      0.9802960  0.8307692  0.9921394
  0.4  1          0.6               0.75        50      0.9787213  0.6769231  0.9843472
  0.4  1          0.6               0.75       100      0.9833351  0.8461538  0.9817498
  0.4  1          0.6               0.75       150      0.9863268  0.8769231  0.9843131
  0.4  1          0.6               1.00        50      0.9809506  0.6769231  0.9895420
  0.4  1          0.6               1.00       100      0.9857721  0.8307692  0.9869446
  0.4  1          0.6               1.00       150      0.9855618  0.8615385  0.9791524
  0.4  1          0.8               0.50        50      0.9797387  0.7538462  0.9869446
  0.4  1          0.8               0.50       100      0.9859325  0.8769231  0.9816815
  0.4  1          0.8               0.50       150      0.9863347  0.8461538  0.9842789
  0.4  1          0.8               0.75        50      0.9775330  0.6923077  0.9895420
  0.4  1          0.8               0.75       100      0.9867448  0.8461538  0.9791183
  0.4  1          0.8               0.75       150      0.9893370  0.8923077  0.9817157
  0.4  1          0.8               1.00        50      0.9841369  0.6769231  0.9895420
  0.4  1          0.8               1.00       100      0.9857642  0.8153846  0.9843472
  0.4  1          0.8               1.00       150      0.9863557  0.8307692  0.9869446
  0.4  2          0.6               0.50        50      0.9811425  0.6769231  0.9817498
  0.4  2          0.6               0.50       100      0.9839187  0.8307692  0.9687286
  0.4  2          0.6               0.50       150      0.9821284  0.8461538  0.9713602
  0.4  2          0.6               0.75        50      0.9855434  0.8769231  0.9765208
  0.4  2          0.6               0.75       100      0.9841211  0.8769231  0.9843131
  0.4  2          0.6               0.75       150      0.9819128  0.8769231  0.9869105
  0.4  2          0.6               1.00        50      0.9849545  0.7846154  0.9817498
  0.4  2          0.6               1.00       100      0.9871471  0.8461538  0.9817157
  0.4  2          0.6               1.00       150      0.9869499  0.8615385  0.9765208
  0.4  2          0.8               0.50        50      0.9798964  0.8153846  0.9843472
  0.4  2          0.8               0.50       100      0.9817104  0.8615385  0.9791183
  0.4  2          0.8               0.50       150      0.9823045  0.8769231  0.9791183
  0.4  2          0.8               0.75        50      0.9881434  0.8769231  0.9869446
  0.4  2          0.8               0.75       100      0.9867185  0.8923077  0.9843131
  0.4  2          0.8               0.75       150      0.9859009  0.8615385  0.9816815
  0.4  2          0.8               1.00        50      0.9847705  0.8307692  0.9791524
  0.4  2          0.8               1.00       100      0.9869473  0.8615385  0.9817157
  0.4  2          0.8               1.00       150      0.9845286  0.8615385  0.9817157
  0.4  3          0.6               0.50        50      0.9873337  0.8461538  0.9868763
  0.4  3          0.6               0.50       100      0.9887402  0.8923077  0.9764867
  0.4  3          0.6               0.50       150      0.9889374  0.8923077  0.9843131
  0.4  3          0.6               0.75        50      0.9853278  0.8923077  0.9869446
  0.4  3          0.6               0.75       100      0.9823124  0.8769231  0.9869446
  0.4  3          0.6               0.75       150      0.9839161  0.8769231  0.9869446
  0.4  3          0.6               1.00        50      0.9843367  0.8615385  0.9869446
  0.4  3          0.6               1.00       100      0.9819049  0.8615385  0.9869446
  0.4  3          0.6               1.00       150      0.9803013  0.8307692  0.9843472
  0.4  3          0.8               0.50        50      0.9849151  0.8461538  0.9817498
  0.4  3          0.8               0.50       100      0.9778721  0.8923077  0.9791183
  0.4  3          0.8               0.50       150      0.9794889  0.8923077  0.9817498
  0.4  3          0.8               0.75        50      0.9849414  0.8461538  0.9843131
  0.4  3          0.8               0.75       100      0.9837268  0.8461538  0.9843131
  0.4  3          0.8               0.75       150      0.9849309  0.8461538  0.9843131
  0.4  3          0.8               1.00        50      0.9881592  0.8615385  0.9895762
  0.4  3          0.8               1.00       100      0.9879463  0.8615385  0.9843814
  0.4  3          0.8               1.00       150      0.9869499  0.8615385  0.9817157

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     12.5      0.9
  positive      2.0     84.6
                           
 Accuracy (average) : 0.971

[1] "TEST accuracy: 0.971046770601336"
[1] "TEST +precision: 0.976863753213368"
[1] "TEST -precision: 0.933333333333333"
[1] "TEST specifity: 0.861538461538462"
[1] "TEST sensitivity: 0.989583333333333"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        0
            positive       10      122
[1] "TEST accuracy: 0.927536231884058"
[1] "TEST +precision: 0.924242424242424"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.375"
[1] "TEST sensitivity: 1"
