[1] "DATASET NAME: Bodegas_Uni_IR_1"
[1] "TRAIN INSTANCES: 810"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.82285094261169"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

810 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 648, 648, 648, 648, 648 
Resampling results:

  ROC  Sens  Spec     
  1    1     0.9876543

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.6
  positive      0.0     49.4
                            
 Accuracy (average) : 0.9938

[1] "TEST accuracy: 0.993827160493827"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.98780487804878"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.987654320987654"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        2
            positive        8      136
[1] "TEST accuracy: 0.937888198757764"
[1] "TEST +precision: 0.944444444444444"
[1] "TEST -precision: 0.882352941176471"
[1] "TEST specifity: 0.652173913043478"
[1] "TEST sensitivity: 0.985507246376812"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.32755434910456"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

810 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 648, 648, 648, 648, 648 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9320073  0.9456790  0.8987654
  0.010  2  0.9493675  0.9456790  0.8987654
  0.010  3  0.9475842  0.9456790  0.8888889
  0.255  1  0.9453589  0.9975309  0.9061728
  0.255  2  0.9644871  0.9950617  0.9135802
  0.255  3  0.9612864  0.9580247  0.9037037
  0.500  1  0.9453589  0.9975309  0.9061728
  0.500  2  0.9630239  0.9950617  0.9135802
  0.500  3  0.9613778  0.9629630  0.9012346

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     49.8      4.3
  positive      0.2     45.7
                            
 Accuracy (average) : 0.9543

[1] "TEST accuracy: 0.954320987654321"
[1] "TEST +precision: 0.994623655913978"
[1] "TEST -precision: 0.920091324200913"
[1] "TEST specifity: 0.995061728395062"
[1] "TEST sensitivity: 0.91358024691358"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       13        7
            positive       10      131
[1] "TEST accuracy: 0.894409937888199"
[1] "TEST +precision: 0.929078014184397"
[1] "TEST -precision: 0.65"
[1] "TEST specifity: 0.565217391304348"
[1] "TEST sensitivity: 0.949275362318841"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.12981576522191"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

810 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 648, 648, 648, 648, 648 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9824874  0.9234568  0.9358025
  0.3  1          0.6               0.50       100      0.9932632  0.9654321  0.9580247
  0.3  1          0.6               0.50       150      0.9942996  0.9827160  0.9580247
  0.3  1          0.6               0.75        50      0.9826551  0.9037037  0.9506173
  0.3  1          0.6               0.75       100      0.9925316  0.9629630  0.9580247
  0.3  1          0.6               0.75       150      0.9952751  0.9827160  0.9654321
  0.3  1          0.6               1.00        50      0.9837525  0.8987654  0.9506173
  0.3  1          0.6               1.00       100      0.9908855  0.9358025  0.9604938
  0.3  1          0.6               1.00       150      0.9944521  0.9753086  0.9703704
  0.3  1          0.8               0.50        50      0.9822588  0.9160494  0.9259259
  0.3  1          0.8               0.50       100      0.9935376  0.9629630  0.9580247
  0.3  1          0.8               0.50       150      0.9960372  0.9925926  0.9654321
  0.3  1          0.8               0.75        50      0.9840116  0.9209877  0.9407407
  0.3  1          0.8               0.75       100      0.9928365  0.9629630  0.9604938
  0.3  1          0.8               0.75       150      0.9960677  0.9827160  0.9654321
  0.3  1          0.8               1.00        50      0.9826246  0.9061728  0.9506173
  0.3  1          0.8               1.00       100      0.9915866  0.9407407  0.9604938
  0.3  1          0.8               1.00       150      0.9941472  0.9753086  0.9679012
  0.3  2          0.6               0.50        50      0.9934766  0.9728395  0.9555556
  0.3  2          0.6               0.50       100      0.9954885  1.0000000  0.9555556
  0.3  2          0.6               0.50       150      0.9958543  1.0000000  0.9604938
  0.3  2          0.6               0.75        50      0.9953970  0.9728395  0.9580247
  0.3  2          0.6               0.75       100      0.9971955  0.9950617  0.9654321
  0.3  2          0.6               0.75       150      0.9983539  1.0000000  0.9679012
  0.3  2          0.6               1.00        50      0.9958543  0.9654321  0.9629630
  0.3  2          0.6               1.00       100      0.9966773  1.0000000  0.9753086
  0.3  2          0.6               1.00       150      0.9976833  1.0000000  0.9703704
  0.3  2          0.8               0.50        50      0.9939948  0.9901235  0.9407407
  0.3  2          0.8               0.50       100      0.9964335  1.0000000  0.9580247
  0.3  2          0.8               0.50       150      0.9971041  1.0000000  0.9604938
  0.3  2          0.8               0.75        50      0.9962201  0.9753086  0.9580247
  0.3  2          0.8               0.75       100      0.9985978  1.0000000  0.9555556
  0.3  2          0.8               0.75       150      0.9986892  1.0000000  0.9604938
  0.3  2          0.8               1.00        50      0.9947569  0.9654321  0.9604938
  0.3  2          0.8               1.00       100      0.9961591  1.0000000  0.9703704
  0.3  2          0.8               1.00       150      0.9963420  1.0000000  0.9703704
  0.3  3          0.6               0.50        50      0.9971346  0.9876543  0.9530864
  0.3  3          0.6               0.50       100      0.9986587  1.0000000  0.9629630
  0.3  3          0.6               0.50       150      0.9988416  1.0000000  0.9604938
  0.3  3          0.6               0.75        50      0.9973480  1.0000000  0.9530864
  0.3  3          0.6               0.75       100      0.9990550  1.0000000  0.9629630
  0.3  3          0.6               0.75       150      0.9995123  1.0000000  0.9629630
  0.3  3          0.6               1.00        50      0.9979271  0.9950617  0.9654321
  0.3  3          0.6               1.00       100      0.9977747  1.0000000  0.9629630
  0.3  3          0.6               1.00       150      0.9979576  1.0000000  0.9580247
  0.3  3          0.8               0.50        50      0.9976833  0.9950617  0.9604938
  0.3  3          0.8               0.50       100      0.9982929  0.9925926  0.9604938
  0.3  3          0.8               0.50       150      0.9984454  1.0000000  0.9555556
  0.3  3          0.8               0.75        50      0.9973784  1.0000000  0.9679012
  0.3  3          0.8               0.75       100      0.9975613  1.0000000  0.9580247
  0.3  3          0.8               0.75       150      0.9980186  1.0000000  0.9580247
  0.3  3          0.8               1.00        50      0.9965859  1.0000000  0.9555556
  0.3  3          0.8               1.00       100      0.9982929  1.0000000  0.9679012
  0.3  3          0.8               1.00       150      0.9987807  1.0000000  0.9580247
  0.4  1          0.6               0.50        50      0.9878829  0.9382716  0.9333333
  0.4  1          0.6               0.50       100      0.9927755  0.9753086  0.9506173
  0.4  1          0.6               0.50       150      0.9950312  0.9975309  0.9555556
  0.4  1          0.6               0.75        50      0.9889346  0.9308642  0.9456790
  0.4  1          0.6               0.75       100      0.9938424  0.9654321  0.9654321
  0.4  1          0.6               0.75       150      0.9952446  0.9901235  0.9679012
  0.4  1          0.6               1.00        50      0.9869532  0.9160494  0.9629630
  0.4  1          0.6               1.00       100      0.9941168  0.9679012  0.9728395
  0.4  1          0.6               1.00       150      0.9952141  0.9851852  0.9753086
  0.4  1          0.8               0.50        50      0.9863131  0.9259259  0.9382716
  0.4  1          0.8               0.50       100      0.9950312  0.9703704  0.9555556
  0.4  1          0.8               0.50       150      0.9958848  0.9901235  0.9580247
  0.4  1          0.8               0.75        50      0.9887212  0.9407407  0.9530864
  0.4  1          0.8               0.75       100      0.9954580  0.9802469  0.9728395
  0.4  1          0.8               0.75       150      0.9959457  0.9950617  0.9703704
  0.4  1          0.8               1.00        50      0.9864807  0.9111111  0.9555556
  0.4  1          0.8               1.00       100      0.9940863  0.9703704  0.9654321
  0.4  1          0.8               1.00       150      0.9949703  0.9802469  0.9753086
  0.4  2          0.6               0.50        50      0.9970431  0.9901235  0.9654321
  0.4  2          0.6               0.50       100      0.9973480  1.0000000  0.9654321
  0.4  2          0.6               0.50       150      0.9975613  1.0000000  0.9703704
  0.4  2          0.6               0.75        50      0.9971041  0.9950617  0.9629630
  0.4  2          0.6               0.75       100      0.9963420  1.0000000  0.9654321
  0.4  2          0.6               0.75       150      0.9961591  1.0000000  0.9629630
  0.4  2          0.6               1.00        50      0.9966773  0.9851852  0.9629630
  0.4  2          0.6               1.00       100      0.9971346  1.0000000  0.9728395
  0.4  2          0.6               1.00       150      0.9978357  1.0000000  0.9679012
  0.4  2          0.8               0.50        50      0.9954885  0.9950617  0.9456790
  0.4  2          0.8               0.50       100      0.9961896  1.0000000  0.9580247
  0.4  2          0.8               0.50       150      0.9964640  1.0000000  0.9580247
  0.4  2          0.8               0.75        50      0.9967383  0.9925926  0.9580247
  0.4  2          0.8               0.75       100      0.9972260  1.0000000  0.9580247
  0.4  2          0.8               0.75       150      0.9977747  1.0000000  0.9555556
  0.4  2          0.8               1.00        50      0.9963725  0.9827160  0.9604938
  0.4  2          0.8               1.00       100      0.9973784  1.0000000  0.9703704
  0.4  2          0.8               1.00       150      0.9977138  1.0000000  0.9629630
  0.4  3          0.6               0.50        50      0.9979576  0.9950617  0.9604938
  0.4  3          0.6               0.50       100      0.9986587  1.0000000  0.9629630
  0.4  3          0.6               0.50       150      0.9987197  1.0000000  0.9580247
  0.4  3          0.6               0.75        50      0.9991770  1.0000000  0.9654321
  0.4  3          0.6               0.75       100      0.9998476  1.0000000  0.9654321
  0.4  3          0.6               0.75       150      0.9998476  1.0000000  0.9654321
  0.4  3          0.6               1.00        50      0.9963420  1.0000000  0.9679012
  0.4  3          0.6               1.00       100      0.9968298  1.0000000  0.9629630
  0.4  3          0.6               1.00       150      0.9975004  1.0000000  0.9654321
  0.4  3          0.8               0.50        50      0.9984149  1.0000000  0.9481481
  0.4  3          0.8               0.50       100      0.9989636  0.9925926  0.9580247
  0.4  3          0.8               0.50       150      0.9985978  1.0000000  0.9580247
  0.4  3          0.8               0.75        50      0.9989636  1.0000000  0.9580247
  0.4  3          0.8               0.75       100      0.9991770  1.0000000  0.9629630
  0.4  3          0.8               0.75       150      0.9992989  1.0000000  0.9654321
  0.4  3          0.8               1.00        50      0.9986892  1.0000000  0.9703704
  0.4  3          0.8               1.00       100      0.9993294  1.0000000  0.9654321
  0.4  3          0.8               1.00       150      0.9995428  1.0000000  0.9654321

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      1.7
  positive      0.0     48.3
                            
 Accuracy (average) : 0.9827

[1] "TEST accuracy: 0.982716049382716"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.966587112171838"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.965432098765432"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       16        4
            positive        7      134
[1] "TEST accuracy: 0.93167701863354"
[1] "TEST +precision: 0.950354609929078"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.695652173913043"
[1] "TEST sensitivity: 0.971014492753623"
