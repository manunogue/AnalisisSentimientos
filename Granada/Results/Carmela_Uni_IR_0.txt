[1] "DATASET NAME: Carmela_Uni_IR_0"
[1] "TRAIN INSTANCES: 308"
[1] "TEST INSTANCES: 103"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 1.84805488586426"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

308 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 247, 247, 246, 246, 246 
Resampling results:

  ROC        Sens       Spec     
  0.9283983  0.4285714  0.9783117

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      4.2      1.9
  positive      5.8     88.0
                            
 Accuracy (average) : 0.9221

[1] "TEST accuracy: 0.922077922077922"
[1] "TEST +precision: 0.937716262975779"
[1] "TEST -precision: 0.684210526315789"
[1] "TEST specifity: 0.419354838709677"
[1] "TEST sensitivity: 0.978339350180505"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        2
            positive        3       93
[1] "TEST accuracy: 0.951456310679612"
[1] "TEST +precision: 0.96875"
[1] "TEST -precision: 0.714285714285714"
[1] "TEST specifity: 0.625"
[1] "TEST sensitivity: 0.978947368421053"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 50.8204128742218"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

308 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 247, 246, 247, 246, 246 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5000000  0.00000000  1.0000000
  0.010  2  0.5000000  0.00000000  1.0000000
  0.010  3  0.5000000  0.00000000  1.0000000
  0.255  1  0.4820942  0.09523810  0.9783766
  0.255  2  0.4991126  0.09523810  0.9746753
  0.255  3  0.4822727  0.02857143  0.9783766
  0.500  1  0.5018561  0.12380952  0.9457143
  0.500  2  0.6058009  0.25714286  0.9457143
  0.500  3  0.5054654  0.12857143  0.9604545

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      2.6      4.9
  positive      7.5     85.1
                            
 Accuracy (average) : 0.8766

[1] "TEST accuracy: 0.876623376623377"
[1] "TEST +precision: 0.919298245614035"
[1] "TEST -precision: 0.347826086956522"
[1] "TEST specifity: 0.258064516129032"
[1] "TEST sensitivity: 0.945848375451264"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        7
            positive        8       88
[1] "TEST accuracy: 0.854368932038835"
[1] "TEST +precision: 0.916666666666667"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.926315789473684"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 1.71552416483561"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

308 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 247, 246, 246, 247, 246 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8831602  0.2476190  0.9963636
  0.3  1          0.6               0.50       100      0.8800758  0.2809524  0.9927273
  0.3  1          0.6               0.50       150      0.8581494  0.3142857  0.9890909
  0.3  1          0.6               0.75        50      0.8743452  0.2142857  0.9963636
  0.3  1          0.6               0.75       100      0.8919372  0.3476190  0.9963636
  0.3  1          0.6               0.75       150      0.8954978  0.3809524  0.9927273
  0.3  1          0.6               1.00        50      0.8895833  0.2285714  0.9963636
  0.3  1          0.6               1.00       100      0.9166829  0.2619048  0.9927273
  0.3  1          0.6               1.00       150      0.9237013  0.3476190  0.9927273
  0.3  1          0.8               0.50        50      0.8662284  0.2476190  0.9855195
  0.3  1          0.8               0.50       100      0.8939610  0.3476190  0.9855195
  0.3  1          0.8               0.50       150      0.8972078  0.4142857  0.9855195
  0.3  1          0.8               0.75        50      0.8828247  0.1904762  0.9927273
  0.3  1          0.8               0.75       100      0.9068398  0.3142857  0.9890909
  0.3  1          0.8               0.75       150      0.8965152  0.3476190  0.9854545
  0.3  1          0.8               1.00        50      0.8994859  0.2285714  1.0000000
  0.3  1          0.8               1.00       100      0.9327273  0.3190476  0.9927273
  0.3  1          0.8               1.00       150      0.9307900  0.3476190  0.9890909
  0.3  2          0.6               0.50        50      0.8447835  0.2476190  0.9890909
  0.3  2          0.6               0.50       100      0.8734524  0.2809524  0.9890909
  0.3  2          0.6               0.50       150      0.8594589  0.3142857  0.9818831
  0.3  2          0.6               0.75        50      0.9130844  0.3476190  0.9890909
  0.3  2          0.6               0.75       100      0.9141234  0.3476190  0.9818182
  0.3  2          0.6               0.75       150      0.9113961  0.3476190  0.9746104
  0.3  2          0.6               1.00        50      0.9274242  0.3190476  0.9890909
  0.3  2          0.6               1.00       100      0.9223160  0.3476190  0.9783117
  0.3  2          0.6               1.00       150      0.9192532  0.3809524  0.9818831
  0.3  2          0.8               0.50        50      0.8824134  0.3476190  0.9890909
  0.3  2          0.8               0.50       100      0.8750541  0.3809524  0.9854545
  0.3  2          0.8               0.50       150      0.8759848  0.3809524  0.9854545
  0.3  2          0.8               0.75        50      0.8854221  0.3142857  0.9854545
  0.3  2          0.8               0.75       100      0.8861688  0.2809524  0.9854545
  0.3  2          0.8               0.75       150      0.8839827  0.3476190  0.9818182
  0.3  2          0.8               1.00        50      0.9170563  0.3476190  0.9927273
  0.3  2          0.8               1.00       100      0.9150000  0.3476190  0.9855195
  0.3  2          0.8               1.00       150      0.9078247  0.3476190  0.9855195
  0.3  3          0.6               0.50        50      0.8541342  0.2190476  0.9927273
  0.3  3          0.6               0.50       100      0.8626840  0.3190476  0.9927273
  0.3  3          0.6               0.50       150      0.8506385  0.2809524  0.9927273
  0.3  3          0.6               0.75        50      0.8853030  0.2809524  0.9891558
  0.3  3          0.6               0.75       100      0.8962446  0.3142857  0.9818182
  0.3  3          0.6               0.75       150      0.8875216  0.3142857  0.9818182
  0.3  3          0.6               1.00        50      0.9212987  0.3476190  0.9927273
  0.3  3          0.6               1.00       100      0.9107684  0.3142857  0.9854545
  0.3  3          0.6               1.00       150      0.9097186  0.3142857  0.9854545
  0.3  3          0.8               0.50        50      0.8747294  0.2809524  0.9891558
  0.3  3          0.8               0.50       100      0.8843615  0.3142857  0.9782468
  0.3  3          0.8               0.50       150      0.8649242  0.3142857  0.9818831
  0.3  3          0.8               0.75        50      0.9056926  0.3476190  0.9818831
  0.3  3          0.8               0.75       100      0.8945238  0.3142857  0.9854545
  0.3  3          0.8               0.75       150      0.8921320  0.3142857  0.9854545
  0.3  3          0.8               1.00        50      0.9135714  0.3142857  0.9891558
  0.3  3          0.8               1.00       100      0.9196753  0.3142857  0.9927273
  0.3  3          0.8               1.00       150      0.9169697  0.3142857  0.9818831
  0.4  1          0.6               0.50        50      0.8499513  0.2142857  0.9963636
  0.4  1          0.6               0.50       100      0.8725541  0.3476190  0.9890909
  0.4  1          0.6               0.50       150      0.8931277  0.3809524  0.9855195
  0.4  1          0.6               0.75        50      0.8983766  0.2857143  0.9963636
  0.4  1          0.6               0.75       100      0.9009416  0.3476190  0.9854545
  0.4  1          0.6               0.75       150      0.9024026  0.3476190  0.9890909
  0.4  1          0.6               1.00        50      0.9002002  0.2619048  1.0000000
  0.4  1          0.6               1.00       100      0.9236472  0.3190476  0.9890909
  0.4  1          0.6               1.00       150      0.9254978  0.3476190  0.9854545
  0.4  1          0.8               0.50        50      0.8643128  0.2809524  0.9890909
  0.4  1          0.8               0.50       100      0.8723701  0.2476190  0.9818182
  0.4  1          0.8               0.50       150      0.8827922  0.2476190  0.9782468
  0.4  1          0.8               0.75        50      0.8751136  0.2857143  0.9963636
  0.4  1          0.8               0.75       100      0.8942424  0.3476190  0.9927273
  0.4  1          0.8               0.75       150      0.9060714  0.3809524  0.9818831
  0.4  1          0.8               1.00        50      0.9055790  0.2619048  0.9963636
  0.4  1          0.8               1.00       100      0.9232792  0.3190476  0.9927273
  0.4  1          0.8               1.00       150      0.9247403  0.3476190  0.9927273
  0.4  2          0.6               0.50        50      0.8554870  0.2476190  0.9890909
  0.4  2          0.6               0.50       100      0.8546537  0.2857143  0.9818831
  0.4  2          0.6               0.50       150      0.8740909  0.2857143  0.9891558
  0.4  2          0.6               0.75        50      0.9173377  0.3476190  0.9927273
  0.4  2          0.6               0.75       100      0.9150325  0.3476190  0.9854545
  0.4  2          0.6               0.75       150      0.9014069  0.3476190  0.9854545
  0.4  2          0.6               1.00        50      0.9385877  0.3476190  0.9891558
  0.4  2          0.6               1.00       100      0.9291667  0.3476190  0.9818831
  0.4  2          0.6               1.00       150      0.9195130  0.3476190  0.9818182
  0.4  2          0.8               0.50        50      0.8995022  0.3761905  0.9855195
  0.4  2          0.8               0.50       100      0.8928355  0.4142857  0.9746753
  0.4  2          0.8               0.50       150      0.8845238  0.3809524  0.9746753
  0.4  2          0.8               0.75        50      0.9094156  0.3809524  0.9890909
  0.4  2          0.8               0.75       100      0.9131602  0.4142857  0.9854545
  0.4  2          0.8               0.75       150      0.9091342  0.3476190  0.9782468
  0.4  2          0.8               1.00        50      0.9185119  0.3809524  0.9891558
  0.4  2          0.8               1.00       100      0.9002597  0.3476190  0.9818831
  0.4  2          0.8               1.00       150      0.8971753  0.3476190  0.9818831
  0.4  3          0.6               0.50        50      0.8558983  0.2857143  0.9855195
  0.4  3          0.6               0.50       100      0.8572403  0.2476190  0.9891558
  0.4  3          0.6               0.50       150      0.8467857  0.2857143  0.9818831
  0.4  3          0.6               0.75        50      0.8852056  0.2809524  0.9854545
  0.4  3          0.6               0.75       100      0.8804113  0.3142857  0.9854545
  0.4  3          0.6               0.75       150      0.8847944  0.3142857  0.9782468
  0.4  3          0.6               1.00        50      0.8955628  0.3142857  0.9855195
  0.4  3          0.6               1.00       100      0.8905736  0.3476190  0.9782468
  0.4  3          0.6               1.00       150      0.8901732  0.3476190  0.9782468
  0.4  3          0.8               0.50        50      0.8635498  0.2476190  0.9890909
  0.4  3          0.8               0.50       100      0.8437229  0.3142857  0.9818182
  0.4  3          0.8               0.50       150      0.8449459  0.3142857  0.9818182
  0.4  3          0.8               0.75        50      0.8584957  0.3142857  0.9782468
  0.4  3          0.8               0.75       100      0.8658009  0.3142857  0.9782468
  0.4  3          0.8               0.75       150      0.8560498  0.3142857  0.9781818
  0.4  3          0.8               1.00        50      0.8999892  0.3142857  0.9855195
  0.4  3          0.8               1.00       100      0.9029762  0.3142857  0.9855195
  0.4  3          0.8               1.00       150      0.8989177  0.3476190  0.9818831

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 2, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      3.6      1.0
  positive      6.5     89.0
                            
 Accuracy (average) : 0.9253

[1] "TEST accuracy: 0.925324675324675"
[1] "TEST +precision: 0.931972789115646"
[1] "TEST -precision: 0.785714285714286"
[1] "TEST specifity: 0.354838709677419"
[1] "TEST sensitivity: 0.989169675090253"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        1
            positive        4       94
[1] "TEST accuracy: 0.951456310679612"
[1] "TEST +precision: 0.959183673469388"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 0.989473684210526"
