[1] "DATASET NAME: Estrellas_Uni_IR_2"
[1] "TRAIN INSTANCES: 591"
[1] "TEST INSTANCES: 138"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.0425078868866"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

591 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 472, 473, 472, 473, 474 
Resampling results:

  ROC  Sens  Spec     
  1    1     0.9973684

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     35.0      0.2
  positive      0.0     64.8
                            
 Accuracy (average) : 0.9983

[1] "TEST accuracy: 0.998307952622673"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.995192307692308"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.997395833333333"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        0
            positive       10      122
[1] "TEST accuracy: 0.927536231884058"
[1] "TEST +precision: 0.924242424242424"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.375"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.19272431929906"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

591 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 472, 473, 474, 472, 473 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9496365  0.9662021  0.9270677
  0.010  2  0.9544860  0.9662021  0.9270677
  0.010  3  0.9551732  0.9515679  0.9323308
  0.255  1  0.9591912  0.9804878  0.9296651
  0.255  2  0.9636138  0.9804878  0.9348599
  0.255  3  0.9565036  0.9515679  0.9349282
  0.500  1  0.9591912  0.9804878  0.9296651
  0.500  2  0.9636138  0.9804878  0.9348599
  0.500  3  0.9565036  0.9515679  0.9349282

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.3      4.2
  positive      0.7     60.7
                            
 Accuracy (average) : 0.9509

[1] "TEST accuracy: 0.95093062605753"
[1] "TEST +precision: 0.988980716253444"
[1] "TEST -precision: 0.890350877192982"
[1] "TEST specifity: 0.980676328502415"
[1] "TEST sensitivity: 0.934895833333333"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        8        6
            positive        8      116
[1] "TEST accuracy: 0.898550724637681"
[1] "TEST +precision: 0.935483870967742"
[1] "TEST -precision: 0.571428571428571"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 0.950819672131147"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.6031343181928"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

591 samples
706 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 473, 472, 473, 472, 474 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9887792  0.8891986  0.9765208
  0.3  1          0.6               0.50       100      0.9956513  1.0000000  0.9739234
  0.3  1          0.6               0.50       150      0.9963987  1.0000000  0.9869446
  0.3  1          0.6               0.75        50      0.9924799  0.9276423  0.9791524
  0.3  1          0.6               0.75       100      0.9944281  1.0000000  0.9791524
  0.3  1          0.6               0.75       150      0.9958146  1.0000000  0.9791524
  0.3  1          0.6               1.00        50      0.9877369  0.8943089  0.9661312
  0.3  1          0.6               1.00       100      0.9939153  1.0000000  0.9739234
  0.3  1          0.6               1.00       150      0.9957965  1.0000000  0.9765550
  0.3  1          0.8               0.50        50      0.9910379  0.9423926  0.9686603
  0.3  1          0.8               0.50       100      0.9936170  1.0000000  0.9739576
  0.3  1          0.8               0.50       150      0.9960197  1.0000000  0.9790841
  0.3  1          0.8               0.75        50      0.9879298  0.9138211  0.9712919
  0.3  1          0.8               0.75       100      0.9939238  1.0000000  0.9712919
  0.3  1          0.8               0.75       150      0.9953720  1.0000000  0.9765208
  0.3  1          0.8               1.00        50      0.9868553  0.8747967  0.9635338
  0.3  1          0.8               1.00       100      0.9941060  1.0000000  0.9687286
  0.3  1          0.8               1.00       150      0.9959814  1.0000000  0.9713602
  0.3  2          0.6               0.50        50      0.9975095  1.0000000  0.9791183
  0.3  2          0.6               0.50       100      0.9974599  1.0000000  0.9791183
  0.3  2          0.6               0.50       150      0.9977073  1.0000000  0.9765208
  0.3  2          0.6               0.75        50      0.9990466  1.0000000  0.9713260
  0.3  2          0.6               0.75       100      0.9994874  1.0000000  0.9791183
  0.3  2          0.6               0.75       150      0.9989182  1.0000000  0.9738551
  0.3  2          0.6               1.00        50      0.9986379  1.0000000  0.9739576
  0.3  2          0.6               1.00       100      0.9998733  1.0000000  0.9817498
  0.3  2          0.6               1.00       150      0.9994959  1.0000000  0.9791524
  0.3  2          0.8               0.50        50      0.9926659  1.0000000  0.9791183
  0.3  2          0.8               0.50       100      0.9955035  1.0000000  0.9817498
  0.3  2          0.8               0.50       150      0.9942984  1.0000000  0.9791183
  0.3  2          0.8               0.75        50      0.9981900  1.0000000  0.9739234
  0.3  2          0.8               0.75       100      0.9993725  1.0000000  0.9738893
  0.3  2          0.8               0.75       150      0.9996274  1.0000000  0.9817157
  0.3  2          0.8               1.00        50      0.9969938  1.0000000  0.9843814
  0.3  2          0.8               1.00       100      0.9981236  1.0000000  0.9817498
  0.3  2          0.8               1.00       150      0.9985022  1.0000000  0.9869446
  0.3  3          0.6               0.50        50      0.9973547  0.9809524  0.9843472
  0.3  3          0.6               0.50       100      0.9976102  1.0000000  0.9817498
  0.3  3          0.6               0.50       150      0.9979953  1.0000000  0.9817157
  0.3  3          0.6               0.75        50      0.9987481  1.0000000  0.9869446
  0.3  3          0.6               0.75       100      0.9984856  1.0000000  0.9817157
  0.3  3          0.6               0.75       150      0.9979215  1.0000000  0.9869446
  0.3  3          0.6               1.00        50      1.0000000  1.0000000  0.9869788
  0.3  3          0.6               1.00       100      1.0000000  1.0000000  0.9895420
  0.3  3          0.6               1.00       150      1.0000000  1.0000000  0.9869446
  0.3  3          0.8               0.50        50      0.9984479  0.9809524  0.9790841
  0.3  3          0.8               0.50       100      0.9985082  1.0000000  0.9843131
  0.3  3          0.8               0.50       150      0.9980014  1.0000000  0.9843131
  0.3  3          0.8               0.75        50      0.9998733  1.0000000  0.9843472
  0.3  3          0.8               0.75       100      0.9997526  1.0000000  0.9843472
  0.3  3          0.8               0.75       150      0.9995053  1.0000000  0.9817157
  0.3  3          0.8               1.00        50      0.9997466  1.0000000  0.9817840
  0.3  3          0.8               1.00       100      0.9996893  1.0000000  0.9869788
  0.3  3          0.8               1.00       150      0.9995626  1.0000000  0.9869446
  0.4  1          0.6               0.50        50      0.9910473  0.9904762  0.9739234
  0.4  1          0.6               0.50       100      0.9948620  1.0000000  0.9739576
  0.4  1          0.6               0.50       150      0.9956958  1.0000000  0.9817498
  0.4  1          0.6               0.75        50      0.9917980  1.0000000  0.9713260
  0.4  1          0.6               0.75       100      0.9949312  1.0000000  0.9764867
  0.4  1          0.6               0.75       150      0.9965592  1.0000000  0.9817498
  0.4  1          0.6               1.00        50      0.9911723  0.9521487  0.9713260
  0.4  1          0.6               1.00       100      0.9951821  1.0000000  0.9713260
  0.4  1          0.6               1.00       150      0.9961097  1.0000000  0.9739234
  0.4  1          0.8               0.50        50      0.9905909  0.9711963  0.9713260
  0.4  1          0.8               0.50       100      0.9949396  1.0000000  0.9712919
  0.4  1          0.8               0.50       150      0.9946845  0.9809524  0.9869446
  0.4  1          0.8               0.75        50      0.9894328  1.0000000  0.9687286
  0.4  1          0.8               0.75       100      0.9954943  1.0000000  0.9687286
  0.4  1          0.8               0.75       150      0.9980836  1.0000000  0.9817498
  0.4  1          0.8               1.00        50      0.9899780  0.9714286  0.9687286
  0.4  1          0.8               1.00       100      0.9949115  1.0000000  0.9687628
  0.4  1          0.8               1.00       150      0.9956723  1.0000000  0.9739234
  0.4  2          0.6               0.50        50      0.9992579  1.0000000  0.9817157
  0.4  2          0.6               0.50       100      0.9997526  1.0000000  0.9817157
  0.4  2          0.6               0.50       150      0.9993197  1.0000000  0.9817157
  0.4  2          0.6               0.75        50      0.9983016  1.0000000  0.9764867
  0.4  2          0.6               0.75       100      0.9986757  1.0000000  0.9817157
  0.4  2          0.6               0.75       150      0.9984238  1.0000000  0.9790841
  0.4  2          0.6               1.00        50      0.9982891  1.0000000  0.9739234
  0.4  2          0.6               1.00       100      0.9995507  1.0000000  0.9843131
  0.4  2          0.6               1.00       150      0.9994959  1.0000000  0.9843131
  0.4  2          0.8               0.50        50      0.9963867  1.0000000  0.9791183
  0.4  2          0.8               0.50       100      0.9987359  1.0000000  0.9790841
  0.4  2          0.8               0.50       150      0.9986231  1.0000000  0.9790841
  0.4  2          0.8               0.75        50      0.9985946  1.0000000  0.9843472
  0.4  2          0.8               0.75       100      0.9989824  1.0000000  0.9816815
  0.4  2          0.8               0.75       150      0.9989182  1.0000000  0.9816815
  0.4  2          0.8               1.00        50      0.9977898  1.0000000  0.9791524
  0.4  2          0.8               1.00       100      0.9995626  1.0000000  0.9817498
  0.4  2          0.8               1.00       150      0.9985550  1.0000000  0.9817157
  0.4  3          0.6               0.50        50      0.9990583  1.0000000  0.9869446
  0.4  3          0.6               0.50       100      0.9981190  1.0000000  0.9843472
  0.4  3          0.6               0.50       150      0.9977521  1.0000000  0.9869446
  0.4  3          0.6               0.75        50      0.9980288  1.0000000  0.9843472
  0.4  3          0.6               0.75       100      0.9985440  1.0000000  0.9843472
  0.4  3          0.6               0.75       150      0.9986073  1.0000000  0.9843472
  0.4  3          0.6               1.00        50      0.9995053  1.0000000  0.9895420
  0.4  3          0.6               1.00       100      0.9989487  1.0000000  0.9869446
  0.4  3          0.6               1.00       150      0.9989487  1.0000000  0.9869446
  0.4  3          0.8               0.50        50      0.9990678  0.9809524  0.9791183
  0.4  3          0.8               0.50       100      0.9995053  1.0000000  0.9843472
  0.4  3          0.8               0.50       150      0.9991885  1.0000000  0.9817157
  0.4  3          0.8               0.75        50      0.9992485  1.0000000  0.9843472
  0.4  3          0.8               0.75       100      0.9992579  1.0000000  0.9843472
  0.4  3          0.8               0.75       150      0.9991960  1.0000000  0.9843472
  0.4  3          0.8               1.00        50      1.0000000  1.0000000  0.9765208
  0.4  3          0.8               1.00       100      0.9994932  1.0000000  0.9791183
  0.4  3          0.8               1.00       150      0.9998099  1.0000000  0.9817157

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     35.0      0.8
  positive      0.0     64.1
                            
 Accuracy (average) : 0.9915

[1] "TEST accuracy: 0.991539763113367"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.976415094339623"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.986979166666667"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        2
            positive       10      120
[1] "TEST accuracy: 0.91304347826087"
[1] "TEST +precision: 0.923076923076923"
[1] "TEST -precision: 0.75"
[1] "TEST specifity: 0.375"
[1] "TEST sensitivity: 0.983606557377049"
