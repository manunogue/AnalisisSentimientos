[1] "DATASET NAME: Bodegas_Uni_IR_5"
[1] "TRAIN INSTANCES: 547"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.40357184410095"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

547 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 437, 438, 437, 438, 438 
Resampling results:

  ROC        Sens      Spec     
  0.9855166  0.929803  0.9876543

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     24.1      0.9
  positive      1.8     73.1
                            
 Accuracy (average) : 0.9726

[1] "TEST accuracy: 0.972577696526508"
[1] "TEST +precision: 0.975609756097561"
[1] "TEST -precision: 0.963503649635037"
[1] "TEST specifity: 0.929577464788732"
[1] "TEST sensitivity: 0.987654320987654"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       16        2
            positive        7      136
[1] "TEST accuracy: 0.944099378881988"
[1] "TEST +precision: 0.951048951048951"
[1] "TEST -precision: 0.888888888888889"
[1] "TEST specifity: 0.695652173913043"
[1] "TEST sensitivity: 0.985507246376812"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.01637236674627"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

547 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 438, 437, 437, 438, 438 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8097838  0.6408867  0.9555556
  0.010  2  0.8173250  0.6480296  0.9530864
  0.010  3  0.8184334  0.6482759  0.9481481
  0.255  1  0.8736423  0.8534483  0.9111111
  0.255  2  0.8818266  0.8253695  0.9135802
  0.255  3  0.8910433  0.7970443  0.9111111
  0.500  1  0.8805556  0.8603448  0.9160494
  0.500  2  0.8906632  0.8322660  0.9185185
  0.500  3  0.9066807  0.8108374  0.9160494

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     21.0      6.2
  positive      4.9     67.8
                            
 Accuracy (average) : 0.8885

[1] "TEST accuracy: 0.888482632541133"
[1] "TEST +precision: 0.9321608040201"
[1] "TEST -precision: 0.771812080536913"
[1] "TEST specifity: 0.809859154929577"
[1] "TEST sensitivity: 0.916049382716049"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       12        8
            positive       11      130
[1] "TEST accuracy: 0.881987577639752"
[1] "TEST +precision: 0.921985815602837"
[1] "TEST -precision: 0.6"
[1] "TEST specifity: 0.521739130434783"
[1] "TEST sensitivity: 0.942028985507246"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.25416996479034"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

547 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 437, 438, 437, 438, 438 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9667944  0.6903941  0.9925926
  0.3  1          0.6               0.50       100      0.9741106  0.8174877  0.9876543
  0.3  1          0.6               0.50       150      0.9780150  0.8519704  0.9876543
  0.3  1          0.6               0.75        50      0.9719455  0.7187192  0.9925926
  0.3  1          0.6               0.75       100      0.9738734  0.8100985  0.9925926
  0.3  1          0.6               0.75       150      0.9803716  0.8450739  0.9901235
  0.3  1          0.6               1.00        50      0.9722678  0.7044335  0.9950617
  0.3  1          0.6               1.00       100      0.9772091  0.7679803  0.9950617
  0.3  1          0.6               1.00       150      0.9745332  0.8593596  0.9901235
  0.3  1          0.8               0.50        50      0.9652284  0.6761084  0.9925926
  0.3  1          0.8               0.50       100      0.9775041  0.8379310  0.9925926
  0.3  1          0.8               0.50       150      0.9763790  0.8588670  0.9876543
  0.3  1          0.8               0.75        50      0.9647814  0.7467980  0.9901235
  0.3  1          0.8               0.75       100      0.9778325  0.8241379  0.9901235
  0.3  1          0.8               0.75       150      0.9775436  0.8450739  0.9901235
  0.3  1          0.8               1.00        50      0.9747157  0.7044335  0.9925926
  0.3  1          0.8               1.00       100      0.9772091  0.7822660  0.9950617
  0.3  1          0.8               1.00       150      0.9753238  0.8593596  0.9925926
  0.3  2          0.6               0.50        50      0.9757921  0.8453202  0.9901235
  0.3  2          0.6               0.50       100      0.9790458  0.8802956  0.9802469
  0.3  2          0.6               0.50       150      0.9792495  0.8731527  0.9777778
  0.3  2          0.6               0.75        50      0.9737852  0.8660099  0.9901235
  0.3  2          0.6               0.75       100      0.9767621  0.8662562  0.9876543
  0.3  2          0.6               0.75       150      0.9781944  0.8874384  0.9753086
  0.3  2          0.6               1.00        50      0.9768427  0.8169951  0.9901235
  0.3  2          0.6               1.00       100      0.9800432  0.8450739  0.9876543
  0.3  2          0.6               1.00       150      0.9797573  0.8945813  0.9851852
  0.3  2          0.8               0.50        50      0.9829228  0.8386700  0.9827160
  0.3  2          0.8               0.50       100      0.9834610  0.8731527  0.9827160
  0.3  2          0.8               0.50       150      0.9799063  0.8802956  0.9753086
  0.3  2          0.8               0.75        50      0.9785927  0.8312808  0.9901235
  0.3  2          0.8               0.75       100      0.9784468  0.8874384  0.9876543
  0.3  2          0.8               0.75       150      0.9780575  0.8874384  0.9827160
  0.3  2          0.8               1.00        50      0.9789242  0.8384236  0.9901235
  0.3  2          0.8               1.00       100      0.9813021  0.8522167  0.9925926
  0.3  2          0.8               1.00       150      0.9800858  0.8802956  0.9901235
  0.3  3          0.6               0.50        50      0.9817095  0.8379310  0.9753086
  0.3  3          0.6               0.50       100      0.9818646  0.8450739  0.9802469
  0.3  3          0.6               0.50       150      0.9805449  0.8665025  0.9753086
  0.3  3          0.6               0.75        50      0.9825731  0.8376847  0.9851852
  0.3  3          0.6               0.75       100      0.9819893  0.8876847  0.9802469
  0.3  3          0.6               0.75       150      0.9815149  0.8662562  0.9753086
  0.3  3          0.6               1.00        50      0.9768199  0.8381773  0.9876543
  0.3  3          0.6               1.00       100      0.9794867  0.8665025  0.9777778
  0.3  3          0.6               1.00       150      0.9802317  0.8802956  0.9703704
  0.3  3          0.8               0.50        50      0.9858785  0.8450739  0.9851852
  0.3  3          0.8               0.50       100      0.9836222  0.8524631  0.9827160
  0.3  3          0.8               0.50       150      0.9822995  0.8596059  0.9827160
  0.3  3          0.8               0.75        50      0.9804233  0.8522167  0.9876543
  0.3  3          0.8               0.75       100      0.9810983  0.8665025  0.9753086
  0.3  3          0.8               0.75       150      0.9801070  0.8802956  0.9777778
  0.3  3          0.8               1.00        50      0.9843763  0.8453202  0.9851852
  0.3  3          0.8               1.00       100      0.9828711  0.8736453  0.9802469
  0.3  3          0.8               1.00       150      0.9830962  0.8665025  0.9802469
  0.4  1          0.6               0.50        50      0.9701621  0.7682266  0.9876543
  0.4  1          0.6               0.50       100      0.9796813  0.8522167  0.9876543
  0.4  1          0.6               0.50       150      0.9797969  0.8738916  0.9703704
  0.4  1          0.6               0.75        50      0.9796783  0.7753695  0.9901235
  0.4  1          0.6               0.75       100      0.9781031  0.8517241  0.9851852
  0.4  1          0.6               0.75       150      0.9808733  0.8802956  0.9901235
  0.4  1          0.6               1.00        50      0.9764489  0.7539409  0.9925926
  0.4  1          0.6               1.00       100      0.9767926  0.8241379  0.9901235
  0.4  1          0.6               1.00       150      0.9757769  0.8731527  0.9901235
  0.4  1          0.8               0.50        50      0.9733625  0.8029557  0.9901235
  0.4  1          0.8               0.50       100      0.9816700  0.8662562  0.9876543
  0.4  1          0.8               0.50       150      0.9815149  0.8733990  0.9851852
  0.4  1          0.8               0.75        50      0.9741182  0.7403941  0.9925926
  0.4  1          0.8               0.75       100      0.9792343  0.8517241  0.9901235
  0.4  1          0.8               0.75       150      0.9779693  0.8802956  0.9876543
  0.4  1          0.8               1.00        50      0.9769142  0.7330049  0.9925926
  0.4  1          0.8               1.00       100      0.9785745  0.8310345  0.9901235
  0.4  1          0.8               1.00       150      0.9746366  0.8593596  0.9876543
  0.4  2          0.6               0.50        50      0.9721036  0.8874384  0.9876543
  0.4  2          0.6               0.50       100      0.9768716  0.8802956  0.9777778
  0.4  2          0.6               0.50       150      0.9778842  0.8731527  0.9703704
  0.4  2          0.6               0.75        50      0.9784498  0.8381773  0.9876543
  0.4  2          0.6               0.75       100      0.9806027  0.8945813  0.9827160
  0.4  2          0.6               0.75       150      0.9786991  0.8874384  0.9728395
  0.4  2          0.6               1.00        50      0.9809737  0.8450739  0.9901235
  0.4  2          0.6               1.00       100      0.9805388  0.8736453  0.9876543
  0.4  2          0.6               1.00       150      0.9817400  0.8874384  0.9827160
  0.4  2          0.8               0.50        50      0.9753147  0.8591133  0.9802469
  0.4  2          0.8               0.50       100      0.9744025  0.8660099  0.9777778
  0.4  2          0.8               0.50       150      0.9755215  0.8731527  0.9703704
  0.4  2          0.8               0.75        50      0.9800949  0.8381773  0.9901235
  0.4  2          0.8               0.75       100      0.9799763  0.8736453  0.9876543
  0.4  2          0.8               0.75       150      0.9782096  0.8665025  0.9753086
  0.4  2          0.8               1.00        50      0.9817764  0.8381773  0.9925926
  0.4  2          0.8               1.00       100      0.9825245  0.8945813  0.9876543
  0.4  2          0.8               1.00       150      0.9833577  0.8802956  0.9777778
  0.4  3          0.6               0.50        50      0.9771362  0.8669951  0.9827160
  0.4  3          0.6               0.50       100      0.9731649  0.8738916  0.9827160
  0.4  3          0.6               0.50       150      0.9723621  0.8596059  0.9753086
  0.4  3          0.6               0.75        50      0.9809524  0.8450739  0.9827160
  0.4  3          0.6               0.75       100      0.9820501  0.8874384  0.9802469
  0.4  3          0.6               0.75       150      0.9799398  0.8802956  0.9753086
  0.4  3          0.6               1.00        50      0.9803929  0.8874384  0.9851852
  0.4  3          0.6               1.00       100      0.9833759  0.8802956  0.9851852
  0.4  3          0.6               1.00       150      0.9824849  0.8945813  0.9777778
  0.4  3          0.8               0.50        50      0.9813142  0.8733990  0.9753086
  0.4  3          0.8               0.50       100      0.9795171  0.8736453  0.9703704
  0.4  3          0.8               0.50       150      0.9787204  0.8874384  0.9654321
  0.4  3          0.8               0.75        50      0.9802925  0.8731527  0.9827160
  0.4  3          0.8               0.75       100      0.9793073  0.8731527  0.9777778
  0.4  3          0.8               0.75       150      0.9788238  0.8945813  0.9728395
  0.4  3          0.8               1.00        50      0.9790640  0.8874384  0.9876543
  0.4  3          0.8               1.00       100      0.9801618  0.8802956  0.9753086
  0.4  3          0.8               1.00       150      0.9808064  0.8802956  0.9777778

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.5.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     21.9      1.1
  positive      4.0     72.9
                            
 Accuracy (average) : 0.9488

[1] "TEST accuracy: 0.948811700182815"
[1] "TEST +precision: 0.947743467933492"
[1] "TEST -precision: 0.952380952380952"
[1] "TEST specifity: 0.845070422535211"
[1] "TEST sensitivity: 0.985185185185185"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        6
            positive        8      132
[1] "TEST accuracy: 0.91304347826087"
[1] "TEST +precision: 0.942857142857143"
[1] "TEST -precision: 0.714285714285714"
[1] "TEST specifity: 0.652173913043478"
[1] "TEST sensitivity: 0.956521739130435"
