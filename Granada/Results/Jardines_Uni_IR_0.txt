[1] "DATASET NAME: Jardines_Uni_IR_0"
[1] "TRAIN INSTANCES: 669"
[1] "TEST INSTANCES: 223"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.51252698898315"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

669 samples
736 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 534, 535, 535, 536, 536 
Resampling results:

  ROC        Sens       Spec     
  0.8451967  0.1166667  0.9984733

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.3      0.1
  positive      2.1     97.5
                            
 Accuracy (average) : 0.9776

[1] "TEST accuracy: 0.977578475336323"
[1] "TEST +precision: 0.978978978978979"
[1] "TEST -precision: 0.666666666666667"
[1] "TEST specifity: 0.125"
[1] "TEST sensitivity: 0.998468606431853"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        0
            positive        2      219
[1] "TEST accuracy: 0.991031390134529"
[1] "TEST +precision: 0.990950226244344"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.22632985115051"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

669 samples
736 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 535, 536, 534, 535, 536 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.5000000  0     1.0000000
  0.010  2  0.5000000  0     1.0000000
  0.010  3  0.5000000  0     1.0000000
  0.255  1  0.4659385  0     0.9984733
  0.255  2  0.4946565  0     0.9984733
  0.255  3  0.5000000  0     1.0000000
  0.500  1  0.4930711  0     0.9923664
  0.500  2  0.5136250  0     0.9923664
  0.500  3  0.4977099  0     0.9984733

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.7
  positive      2.4     96.9
                            
 Accuracy (average) : 0.9686

[1] "TEST accuracy: 0.968609865470852"
[1] "TEST +precision: 0.975903614457831"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.992343032159265"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        1
            positive        4      218
[1] "TEST accuracy: 0.977578475336323"
[1] "TEST +precision: 0.981981981981982"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.995433789954338"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.72607359886169"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

669 samples
736 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 535, 534, 536, 536, 535 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7068761  0.00000000  1.0000000
  0.3  1          0.6               0.50       100      0.7318555  0.00000000  1.0000000
  0.3  1          0.6               0.50       150      0.7225328  0.06666667  0.9969466
  0.3  1          0.6               0.75        50      0.7869877  0.00000000  1.0000000
  0.3  1          0.6               0.75       100      0.8064631  0.00000000  0.9984615
  0.3  1          0.6               0.75       150      0.7781640  0.05000000  0.9969348
  0.3  1          0.6               1.00        50      0.7417264  0.05000000  1.0000000
  0.3  1          0.6               1.00       100      0.7389372  0.05000000  0.9984615
  0.3  1          0.6               1.00       150      0.7370777  0.05000000  0.9969348
  0.3  1          0.8               0.50        50      0.7188002  0.00000000  1.0000000
  0.3  1          0.8               0.50       100      0.7431591  0.05000000  1.0000000
  0.3  1          0.8               0.50       150      0.7632472  0.18333333  0.9969466
  0.3  1          0.8               0.75        50      0.7854198  0.00000000  1.0000000
  0.3  1          0.8               0.75       100      0.7962419  0.11666667  0.9984615
  0.3  1          0.8               0.75       150      0.7802897  0.11666667  0.9969348
  0.3  1          0.8               1.00        50      0.7350636  0.05000000  1.0000000
  0.3  1          0.8               1.00       100      0.7273850  0.05000000  0.9984615
  0.3  1          0.8               1.00       150      0.7333098  0.05000000  0.9969348
  0.3  2          0.6               0.50        50      0.7148914  0.00000000  0.9984615
  0.3  2          0.6               0.50       100      0.7483461  0.06666667  0.9984615
  0.3  2          0.6               0.50       150      0.7441554  0.13333333  0.9984615
  0.3  2          0.6               0.75        50      0.7456958  0.00000000  0.9969231
  0.3  2          0.6               0.75       100      0.7666823  0.00000000  0.9969231
  0.3  2          0.6               0.75       150      0.7700685  0.00000000  0.9969231
  0.3  2          0.6               1.00        50      0.7294578  0.11666667  1.0000000
  0.3  2          0.6               1.00       100      0.7186123  0.06666667  1.0000000
  0.3  2          0.6               1.00       150      0.7271677  0.00000000  1.0000000
  0.3  2          0.8               0.50        50      0.7546643  0.00000000  0.9984615
  0.3  2          0.8               0.50       100      0.7441828  0.00000000  0.9984615
  0.3  2          0.8               0.50       150      0.7429301  0.00000000  0.9984615
  0.3  2          0.8               0.75        50      0.7340380  0.05000000  0.9984615
  0.3  2          0.8               0.75       100      0.7197123  0.00000000  0.9984615
  0.3  2          0.8               0.75       150      0.7380035  0.06666667  0.9984615
  0.3  2          0.8               1.00        50      0.7201018  0.00000000  1.0000000
  0.3  2          0.8               1.00       100      0.7211529  0.06666667  0.9984615
  0.3  2          0.8               1.00       150      0.7195185  0.06666667  0.9984615
  0.3  3          0.6               0.50        50      0.7141006  0.00000000  0.9984615
  0.3  3          0.6               0.50       100      0.7251987  0.00000000  0.9984615
  0.3  3          0.6               0.50       150      0.7142259  0.00000000  0.9984615
  0.3  3          0.6               0.75        50      0.7326267  0.00000000  0.9984615
  0.3  3          0.6               0.75       100      0.7416970  0.00000000  0.9984615
  0.3  3          0.6               0.75       150      0.7304893  0.00000000  0.9984615
  0.3  3          0.6               1.00        50      0.7364494  0.05000000  1.0000000
  0.3  3          0.6               1.00       100      0.7348972  0.00000000  0.9984615
  0.3  3          0.6               1.00       150      0.7462321  0.00000000  1.0000000
  0.3  3          0.8               0.50        50      0.7189411  0.00000000  1.0000000
  0.3  3          0.8               0.50       100      0.7138305  0.06666667  0.9984615
  0.3  3          0.8               0.50       150      0.6835095  0.06666667  0.9969348
  0.3  3          0.8               0.75        50      0.7400450  0.05000000  0.9969348
  0.3  3          0.8               0.75       100      0.7375475  0.00000000  0.9954081
  0.3  3          0.8               0.75       150      0.7324819  0.00000000  0.9969348
  0.3  3          0.8               1.00        50      0.7434977  0.00000000  0.9984615
  0.3  3          0.8               1.00       100      0.7388569  0.00000000  0.9984615
  0.3  3          0.8               1.00       150      0.7359542  0.06666667  0.9984615
  0.4  1          0.6               0.50        50      0.6796888  0.00000000  1.0000000
  0.4  1          0.6               0.50       100      0.7282364  0.00000000  0.9953964
  0.4  1          0.6               0.50       150      0.7394794  0.05000000  0.9969466
  0.4  1          0.6               0.75        50      0.7735995  0.05000000  0.9984615
  0.4  1          0.6               0.75       100      0.7760697  0.18333333  0.9969348
  0.4  1          0.6               0.75       150      0.7632903  0.18333333  0.9923547
  0.4  1          0.6               1.00        50      0.7144901  0.05000000  1.0000000
  0.4  1          0.6               1.00       100      0.7133842  0.05000000  0.9984615
  0.4  1          0.6               1.00       150      0.7249599  0.11666667  0.9984615
  0.4  1          0.8               0.50        50      0.7833862  0.06666667  0.9984615
  0.4  1          0.8               0.50       100      0.7553748  0.13333333  0.9984733
  0.4  1          0.8               0.50       150      0.7347915  0.13333333  0.9954081
  0.4  1          0.8               0.75        50      0.7821863  0.00000000  0.9969348
  0.4  1          0.8               0.75       100      0.7754923  0.06666667  0.9938814
  0.4  1          0.8               0.75       150      0.7644705  0.13333333  0.9908280
  0.4  1          0.8               1.00        50      0.7654140  0.05000000  1.0000000
  0.4  1          0.8               1.00       100      0.7504424  0.05000000  0.9969348
  0.4  1          0.8               1.00       150      0.7573948  0.11666667  0.9969348
  0.4  2          0.6               0.50        50      0.6717087  0.06666667  0.9984615
  0.4  2          0.6               0.50       100      0.6865864  0.06666667  0.9984615
  0.4  2          0.6               0.50       150      0.7044334  0.06666667  0.9984615
  0.4  2          0.6               0.75        50      0.7389802  0.11666667  0.9984615
  0.4  2          0.6               0.75       100      0.7268898  0.06666667  0.9984615
  0.4  2          0.6               0.75       150      0.7270757  0.06666667  0.9969348
  0.4  2          0.6               1.00        50      0.7453729  0.05000000  0.9984615
  0.4  2          0.6               1.00       100      0.7498043  0.05000000  0.9984615
  0.4  2          0.6               1.00       150      0.7548738  0.05000000  0.9984615
  0.4  2          0.8               0.50        50      0.7123566  0.00000000  0.9984733
  0.4  2          0.8               0.50       100      0.7501566  0.00000000  0.9938696
  0.4  2          0.8               0.50       150      0.7566999  0.05000000  0.9938696
  0.4  2          0.8               0.75        50      0.7296477  0.05000000  0.9984615
  0.4  2          0.8               0.75       100      0.7288589  0.05000000  0.9938814
  0.4  2          0.8               0.75       150      0.7371717  0.00000000  0.9938814
  0.4  2          0.8               1.00        50      0.7271814  0.00000000  1.0000000
  0.4  2          0.8               1.00       100      0.7315013  0.00000000  0.9969348
  0.4  2          0.8               1.00       150      0.7263966  0.06666667  0.9969348
  0.4  3          0.6               0.50        50      0.7270053  0.06666667  1.0000000
  0.4  3          0.6               0.50       100      0.7379702  0.06666667  0.9984733
  0.4  3          0.6               0.50       150      0.7325739  0.06666667  1.0000000
  0.4  3          0.6               0.75        50      0.7747152  0.00000000  0.9969348
  0.4  3          0.6               0.75       100      0.7747465  0.05000000  0.9938814
  0.4  3          0.6               0.75       150      0.7598375  0.05000000  0.9938814
  0.4  3          0.6               1.00        50      0.7336074  0.00000000  0.9984615
  0.4  3          0.6               1.00       100      0.7303190  0.00000000  0.9984615
  0.4  3          0.6               1.00       150      0.7318888  0.00000000  0.9984615
  0.4  3          0.8               0.50        50      0.6394656  0.00000000  1.0000000
  0.4  3          0.8               0.50       100      0.6752339  0.00000000  0.9969231
  0.4  3          0.8               0.50       150      0.6330671  0.00000000  0.9984615
  0.4  3          0.8               0.75        50      0.7624819  0.00000000  1.0000000
  0.4  3          0.8               0.75       100      0.7608397  0.00000000  1.0000000
  0.4  3          0.8               0.75       150      0.7656058  0.05000000  1.0000000
  0.4  3          0.8               1.00        50      0.7333235  0.06666667  0.9984615
  0.4  3          0.8               1.00       100      0.7270209  0.00000000  0.9984615
  0.4  3          0.8               1.00       150      0.7257526  0.00000000  0.9984615

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 1, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.1
  positive      2.4     97.5
                            
 Accuracy (average) : 0.9746

[1] "TEST accuracy: 0.974588938714499"
[1] "TEST +precision: 0.976047904191617"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.998468606431853"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        0
            positive        3      219
[1] "TEST accuracy: 0.986547085201794"
[1] "TEST +precision: 0.986486486486487"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.25"
[1] "TEST sensitivity: 1"
