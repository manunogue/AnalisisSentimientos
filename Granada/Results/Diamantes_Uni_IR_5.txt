[1] "DATASET NAME: Diamantes_Uni_IR_5"
[1] "TRAIN INSTANCES: 462"
[1] "TEST INSTANCES: 131"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.15010690689087"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

462 samples
797 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 370, 369, 371, 369, 369 
Resampling results:

  ROC       Sens       Spec     
  0.999682  0.9764706  0.9946306

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.6      0.4
  positive      0.4     80.5
                            
 Accuracy (average) : 0.9913

[1] "TEST accuracy: 0.991341991341991"
[1] "TEST +precision: 0.994652406417112"
[1] "TEST -precision: 0.977272727272727"
[1] "TEST specifity: 0.977272727272727"
[1] "TEST sensitivity: 0.994652406417112"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        0
            positive        8      122
[1] "TEST accuracy: 0.938931297709924"
[1] "TEST +precision: 0.938461538461538"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.22058864831924"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

462 samples
797 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 370, 369, 369, 370, 370 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8905928  0.8267974  0.9464505
  0.010  2  0.8614616  0.7797386  0.9464505
  0.010  3  0.8123947  0.6797386  0.9491171
  0.255  1  0.9719915  0.9764706  0.9491171
  0.255  2  0.9660790  0.9764706  0.9544505
  0.255  3  0.9672620  0.9764706  0.9518198
  0.500  1  0.9687758  0.9764706  0.9491171
  0.500  2  0.9660790  0.9764706  0.9544505
  0.500  3  0.9662598  0.9764706  0.9544865

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.6      4.1
  positive      0.4     76.8
                            
 Accuracy (average) : 0.9545

[1] "TEST accuracy: 0.954545454545455"
[1] "TEST +precision: 0.994397759103641"
[1] "TEST -precision: 0.819047619047619"
[1] "TEST specifity: 0.977272727272727"
[1] "TEST sensitivity: 0.949197860962567"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        9
            positive        8      113
[1] "TEST accuracy: 0.870229007633588"
[1] "TEST +precision: 0.933884297520661"
[1] "TEST -precision: 0.1"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.926229508196721"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.20555556615194"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

462 samples
797 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 370, 369, 369, 370, 370 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9906234  0.8189542  0.9866667
  0.3  1          0.6               0.50       100      0.9920101  0.9542484  0.9786306
  0.3  1          0.6               0.50       150      0.9923366  0.9764706  0.9759279
  0.3  1          0.6               0.75        50      0.9925246  0.8758170  0.9812973
  0.3  1          0.6               0.75       100      0.9970995  1.0000000  0.9839640
  0.3  1          0.6               0.75       150      0.9975432  1.0000000  0.9839640
  0.3  1          0.6               1.00        50      0.9944291  0.9078431  0.9866306
  0.3  1          0.6               1.00       100      0.9966296  1.0000000  0.9839640
  0.3  1          0.6               1.00       150      0.9986151  1.0000000  0.9839640
  0.3  1          0.8               0.50        50      0.9900400  0.8522876  0.9812973
  0.3  1          0.8               0.50       100      0.9939756  0.9542484  0.9812973
  0.3  1          0.8               0.50       150      0.9916891  0.9542484  0.9786306
  0.3  1          0.8               0.75        50      0.9947019  0.9000000  0.9866306
  0.3  1          0.8               0.75       100      0.9981599  1.0000000  0.9839640
  0.3  1          0.8               0.75       150      0.9958264  1.0000000  0.9839640
  0.3  1          0.8               1.00        50      0.9908387  0.9098039  0.9839640
  0.3  1          0.8               1.00       100      0.9975882  1.0000000  0.9812973
  0.3  1          0.8               1.00       150      0.9974139  1.0000000  0.9812973
  0.3  2          0.6               0.50        50      0.9954905  0.9431373  0.9839640
  0.3  2          0.6               0.50       100      0.9953598  0.9764706  0.9786306
  0.3  2          0.6               0.50       150      0.9955080  0.9764706  0.9812973
  0.3  2          0.6               0.75        50      0.9978301  1.0000000  0.9839640
  0.3  2          0.6               0.75       100      0.9965886  1.0000000  0.9839640
  0.3  2          0.6               0.75       150      0.9961354  1.0000000  0.9839640
  0.3  2          0.6               1.00        50      0.9970458  1.0000000  0.9866306
  0.3  2          0.6               1.00       100      0.9964183  1.0000000  0.9812613
  0.3  2          0.6               1.00       150      0.9965752  1.0000000  0.9812613
  0.3  2          0.8               0.50        50      0.9937959  0.9542484  0.9839640
  0.3  2          0.8               0.50       100      0.9936458  0.9542484  0.9812973
  0.3  2          0.8               0.50       150      0.9931926  0.9764706  0.9812973
  0.3  2          0.8               0.75        50      0.9965624  1.0000000  0.9812973
  0.3  2          0.8               0.75       100      0.9958177  1.0000000  0.9839640
  0.3  2          0.8               0.75       150      0.9955080  1.0000000  0.9839640
  0.3  2          0.8               1.00        50      0.9962963  1.0000000  0.9866306
  0.3  2          0.8               1.00       100      0.9956514  1.0000000  0.9839640
  0.3  2          0.8               1.00       150      0.9951808  1.0000000  0.9839640
  0.3  3          0.6               0.50        50      0.9966060  0.9542484  0.9893333
  0.3  3          0.6               0.50       100      0.9961703  0.9764706  0.9839640
  0.3  3          0.6               0.50       150      0.9970766  1.0000000  0.9786306
  0.3  3          0.6               0.75        50      0.9983181  1.0000000  0.9866306
  0.3  3          0.6               0.75       100      0.9978562  1.0000000  0.9866306
  0.3  3          0.6               0.75       150      0.9972723  1.0000000  0.9866306
  0.3  3          0.6               1.00        50      0.9970632  1.0000000  0.9839640
  0.3  3          0.6               1.00       100      0.9953725  1.0000000  0.9893333
  0.3  3          0.6               1.00       150      0.9956776  1.0000000  0.9893333
  0.3  3          0.8               0.50        50      0.9967320  0.9764706  0.9892973
  0.3  3          0.8               0.50       100      0.9981438  1.0000000  0.9840000
  0.3  3          0.8               0.50       150      0.9986144  1.0000000  0.9785946
  0.3  3          0.8               0.75        50      0.9970766  1.0000000  0.9839640
  0.3  3          0.8               0.75       100      0.9953947  1.0000000  0.9839640
  0.3  3          0.8               0.75       150      0.9961481  1.0000000  0.9839640
  0.3  3          0.8               1.00        50      0.9964357  1.0000000  0.9866667
  0.3  3          0.8               1.00       100      0.9957908  1.0000000  0.9866667
  0.3  3          0.8               1.00       150      0.9959739  1.0000000  0.9866667
  0.4  1          0.6               0.50        50      0.9945769  0.9542484  0.9812973
  0.4  1          0.6               0.50       100      0.9921483  0.9542484  0.9866306
  0.4  1          0.6               0.50       150      0.9918527  0.9542484  0.9839640
  0.4  1          0.6               0.75        50      0.9970025  0.9333333  0.9866306
  0.4  1          0.6               0.75       100      0.9967589  1.0000000  0.9812973
  0.4  1          0.6               0.75       150      0.9961381  1.0000000  0.9812973
  0.4  1          0.6               1.00        50      0.9962538  1.0000000  0.9866306
  0.4  1          0.6               1.00       100      0.9967790  1.0000000  0.9812973
  0.4  1          0.6               1.00       150      0.9964452  1.0000000  0.9812973
  0.4  1          0.8               0.50        50      0.9951882  0.9777778  0.9839640
  0.4  1          0.8               0.50       100      0.9950555  0.9542484  0.9866306
  0.4  1          0.8               0.50       150      0.9938362  0.9777778  0.9866306
  0.4  1          0.8               0.75        50      0.9955443  1.0000000  0.9812973
  0.4  1          0.8               0.75       100      0.9960148  1.0000000  0.9839640
  0.4  1          0.8               0.75       150      0.9929266  1.0000000  0.9866306
  0.4  1          0.8               1.00        50      0.9951565  1.0000000  0.9812973
  0.4  1          0.8               1.00       100      0.9981713  1.0000000  0.9812973
  0.4  1          0.8               1.00       150      0.9964653  1.0000000  0.9839640
  0.4  2          0.6               0.50        50      0.9958217  0.9209150  0.9866306
  0.4  2          0.6               0.50       100      0.9959786  0.9764706  0.9812973
  0.4  2          0.6               0.50       150      0.9965886  1.0000000  0.9839640
  0.4  2          0.6               0.75        50      0.9974239  1.0000000  0.9866306
  0.4  2          0.6               0.75       100      0.9970766  1.0000000  0.9839279
  0.4  2          0.6               0.75       150      0.9967455  1.0000000  0.9839640
  0.4  2          0.6               1.00        50      0.9972026  1.0000000  0.9839640
  0.4  2          0.6               1.00       100      0.9950374  1.0000000  0.9839640
  0.4  2          0.6               1.00       150      0.9953377  1.0000000  0.9839640
  0.4  2          0.8               0.50        50      0.9952808  1.0000000  0.9866306
  0.4  2          0.8               0.50       100      0.9955697  1.0000000  0.9839640
  0.4  2          0.8               0.50       150      0.9974105  1.0000000  0.9812613
  0.4  2          0.8               0.75        50      0.9978475  1.0000000  0.9866667
  0.4  2          0.8               0.75       100      0.9969023  1.0000000  0.9839640
  0.4  2          0.8               0.75       150      0.9968889  1.0000000  0.9839640
  0.4  2          0.8               1.00        50      0.9964452  1.0000000  0.9839640
  0.4  2          0.8               1.00       100      0.9955174  1.0000000  0.9839640
  0.4  2          0.8               1.00       150      0.9952037  1.0000000  0.9839640
  0.4  3          0.6               0.50        50      0.9955951  0.9209150  0.9866306
  0.4  3          0.6               0.50       100      0.9957433  0.9666667  0.9866306
  0.4  3          0.6               0.50       150      0.9968017  0.9666667  0.9839640
  0.4  3          0.6               0.75        50      0.9955080  1.0000000  0.9812973
  0.4  3          0.6               0.75       100      0.9965926  1.0000000  0.9812973
  0.4  3          0.6               0.75       150      0.9953987  1.0000000  0.9812973
  0.4  3          0.6               1.00        50      0.9968889  1.0000000  0.9812613
  0.4  3          0.6               1.00       100      0.9958344  1.0000000  0.9812613
  0.4  3          0.6               1.00       150      0.9961220  1.0000000  0.9812613
  0.4  3          0.8               0.50        50      0.9923373  0.9777778  0.9812613
  0.4  3          0.8               0.50       100      0.9946634  0.9777778  0.9785586
  0.4  3          0.8               0.50       150      0.9949510  1.0000000  0.9785586
  0.4  3          0.8               0.75        50      0.9956823  1.0000000  0.9839640
  0.4  3          0.8               0.75       100      0.9962749  1.0000000  0.9785946
  0.4  3          0.8               0.75       150      0.9953638  1.0000000  0.9785946
  0.4  3          0.8               1.00        50      0.9964706  1.0000000  0.9839640
  0.4  3          0.8               1.00       100      0.9953725  1.0000000  0.9839640
  0.4  3          0.8               1.00       150      0.9950588  1.0000000  0.9812973

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 1, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     19.0      1.3
  positive      0.0     79.7
                           
 Accuracy (average) : 0.987

[1] "TEST accuracy: 0.987012987012987"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.936170212765957"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.983957219251337"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        1
            positive        8      121
[1] "TEST accuracy: 0.931297709923664"
[1] "TEST +precision: 0.937984496124031"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.991803278688525"
