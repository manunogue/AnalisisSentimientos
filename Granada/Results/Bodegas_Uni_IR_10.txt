[1] "DATASET NAME: Bodegas_Uni_IR_10"
[1] "TRAIN INSTANCES: 514"
[1] "TEST INSTANCES: 161"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.48086714744568"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

514 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 411, 411, 411, 412, 411 
Resampling results:

  ROC        Sens       Spec     
  0.9856181  0.8714286  0.9876543

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.5      1.0
  positive      2.7     77.8
                           
 Accuracy (average) : 0.963

[1] "TEST accuracy: 0.963035019455253"
[1] "TEST +precision: 0.966183574879227"
[1] "TEST -precision: 0.95"
[1] "TEST specifity: 0.871559633027523"
[1] "TEST sensitivity: 0.987654320987654"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       17        2
            positive        6      136
[1] "TEST accuracy: 0.950310559006211"
[1] "TEST +precision: 0.957746478873239"
[1] "TEST -precision: 0.894736842105263"
[1] "TEST specifity: 0.739130434782609"
[1] "TEST sensitivity: 0.985507246376812"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 58.1770689487457"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

514 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 412, 411, 411, 411, 411 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.6936748  0.5402597  0.9555556
  0.010  2  0.6946636  0.5402597  0.9555556
  0.010  3  0.7322003  0.5493506  0.9580247
  0.255  1  0.7927262  0.6779221  0.9382716
  0.255  2  0.8002939  0.6688312  0.9358025
  0.255  3  0.7964032  0.6688312  0.9407407
  0.500  1  0.7954866  0.7142857  0.9283951
  0.500  2  0.8021351  0.6779221  0.9283951
  0.500  3  0.8331730  0.6870130  0.9308642

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     14.6      5.4
  positive      6.6     73.3
                            
 Accuracy (average) : 0.8794

[1] "TEST accuracy: 0.879377431906615"
[1] "TEST +precision: 0.917274939172749"
[1] "TEST -precision: 0.728155339805825"
[1] "TEST specifity: 0.688073394495413"
[1] "TEST sensitivity: 0.930864197530864"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       10        5
            positive       13      133
[1] "TEST accuracy: 0.888198757763975"
[1] "TEST +precision: 0.910958904109589"
[1] "TEST -precision: 0.666666666666667"
[1] "TEST specifity: 0.434782608695652"
[1] "TEST sensitivity: 0.963768115942029"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.10595523118973"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

514 samples
707 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 412, 411, 411, 411, 411 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9614532  0.7069264  0.9851852
  0.3  1          0.6               0.50       100      0.9763081  0.7978355  0.9925926
  0.3  1          0.6               0.50       150      0.9765165  0.8354978  0.9802469
  0.3  1          0.6               0.75        50      0.9710678  0.6506494  0.9925926
  0.3  1          0.6               0.75       100      0.9758164  0.8264069  0.9925926
  0.3  1          0.6               0.75       150      0.9801881  0.8627706  0.9827160
  0.3  1          0.6               1.00        50      0.9686682  0.6515152  0.9925926
  0.3  1          0.6               1.00       100      0.9773075  0.7987013  0.9901235
  0.3  1          0.6               1.00       150      0.9791085  0.8445887  0.9901235
  0.3  1          0.8               0.50        50      0.9688365  0.6246753  0.9901235
  0.3  1          0.8               0.50       100      0.9734541  0.8264069  0.9703704
  0.3  1          0.8               0.50       150      0.9735984  0.8813853  0.9728395
  0.3  1          0.8               0.75        50      0.9678184  0.6978355  0.9901235
  0.3  1          0.8               0.75       100      0.9755705  0.8350649  0.9925926
  0.3  1          0.8               0.75       150      0.9768639  0.8718615  0.9851852
  0.3  1          0.8               1.00        50      0.9697504  0.6606061  0.9925926
  0.3  1          0.8               1.00       100      0.9760088  0.7987013  0.9901235
  0.3  1          0.8               1.00       150      0.9768158  0.8445887  0.9925926
  0.3  2          0.6               0.50        50      0.9732029  0.7809524  0.9827160
  0.3  2          0.6               0.50       100      0.9759820  0.8904762  0.9827160
  0.3  2          0.6               0.50       150      0.9752178  0.8904762  0.9728395
  0.3  2          0.6               0.75        50      0.9809631  0.8441558  0.9901235
  0.3  2          0.6               0.75       100      0.9798300  0.8900433  0.9901235
  0.3  2          0.6               0.75       150      0.9803966  0.8900433  0.9827160
  0.3  2          0.6               1.00        50      0.9759286  0.8073593  0.9925926
  0.3  2          0.6               1.00       100      0.9783389  0.8441558  0.9876543
  0.3  2          0.6               1.00       150      0.9756453  0.8259740  0.9851852
  0.3  2          0.8               0.50        50      0.9734434  0.8259740  0.9851852
  0.3  2          0.8               0.50       100      0.9735343  0.8632035  0.9827160
  0.3  2          0.8               0.50       150      0.9729731  0.8632035  0.9827160
  0.3  2          0.8               0.75        50      0.9791192  0.8264069  0.9925926
  0.3  2          0.8               0.75       100      0.9786970  0.8904762  0.9851852
  0.3  2          0.8               0.75       150      0.9776976  0.8904762  0.9777778
  0.3  2          0.8               1.00        50      0.9770830  0.8445887  0.9901235
  0.3  2          0.8               1.00       100      0.9805034  0.8627706  0.9876543
  0.3  2          0.8               1.00       150      0.9796002  0.8722944  0.9827160
  0.3  3          0.6               0.50        50      0.9730800  0.8541126  0.9925926
  0.3  3          0.6               0.50       100      0.9724921  0.8450216  0.9901235
  0.3  3          0.6               0.50       150      0.9715034  0.8359307  0.9802469
  0.3  3          0.6               0.75        50      0.9771578  0.8536797  0.9925926
  0.3  3          0.6               0.75       100      0.9760515  0.8359307  0.9827160
  0.3  3          0.6               0.75       150      0.9732403  0.8359307  0.9827160
  0.3  3          0.6               1.00        50      0.9750468  0.8441558  0.9901235
  0.3  3          0.6               1.00       100      0.9778793  0.8536797  0.9851852
  0.3  3          0.6               1.00       150      0.9781038  0.8536797  0.9802469
  0.3  3          0.8               0.50        50      0.9799209  0.8722944  0.9802469
  0.3  3          0.8               0.50       100      0.9779114  0.8445887  0.9802469
  0.3  3          0.8               0.50       150      0.9730800  0.8536797  0.9753086
  0.3  3          0.8               0.75        50      0.9739244  0.8623377  0.9876543
  0.3  3          0.8               0.75       100      0.9734434  0.8718615  0.9802469
  0.3  3          0.8               0.75       150      0.9744535  0.8627706  0.9777778
  0.3  3          0.8               1.00        50      0.9809417  0.8445887  0.9876543
  0.3  3          0.8               1.00       100      0.9776923  0.8350649  0.9802469
  0.3  3          0.8               1.00       150      0.9782534  0.8259740  0.9777778
  0.4  1          0.6               0.50        50      0.9752205  0.7432900  0.9901235
  0.4  1          0.6               0.50       100      0.9746673  0.8722944  0.9851852
  0.4  1          0.6               0.50       150      0.9722089  0.8718615  0.9851852
  0.4  1          0.6               0.75        50      0.9706590  0.7619048  0.9925926
  0.4  1          0.6               0.75       100      0.9789055  0.8536797  0.9876543
  0.4  1          0.6               0.75       150      0.9803805  0.8623377  0.9802469
  0.4  1          0.6               1.00        50      0.9772246  0.7441558  0.9925926
  0.4  1          0.6               1.00       100      0.9790925  0.8264069  0.9901235
  0.4  1          0.6               1.00       150      0.9797819  0.8718615  0.9876543
  0.4  1          0.8               0.50        50      0.9677569  0.6792208  0.9851852
  0.4  1          0.8               0.50       100      0.9739458  0.8722944  0.9753086
  0.4  1          0.8               0.50       150      0.9784405  0.8528139  0.9802469
  0.4  1          0.8               0.75        50      0.9688739  0.7064935  0.9876543
  0.4  1          0.8               0.75       100      0.9754904  0.8718615  0.9851852
  0.4  1          0.8               0.75       150      0.9768959  0.8813853  0.9777778
  0.4  1          0.8               1.00        50      0.9749906  0.7350649  0.9901235
  0.4  1          0.8               1.00       100      0.9769761  0.8354978  0.9901235
  0.4  1          0.8               1.00       150      0.9787184  0.8718615  0.9851852
  0.4  2          0.6               0.50        50      0.9780503  0.8718615  0.9851852
  0.4  2          0.6               0.50       100      0.9709850  0.8718615  0.9802469
  0.4  2          0.6               0.50       150      0.9713537  0.8809524  0.9802469
  0.4  2          0.6               0.75        50      0.9797980  0.8718615  0.9827160
  0.4  2          0.6               0.75       100      0.9751483  0.8632035  0.9753086
  0.4  2          0.6               0.75       150      0.9750468  0.8541126  0.9728395
  0.4  2          0.6               1.00        50      0.9801721  0.8441558  0.9851852
  0.4  2          0.6               1.00       100      0.9797713  0.8536797  0.9851852
  0.4  2          0.6               1.00       150      0.9805462  0.8627706  0.9777778
  0.4  2          0.8               0.50        50      0.9752499  0.8259740  0.9901235
  0.4  2          0.8               0.50       100      0.9734381  0.8445887  0.9777778
  0.4  2          0.8               0.50       150      0.9730052  0.8445887  0.9728395
  0.4  2          0.8               0.75        50      0.9773288  0.8718615  0.9851852
  0.4  2          0.8               0.75       100      0.9735610  0.8722944  0.9827160
  0.4  2          0.8               0.75       150      0.9725509  0.8627706  0.9802469
  0.4  2          0.8               1.00        50      0.9769120  0.8350649  0.9950617
  0.4  2          0.8               1.00       100      0.9744054  0.8627706  0.9851852
  0.4  2          0.8               1.00       150      0.9728074  0.8536797  0.9827160
  0.4  3          0.6               0.50        50      0.9683983  0.8619048  0.9728395
  0.4  3          0.6               0.50       100      0.9700123  0.8805195  0.9802469
  0.4  3          0.6               0.50       150      0.9674523  0.8532468  0.9728395
  0.4  3          0.6               0.75        50      0.9731441  0.8904762  0.9851852
  0.4  3          0.6               0.75       100      0.9726097  0.8536797  0.9777778
  0.4  3          0.6               0.75       150      0.9719470  0.8541126  0.9777778
  0.4  3          0.6               1.00        50      0.9760996  0.8536797  0.9925926
  0.4  3          0.6               1.00       100      0.9772059  0.8354978  0.9851852
  0.4  3          0.6               1.00       150      0.9773449  0.8354978  0.9851852
  0.4  3          0.8               0.50        50      0.9762119  0.8813853  0.9876543
  0.4  3          0.8               0.50       100      0.9749559  0.8718615  0.9827160
  0.4  3          0.8               0.50       150      0.9754369  0.8714286  0.9802469
  0.4  3          0.8               0.75        50      0.9734595  0.8350649  0.9777778
  0.4  3          0.8               0.75       100      0.9736198  0.8536797  0.9777778
  0.4  3          0.8               0.75       150      0.9735183  0.8536797  0.9777778
  0.4  3          0.8               1.00        50      0.9738656  0.8632035  0.9777778
  0.4  3          0.8               1.00       100      0.9747956  0.8445887  0.9753086
  0.4  3          0.8               1.00       150      0.9743894  0.8541126  0.9753086

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 2, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     17.9      0.8
  positive      3.3     78.0
                            
 Accuracy (average) : 0.9591

[1] "TEST accuracy: 0.959143968871595"
[1] "TEST +precision: 0.95933014354067"
[1] "TEST -precision: 0.958333333333333"
[1] "TEST specifity: 0.844036697247706"
[1] "TEST sensitivity: 0.990123456790123"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       14        3
            positive        9      135
[1] "TEST accuracy: 0.925465838509317"
[1] "TEST +precision: 0.9375"
[1] "TEST -precision: 0.823529411764706"
[1] "TEST specifity: 0.608695652173913"
[1] "TEST sensitivity: 0.978260869565217"
