[1] "DATASET NAME: Carmela_Uni_IR_2"
[1] "TRAIN INSTANCES: 431"
[1] "TEST INSTANCES: 103"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 1.94428491592407"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

431 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 344, 345, 345, 345, 345 
Resampling results:

  ROC        Sens       Spec     
  0.9960117  0.9741935  0.9892208

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.8      0.7
  positive      0.9     63.6
                            
 Accuracy (average) : 0.9838

[1] "TEST accuracy: 0.983758700696056"
[1] "TEST +precision: 0.985611510791367"
[1] "TEST -precision: 0.980392156862745"
[1] "TEST specifity: 0.974025974025974"
[1] "TEST sensitivity: 0.989169675090253"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        2
            positive        6       93
[1] "TEST accuracy: 0.922330097087379"
[1] "TEST +precision: 0.939393939393939"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.25"
[1] "TEST sensitivity: 0.978947368421053"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 59.0088250637054"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

431 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 344, 346, 344, 345, 345 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9099198  0.8694624  0.9531818
  0.010  2  0.9090760  0.8630108  0.9496104
  0.010  3  0.9206920  0.8630108  0.9496104
  0.255  1  0.9600723  0.9870968  0.9424026
  0.255  2  0.9622080  0.9677419  0.9461039
  0.255  3  0.9533717  0.9348387  0.9461039
  0.500  1  0.9600723  0.9870968  0.9424026
  0.500  2  0.9622080  0.9677419  0.9461039
  0.500  3  0.9533717  0.9348387  0.9461039

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.6      3.5
  positive      1.2     60.8
                            
 Accuracy (average) : 0.9536

[1] "TEST accuracy: 0.953596287703016"
[1] "TEST +precision: 0.9812734082397"
[1] "TEST -precision: 0.908536585365854"
[1] "TEST specifity: 0.967532467532468"
[1] "TEST sensitivity: 0.945848375451264"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        3        7
            positive        5       88
[1] "TEST accuracy: 0.883495145631068"
[1] "TEST +precision: 0.946236559139785"
[1] "TEST -precision: 0.3"
[1] "TEST specifity: 0.375"
[1] "TEST sensitivity: 0.926315789473684"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.00272743701935"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

431 samples
746 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 344, 345, 345, 345, 345 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9827751  0.8894624  0.9746753
  0.3  1          0.6               0.50       100      0.9970538  0.9673118  0.9711039
  0.3  1          0.6               0.50       150      0.9970535  0.9870968  0.9638312
  0.3  1          0.6               0.75        50      0.9836992  0.8892473  0.9709740
  0.3  1          0.6               0.75       100      0.9975314  0.9608602  0.9746104
  0.3  1          0.6               0.75       150      0.9980024  0.9870968  0.9746104
  0.3  1          0.6               1.00        50      0.9834667  0.8896774  0.9782468
  0.3  1          0.6               1.00       100      0.9947162  0.9481720  0.9710390
  0.3  1          0.6               1.00       150      0.9957754  0.9806452  0.9710390
  0.3  1          0.8               0.50        50      0.9883881  0.9154839  0.9674026
  0.3  1          0.8               0.50       100      0.9988252  0.9739785  0.9854545
  0.3  1          0.8               0.50       150      0.9994135  1.0000000  0.9746753
  0.3  1          0.8               0.75        50      0.9835840  0.9286022  0.9710390
  0.3  1          0.8               0.75       100      0.9971813  0.9741935  0.9710390
  0.3  1          0.8               0.75       150      0.9989408  0.9804301  0.9746104
  0.3  1          0.8               1.00        50      0.9800841  0.8896774  0.9782468
  0.3  1          0.8               1.00       100      0.9941359  0.9546237  0.9709740
  0.3  1          0.8               1.00       150      0.9954200  0.9806452  0.9782468
  0.3  2          0.6               0.50        50      0.9971746  0.9608602  0.9746753
  0.3  2          0.6               0.50       100      0.9992875  1.0000000  0.9782468
  0.3  2          0.6               0.50       150      0.9996429  1.0000000  0.9855195
  0.3  2          0.6               0.75        50      0.9988277  0.9806452  0.9747403
  0.3  2          0.6               0.75       100      1.0000000  1.0000000  0.9782468
  0.3  2          0.6               0.75       150      1.0000000  1.0000000  0.9782468
  0.3  2          0.6               1.00        50      0.9977775  0.9741935  0.9818831
  0.3  2          0.6               1.00       100      0.9988270  1.0000000  0.9818831
  0.3  2          0.6               1.00       150      0.9997654  1.0000000  0.9782468
  0.3  2          0.8               0.50        50      0.9994124  0.9675269  0.9783117
  0.3  2          0.8               0.50       100      0.9996481  1.0000000  0.9783117
  0.3  2          0.8               0.50       150      0.9991667  1.0000000  0.9819481
  0.3  2          0.8               0.75        50      0.9992944  0.9870968  0.9746753
  0.3  2          0.8               0.75       100      0.9998810  1.0000000  0.9782468
  0.3  2          0.8               0.75       150      0.9996429  1.0000000  0.9818831
  0.3  2          0.8               1.00        50      0.9978928  0.9806452  0.9855195
  0.3  2          0.8               1.00       100      0.9988270  1.0000000  0.9782468
  0.3  2          0.8               1.00       150      1.0000000  1.0000000  0.9818831
  0.3  3          0.6               0.50        50      0.9984730  0.9804301  0.9783766
  0.3  3          0.6               0.50       100      0.9992896  1.0000000  0.9783766
  0.3  3          0.6               0.50       150      0.9996467  1.0000000  0.9783766
  0.3  3          0.6               0.75        50      0.9996481  1.0000000  0.9818831
  0.3  3          0.6               0.75       100      1.0000000  1.0000000  0.9855195
  0.3  3          0.6               0.75       150      1.0000000  1.0000000  0.9855195
  0.3  3          0.6               1.00        50      0.9998848  1.0000000  0.9819481
  0.3  3          0.6               1.00       100      1.0000000  1.0000000  0.9855844
  0.3  3          0.6               1.00       150      1.0000000  1.0000000  0.9855844
  0.3  3          0.8               0.50        50      0.9990616  0.9935484  0.9855195
  0.3  3          0.8               0.50       100      1.0000000  1.0000000  0.9747403
  0.3  3          0.8               0.50       150      1.0000000  1.0000000  0.9747403
  0.3  3          0.8               0.75        50      0.9995308  1.0000000  0.9854545
  0.3  3          0.8               0.75       100      1.0000000  1.0000000  0.9782468
  0.3  3          0.8               0.75       150      1.0000000  1.0000000  0.9818831
  0.3  3          0.8               1.00        50      1.0000000  1.0000000  0.9890909
  0.3  3          0.8               1.00       100      1.0000000  1.0000000  0.9855195
  0.3  3          0.8               1.00       150      1.0000000  1.0000000  0.9927273
  0.4  1          0.6               0.50        50      0.9921278  0.9415054  0.9782468
  0.4  1          0.6               0.50       100      0.9990598  0.9806452  0.9746104
  0.4  1          0.6               0.50       150      0.9994048  1.0000000  0.9746104
  0.4  1          0.6               0.75        50      0.9879483  0.9154839  0.9675325
  0.4  1          0.6               0.75       100      0.9974141  0.9806452  0.9709740
  0.4  1          0.6               0.75       150      0.9978798  1.0000000  0.9746104
  0.4  1          0.6               1.00        50      0.9907345  0.9288172  0.9782468
  0.4  1          0.6               1.00       100      0.9965965  0.9806452  0.9746104
  0.4  1          0.6               1.00       150      0.9968328  1.0000000  0.9782468
  0.4  1          0.8               0.50        50      0.9917941  0.9090323  0.9782468
  0.4  1          0.8               0.50       100      0.9989356  0.9804301  0.9782468
  0.4  1          0.8               0.50       150      0.9988095  1.0000000  0.9601299
  0.4  1          0.8               0.75        50      0.9892082  0.9415054  0.9709740
  0.4  1          0.8               0.75       100      0.9990598  0.9741935  0.9782468
  0.4  1          0.8               0.75       150      0.9989356  1.0000000  0.9782468
  0.4  1          0.8               1.00        50      0.9883190  0.9544086  0.9709740
  0.4  1          0.8               1.00       100      0.9957771  0.9806452  0.9674026
  0.4  1          0.8               1.00       150      0.9965982  1.0000000  0.9782468
  0.4  2          0.6               0.50        50      0.9975161  0.9866667  0.9602597
  0.4  2          0.6               0.50       100      0.9987009  1.0000000  0.9566234
  0.4  2          0.6               0.50       150      0.9992857  1.0000000  0.9530519
  0.4  2          0.6               0.75        50      0.9970674  1.0000000  0.9746104
  0.4  2          0.6               0.75       100      0.9980059  1.0000000  0.9711039
  0.4  2          0.6               0.75       150      0.9995308  1.0000000  0.9747403
  0.4  2          0.6               1.00        50      0.9981232  1.0000000  0.9782468
  0.4  2          0.6               1.00       100      1.0000000  1.0000000  0.9818831
  0.4  2          0.6               1.00       150      1.0000000  1.0000000  0.9855195
  0.4  2          0.8               0.50        50      0.9991684  0.9935484  0.9711039
  0.4  2          0.8               0.50       100      0.9989286  1.0000000  0.9783766
  0.4  2          0.8               0.50       150      0.9986905  1.0000000  0.9711039
  0.4  2          0.8               0.75        50      1.0000000  1.0000000  0.9818831
  0.4  2          0.8               0.75       100      0.9998810  1.0000000  0.9746104
  0.4  2          0.8               0.75       150      1.0000000  1.0000000  0.9782468
  0.4  2          0.8               1.00        50      0.9976540  0.9935484  0.9746104
  0.4  2          0.8               1.00       100      1.0000000  1.0000000  0.9782468
  0.4  2          0.8               1.00       150      1.0000000  1.0000000  0.9818831
  0.4  3          0.6               0.50        50      0.9996429  1.0000000  0.9818831
  0.4  3          0.6               0.50       100      0.9997619  1.0000000  0.9819481
  0.4  3          0.6               0.50       150      1.0000000  1.0000000  0.9820130
  0.4  3          0.6               0.75        50      0.9995290  1.0000000  0.9818831
  0.4  3          0.6               0.75       100      1.0000000  1.0000000  0.9818831
  0.4  3          0.6               0.75       150      1.0000000  1.0000000  0.9818831
  0.4  3          0.6               1.00        50      1.0000000  1.0000000  0.9854545
  0.4  3          0.6               1.00       100      1.0000000  1.0000000  0.9890909
  0.4  3          0.6               1.00       150      1.0000000  1.0000000  0.9855195
  0.4  3          0.8               0.50        50      0.9998810  1.0000000  0.9818831
  0.4  3          0.8               0.50       100      0.9997619  1.0000000  0.9892208
  0.4  3          0.8               0.50       150      1.0000000  1.0000000  0.9820130
  0.4  3          0.8               0.75        50      1.0000000  1.0000000  0.9710390
  0.4  3          0.8               0.75       100      1.0000000  1.0000000  0.9819481
  0.4  3          0.8               0.75       150      1.0000000  1.0000000  0.9783766
  0.4  3          0.8               1.00        50      1.0000000  1.0000000  0.9818831
  0.4  3          0.8               1.00       100      1.0000000  1.0000000  0.9855195
  0.4  3          0.8               1.00       150      1.0000000  1.0000000  0.9855195

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 2, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     35.7      1.2
  positive      0.0     63.1
                            
 Accuracy (average) : 0.9884

[1] "TEST accuracy: 0.988399071925754"
[1] "TEST +precision: 1"
[1] "TEST -precision: 0.968553459119497"
[1] "TEST specifity: 1"
[1] "TEST sensitivity: 0.981949458483754"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        3
            positive        4       92
[1] "TEST accuracy: 0.932038834951456"
[1] "TEST +precision: 0.958333333333333"
[1] "TEST -precision: 0.571428571428571"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 0.968421052631579"
