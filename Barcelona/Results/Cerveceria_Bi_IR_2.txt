[1] "DATASET NAME: Cerveceria_Bi_IR_2"
[1] "TRAIN INSTANCES: 4211"
[1] "TEST INSTANCES: 968"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 52.6626091003418"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

4211 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 3369, 3368, 3369, 3369, 3369 
Resampling results:

  ROC        Sens  Spec     
  0.9638875  1     0.9289855

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.5      4.7
  positive      0.0     60.9
                            
 Accuracy (average) : 0.9535

[1] "TRAIN accuracy: 0.953455236285918"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.880995749848209"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.928985507246377"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       26       57
            positive       30      855
[1] "TEST accuracy: 0.910123966942149"
[1] "TEST +precision: 0.966101694915254"
[1] "TEST -precision: 0.313253012048193"
[1] "TEST specifity: 0.464285714285714"
[1] "TEST sensitivity: 0.9375"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 10.0414668162664"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

4211 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 3369, 3369, 3369, 3368, 3369 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8974568  0.7339756  0.9579710
  0.010  2  0.8978802  0.7339756  0.9579710
  0.010  3  0.9040849  0.7456997  0.9612319
  0.255  1  0.9362221  0.7932314  0.9648551
  0.255  2  0.9367692  0.7897950  0.9637681
  0.255  3  0.9374038  0.7849674  0.9746377
  0.500  1  0.9454533  0.7946107  0.9677536
  0.500  2  0.9445798  0.7932314  0.9692029
  0.500  3  0.9459768  0.7849674  0.9768116

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     27.0      1.5
  positive      7.4     64.0
                            
 Accuracy (average) : 0.9107

[1] "TRAIN accuracy: 0.910710045119924"
[1] "TRAIN +precision: 0.896276595744681"
[1] "TRAIN -precision: 0.946799667497922"
[1] "TRAIN specifity: 0.784975878704342"
[1] "TRAIN sensitivity: 0.976811594202899"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       13       18
            positive       43      894
[1] "TEST accuracy: 0.93698347107438"
[1] "TEST +precision: 0.954108858057631"
[1] "TEST -precision: 0.419354838709677"
[1] "TEST specifity: 0.232142857142857"
[1] "TEST sensitivity: 0.980263157894737"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 13.1246230999629"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

4211 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 3368, 3369, 3369, 3369, 3369 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8760401  0.3453039  0.9891304
  0.3  1          0.6               0.50       100      0.9291111  0.5348383  0.9811594
  0.3  1          0.6               0.50       150      0.9493783  0.6409409  0.9768116
  0.3  1          0.6               0.75        50      0.8810825  0.3494324  0.9931159
  0.3  1          0.6               0.75       100      0.9294603  0.5486266  0.9836957
  0.3  1          0.6               0.75       150      0.9511330  0.6437137  0.9753623
  0.3  1          0.6               1.00        50      0.8824811  0.3370305  0.9927536
  0.3  1          0.6               1.00       100      0.9283553  0.5155232  0.9840580
  0.3  1          0.6               1.00       150      0.9488683  0.6416661  0.9789855
  0.3  1          0.8               0.50        50      0.8703985  0.3501315  0.9902174
  0.3  1          0.8               0.50       100      0.9299277  0.5444626  0.9786232
  0.3  1          0.8               0.50       150      0.9488453  0.6685437  0.9721014
  0.3  1          0.8               0.75        50      0.8758091  0.3521649  0.9891304
  0.3  1          0.8               0.75       100      0.9280404  0.5320678  0.9822464
  0.3  1          0.8               0.75       150      0.9515434  0.6382059  0.9731884
  0.3  1          0.8               1.00        50      0.8832321  0.3246309  0.9927536
  0.3  1          0.8               1.00       100      0.9261342  0.5237967  0.9844203
  0.3  1          0.8               1.00       150      0.9483698  0.6395971  0.9797101
  0.3  2          0.6               0.50        50      0.9315436  0.5306600  0.9818841
  0.3  2          0.6               0.50       100      0.9623306  0.7353596  0.9739130
  0.3  2          0.6               0.50       150      0.9744143  0.8029127  0.9695652
  0.3  2          0.6               0.75        50      0.9328486  0.5658443  0.9807971
  0.3  2          0.6               0.75       100      0.9671251  0.7553549  0.9735507
  0.3  2          0.6               0.75       150      0.9768837  0.8153170  0.9739130
  0.3  2          0.6               1.00        50      0.9341052  0.5265576  0.9851449
  0.3  2          0.6               1.00       100      0.9655595  0.7312501  0.9797101
  0.3  2          0.6               1.00       150      0.9761606  0.8091053  0.9782609
  0.3  2          0.8               0.50        50      0.9320324  0.5520393  0.9797101
  0.3  2          0.8               0.50       100      0.9655149  0.7264249  0.9710145
  0.3  2          0.8               0.50       150      0.9742611  0.8187534  0.9659420
  0.3  2          0.8               0.75        50      0.9341452  0.5610049  0.9811594
  0.3  2          0.8               0.75       100      0.9670711  0.7518948  0.9764493
  0.3  2          0.8               0.75       150      0.9769804  0.8180661  0.9750000
  0.3  2          0.8               1.00        50      0.9330801  0.5389525  0.9847826
  0.3  2          0.8               1.00       100      0.9659992  0.7071383  0.9786232
  0.3  2          0.8               1.00       150      0.9779775  0.7932599  0.9775362
  0.3  3          0.6               0.50        50      0.9551764  0.6602465  0.9750000
  0.3  3          0.6               0.50       100      0.9762594  0.8222230  0.9710145
  0.3  3          0.6               0.50       150      0.9824150  0.8821495  0.9695652
  0.3  3          0.6               0.75        50      0.9586945  0.6843726  0.9782609
  0.3  3          0.6               0.75       100      0.9781352  0.8208271  0.9728261
  0.3  3          0.6               0.75       150      0.9844976  0.8924778  0.9735507
  0.3  3          0.6               1.00        50      0.9576353  0.6733404  0.9804348
  0.3  3          0.6               1.00       100      0.9812674  0.8283991  0.9782609
  0.3  3          0.6               1.00       150      0.9871020  0.8849200  0.9771739
  0.3  3          0.8               0.50        50      0.9557633  0.6712810  0.9760870
  0.3  3          0.8               0.50       100      0.9745072  0.8118640  0.9710145
  0.3  3          0.8               0.50       150      0.9816569  0.8890603  0.9699275
  0.3  3          0.8               0.75        50      0.9563398  0.6609456  0.9797101
  0.3  3          0.8               0.75       100      0.9778357  0.8194620  0.9728261
  0.3  3          0.8               0.75       150      0.9847306  0.8931793  0.9735507
  0.3  3          0.8               1.00        50      0.9591636  0.6650764  0.9797101
  0.3  3          0.8               1.00       100      0.9798896  0.8187676  0.9782609
  0.3  3          0.8               1.00       150      0.9861715  0.8725110  0.9768116
  0.4  1          0.6               0.50        50      0.8880826  0.5320607  0.9775362
  0.4  1          0.6               0.50       100      0.9403094  0.6023415  0.9735507
  0.4  1          0.6               0.50       150      0.9598213  0.7105747  0.9670290
  0.4  1          0.6               0.75        50      0.8886079  0.5506648  0.9757246
  0.4  1          0.6               0.75       100      0.9410224  0.6368243  0.9757246
  0.4  1          0.6               0.75       150      0.9589363  0.7064415  0.9706522
  0.4  1          0.6               1.00        50      0.8922071  0.5238014  0.9804348
  0.4  1          0.6               1.00       100      0.9389063  0.6154521  0.9782609
  0.4  1          0.6               1.00       150      0.9568973  0.6940254  0.9764493
  0.4  1          0.8               0.50        50      0.8922018  0.5244792  0.9771739
  0.4  1          0.8               0.50       100      0.9413335  0.6085697  0.9746377
  0.4  1          0.8               0.50       150      0.9584690  0.7181372  0.9641304
  0.4  1          0.8               0.75        50      0.8946878  0.5389643  0.9764493
  0.4  1          0.8               0.75       100      0.9428433  0.6223534  0.9753623
  0.4  1          0.8               0.75       150      0.9591378  0.7236474  0.9710145
  0.4  1          0.8               1.00        50      0.8958444  0.5465529  0.9782609
  0.4  1          0.8               1.00       100      0.9395103  0.6237208  0.9782609
  0.4  1          0.8               1.00       150      0.9574018  0.6947103  0.9760870
  0.4  2          0.6               0.50        50      0.9420263  0.6540562  0.9750000
  0.4  2          0.6               0.50       100      0.9719990  0.7849935  0.9710145
  0.4  2          0.6               0.50       150      0.9788500  0.8607679  0.9655797
  0.4  2          0.6               0.75        50      0.9447378  0.6444081  0.9764493
  0.4  2          0.6               0.75       100      0.9723528  0.8056381  0.9742754
  0.4  2          0.6               0.75       150      0.9815774  0.8559735  0.9735507
  0.4  2          0.6               1.00        50      0.9483348  0.6747198  0.9786232
  0.4  2          0.6               1.00       100      0.9731255  0.8008532  0.9768116
  0.4  2          0.6               1.00       150      0.9825984  0.8545752  0.9757246
  0.4  2          0.8               0.50        50      0.9418008  0.6485437  0.9735507
  0.4  2          0.8               0.50       100      0.9700855  0.7946131  0.9684783
  0.4  2          0.8               0.50       150      0.9781477  0.8580164  0.9670290
  0.4  2          0.8               0.75        50      0.9475454  0.6719801  0.9717391
  0.4  2          0.8               0.75       100      0.9731467  0.8029056  0.9702899
  0.4  2          0.8               0.75       150      0.9795379  0.8545776  0.9684783
  0.4  2          0.8               1.00        50      0.9457238  0.6643939  0.9800725
  0.4  2          0.8               1.00       100      0.9720407  0.7870553  0.9768116
  0.4  2          0.8               1.00       150      0.9828600  0.8476952  0.9757246
  0.4  3          0.6               0.50        50      0.9619414  0.7243536  0.9724638
  0.4  3          0.6               0.50       100      0.9797016  0.8676905  0.9713768
  0.4  3          0.6               0.50       150      0.9842772  0.9131532  0.9659420
  0.4  3          0.6               0.75        50      0.9651352  0.7484512  0.9746377
  0.4  3          0.6               0.75       100      0.9822946  0.8663017  0.9728261
  0.4  3          0.6               0.75       150      0.9872269  0.9097002  0.9721014
  0.4  3          0.6               1.00        50      0.9673023  0.7381443  0.9768116
  0.4  3          0.6               1.00       100      0.9837751  0.8566513  0.9771739
  0.4  3          0.6               1.00       150      0.9887574  0.9000640  0.9768116
  0.4  3          0.8               0.50        50      0.9632379  0.7312762  0.9728261
  0.4  3          0.8               0.50       100      0.9801258  0.8752720  0.9681159
  0.4  3          0.8               0.50       150      0.9847770  0.9166086  0.9652174
  0.4  3          0.8               0.75        50      0.9648036  0.7505415  0.9713768
  0.4  3          0.8               0.75       100      0.9829706  0.8814646  0.9713768
  0.4  3          0.8               0.75       150      0.9877620  0.9255409  0.9702899
  0.4  3          0.8               1.00        50      0.9665467  0.7484868  0.9793478
  0.4  3          0.8               1.00       100      0.9848543  0.8745610  0.9768116
  0.4  3          0.8               1.00       150      0.9887669  0.9124588  0.9764493

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     31.4      1.5
  positive      3.0     64.0
                            
 Accuracy (average) : 0.9544

[1] "TRAIN accuracy: 0.95440512942294"
[1] "TRAIN +precision: 0.954996456413891"
[1] "TRAIN -precision: 0.953203743700504"
[1] "TRAIN specifity: 0.912474155754652"
[1] "TRAIN sensitivity: 0.976449275362319"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       24       19
            positive       32      893
[1] "TEST accuracy: 0.947314049586777"
[1] "TEST +precision: 0.965405405405405"
[1] "TEST -precision: 0.558139534883721"
[1] "TEST specifity: 0.428571428571429"
[1] "TEST sensitivity: 0.979166666666667"
