[1] "DATASET NAME: Condal_Uni_IR_10"
[1] "TRAIN INSTANCES: 2601"
[1] "TEST INSTANCES: 795"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 8.52377319335938"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

2601 samples
 652 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2080, 2081, 2081, 2081, 2081 
Resampling results:

  ROC        Sens       Spec     
  0.9901549  0.9454545  0.9894312

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     12.0      0.9
  positive      0.7     86.4
                            
 Accuracy (average) : 0.9839

[1] "TRAIN accuracy: 0.983852364475202"
[1] "TRAIN +precision: 0.99205298013245"
[1] "TRAIN -precision: 0.928571428571429"
[1] "TRAIN specifity: 0.945454545454545"
[1] "TRAIN sensitivity: 0.989431968295905"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       22        5
            positive       17      751
[1] "TEST accuracy: 0.972327044025157"
[1] "TEST +precision: 0.977864583333333"
[1] "TEST -precision: 0.814814814814815"
[1] "TEST specifity: 0.564102564102564"
[1] "TEST sensitivity: 0.993386243386243"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 3.80940984884898"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

2601 samples
 652 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2081, 2081, 2081, 2080, 2081 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8409523  0.6757576  0.9793106
  0.010  2  0.8202508  0.6424242  0.9793106
  0.010  3  0.8167874  0.6272727  0.9788711
  0.255  1  0.9223832  0.8454545  0.9771051
  0.255  2  0.9213653  0.8333333  0.9766646
  0.255  3  0.9341383  0.8090909  0.9766665
  0.500  1  0.9293113  0.8757576  0.9744629
  0.500  2  0.9269818  0.8606061  0.9740224
  0.500  3  0.9388399  0.8212121  0.9762269

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.4      2.1
  positive      2.3     85.2
                            
 Accuracy (average) : 0.9566

[1] "TRAIN accuracy: 0.956555171088043"
[1] "TRAIN +precision: 0.974077328646749"
[1] "TRAIN -precision: 0.833846153846154"
[1] "TRAIN specifity: 0.821212121212121"
[1] "TRAIN sensitivity: 0.976221928665786"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       16       17
            positive       23      739
[1] "TEST accuracy: 0.949685534591195"
[1] "TEST +precision: 0.969816272965879"
[1] "TEST -precision: 0.484848484848485"
[1] "TEST specifity: 0.41025641025641"
[1] "TEST sensitivity: 0.977513227513228"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 8.46087963183721"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

2601 samples
 652 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2081, 2080, 2081, 2081, 2081 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9659292  0.4696970  0.9947156
  0.3  1          0.6               0.50       100      0.9778298  0.6242424  0.9933940
  0.3  1          0.6               0.50       150      0.9804923  0.7454545  0.9929535
  0.3  1          0.6               0.75        50      0.9726195  0.4757576  0.9969173
  0.3  1          0.6               0.75       100      0.9791840  0.6454545  0.9955957
  0.3  1          0.6               0.75       150      0.9826842  0.7545455  0.9938355
  0.3  1          0.6               1.00        50      0.9707075  0.4484848  0.9964758
  0.3  1          0.6               1.00       100      0.9798470  0.6272727  0.9960362
  0.3  1          0.6               1.00       150      0.9834204  0.7575758  0.9951561
  0.3  1          0.8               0.50        50      0.9682220  0.4757576  0.9955957
  0.3  1          0.8               0.50       100      0.9788448  0.6363636  0.9947156
  0.3  1          0.8               0.50       150      0.9810290  0.7515152  0.9951561
  0.3  1          0.8               0.75        50      0.9695091  0.4575758  0.9973568
  0.3  1          0.8               0.75       100      0.9807913  0.6181818  0.9951552
  0.3  1          0.8               0.75       150      0.9833461  0.7606061  0.9938355
  0.3  1          0.8               1.00        50      0.9709047  0.4484848  0.9969163
  0.3  1          0.8               1.00       100      0.9818395  0.6090909  0.9960362
  0.3  1          0.8               1.00       150      0.9826146  0.7333333  0.9955957
  0.3  2          0.6               0.50        50      0.9789273  0.6939394  0.9960362
  0.3  2          0.6               0.50       100      0.9867645  0.8333333  0.9942760
  0.3  2          0.6               0.50       150      0.9893192  0.9121212  0.9911943
  0.3  2          0.6               0.75        50      0.9816467  0.6909091  0.9960381
  0.3  2          0.6               0.75       100      0.9878322  0.8515152  0.9951561
  0.3  2          0.6               0.75       150      0.9902504  0.9090909  0.9929554
  0.3  2          0.6               1.00        50      0.9805809  0.6848485  0.9947146
  0.3  2          0.6               1.00       100      0.9862180  0.8515152  0.9947156
  0.3  2          0.6               1.00       150      0.9898293  0.9030303  0.9951561
  0.3  2          0.8               0.50        50      0.9788670  0.6848485  0.9951561
  0.3  2          0.8               0.50       100      0.9874209  0.8484848  0.9942760
  0.3  2          0.8               0.50       150      0.9893020  0.9060606  0.9925139
  0.3  2          0.8               0.75        50      0.9820193  0.6848485  0.9947146
  0.3  2          0.8               0.75       100      0.9874769  0.8303030  0.9920744
  0.3  2          0.8               0.75       150      0.9919137  0.9121212  0.9933959
  0.3  2          0.8               1.00        50      0.9822129  0.6727273  0.9969163
  0.3  2          0.8               1.00       100      0.9878667  0.8303030  0.9955967
  0.3  2          0.8               1.00       150      0.9890905  0.8969697  0.9942760
  0.3  3          0.6               0.50        50      0.9862208  0.7969697  0.9942760
  0.3  3          0.6               0.50       100      0.9903688  0.9060606  0.9938355
  0.3  3          0.6               0.50       150      0.9907020  0.9272727  0.9916329
  0.3  3          0.6               0.75        50      0.9882757  0.8060606  0.9929554
  0.3  3          0.6               0.75       100      0.9914829  0.9030303  0.9925149
  0.3  3          0.6               0.75       150      0.9929716  0.9272727  0.9907518
  0.3  3          0.6               1.00        50      0.9866726  0.8121212  0.9969163
  0.3  3          0.6               1.00       100      0.9908057  0.9000000  0.9955957
  0.3  3          0.6               1.00       150      0.9926800  0.9272727  0.9933950
  0.3  3          0.8               0.50        50      0.9859049  0.7909091  0.9929525
  0.3  3          0.8               0.50       100      0.9888945  0.9000000  0.9911933
  0.3  3          0.8               0.50       150      0.9907549  0.9272727  0.9911933
  0.3  3          0.8               0.75        50      0.9879091  0.8030303  0.9929574
  0.3  3          0.8               0.75       100      0.9897186  0.9181818  0.9933969
  0.3  3          0.8               0.75       150      0.9904132  0.9242424  0.9929564
  0.3  3          0.8               1.00        50      0.9905298  0.8151515  0.9951571
  0.3  3          0.8               1.00       100      0.9935446  0.9030303  0.9947166
  0.3  3          0.8               1.00       150      0.9955317  0.9212121  0.9933959
  0.4  1          0.6               0.50        50      0.9715840  0.5424242  0.9955967
  0.4  1          0.6               0.50       100      0.9796589  0.7393939  0.9925159
  0.4  1          0.6               0.50       150      0.9844169  0.8060606  0.9916338
  0.4  1          0.6               0.75        50      0.9752611  0.5545455  0.9942751
  0.4  1          0.6               0.75       100      0.9818794  0.7363636  0.9947166
  0.4  1          0.6               0.75       150      0.9849420  0.8424242  0.9947166
  0.4  1          0.6               1.00        50      0.9742741  0.5303030  0.9951561
  0.4  1          0.6               1.00       100      0.9830216  0.7272727  0.9947146
  0.4  1          0.6               1.00       150      0.9862037  0.8121212  0.9969173
  0.4  1          0.8               0.50        50      0.9727116  0.5606061  0.9938365
  0.4  1          0.8               0.50       100      0.9803501  0.7606061  0.9916329
  0.4  1          0.8               0.50       150      0.9842156  0.8151515  0.9903122
  0.4  1          0.8               0.75        50      0.9728590  0.5424242  0.9938355
  0.4  1          0.8               0.75       100      0.9818019  0.7121212  0.9938365
  0.4  1          0.8               0.75       150      0.9824575  0.8181818  0.9925149
  0.4  1          0.8               1.00        50      0.9736561  0.5151515  0.9955967
  0.4  1          0.8               1.00       100      0.9821087  0.7090909  0.9955957
  0.4  1          0.8               1.00       150      0.9844248  0.8090909  0.9955967
  0.4  2          0.6               0.50        50      0.9835881  0.7757576  0.9929554
  0.4  2          0.6               0.50       100      0.9868519  0.9090909  0.9925159
  0.4  2          0.6               0.50       150      0.9882599  0.9212121  0.9903132
  0.4  2          0.6               0.75        50      0.9876692  0.7575758  0.9955957
  0.4  2          0.6               0.75       100      0.9912415  0.9030303  0.9947156
  0.4  2          0.6               0.75       150      0.9924694  0.9242424  0.9938345
  0.4  2          0.6               1.00        50      0.9836578  0.7727273  0.9951571
  0.4  2          0.6               1.00       100      0.9888303  0.8969697  0.9955967
  0.4  2          0.6               1.00       150      0.9916206  0.9181818  0.9955957
  0.4  2          0.8               0.50        50      0.9812750  0.7757576  0.9929554
  0.4  2          0.8               0.50       100      0.9888522  0.9212121  0.9920744
  0.4  2          0.8               0.50       150      0.9883422  0.9212121  0.9894322
  0.4  2          0.8               0.75        50      0.9878912  0.7848485  0.9942751
  0.4  2          0.8               0.75       100      0.9911758  0.9212121  0.9929554
  0.4  2          0.8               0.75       150      0.9926919  0.9333333  0.9903122
  0.4  2          0.8               1.00        50      0.9857430  0.7606061  0.9960372
  0.4  2          0.8               1.00       100      0.9900693  0.8969697  0.9951561
  0.4  2          0.8               1.00       150      0.9911466  0.9242424  0.9933950
  0.4  3          0.6               0.50        50      0.9861450  0.8393939  0.9894312
  0.4  3          0.6               0.50       100      0.9892492  0.9151515  0.9885501
  0.4  3          0.6               0.50       150      0.9911700  0.9303030  0.9881106
  0.4  3          0.6               0.75        50      0.9889709  0.8757576  0.9942770
  0.4  3          0.6               0.75       100      0.9929878  0.9303030  0.9911933
  0.4  3          0.6               0.75       150      0.9928159  0.9272727  0.9916338
  0.4  3          0.6               1.00        50      0.9884427  0.8636364  0.9933950
  0.4  3          0.6               1.00       100      0.9922666  0.9151515  0.9938355
  0.4  3          0.6               1.00       150      0.9923731  0.9333333  0.9920744
  0.4  3          0.8               0.50        50      0.9872253  0.8636364  0.9933959
  0.4  3          0.8               0.50       100      0.9882390  0.9242424  0.9938355
  0.4  3          0.8               0.50       150      0.9874793  0.9393939  0.9903113
  0.4  3          0.8               0.75        50      0.9859353  0.8909091  0.9925139
  0.4  3          0.8               0.75       100      0.9899237  0.9242424  0.9925139
  0.4  3          0.8               0.75       150      0.9913499  0.9424242  0.9911933
  0.4  3          0.8               1.00        50      0.9878028  0.8636364  0.9947166
  0.4  3          0.8               1.00       100      0.9923536  0.9303030  0.9947156
  0.4  3          0.8               1.00       150      0.9928725  0.9454545  0.9938365

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.7      0.6
  positive      1.0     86.7
                            
 Accuracy (average) : 0.9842

[1] "TRAIN accuracy: 0.984236831987697"
[1] "TRAIN +precision: 0.988606485539001"
[1] "TRAIN -precision: 0.952978056426332"
[1] "TRAIN specifity: 0.921212121212121"
[1] "TRAIN sensitivity: 0.993394980184941"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       19        6
            positive       20      750
[1] "TEST accuracy: 0.967295597484277"
[1] "TEST +precision: 0.974025974025974"
[1] "TEST -precision: 0.76"
[1] "TEST specifity: 0.487179487179487"
[1] "TEST sensitivity: 0.992063492063492"
