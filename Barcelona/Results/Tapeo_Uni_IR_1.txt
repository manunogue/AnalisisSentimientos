[1] "DATASET NAME: Tapeo_Uni_IR_1"
[1] "TRAIN INSTANCES: 1922"
[1] "TEST INSTANCES: 333"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 6.31088280677795"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1922 samples
 672 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1538, 1537, 1537, 1538, 1538 
Resampling results:

  ROC        Sens  Spec     
  0.9990017  1     0.9989583

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.1
  positive      0.0     49.9
                            
 Accuracy (average) : 0.9995

[1] "TRAIN accuracy: 0.999479708636837"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.998960498960499"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.998959417273673"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        3
            positive        7      319
[1] "TEST accuracy: 0.96996996996997"
[1] "TEST +precision: 0.978527607361963"
[1] "TEST -precision: 0.571428571428571"
[1] "TEST specifity: 0.363636363636364"
[1] "TEST sensitivity: 0.990683229813665"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.54199111461639"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1922 samples
 672 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1538, 1537, 1538, 1538, 1537 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.9859516  1     0.9490393
  0.010  2  0.9859516  1     0.9490393
  0.010  3  0.9859516  1     0.9490393
  0.255  1  0.9941101  1     0.9750324
  0.255  2  0.9941101  1     0.9750324
  0.255  3  0.9948711  1     0.9781412
  0.500  1  0.9906607  1     0.9750324
  0.500  2  0.9906607  1     0.9750324
  0.500  3  0.9922610  1     0.9781466

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      1.1
  positive      0.0     48.9
                            
 Accuracy (average) : 0.9891

[1] "TRAIN accuracy: 0.989073881373569"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.978615071283096"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.978147762747138"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5       10
            positive        6      312
[1] "TEST accuracy: 0.951951951951952"
[1] "TEST +precision: 0.981132075471698"
[1] "TEST -precision: 0.333333333333333"
[1] "TEST specifity: 0.454545454545455"
[1] "TEST sensitivity: 0.968944099378882"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 6.77882144848506"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1922 samples
 672 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1538, 1537, 1538, 1538, 1537 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9885546  0.9916667  0.9157060
  0.3  1          0.6               0.50       100      0.9958244  1.0000000  0.9510848
  0.3  1          0.6               0.50       150      0.9976048  1.0000000  0.9646211
  0.3  1          0.6               0.75        50      0.9905037  1.0000000  0.9177893
  0.3  1          0.6               0.75       100      0.9967618  1.0000000  0.9552515
  0.3  1          0.6               0.75       150      0.9978975  1.0000000  0.9666883
  0.3  1          0.6               1.00        50      0.9908036  0.9906250  0.9104922
  0.3  1          0.6               1.00       100      0.9973455  1.0000000  0.9562932
  0.3  1          0.6               1.00       150      0.9981358  1.0000000  0.9708603
  0.3  1          0.8               0.50        50      0.9915440  1.0000000  0.9115231
  0.3  1          0.8               0.50       100      0.9961801  1.0000000  0.9479598
  0.3  1          0.8               0.50       150      0.9974404  1.0000000  0.9646157
  0.3  1          0.8               0.75        50      0.9910337  1.0000000  0.9250810
  0.3  1          0.8               0.75       100      0.9972967  1.0000000  0.9583711
  0.3  1          0.8               0.75       150      0.9982587  1.0000000  0.9698187
  0.3  1          0.8               1.00        50      0.9913687  0.9947917  0.8959035
  0.3  1          0.8               1.00       100      0.9968265  1.0000000  0.9562932
  0.3  1          0.8               1.00       150      0.9978976  1.0000000  0.9708549
  0.3  2          0.6               0.50        50      0.9981004  1.0000000  0.9583765
  0.3  2          0.6               0.50       100      0.9989179  1.0000000  0.9729544
  0.3  2          0.6               0.50       150      0.9994315  1.0000000  0.9781574
  0.3  2          0.6               0.75        50      0.9988484  1.0000000  0.9635794
  0.3  2          0.6               0.75       100      0.9993088  1.0000000  0.9864691
  0.3  2          0.6               0.75       150      0.9996222  1.0000000  0.9906358
  0.3  2          0.6               1.00        50      0.9982368  1.0000000  0.9583765
  0.3  2          0.6               1.00       100      0.9992120  1.0000000  0.9864691
  0.3  2          0.6               1.00       150      0.9991742  1.0000000  0.9916775
  0.3  2          0.8               0.50        50      0.9975664  1.0000000  0.9615015
  0.3  2          0.8               0.50       100      0.9988053  1.0000000  0.9812716
  0.3  2          0.8               0.50       150      0.9995124  1.0000000  0.9833603
  0.3  2          0.8               0.75        50      0.9977995  1.0000000  0.9604598
  0.3  2          0.8               0.75       100      0.9988491  1.0000000  0.9895887
  0.3  2          0.8               0.75       150      0.9989793  1.0000000  0.9906304
  0.3  2          0.8               1.00        50      0.9982308  1.0000000  0.9635794
  0.3  2          0.8               1.00       100      0.9991634  1.0000000  0.9875162
  0.3  2          0.8               1.00       150      0.9991472  1.0000000  0.9916775
  0.3  3          0.6               0.50        50      0.9997246  1.0000000  0.9791883
  0.3  3          0.6               0.50       100      0.9998111  1.0000000  0.9885525
  0.3  3          0.6               0.50       150      1.0000000  1.0000000  0.9833495
  0.3  3          0.6               0.75        50      1.0000000  1.0000000  0.9791829
  0.3  3          0.6               0.75       100      1.0000000  1.0000000  0.9885525
  0.3  3          0.6               0.75       150      1.0000000  1.0000000  0.9875108
  0.3  3          0.6               1.00        50      1.0000000  1.0000000  0.9770941
  0.3  3          0.6               1.00       100      1.0000000  1.0000000  0.9927083
  0.3  3          0.6               1.00       150      1.0000000  1.0000000  0.9927083
  0.3  3          0.8               0.50        50      0.9991087  1.0000000  0.9750324
  0.3  3          0.8               0.50       100      1.0000000  1.0000000  0.9895941
  0.3  3          0.8               0.50       150      1.0000000  1.0000000  0.9823187
  0.3  3          0.8               0.75        50      1.0000000  1.0000000  0.9812716
  0.3  3          0.8               0.75       100      1.0000000  1.0000000  0.9927083
  0.3  3          0.8               0.75       150      1.0000000  1.0000000  0.9895887
  0.3  3          0.8               1.00        50      1.0000000  1.0000000  0.9812554
  0.3  3          0.8               1.00       100      0.9999892  1.0000000  0.9916721
  0.3  3          0.8               1.00       150      1.0000000  1.0000000  0.9906304
  0.4  1          0.6               0.50        50      0.9924108  1.0000000  0.9354760
  0.4  1          0.6               0.50       100      0.9962695  1.0000000  0.9583711
  0.4  1          0.6               0.50       150      0.9980807  1.0000000  0.9698241
  0.4  1          0.6               0.75        50      0.9944034  1.0000000  0.9386064
  0.4  1          0.6               0.75       100      0.9969262  1.0000000  0.9604598
  0.4  1          0.6               0.75       150      0.9985352  1.0000000  0.9781412
  0.4  1          0.6               1.00        50      0.9942102  1.0000000  0.9385902
  0.4  1          0.6               1.00       100      0.9980164  1.0000000  0.9614907
  0.4  1          0.6               1.00       150      0.9980479  1.0000000  0.9812662
  0.4  1          0.8               0.50        50      0.9927380  1.0000000  0.9281898
  0.4  1          0.8               0.50       100      0.9965686  1.0000000  0.9614907
  0.4  1          0.8               0.50       150      0.9974343  1.0000000  0.9677515
  0.4  1          0.8               0.75        50      0.9934923  1.0000000  0.9386064
  0.4  1          0.8               0.75       100      0.9974564  1.0000000  0.9687824
  0.4  1          0.8               0.75       150      0.9985076  1.0000000  0.9750216
  0.4  1          0.8               1.00        50      0.9929328  1.0000000  0.9365177
  0.4  1          0.8               1.00       100      0.9981678  1.0000000  0.9666937
  0.4  1          0.8               1.00       150      0.9986930  1.0000000  0.9791829
  0.4  2          0.6               0.50        50      0.9987227  1.0000000  0.9708603
  0.4  2          0.6               0.50       100      0.9997125  1.0000000  0.9854275
  0.4  2          0.6               0.50       150      0.9994954  1.0000000  0.9885525
  0.4  2          0.6               0.75        50      0.9985011  1.0000000  0.9687824
  0.4  2          0.6               0.75       100      0.9993415  1.0000000  0.9864691
  0.4  2          0.6               0.75       150      0.9996060  1.0000000  0.9875054
  0.4  2          0.6               1.00        50      0.9990224  1.0000000  0.9718966
  0.4  2          0.6               1.00       100      0.9992282  1.0000000  0.9885471
  0.4  2          0.6               1.00       150      0.9990501  1.0000000  0.9927137
  0.4  2          0.8               0.50        50      0.9987185  1.0000000  0.9750324
  0.4  2          0.8               0.50       100      0.9992930  1.0000000  0.9895887
  0.4  2          0.8               0.50       150      0.9999240  1.0000000  0.9875108
  0.4  2          0.8               0.75        50      0.9992149  1.0000000  0.9770941
  0.4  2          0.8               0.75       100      0.9991742  1.0000000  0.9895833
  0.4  2          0.8               0.75       150      0.9995898  1.0000000  0.9895833
  0.4  2          0.8               1.00        50      0.9989525  1.0000000  0.9708603
  0.4  2          0.8               1.00       100      0.9991256  1.0000000  0.9864745
  0.4  2          0.8               1.00       150      0.9991364  1.0000000  0.9895941
  0.4  3          0.6               0.50        50      0.9999566  1.0000000  0.9885471
  0.4  3          0.6               0.50       100      1.0000000  1.0000000  0.9875108
  0.4  3          0.6               0.50       150      1.0000000  1.0000000  0.9854275
  0.4  3          0.6               0.75        50      1.0000000  1.0000000  0.9864745
  0.4  3          0.6               0.75       100      1.0000000  1.0000000  0.9916721
  0.4  3          0.6               0.75       150      1.0000000  1.0000000  0.9885525
  0.4  3          0.6               1.00        50      0.9993793  1.0000000  0.9906358
  0.4  3          0.6               1.00       100      1.0000000  1.0000000  0.9927083
  0.4  3          0.6               1.00       150      1.0000000  1.0000000  0.9927083
  0.4  3          0.8               0.50        50      1.0000000  1.0000000  0.9822917
  0.4  3          0.8               0.50       100      1.0000000  1.0000000  0.9843858
  0.4  3          0.8               0.50       150      1.0000000  1.0000000  0.9854329
  0.4  3          0.8               0.75        50      0.9995790  1.0000000  0.9864745
  0.4  3          0.8               0.75       100      1.0000000  1.0000000  0.9916775
  0.4  3          0.8               0.75       150      1.0000000  1.0000000  0.9885525
  0.4  3          0.8               1.00        50      0.9998327  1.0000000  0.9854383
  0.4  3          0.8               1.00       100      0.9999568  1.0000000  0.9906358
  0.4  3          0.8               1.00       150      1.0000000  1.0000000  0.9916721

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative       50        1
  positive        0       49
                            
 Accuracy (average) : 0.9896

[1] "TRAIN accuracy: 0.989594172736733"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.979612640163099"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.979188345473465"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        8
            positive        6      314
[1] "TEST accuracy: 0.957957957957958"
[1] "TEST +precision: 0.98125"
[1] "TEST -precision: 0.384615384615385"
[1] "TEST specifity: 0.454545454545455"
[1] "TEST sensitivity: 0.975155279503106"
