[1] "DATASET NAME: Tapeo_Bi_IR_1"
[1] "TRAIN INSTANCES: 1918"
[1] "TEST INSTANCES: 333"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 6.23938894271851"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1918 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1534, 1535, 1534, 1534, 1535 
Resampling results:

  ROC        Sens  Spec     
  0.9947808  1     0.9853949

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.7
  positive      0.0     49.3
                            
 Accuracy (average) : 0.9927

[1] "TRAIN accuracy: 0.992700729927007"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.985611510791367"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.985401459854015"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        4
            positive        8      320
[1] "TEST accuracy: 0.963963963963964"
[1] "TEST +precision: 0.975609756097561"
[1] "TEST -precision: 0.2"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.987654320987654"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.47533263365428"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1918 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1534, 1535, 1534, 1534, 1535 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9754233  0.9498527  0.9687336
  0.010  2  0.9753035  0.9498527  0.9687336
  0.010  3  0.9750769  0.9435918  0.9697644
  0.255  1  0.9840894  0.9581861  0.9697589
  0.255  2  0.9839695  0.9581861  0.9697589
  0.255  3  0.9841738  0.9581861  0.9635035
  0.500  1  0.9858280  0.9581861  0.9718477
  0.500  2  0.9857081  0.9581861  0.9718477
  0.500  3  0.9844327  0.9581861  0.9645452

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     47.9      1.4
  positive      2.1     48.6
                            
 Accuracy (average) : 0.9651

[1] "TRAIN accuracy: 0.965067778936392"
[1] "TRAIN +precision: 0.958847736625514"
[1] "TRAIN -precision: 0.971458773784355"
[1] "TRAIN specifity: 0.958289885297185"
[1] "TRAIN sensitivity: 0.9718456725756"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1       14
            positive        8      310
[1] "TEST accuracy: 0.933933933933934"
[1] "TEST +precision: 0.974842767295597"
[1] "TEST -precision: 0.0666666666666667"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.95679012345679"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 6.32029548486074"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1918 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1534, 1534, 1534, 1535, 1535 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9521416  0.8249073  0.9645561
  0.3  1          0.6               0.50       100      0.9860443  0.9614092  0.9635035
  0.3  1          0.6               0.50       150      0.9896246  0.9739092  0.9697535
  0.3  1          0.6               0.75        50      0.9579272  0.8592659  0.9697480
  0.3  1          0.6               0.75       100      0.9861276  0.9676592  0.9760253
  0.3  1          0.6               0.75       150      0.9889986  0.9739092  0.9687282
  0.3  1          0.6               1.00        50      0.9656182  0.8873909  0.9749564
  0.3  1          0.6               1.00       100      0.9860218  0.9739092  0.9770670
  0.3  1          0.6               1.00       150      0.9882799  0.9739092  0.9729003
  0.3  1          0.8               0.50        50      0.9581941  0.8707352  0.9634926
  0.3  1          0.8               0.50       100      0.9855213  0.9687009  0.9634926
  0.3  1          0.8               0.50       150      0.9904305  0.9739092  0.9697480
  0.3  1          0.8               0.75        50      0.9588281  0.8707406  0.9687064
  0.3  1          0.8               0.75       100      0.9849330  0.9687009  0.9645342
  0.3  1          0.8               0.75       150      0.9893976  0.9739092  0.9676647
  0.3  1          0.8               1.00        50      0.9625007  0.8717659  0.9770397
  0.3  1          0.8               1.00       100      0.9857003  0.9739092  0.9760253
  0.3  1          0.8               1.00       150      0.9886288  0.9739092  0.9749836
  0.3  2          0.6               0.50        50      0.9862019  0.9614092  0.9697426
  0.3  2          0.6               0.50       100      0.9925702  0.9791176  0.9603458
  0.3  2          0.6               0.50       150      0.9932903  0.9843259  0.9645342
  0.3  2          0.6               0.75        50      0.9861760  0.9739092  0.9708115
  0.3  2          0.6               0.75       100      0.9924749  0.9739092  0.9718423
  0.3  2          0.6               0.75       150      0.9941522  0.9791176  0.9655705
  0.3  2          0.6               1.00        50      0.9866671  0.9739092  0.9739420
  0.3  2          0.6               1.00       100      0.9930598  0.9739092  0.9770615
  0.3  2          0.6               1.00       150      0.9940972  0.9770342  0.9718368
  0.3  2          0.8               0.50        50      0.9852613  0.9739092  0.9707842
  0.3  2          0.8               0.50       100      0.9921228  0.9770342  0.9624400
  0.3  2          0.8               0.50       150      0.9934112  0.9853676  0.9676647
  0.3  2          0.8               0.75        50      0.9856257  0.9739092  0.9697699
  0.3  2          0.8               0.75       100      0.9924114  0.9739092  0.9749782
  0.3  2          0.8               0.75       150      0.9938447  0.9791176  0.9676647
  0.3  2          0.8               1.00        50      0.9866699  0.9739092  0.9749673
  0.3  2          0.8               1.00       100      0.9932819  0.9739092  0.9749782
  0.3  2          0.8               1.00       150      0.9951813  0.9770342  0.9718314
  0.3  3          0.6               0.50        50      0.9895313  0.9739092  0.9718368
  0.3  3          0.6               0.50       100      0.9941905  0.9843259  0.9697426
  0.3  3          0.6               0.50       150      0.9936280  1.0000000  0.9697426
  0.3  3          0.6               0.75        50      0.9909839  0.9739092  0.9739420
  0.3  3          0.6               0.75       100      0.9937842  0.9843259  0.9687118
  0.3  3          0.6               0.75       150      0.9946066  0.9905759  0.9718314
  0.3  3          0.6               1.00        50      0.9897368  0.9739092  0.9749836
  0.3  3          0.6               1.00       100      0.9953934  0.9770342  0.9728730
  0.3  3          0.6               1.00       150      0.9965246  0.9905759  0.9728730
  0.3  3          0.8               0.50        50      0.9906087  0.9770342  0.9624400
  0.3  3          0.8               0.50       100      0.9941542  0.9884926  0.9655596
  0.3  3          0.8               0.50       150      0.9936880  1.0000000  0.9645288
  0.3  3          0.8               0.75        50      0.9914748  0.9739092  0.9739365
  0.3  3          0.8               0.75       100      0.9946842  0.9791176  0.9687009
  0.3  3          0.8               0.75       150      0.9948609  1.0000000  0.9676592
  0.3  3          0.8               1.00        50      0.9899219  0.9739092  0.9749782
  0.3  3          0.8               1.00       100      0.9952236  0.9770342  0.9697480
  0.3  3          0.8               1.00       150      0.9962279  0.9905759  0.9718314
  0.4  1          0.6               0.50        50      0.9763012  0.9364092  0.9645561
  0.4  1          0.6               0.50       100      0.9884405  0.9739092  0.9687118
  0.4  1          0.6               0.50       150      0.9923306  0.9822426  0.9645288
  0.4  1          0.6               0.75        50      0.9804237  0.9551483  0.9718532
  0.4  1          0.6               0.75       100      0.9879436  0.9739092  0.9655759
  0.4  1          0.6               0.75       150      0.9918087  0.9739092  0.9728894
  0.4  1          0.6               1.00        50      0.9831084  0.9676592  0.9739420
  0.4  1          0.6               1.00       100      0.9858533  0.9739092  0.9697753
  0.4  1          0.6               1.00       150      0.9921438  0.9739092  0.9760253
  0.4  1          0.8               0.50        50      0.9794081  0.9603567  0.9624455
  0.4  1          0.8               0.50       100      0.9895460  0.9739092  0.9687064
  0.4  1          0.8               0.50       150      0.9910829  0.9759926  0.9655923
  0.4  1          0.8               0.75        50      0.9825217  0.9634926  0.9645288
  0.4  1          0.8               0.75       100      0.9885200  0.9739092  0.9655759
  0.4  1          0.8               0.75       150      0.9915711  0.9770342  0.9655759
  0.4  1          0.8               1.00        50      0.9822991  0.9603676  0.9718314
  0.4  1          0.8               1.00       100      0.9862842  0.9739092  0.9697753
  0.4  1          0.8               1.00       150      0.9916328  0.9739092  0.9729003
  0.4  2          0.6               0.50        50      0.9890248  0.9739092  0.9708006
  0.4  2          0.6               0.50       100      0.9926038  0.9791176  0.9666285
  0.4  2          0.6               0.50       150      0.9939100  0.9822426  0.9676592
  0.4  2          0.6               0.75        50      0.9897654  0.9739092  0.9676592
  0.4  2          0.6               0.75       100      0.9934033  0.9843259  0.9676592
  0.4  2          0.6               0.75       150      0.9940401  0.9843259  0.9676647
  0.4  2          0.6               1.00        50      0.9872329  0.9739092  0.9718586
  0.4  2          0.6               1.00       100      0.9937360  0.9739092  0.9749836
  0.4  2          0.6               1.00       150      0.9949558  0.9843259  0.9687064
  0.4  2          0.8               0.50        50      0.9899034  0.9739092  0.9697644
  0.4  2          0.8               0.50       100      0.9926803  0.9905759  0.9645342
  0.4  2          0.8               0.50       150      0.9931003  0.9937500  0.9655814
  0.4  2          0.8               0.75        50      0.9875160  0.9739092  0.9676647
  0.4  2          0.8               0.75       100      0.9926040  0.9770342  0.9655705
  0.4  2          0.8               0.75       150      0.9942094  0.9905759  0.9707842
  0.4  2          0.8               1.00        50      0.9882110  0.9739092  0.9791503
  0.4  2          0.8               1.00       100      0.9937246  0.9739092  0.9760144
  0.4  2          0.8               1.00       150      0.9958833  0.9843259  0.9728730
  0.4  3          0.6               0.50        50      0.9920218  0.9739092  0.9718532
  0.4  3          0.6               0.50       100      0.9946093  0.9937500  0.9614038
  0.4  3          0.6               0.50       150      0.9943591  1.0000000  0.9655759
  0.4  3          0.6               0.75        50      0.9933529  0.9770342  0.9718314
  0.4  3          0.6               0.75       100      0.9946372  1.0000000  0.9687064
  0.4  3          0.6               0.75       150      0.9948993  1.0000000  0.9676647
  0.4  3          0.6               1.00        50      0.9937640  0.9739092  0.9749836
  0.4  3          0.6               1.00       100      0.9956841  0.9843259  0.9687064
  0.4  3          0.6               1.00       150      0.9960483  1.0000000  0.9676647
  0.4  3          0.8               0.50        50      0.9933448  0.9791176  0.9697644
  0.4  3          0.8               0.50       100      0.9936932  1.0000000  0.9676592
  0.4  3          0.8               0.50       150      0.9949373  1.0000000  0.9666176
  0.4  3          0.8               0.75        50      0.9929736  0.9739092  0.9760253
  0.4  3          0.8               0.75       100      0.9952589  1.0000000  0.9687064
  0.4  3          0.8               0.75       150      0.9947523  1.0000000  0.9687064
  0.4  3          0.8               1.00        50      0.9942709  0.9739092  0.9739420
  0.4  3          0.8               1.00       100      0.9959891  0.9843259  0.9697480
  0.4  3          0.8               1.00       150      0.9964871  1.0000000  0.9697480

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     49.5      1.4
  positive      0.5     48.6
                            
 Accuracy (average) : 0.9818

[1] "TRAIN accuracy: 0.981751824817518"
[1] "TRAIN +precision: 0.990445859872611"
[1] "TRAIN -precision: 0.973360655737705"
[1] "TRAIN specifity: 0.990615224191867"
[1] "TRAIN sensitivity: 0.97288842544317"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        7
            positive        7      317
[1] "TEST accuracy: 0.957957957957958"
[1] "TEST +precision: 0.978395061728395"
[1] "TEST -precision: 0.222222222222222"
[1] "TEST specifity: 0.222222222222222"
[1] "TEST sensitivity: 0.978395061728395"
