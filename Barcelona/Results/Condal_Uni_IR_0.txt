[1] "DATASET NAME: Condal_Uni_IR_0"
[1] "TRAIN INSTANCES: 2385"
[1] "TEST INSTANCES: 795"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 11.2588789463043"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

2385 samples
 652 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1908, 1908, 1907, 1908, 1909 
Resampling results:

  ROC        Sens       Spec     
  0.9499185  0.4818182  0.9929564

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      2.3      0.7
  positive      2.5     94.5
                            
 Accuracy (average) : 0.9686

[1] "TRAIN accuracy: 0.968553459119497"
[1] "TRAIN +precision: 0.974503025064823"
[1] "TRAIN -precision: 0.774647887323944"
[1] "TRAIN specifity: 0.482456140350877"
[1] "TRAIN sensitivity: 0.992954645530603"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       20        5
            positive       19      751
[1] "TEST accuracy: 0.969811320754717"
[1] "TEST +precision: 0.975324675324675"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.512820512820513"
[1] "TEST sensitivity: 0.993386243386243"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 4.42936344941457"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

2385 samples
 652 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1908, 1909, 1908, 1908, 1907 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5481570  0.11383399  0.9986794
  0.010  2  0.5473538  0.09644269  0.9982379
  0.010  3  0.5469329  0.08735178  0.9977983
  0.255  1  0.6223383  0.31581028  0.9863485
  0.255  2  0.6468968  0.28972332  0.9894292
  0.255  3  0.6310577  0.20237154  0.9964767
  0.500  1  0.6507639  0.32490119  0.9819461
  0.500  2  0.7334180  0.37786561  0.9823827
  0.500  3  0.6839535  0.28063241  0.9881096

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.8      1.7
  positive      3.0     93.5
                            
 Accuracy (average) : 0.9535

[1] "TRAIN accuracy: 0.953459119496855"
[1] "TRAIN +precision: 0.969157254561251"
[1] "TRAIN -precision: 0.518072289156627"
[1] "TRAIN specifity: 0.37719298245614"
[1] "TRAIN sensitivity: 0.982386613826508"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       12       13
            positive       27      743
[1] "TEST accuracy: 0.949685534591195"
[1] "TEST +precision: 0.964935064935065"
[1] "TEST -precision: 0.48"
[1] "TEST specifity: 0.307692307692308"
[1] "TEST sensitivity: 0.982804232804233"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 12.6207566658656"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

2385 samples
 652 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1907, 1909, 1908, 1908, 1908 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9338575  0.2814229  0.9977974
  0.3  1          0.6               0.50       100      0.9474200  0.3778656  0.9964767
  0.3  1          0.6               0.50       150      0.9428105  0.4387352  0.9951552
  0.3  1          0.6               0.75        50      0.9371986  0.3162055  0.9986784
  0.3  1          0.6               0.75       100      0.9519528  0.3513834  0.9982379
  0.3  1          0.6               0.75       150      0.9538662  0.3952569  0.9973568
  0.3  1          0.6               1.00        50      0.9367241  0.2810277  0.9991189
  0.3  1          0.6               1.00       100      0.9474110  0.3596838  0.9982379
  0.3  1          0.6               1.00       150      0.9557727  0.3509881  0.9982379
  0.3  1          0.8               0.50        50      0.9258612  0.3075099  0.9982379
  0.3  1          0.8               0.50       100      0.9426203  0.3430830  0.9964758
  0.3  1          0.8               0.50       150      0.9484162  0.3865613  0.9947166
  0.3  1          0.8               0.75        50      0.9379247  0.2632411  0.9982379
  0.3  1          0.8               0.75       100      0.9554525  0.3604743  0.9969163
  0.3  1          0.8               0.75       150      0.9539827  0.3952569  0.9969173
  0.3  1          0.8               1.00        50      0.9395567  0.2723320  0.9991189
  0.3  1          0.8               1.00       100      0.9500506  0.3509881  0.9991189
  0.3  1          0.8               1.00       150      0.9556858  0.3774704  0.9986784
  0.3  2          0.6               0.50        50      0.9378391  0.3513834  0.9955947
  0.3  2          0.6               0.50       100      0.9422522  0.4387352  0.9933950
  0.3  2          0.6               0.50       150      0.9401802  0.4296443  0.9925139
  0.3  2          0.6               0.75        50      0.9485970  0.3861660  0.9969163
  0.3  2          0.6               0.75       100      0.9515470  0.4561265  0.9951552
  0.3  2          0.6               0.75       150      0.9490167  0.4735178  0.9947156
  0.3  2          0.6               1.00        50      0.9478486  0.3249012  0.9969163
  0.3  2          0.6               1.00       100      0.9578558  0.3952569  0.9955976
  0.3  2          0.6               1.00       150      0.9571753  0.4648221  0.9955967
  0.3  2          0.8               0.50        50      0.9422543  0.3778656  0.9964758
  0.3  2          0.8               0.50       100      0.9430477  0.4126482  0.9938345
  0.3  2          0.8               0.50       150      0.9403577  0.4470356  0.9907518
  0.3  2          0.8               0.75        50      0.9421004  0.3604743  0.9973578
  0.3  2          0.8               0.75       100      0.9454517  0.4300395  0.9947156
  0.3  2          0.8               0.75       150      0.9437979  0.4731225  0.9925139
  0.3  2          0.8               1.00        50      0.9512267  0.3426877  0.9982379
  0.3  2          0.8               1.00       100      0.9558499  0.4474308  0.9964767
  0.3  2          0.8               1.00       150      0.9551489  0.4913043  0.9964758
  0.3  3          0.6               0.50        50      0.9455170  0.4035573  0.9955976
  0.3  3          0.6               0.50       100      0.9460063  0.4383399  0.9942741
  0.3  3          0.6               0.50       150      0.9402119  0.4735178  0.9933940
  0.3  3          0.6               0.75        50      0.9455661  0.3770751  0.9973568
  0.3  3          0.6               0.75       100      0.9413214  0.4296443  0.9942751
  0.3  3          0.6               0.75       150      0.9401030  0.4387352  0.9929544
  0.3  3          0.6               1.00        50      0.9518715  0.3948617  0.9982379
  0.3  3          0.6               1.00       100      0.9536801  0.4387352  0.9960372
  0.3  3          0.6               1.00       150      0.9526874  0.4474308  0.9951571
  0.3  3          0.8               0.50        50      0.9387900  0.4300395  0.9947137
  0.3  3          0.8               0.50       100      0.9338235  0.4300395  0.9947146
  0.3  3          0.8               0.50       150      0.9327731  0.4300395  0.9929535
  0.3  3          0.8               0.75        50      0.9531944  0.4035573  0.9969163
  0.3  3          0.8               0.75       100      0.9537353  0.4387352  0.9938355
  0.3  3          0.8               0.75       150      0.9461906  0.4387352  0.9916329
  0.3  3          0.8               1.00        50      0.9487266  0.3770751  0.9964758
  0.3  3          0.8               1.00       100      0.9504995  0.4561265  0.9942751
  0.3  3          0.8               1.00       150      0.9512694  0.4561265  0.9933950
  0.4  1          0.6               0.50        50      0.9416289  0.3252964  0.9964758
  0.4  1          0.6               0.50       100      0.9390158  0.4387352  0.9951542
  0.4  1          0.6               0.50       150      0.9432927  0.4474308  0.9938345
  0.4  1          0.6               0.75        50      0.9444038  0.2901186  0.9982379
  0.4  1          0.6               0.75       100      0.9573041  0.4035573  0.9964767
  0.4  1          0.6               0.75       150      0.9582202  0.5000000  0.9951552
  0.4  1          0.6               1.00        50      0.9424956  0.3162055  0.9991189
  0.4  1          0.6               1.00       100      0.9555184  0.3596838  0.9986784
  0.4  1          0.6               1.00       150      0.9591474  0.3770751  0.9973568
  0.4  1          0.8               0.50        50      0.9449530  0.3158103  0.9982379
  0.4  1          0.8               0.50       100      0.9469345  0.4213439  0.9942741
  0.4  1          0.8               0.50       150      0.9401173  0.4122530  0.9929525
  0.4  1          0.8               0.75        50      0.9381974  0.3079051  0.9977974
  0.4  1          0.8               0.75       100      0.9496637  0.4035573  0.9964758
  0.4  1          0.8               0.75       150      0.9547002  0.4648221  0.9951552
  0.4  1          0.8               1.00        50      0.9410410  0.3071146  0.9991189
  0.4  1          0.8               1.00       100      0.9556035  0.3865613  0.9982379
  0.4  1          0.8               1.00       150      0.9592179  0.4035573  0.9982379
  0.4  2          0.6               0.50        50      0.9459208  0.3948617  0.9951552
  0.4  2          0.6               0.50       100      0.9409354  0.4909091  0.9903132
  0.4  2          0.6               0.50       150      0.9393564  0.4474308  0.9907537
  0.4  2          0.6               0.75        50      0.9575167  0.4209486  0.9955957
  0.4  2          0.6               0.75       100      0.9541641  0.4818182  0.9951552
  0.4  2          0.6               0.75       150      0.9441375  0.5256917  0.9925129
  0.4  2          0.6               1.00        50      0.9510536  0.3778656  0.9973568
  0.4  2          0.6               1.00       100      0.9580953  0.4735178  0.9969163
  0.4  2          0.6               1.00       150      0.9563503  0.5090909  0.9942770
  0.4  2          0.8               0.50        50      0.9343470  0.3944664  0.9955967
  0.4  2          0.8               0.50       100      0.9274180  0.4648221  0.9903113
  0.4  2          0.8               0.50       150      0.9292486  0.4913043  0.9885511
  0.4  2          0.8               0.75        50      0.9489828  0.3774704  0.9964758
  0.4  2          0.8               0.75       100      0.9455112  0.4296443  0.9947156
  0.4  2          0.8               0.75       150      0.9430488  0.4996047  0.9916329
  0.4  2          0.8               1.00        50      0.9472933  0.3687747  0.9969163
  0.4  2          0.8               1.00       100      0.9538206  0.4735178  0.9960362
  0.4  2          0.8               1.00       150      0.9515632  0.4913043  0.9938355
  0.4  3          0.6               0.50        50      0.9348233  0.4031621  0.9942760
  0.4  3          0.6               0.50       100      0.9232678  0.4387352  0.9925149
  0.4  3          0.6               0.50       150      0.9211036  0.4470356  0.9920753
  0.4  3          0.6               0.75        50      0.9437585  0.4296443  0.9955947
  0.4  3          0.6               0.75       100      0.9364024  0.4731225  0.9929544
  0.4  3          0.6               0.75       150      0.9324784  0.4470356  0.9933940
  0.4  3          0.6               1.00        50      0.9553484  0.4474308  0.9964777
  0.4  3          0.6               1.00       100      0.9527627  0.4561265  0.9938355
  0.4  3          0.6               1.00       150      0.9505615  0.4644269  0.9916329
  0.4  3          0.8               0.50        50      0.9346773  0.4565217  0.9925110
  0.4  3          0.8               0.50       100      0.9333132  0.4387352  0.9907489
  0.4  3          0.8               0.50       150      0.9162778  0.4474308  0.9889897
  0.4  3          0.8               0.75        50      0.9489924  0.4300395  0.9964777
  0.4  3          0.8               0.75       100      0.9373570  0.4387352  0.9938355
  0.4  3          0.8               0.75       150      0.9325080  0.4391304  0.9933959
  0.4  3          0.8               1.00        50      0.9483283  0.4126482  0.9951552
  0.4  3          0.8               1.00       100      0.9504016  0.4474308  0.9942751
  0.4  3          0.8               1.00       150      0.9471375  0.4300395  0.9942760

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 1, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.9      0.2
  positive      2.9     95.1
                            
 Accuracy (average) : 0.9698

[1] "TRAIN accuracy: 0.969811320754717"
[1] "TRAIN +precision: 0.970877944325482"
[1] "TRAIN -precision: 0.92"
[1] "TRAIN specifity: 0.403508771929824"
[1] "TRAIN sensitivity: 0.998238661382651"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        1
            positive       24      755
[1] "TEST accuracy: 0.968553459119497"
[1] "TEST +precision: 0.969191270860077"
[1] "TEST -precision: 0.9375"
[1] "TEST specifity: 0.384615384615385"
[1] "TEST sensitivity: 0.998677248677249"
