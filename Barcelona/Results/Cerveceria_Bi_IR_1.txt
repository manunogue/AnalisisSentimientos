[1] "DATASET NAME: Cerveceria_Bi_IR_1"
[1] "TRAIN INSTANCES: 5520"
[1] "TEST INSTANCES: 968"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 1.37915339867274"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

5520 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 4416, 4416, 4416, 4416, 4416 
Resampling results:

  ROC        Sens  Spec     
  0.9617251  1     0.9195652

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative       50        4
  positive        0       46
                            
 Accuracy (average) : 0.9598

[1] "TRAIN accuracy: 0.959782608695652"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.925553319919517"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.919565217391304"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       26       59
            positive       30      853
[1] "TEST accuracy: 0.908057851239669"
[1] "TEST +precision: 0.966024915062288"
[1] "TEST -precision: 0.305882352941176"
[1] "TEST specifity: 0.464285714285714"
[1] "TEST sensitivity: 0.93530701754386"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 19.1761661489805"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

5520 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 4416, 4416, 4416, 4416, 4416 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9653910  0.8902174  0.9510870
  0.010  2  0.9652722  0.8902174  0.9489130
  0.010  3  0.9650047  0.8902174  0.9503623
  0.255  1  0.9722396  0.8934783  0.9601449
  0.255  2  0.9727670  0.8934783  0.9601449
  0.255  3  0.9728648  0.8923913  0.9623188
  0.500  1  0.9774302  0.9010870  0.9597826
  0.500  2  0.9779478  0.9010870  0.9597826
  0.500  3  0.9760633  0.8942029  0.9623188

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     45.1      2.0
  positive      4.9     48.0
                            
 Accuracy (average) : 0.9304

[1] "TRAIN accuracy: 0.930434782608696"
[1] "TRAIN +precision: 0.906570841889117"
[1] "TRAIN -precision: 0.957274826789838"
[1] "TRAIN specifity: 0.901086956521739"
[1] "TRAIN sensitivity: 0.959782608695652"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       24       30
            positive       32      882
[1] "TEST accuracy: 0.935950413223141"
[1] "TEST +precision: 0.964989059080963"
[1] "TEST -precision: 0.444444444444444"
[1] "TEST specifity: 0.428571428571429"
[1] "TEST sensitivity: 0.967105263157895"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 19.4168696006139"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

5520 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 4416, 4416, 4416, 4416, 4416 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8763958  0.9376812  0.6177536
  0.3  1          0.6               0.50       100      0.9307863  0.9634058  0.6731884
  0.3  1          0.6               0.50       150      0.9557695  0.9000000  0.8485507
  0.3  1          0.6               0.75        50      0.8653989  0.9347826  0.5887681
  0.3  1          0.6               0.75       100      0.9321935  0.9666667  0.6619565
  0.3  1          0.6               0.75       150      0.9527873  0.8561594  0.8916667
  0.3  1          0.6               1.00        50      0.8729944  0.9373188  0.5960145
  0.3  1          0.6               1.00       100      0.9307288  0.9681159  0.6586957
  0.3  1          0.6               1.00       150      0.9546284  0.8869565  0.8518116
  0.3  1          0.8               0.50        50      0.8689676  0.9271739  0.5934783
  0.3  1          0.8               0.50       100      0.9258615  0.9239130  0.7170290
  0.3  1          0.8               0.50       150      0.9559363  0.8634058  0.8985507
  0.3  1          0.8               0.75        50      0.8744936  0.9376812  0.5985507
  0.3  1          0.8               0.75       100      0.9311447  0.9702899  0.6626812
  0.3  1          0.8               0.75       150      0.9558106  0.8427536  0.9423913
  0.3  1          0.8               1.00        50      0.8711625  0.9369565  0.5956522
  0.3  1          0.8               1.00       100      0.9313770  0.9706522  0.6597826
  0.3  1          0.8               1.00       150      0.9542700  0.8583333  0.9003623
  0.3  2          0.6               0.50        50      0.9389017  0.9724638  0.6786232
  0.3  2          0.6               0.50       100      0.9712826  0.9000000  0.9036232
  0.3  2          0.6               0.50       150      0.9797797  0.9217391  0.9409420
  0.3  2          0.6               0.75        50      0.9429098  0.9804348  0.6847826
  0.3  2          0.6               0.75       100      0.9725773  0.8923913  0.9456522
  0.3  2          0.6               0.75       150      0.9802208  0.9206522  0.9423913
  0.3  2          0.6               1.00        50      0.9406388  0.9750000  0.6739130
  0.3  2          0.6               1.00       100      0.9720923  0.9202899  0.8724638
  0.3  2          0.6               1.00       150      0.9817909  0.9181159  0.9492754
  0.3  2          0.8               0.50        50      0.9361521  0.9735507  0.6746377
  0.3  2          0.8               0.50       100      0.9739931  0.8931159  0.9463768
  0.3  2          0.8               0.50       150      0.9801174  0.9213768  0.9420290
  0.3  2          0.8               0.75        50      0.9419519  0.9423913  0.7271739
  0.3  2          0.8               0.75       100      0.9737604  0.8836957  0.9471014
  0.3  2          0.8               0.75       150      0.9813196  0.9221014  0.9456522
  0.3  2          0.8               1.00        50      0.9446522  0.9847826  0.6782609
  0.3  2          0.8               1.00       100      0.9730808  0.9677536  0.7992754
  0.3  2          0.8               1.00       150      0.9818617  0.9144928  0.9518116
  0.3  3          0.6               0.50        50      0.9640806  0.9282609  0.8282609
  0.3  3          0.6               0.50       100      0.9828118  0.9260870  0.9449275
  0.3  3          0.6               0.50       150      0.9860235  0.9405797  0.9460145
  0.3  3          0.6               0.75        50      0.9660556  0.9101449  0.8568841
  0.3  3          0.6               0.75       100      0.9827022  0.9231884  0.9503623
  0.3  3          0.6               0.75       150      0.9877166  0.9369565  0.9576087
  0.3  3          0.6               1.00        50      0.9655810  0.9884058  0.7391304
  0.3  3          0.6               1.00       100      0.9843117  0.9481884  0.8971014
  0.3  3          0.6               1.00       150      0.9884452  0.9340580  0.9561594
  0.3  3          0.8               0.50        50      0.9652325  0.9572464  0.7789855
  0.3  3          0.8               0.50       100      0.9814161  0.9166667  0.9445652
  0.3  3          0.8               0.50       150      0.9867530  0.9492754  0.9460145
  0.3  3          0.8               0.75        50      0.9679761  0.9876812  0.7478261
  0.3  3          0.8               0.75       100      0.9833504  0.9253623  0.9463768
  0.3  3          0.8               0.75       150      0.9880008  0.9413043  0.9514493
  0.3  3          0.8               1.00        50      0.9649539  0.9873188  0.7413043
  0.3  3          0.8               1.00       100      0.9839831  0.9565217  0.8721014
  0.3  3          0.8               1.00       150      0.9887232  0.9336957  0.9576087
  0.4  1          0.6               0.50        50      0.8838752  0.9503623  0.5876812
  0.4  1          0.6               0.50       100      0.9427713  0.8239130  0.8913043
  0.4  1          0.6               0.50       150      0.9651980  0.8822464  0.9340580
  0.4  1          0.6               0.75        50      0.8910805  0.9420290  0.6043478
  0.4  1          0.6               0.75       100      0.9462491  0.8057971  0.9463768
  0.4  1          0.6               0.75       150      0.9667835  0.8833333  0.9380435
  0.4  1          0.6               1.00        50      0.8878882  0.9420290  0.6086957
  0.4  1          0.6               1.00       100      0.9462213  0.9090580  0.7880435
  0.4  1          0.6               1.00       150      0.9639739  0.8699275  0.9420290
  0.4  1          0.8               0.50        50      0.8868128  0.9442029  0.6021739
  0.4  1          0.8               0.50       100      0.9423463  0.9268116  0.7405797
  0.4  1          0.8               0.50       150      0.9649230  0.8811594  0.9380435
  0.4  1          0.8               0.75        50      0.8902397  0.9413043  0.6018116
  0.4  1          0.8               0.75       100      0.9477033  0.8405797  0.8869565
  0.4  1          0.8               0.75       150      0.9638531  0.8699275  0.9431159
  0.4  1          0.8               1.00        50      0.8880218  0.9449275  0.6057971
  0.4  1          0.8               1.00       100      0.9457805  0.9416667  0.7347826
  0.4  1          0.8               1.00       150      0.9648177  0.8717391  0.9434783
  0.4  2          0.6               0.50        50      0.9529461  0.9485507  0.7528986
  0.4  2          0.6               0.50       100      0.9760889  0.9130435  0.9434783
  0.4  2          0.6               0.50       150      0.9827492  0.9326087  0.9405797
  0.4  2          0.6               0.75        50      0.9524388  0.9481884  0.7445652
  0.4  2          0.6               0.75       100      0.9768428  0.9134058  0.9431159
  0.4  2          0.6               0.75       150      0.9829615  0.9340580  0.9471014
  0.4  2          0.6               1.00        50      0.9538775  0.9452899  0.7438406
  0.4  2          0.6               1.00       100      0.9794391  0.9076087  0.9525362
  0.4  2          0.6               1.00       150      0.9856392  0.9297101  0.9557971
  0.4  2          0.8               0.50        50      0.9508592  0.9449275  0.7449275
  0.4  2          0.8               0.50       100      0.9776278  0.9221014  0.9405797
  0.4  2          0.8               0.50       150      0.9828886  0.9391304  0.9413043
  0.4  2          0.8               0.75        50      0.9514906  0.9880435  0.6865942
  0.4  2          0.8               0.75       100      0.9786271  0.9130435  0.9507246
  0.4  2          0.8               0.75       150      0.9843766  0.9340580  0.9460145
  0.4  2          0.8               1.00        50      0.9555684  0.9862319  0.6985507
  0.4  2          0.8               1.00       100      0.9789333  0.9253623  0.9199275
  0.4  2          0.8               1.00       150      0.9854462  0.9297101  0.9539855
  0.4  3          0.6               0.50        50      0.9692905  0.8869565  0.9079710
  0.4  3          0.6               0.50       100      0.9854144  0.9387681  0.9456522
  0.4  3          0.6               0.50       150      0.9887087  0.9576087  0.9489130
  0.4  3          0.6               0.75        50      0.9723144  0.9043478  0.9115942
  0.4  3          0.6               0.75       100      0.9858029  0.9336957  0.9507246
  0.4  3          0.6               0.75       150      0.9893375  0.9434783  0.9561594
  0.4  3          0.6               1.00        50      0.9725235  0.9463768  0.8304348
  0.4  3          0.6               1.00       100      0.9867632  0.9300725  0.9539855
  0.4  3          0.6               1.00       150      0.9900313  0.9391304  0.9583333
  0.4  3          0.8               0.50        50      0.9707664  0.8847826  0.9427536
  0.4  3          0.8               0.50       100      0.9846727  0.9358696  0.9474638
  0.4  3          0.8               0.50       150      0.9888459  0.9572464  0.9532609
  0.4  3          0.8               0.75        50      0.9747480  0.9018116  0.9119565
  0.4  3          0.8               0.75       100      0.9861567  0.9355072  0.9532609
  0.4  3          0.8               0.75       150      0.9901629  0.9554348  0.9572464
  0.4  3          0.8               1.00        50      0.9734638  0.9735507  0.7989130
  0.4  3          0.8               1.00       100      0.9866441  0.9315217  0.9579710
  0.4  3          0.8               1.00       150      0.9902991  0.9423913  0.9601449

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     47.1      2.0
  positive      2.9     48.0
                            
 Accuracy (average) : 0.9513

[1] "TRAIN accuracy: 0.951268115942029"
[1] "TRAIN +precision: 0.943396226415094"
[1] "TRAIN -precision: 0.959424566580598"
[1] "TRAIN specifity: 0.942391304347826"
[1] "TRAIN sensitivity: 0.960144927536232"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       29       41
            positive       27      871
[1] "TEST accuracy: 0.929752066115702"
[1] "TEST +precision: 0.969933184855234"
[1] "TEST -precision: 0.414285714285714"
[1] "TEST specifity: 0.517857142857143"
[1] "TEST sensitivity: 0.955043859649123"
