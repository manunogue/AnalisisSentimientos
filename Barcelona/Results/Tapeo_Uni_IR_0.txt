[1] "DATASET NAME: Tapeo_Uni_IR_0"
[1] "TRAIN INSTANCES: 996"
[1] "TEST INSTANCES: 333"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 4.71055507659912"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

996 samples
672 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 797, 797, 797, 797, 796 
Resampling results:

  ROC        Sens       Spec    
  0.9387776  0.2571429  0.996875

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.9      0.3
  positive      2.6     96.2
                            
 Accuracy (average) : 0.9709

[1] "TRAIN accuracy: 0.970883534136546"
[1] "TRAIN +precision: 0.973577235772358"
[1] "TRAIN -precision: 0.75"
[1] "TRAIN specifity: 0.257142857142857"
[1] "TRAIN sensitivity: 0.99687825182102"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        6
            positive        6      316
[1] "TEST accuracy: 0.963963963963964"
[1] "TEST +precision: 0.981366459627329"
[1] "TEST -precision: 0.454545454545455"
[1] "TEST specifity: 0.454545454545455"
[1] "TEST sensitivity: 0.981366459627329"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.51834326585134"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

996 samples
672 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 797, 797, 797, 796, 797 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5000000  0.00000000  1.0000000
  0.010  2  0.5000000  0.00000000  1.0000000
  0.010  3  0.5000000  0.00000000  1.0000000
  0.255  1  0.4990397  0.00000000  0.9968804
  0.255  2  0.5012603  0.00000000  0.9968804
  0.255  3  0.4974093  0.00000000  1.0000000
  0.500  1  0.5191251  0.02857143  0.9906304
  0.500  2  0.5253608  0.02857143  0.9916721
  0.500  3  0.5077666  0.00000000  0.9958333

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.1      0.8
  positive      3.4     95.7
                            
 Accuracy (average) : 0.9578

[1] "TRAIN accuracy: 0.957831325301205"
[1] "TRAIN +precision: 0.965552178318136"
[1] "TRAIN -precision: 0.111111111111111"
[1] "TRAIN specifity: 0.0285714285714286"
[1] "TRAIN sensitivity: 0.991675338189386"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        2
            positive       10      320
[1] "TEST accuracy: 0.963963963963964"
[1] "TEST +precision: 0.96969696969697"
[1] "TEST -precision: 0.333333333333333"
[1] "TEST specifity: 0.0909090909090909"
[1] "TEST sensitivity: 0.993788819875776"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.69657075007757"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

996 samples
672 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 797, 797, 796, 797, 797 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.8797045  0.02857143  1.0000000
  0.3  1          0.6               0.50       100      0.9028474  0.08571429  0.9979221
  0.3  1          0.6               0.50       150      0.8822292  0.08571429  0.9948025
  0.3  1          0.6               0.75        50      0.8909747  0.00000000  1.0000000
  0.3  1          0.6               0.75       100      0.8935596  0.08571429  0.9979167
  0.3  1          0.6               0.75       150      0.8836664  0.14285714  0.9968750
  0.3  1          0.6               1.00        50      0.8939867  0.00000000  1.0000000
  0.3  1          0.6               1.00       100      0.8887795  0.02857143  1.0000000
  0.3  1          0.6               1.00       150      0.8851198  0.08571429  0.9989583
  0.3  1          0.8               0.50        50      0.8507942  0.08571429  1.0000000
  0.3  1          0.8               0.50       100      0.8625478  0.08571429  0.9958441
  0.3  1          0.8               0.50       150      0.8567643  0.11428571  0.9906466
  0.3  1          0.8               0.75        50      0.8892217  0.00000000  1.0000000
  0.3  1          0.8               0.75       100      0.8891743  0.05714286  0.9979167
  0.3  1          0.8               0.75       150      0.8789053  0.11428571  0.9968804
  0.3  1          0.8               1.00        50      0.8928706  0.00000000  1.0000000
  0.3  1          0.8               1.00       100      0.8878797  0.02857143  1.0000000
  0.3  1          0.8               1.00       150      0.8824459  0.05714286  0.9989583
  0.3  2          0.6               0.50        50      0.8749136  0.05714286  0.9989583
  0.3  2          0.6               0.50       100      0.8706066  0.11428571  0.9979221
  0.3  2          0.6               0.50       150      0.8600497  0.17142857  0.9968858
  0.3  2          0.6               0.75        50      0.8837335  0.00000000  0.9979167
  0.3  2          0.6               0.75       100      0.8792376  0.05714286  0.9968750
  0.3  2          0.6               0.75       150      0.8596109  0.08571429  0.9947971
  0.3  2          0.6               1.00        50      0.8989911  0.05714286  1.0000000
  0.3  2          0.6               1.00       100      0.8977794  0.08571429  0.9968804
  0.3  2          0.6               1.00       150      0.8808398  0.11428571  0.9968858
  0.3  2          0.8               0.50        50      0.8709050  0.05714286  0.9989637
  0.3  2          0.8               0.50       100      0.8564767  0.11428571  0.9948025
  0.3  2          0.8               0.50       150      0.8517225  0.11428571  0.9968858
  0.3  2          0.8               0.75        50      0.8775097  0.00000000  0.9989583
  0.3  2          0.8               0.75       100      0.8567751  0.08571429  0.9989583
  0.3  2          0.8               0.75       150      0.8411778  0.08571429  0.9958387
  0.3  2          0.8               1.00        50      0.8970543  0.00000000  1.0000000
  0.3  2          0.8               1.00       100      0.8900475  0.08571429  0.9989583
  0.3  2          0.8               1.00       150      0.8784565  0.08571429  0.9968858
  0.3  3          0.6               0.50        50      0.8537704  0.08571429  0.9989637
  0.3  3          0.6               0.50       100      0.8344652  0.05714286  0.9979275
  0.3  3          0.6               0.50       150      0.8318113  0.08571429  0.9979275
  0.3  3          0.6               0.75        50      0.8930615  0.08571429  0.9989583
  0.3  3          0.6               0.75       100      0.8805476  0.14285714  0.9968858
  0.3  3          0.6               0.75       150      0.8757564  0.11428571  0.9958441
  0.3  3          0.6               1.00        50      0.8958434  0.05714286  0.9989583
  0.3  3          0.6               1.00       100      0.8711849  0.05714286  0.9989583
  0.3  3          0.6               1.00       150      0.8588414  0.08571429  0.9937608
  0.3  3          0.8               0.50        50      0.8786354  0.05714286  0.9968804
  0.3  3          0.8               0.50       100      0.8624383  0.11428571  0.9916883
  0.3  3          0.8               0.50       150      0.8591522  0.14285714  0.9958441
  0.3  3          0.8               0.75        50      0.8811482  0.08571429  0.9989583
  0.3  3          0.8               0.75       100      0.8616596  0.08571429  0.9927299
  0.3  3          0.8               0.75       150      0.8503601  0.08571429  0.9948079
  0.3  3          0.8               1.00        50      0.8922658  0.02857143  1.0000000
  0.3  3          0.8               1.00       100      0.8677500  0.08571429  0.9968804
  0.3  3          0.8               1.00       150      0.8561459  0.08571429  0.9948025
  0.4  1          0.6               0.50        50      0.8599035  0.05714286  0.9989637
  0.4  1          0.6               0.50       100      0.8509013  0.05714286  0.9958441
  0.4  1          0.6               0.50       150      0.8577180  0.17142857  0.9948025
  0.4  1          0.6               0.75        50      0.8807184  0.05714286  0.9989583
  0.4  1          0.6               0.75       100      0.8761188  0.11428571  1.0000000
  0.4  1          0.6               0.75       150      0.8734602  0.08571429  0.9979221
  0.4  1          0.6               1.00        50      0.8849120  0.00000000  1.0000000
  0.4  1          0.6               1.00       100      0.8935295  0.08571429  0.9989583
  0.4  1          0.6               1.00       150      0.8872733  0.08571429  0.9968750
  0.4  1          0.8               0.50        50      0.8853245  0.05714286  0.9989583
  0.4  1          0.8               0.50       100      0.8880151  0.02857143  0.9958441
  0.4  1          0.8               0.50       150      0.8740462  0.17142857  0.9916883
  0.4  1          0.8               0.75        50      0.8954871  0.00000000  1.0000000
  0.4  1          0.8               0.75       100      0.8800973  0.17142857  0.9989637
  0.4  1          0.8               0.75       150      0.8779978  0.17142857  0.9927191
  0.4  1          0.8               1.00        50      0.8880501  0.02857143  1.0000000
  0.4  1          0.8               1.00       100      0.8839386  0.08571429  0.9989583
  0.4  1          0.8               1.00       150      0.8865354  0.11428571  0.9979167
  0.4  2          0.6               0.50        50      0.8457485  0.08571429  0.9958441
  0.4  2          0.6               0.50       100      0.8377090  0.05714286  0.9927245
  0.4  2          0.6               0.50       150      0.8362293  0.08571429  0.9937662
  0.4  2          0.6               0.75        50      0.8932134  0.02857143  0.9989583
  0.4  2          0.6               0.75       100      0.8772900  0.14285714  0.9937554
  0.4  2          0.6               0.75       150      0.8643574  0.08571429  0.9906412
  0.4  2          0.6               1.00        50      0.8994796  0.08571429  0.9989583
  0.4  2          0.6               1.00       100      0.8823233  0.11428571  0.9968804
  0.4  2          0.6               1.00       150      0.8647985  0.11428571  0.9927299
  0.4  2          0.8               0.50        50      0.8565160  0.08571429  0.9968858
  0.4  2          0.8               0.50       100      0.8566278  0.11428571  0.9968912
  0.4  2          0.8               0.50       150      0.8554327  0.08571429  0.9968912
  0.4  2          0.8               0.75        50      0.8724047  0.11428571  0.9979167
  0.4  2          0.8               0.75       100      0.8431309  0.14285714  0.9906412
  0.4  2          0.8               0.75       150      0.8408879  0.11428571  0.9916775
  0.4  2          0.8               1.00        50      0.8792600  0.02857143  0.9979167
  0.4  2          0.8               1.00       100      0.8729398  0.14285714  0.9958441
  0.4  2          0.8               1.00       150      0.8592701  0.11428571  0.9916829
  0.4  3          0.6               0.50        50      0.8634476  0.05714286  0.9968804
  0.4  3          0.6               0.50       100      0.8353426  0.14285714  0.9937554
  0.4  3          0.6               0.50       150      0.8541960  0.14285714  0.9948025
  0.4  3          0.6               0.75        50      0.8700338  0.17142857  0.9948079
  0.4  3          0.6               0.75       100      0.8588939  0.14285714  0.9927245
  0.4  3          0.6               0.75       150      0.8597906  0.14285714  0.9906520
  0.4  3          0.6               1.00        50      0.8825854  0.05714286  0.9979167
  0.4  3          0.6               1.00       100      0.8534789  0.08571429  0.9937662
  0.4  3          0.6               1.00       150      0.8481295  0.05714286  0.9927299
  0.4  3          0.8               0.50        50      0.8323518  0.11428571  0.9958333
  0.4  3          0.8               0.50       100      0.8281728  0.11428571  0.9958333
  0.4  3          0.8               0.50       150      0.8339802  0.11428571  0.9916775
  0.4  3          0.8               0.75        50      0.8644916  0.08571429  0.9979221
  0.4  3          0.8               0.75       100      0.8600273  0.08571429  0.9958387
  0.4  3          0.8               0.75       150      0.8594197  0.11428571  0.9958387
  0.4  3          0.8               1.00        50      0.8827712  0.08571429  1.0000000
  0.4  3          0.8               1.00       100      0.8490177  0.02857143  0.9968858
  0.4  3          0.8               1.00       150      0.8485674  0.11428571  0.9937662

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 1, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.5.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.3      0.2
  positive      3.2     96.3
                            
 Accuracy (average) : 0.9659

[1] "TRAIN accuracy: 0.965863453815261"
[1] "TRAIN +precision: 0.967709384460141"
[1] "TRAIN -precision: 0.6"
[1] "TRAIN specifity: 0.0857142857142857"
[1] "TRAIN sensitivity: 0.997918834547347"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        0
            positive        6      322
[1] "TEST accuracy: 0.981981981981982"
[1] "TEST +precision: 0.981707317073171"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.454545454545455"
[1] "TEST sensitivity: 1"
