[1] "DATASET NAME: Tapeo_Bi_IR_0"
[1] "TRAIN INSTANCES: 996"
[1] "TEST INSTANCES: 333"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.47100710868835"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

996 samples
622 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 797, 797, 796, 797, 797 
Resampling results:

  ROC       Sens        Spec     
  0.861937  0.08214286  0.9979167

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.3      0.2
  positive      3.4     96.1
                            
 Accuracy (average) : 0.9639

[1] "TRAIN accuracy: 0.963855421686747"
[1] "TRAIN +precision: 0.9656912209889"
[1] "TRAIN -precision: 0.6"
[1] "TRAIN specifity: 0.0810810810810811"
[1] "TRAIN sensitivity: 0.997914494264859"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        2
            positive        7      322
[1] "TEST accuracy: 0.972972972972973"
[1] "TEST +precision: 0.978723404255319"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.222222222222222"
[1] "TEST sensitivity: 0.993827160493827"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.18781098524729"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

996 samples
622 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 796, 797, 798, 796, 797 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.5000000  0     1.0000000
  0.010  2  0.5000000  0     1.0000000
  0.010  3  0.5000000  0     1.0000000
  0.255  1  0.5000000  0     1.0000000
  0.255  2  0.5000000  0     1.0000000
  0.255  3  0.5000000  0     1.0000000
  0.500  1  0.5130617  0     0.9989529
  0.500  2  0.5000000  0     1.0000000
  0.500  3  0.5000000  0     1.0000000

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.1
  positive      3.7     96.2
                            
 Accuracy (average) : 0.9618

[1] "TRAIN accuracy: 0.961847389558233"
[1] "TRAIN +precision: 0.962814070351759"
[1] "TRAIN -precision: 0"
[1] "TRAIN specifity: 0"
[1] "TRAIN sensitivity: 0.99895724713243"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        9      324
[1] "TEST accuracy: 0.972972972972973"
[1] "TEST +precision: 0.972972972972973"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.10944698254267"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

996 samples
622 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 797, 797, 796, 797, 797 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7107526  0.00000000  1.0000000
  0.3  1          0.6               0.50       100      0.7090962  0.00000000  1.0000000
  0.3  1          0.6               0.50       150      0.7259675  0.00000000  1.0000000
  0.3  1          0.6               0.75        50      0.7361479  0.00000000  1.0000000
  0.3  1          0.6               0.75       100      0.7344964  0.00000000  1.0000000
  0.3  1          0.6               0.75       150      0.7391746  0.00000000  1.0000000
  0.3  1          0.6               1.00        50      0.7328354  0.00000000  1.0000000
  0.3  1          0.6               1.00       100      0.7360265  0.00000000  1.0000000
  0.3  1          0.6               1.00       150      0.7410597  0.00000000  1.0000000
  0.3  1          0.8               0.50        50      0.7256618  0.00000000  1.0000000
  0.3  1          0.8               0.50       100      0.7160006  0.00000000  1.0000000
  0.3  1          0.8               0.50       150      0.7311310  0.00000000  1.0000000
  0.3  1          0.8               0.75        50      0.7505157  0.00000000  1.0000000
  0.3  1          0.8               0.75       100      0.7718547  0.00000000  1.0000000
  0.3  1          0.8               0.75       150      0.7791300  0.00000000  1.0000000
  0.3  1          0.8               1.00        50      0.7397741  0.00000000  1.0000000
  0.3  1          0.8               1.00       100      0.7436931  0.00000000  1.0000000
  0.3  1          0.8               1.00       150      0.7448287  0.00000000  1.0000000
  0.3  2          0.6               0.50        50      0.6994901  0.00000000  1.0000000
  0.3  2          0.6               0.50       100      0.7135620  0.00000000  1.0000000
  0.3  2          0.6               0.50       150      0.7288658  0.00000000  1.0000000
  0.3  2          0.6               0.75        50      0.7473157  0.00000000  1.0000000
  0.3  2          0.6               0.75       100      0.7423167  0.00000000  1.0000000
  0.3  2          0.6               0.75       150      0.7464385  0.00000000  1.0000000
  0.3  2          0.6               1.00        50      0.7730622  0.00000000  1.0000000
  0.3  2          0.6               1.00       100      0.7825432  0.00000000  0.9989583
  0.3  2          0.6               1.00       150      0.7820927  0.00000000  0.9989583
  0.3  2          0.8               0.50        50      0.7310935  0.00000000  1.0000000
  0.3  2          0.8               0.50       100      0.7410438  0.00000000  1.0000000
  0.3  2          0.8               0.50       150      0.7291504  0.00000000  1.0000000
  0.3  2          0.8               0.75        50      0.7564029  0.00000000  1.0000000
  0.3  2          0.8               0.75       100      0.7516317  0.00000000  1.0000000
  0.3  2          0.8               0.75       150      0.7570833  0.00000000  1.0000000
  0.3  2          0.8               1.00        50      0.7626289  0.00000000  1.0000000
  0.3  2          0.8               1.00       100      0.7650668  0.00000000  1.0000000
  0.3  2          0.8               1.00       150      0.7670943  0.00000000  1.0000000
  0.3  3          0.6               0.50        50      0.7049979  0.00000000  1.0000000
  0.3  3          0.6               0.50       100      0.7280689  0.00000000  1.0000000
  0.3  3          0.6               0.50       150      0.7301290  0.00000000  1.0000000
  0.3  3          0.6               0.75        50      0.7213307  0.00000000  1.0000000
  0.3  3          0.6               0.75       100      0.7160587  0.00000000  1.0000000
  0.3  3          0.6               0.75       150      0.7212683  0.00000000  1.0000000
  0.3  3          0.6               1.00        50      0.7691589  0.00000000  1.0000000
  0.3  3          0.6               1.00       100      0.7639878  0.00000000  1.0000000
  0.3  3          0.6               1.00       150      0.7663115  0.00000000  1.0000000
  0.3  3          0.8               0.50        50      0.6814160  0.00000000  1.0000000
  0.3  3          0.8               0.50       100      0.6973330  0.00000000  1.0000000
  0.3  3          0.8               0.50       150      0.7112570  0.00000000  1.0000000
  0.3  3          0.8               0.75        50      0.7474981  0.00000000  1.0000000
  0.3  3          0.8               0.75       100      0.7617155  0.00000000  1.0000000
  0.3  3          0.8               0.75       150      0.7603452  0.00000000  1.0000000
  0.3  3          0.8               1.00        50      0.7574783  0.00000000  1.0000000
  0.3  3          0.8               1.00       100      0.7624634  0.00000000  1.0000000
  0.3  3          0.8               1.00       150      0.7654733  0.00000000  1.0000000
  0.4  1          0.6               0.50        50      0.7190811  0.00000000  1.0000000
  0.4  1          0.6               0.50       100      0.7345246  0.00000000  1.0000000
  0.4  1          0.6               0.50       150      0.7432196  0.00000000  1.0000000
  0.4  1          0.6               0.75        50      0.7697430  0.00000000  1.0000000
  0.4  1          0.6               0.75       100      0.7754955  0.00000000  1.0000000
  0.4  1          0.6               0.75       150      0.7754762  0.00000000  0.9989583
  0.4  1          0.6               1.00        50      0.7541148  0.00000000  1.0000000
  0.4  1          0.6               1.00       100      0.7566204  0.00000000  1.0000000
  0.4  1          0.6               1.00       150      0.7589077  0.00000000  1.0000000
  0.4  1          0.8               0.50        50      0.7112733  0.00000000  1.0000000
  0.4  1          0.8               0.50       100      0.7326596  0.00000000  1.0000000
  0.4  1          0.8               0.50       150      0.7273301  0.00000000  1.0000000
  0.4  1          0.8               0.75        50      0.7299561  0.00000000  1.0000000
  0.4  1          0.8               0.75       100      0.7360249  0.00000000  1.0000000
  0.4  1          0.8               0.75       150      0.7309427  0.00000000  1.0000000
  0.4  1          0.8               1.00        50      0.7474504  0.00000000  1.0000000
  0.4  1          0.8               1.00       100      0.7500223  0.00000000  1.0000000
  0.4  1          0.8               1.00       150      0.7508966  0.00000000  1.0000000
  0.4  2          0.6               0.50        50      0.7066220  0.00000000  1.0000000
  0.4  2          0.6               0.50       100      0.7198340  0.00000000  1.0000000
  0.4  2          0.6               0.50       150      0.7100325  0.00000000  1.0000000
  0.4  2          0.6               0.75        50      0.7617591  0.00000000  0.9989583
  0.4  2          0.6               0.75       100      0.7579939  0.00000000  0.9989583
  0.4  2          0.6               0.75       150      0.7664213  0.00000000  1.0000000
  0.4  2          0.6               1.00        50      0.7624941  0.00000000  1.0000000
  0.4  2          0.6               1.00       100      0.7604252  0.00000000  1.0000000
  0.4  2          0.6               1.00       150      0.7633821  0.00000000  1.0000000
  0.4  2          0.8               0.50        50      0.6967991  0.00000000  1.0000000
  0.4  2          0.8               0.50       100      0.7175323  0.00000000  1.0000000
  0.4  2          0.8               0.50       150      0.7233842  0.00000000  1.0000000
  0.4  2          0.8               0.75        50      0.7522785  0.00000000  1.0000000
  0.4  2          0.8               0.75       100      0.7528817  0.00000000  1.0000000
  0.4  2          0.8               0.75       150      0.7628125  0.00000000  1.0000000
  0.4  2          0.8               1.00        50      0.7754197  0.00000000  1.0000000
  0.4  2          0.8               1.00       100      0.7833066  0.00000000  1.0000000
  0.4  2          0.8               1.00       150      0.7810187  0.00000000  1.0000000
  0.4  3          0.6               0.50        50      0.6750139  0.00000000  1.0000000
  0.4  3          0.6               0.50       100      0.6969852  0.00000000  1.0000000
  0.4  3          0.6               0.50       150      0.6957639  0.00000000  1.0000000
  0.4  3          0.6               0.75        50      0.7355290  0.00000000  1.0000000
  0.4  3          0.6               0.75       100      0.7386024  0.00000000  1.0000000
  0.4  3          0.6               0.75       150      0.7351900  0.02857143  1.0000000
  0.4  3          0.6               1.00        50      0.7635978  0.00000000  1.0000000
  0.4  3          0.6               1.00       100      0.7603076  0.00000000  1.0000000
  0.4  3          0.6               1.00       150      0.7615932  0.00000000  1.0000000
  0.4  3          0.8               0.50        50      0.6914515  0.00000000  1.0000000
  0.4  3          0.8               0.50       100      0.7108555  0.00000000  1.0000000
  0.4  3          0.8               0.50       150      0.7112599  0.00000000  1.0000000
  0.4  3          0.8               0.75        50      0.7683222  0.00000000  1.0000000
  0.4  3          0.8               0.75       100      0.7602750  0.02857143  1.0000000
  0.4  3          0.8               0.75       150      0.7648775  0.00000000  1.0000000
  0.4  3          0.8               1.00        50      0.7732116  0.00000000  1.0000000
  0.4  3          0.8               1.00       100      0.7731606  0.00000000  1.0000000
  0.4  3          0.8               1.00       150      0.7737558  0.00000000  1.0000000

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 2, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.0
  positive      3.7     96.3
                            
 Accuracy (average) : 0.9629

[1] "TRAIN accuracy: 0.96285140562249"
[1] "TRAIN +precision: 0.96285140562249"
[1] "TRAIN -precision: NaN"
[1] "TRAIN specifity: 0"
[1] "TRAIN sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        1
            positive        9      323
[1] "TEST accuracy: 0.96996996996997"
[1] "TEST +precision: 0.97289156626506"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.996913580246914"
