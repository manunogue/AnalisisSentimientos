[1] "DATASET NAME: Teresa_Uni_IR_0"
[1] "TRAIN INSTANCES: 1137"
[1] "TEST INSTANCES: 379"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.24600696563721"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1137 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 910, 909, 910, 909, 910 
Resampling results:

  ROC        Sens       Spec     
  0.9590526  0.4109091  0.9908003

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.8      0.9
  positive      2.6     94.6
                            
 Accuracy (average) : 0.9648

[1] "TRAIN accuracy: 0.964819700967458"
[1] "TRAIN +precision: 0.972875226039783"
[1] "TRAIN -precision: 0.67741935483871"
[1] "TRAIN specifity: 0.411764705882353"
[1] "TRAIN sensitivity: 0.990791896869245"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       11        4
            positive        7      357
[1] "TEST accuracy: 0.970976253298153"
[1] "TEST +precision: 0.980769230769231"
[1] "TEST -precision: 0.733333333333333"
[1] "TEST specifity: 0.611111111111111"
[1] "TEST sensitivity: 0.988919667590028"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.42486071586609"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1137 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 910, 910, 908, 910, 910 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5000000  0.00000000  0.9990783
  0.010  2  0.5000000  0.00000000  0.9990783
  0.010  3  0.5000000  0.00000000  0.9990783
  0.255  1  0.5423039  0.13454545  0.9953917
  0.255  2  0.5421399  0.09818182  0.9953917
  0.255  3  0.4625130  0.09818182  0.9917093
  0.500  1  0.6229121  0.15454545  0.9917051
  0.500  2  0.6778438  0.13636364  0.9926267
  0.500  3  0.5765698  0.15636364  0.9880227

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.6      0.7
  positive      3.9     94.8
                            
 Accuracy (average) : 0.9543

[1] "TRAIN accuracy: 0.954265611257696"
[1] "TRAIN +precision: 0.96078431372549"
[1] "TRAIN -precision: 0.466666666666667"
[1] "TRAIN specifity: 0.137254901960784"
[1] "TRAIN sensitivity: 0.992633517495396"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        8
            positive       13      353
[1] "TEST accuracy: 0.944591029023747"
[1] "TEST +precision: 0.96448087431694"
[1] "TEST -precision: 0.384615384615385"
[1] "TEST specifity: 0.277777777777778"
[1] "TEST sensitivity: 0.977839335180055"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.82132929960887"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1137 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 910, 909, 910, 910, 909 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9314195  0.2381818  0.9972393
  0.3  1          0.6               0.50       100      0.9347429  0.4109091  0.9935526
  0.3  1          0.6               0.50       150      0.9380495  0.4509091  0.9926310
  0.3  1          0.6               0.75        50      0.9099802  0.2745455  0.9990826
  0.3  1          0.6               0.75       100      0.9421386  0.3727273  0.9972393
  0.3  1          0.6               0.75       150      0.9430704  0.3927273  0.9953959
  0.3  1          0.6               1.00        50      0.9421708  0.2945455  1.0000000
  0.3  1          0.6               1.00       100      0.9430648  0.3527273  0.9972393
  0.3  1          0.6               1.00       150      0.9415990  0.3727273  0.9963176
  0.3  1          0.8               0.50        50      0.8951833  0.2745455  0.9972350
  0.3  1          0.8               0.50       100      0.9230027  0.3909091  0.9944743
  0.3  1          0.8               0.50       150      0.9229058  0.4272727  0.9926310
  0.3  1          0.8               0.75        50      0.9259736  0.2545455  1.0000000
  0.3  1          0.8               0.75       100      0.9398441  0.3327273  0.9972393
  0.3  1          0.8               0.75       150      0.9421033  0.3527273  0.9972393
  0.3  1          0.8               1.00        50      0.9401083  0.2745455  1.0000000
  0.3  1          0.8               1.00       100      0.9387682  0.3127273  0.9981567
  0.3  1          0.8               1.00       150      0.9414289  0.3527273  0.9972393
  0.3  2          0.6               0.50        50      0.9411060  0.2763636  0.9963176
  0.3  2          0.6               0.50       100      0.9365912  0.3909091  0.9963176
  0.3  2          0.6               0.50       150      0.9277551  0.4290909  0.9944743
  0.3  2          0.6               0.75        50      0.9171535  0.2945455  0.9981567
  0.3  2          0.6               0.75       100      0.9339593  0.3727273  0.9953917
  0.3  2          0.6               0.75       150      0.9254499  0.3727273  0.9917093
  0.3  2          0.6               1.00        50      0.9368177  0.2545455  1.0000000
  0.3  2          0.6               1.00       100      0.9375840  0.3145455  0.9972393
  0.3  2          0.6               1.00       150      0.9315265  0.3345455  0.9972393
  0.3  2          0.8               0.50        50      0.9278928  0.2927273  0.9935526
  0.3  2          0.8               0.50       100      0.9220989  0.3909091  0.9926310
  0.3  2          0.8               0.50       150      0.9179309  0.4290909  0.9898660
  0.3  2          0.8               0.75        50      0.9360796  0.3327273  0.9953959
  0.3  2          0.8               0.75       100      0.9311020  0.4109091  0.9953959
  0.3  2          0.8               0.75       150      0.9282407  0.4309091  0.9935526
  0.3  2          0.8               1.00        50      0.9407898  0.3145455  1.0000000
  0.3  2          0.8               1.00       100      0.9416895  0.3327273  0.9972435
  0.3  2          0.8               1.00       150      0.9341508  0.3709091  0.9963176
  0.3  3          0.6               0.50        50      0.9102922  0.3727273  0.9944743
  0.3  3          0.6               0.50       100      0.9039998  0.3909091  0.9889443
  0.3  3          0.6               0.50       150      0.9071669  0.3709091  0.9898660
  0.3  3          0.6               0.75        50      0.9349061  0.2745455  0.9972350
  0.3  3          0.6               0.75       100      0.9274403  0.3345455  0.9953917
  0.3  3          0.6               0.75       150      0.9269119  0.3727273  0.9944743
  0.3  3          0.6               1.00        50      0.9416599  0.3327273  0.9990783
  0.3  3          0.6               1.00       100      0.9321923  0.3145455  0.9981567
  0.3  3          0.6               1.00       150      0.9339208  0.3145455  0.9963134
  0.3  3          0.8               0.50        50      0.9355698  0.3890909  0.9963176
  0.3  3          0.8               0.50       100      0.9259682  0.3890909  0.9907876
  0.3  3          0.8               0.50       150      0.9190274  0.3509091  0.9926310
  0.3  3          0.8               0.75        50      0.9395480  0.3727273  0.9963176
  0.3  3          0.8               0.75       100      0.9331276  0.4309091  0.9935526
  0.3  3          0.8               0.75       150      0.9283803  0.4309091  0.9926310
  0.3  3          0.8               1.00        50      0.9344283  0.3327273  0.9990783
  0.3  3          0.8               1.00       100      0.9319979  0.2927273  0.9981567
  0.3  3          0.8               1.00       150      0.9317029  0.3327273  0.9963134
  0.4  1          0.6               0.50        50      0.9202271  0.3127273  0.9963176
  0.4  1          0.6               0.50       100      0.9256611  0.3527273  0.9935526
  0.4  1          0.6               0.50       150      0.9222373  0.3727273  0.9880227
  0.4  1          0.6               0.75        50      0.9274358  0.3145455  0.9981567
  0.4  1          0.6               0.75       100      0.9323935  0.3727273  0.9944785
  0.4  1          0.6               0.75       150      0.9321056  0.4109091  0.9944785
  0.4  1          0.6               1.00        50      0.9376877  0.2945455  0.9990783
  0.4  1          0.6               1.00       100      0.9397473  0.3527273  0.9972393
  0.4  1          0.6               1.00       150      0.9433749  0.3727273  0.9972393
  0.4  1          0.8               0.50        50      0.8973953  0.3327273  0.9963134
  0.4  1          0.8               0.50       100      0.9101539  0.3890909  0.9926310
  0.4  1          0.8               0.50       150      0.9128722  0.4090909  0.9898660
  0.4  1          0.8               0.75        50      0.9284406  0.3145455  0.9972350
  0.4  1          0.8               0.75       100      0.9389492  0.3727273  0.9944743
  0.4  1          0.8               0.75       150      0.9391445  0.4109091  0.9953959
  0.4  1          0.8               1.00        50      0.9235915  0.2745455  1.0000000
  0.4  1          0.8               1.00       100      0.9342647  0.3127273  0.9972350
  0.4  1          0.8               1.00       150      0.9319991  0.3527273  0.9972350
  0.4  2          0.6               0.50        50      0.9337156  0.4309091  0.9907876
  0.4  2          0.6               0.50       100      0.9262690  0.3709091  0.9852577
  0.4  2          0.6               0.50       150      0.9127476  0.4109091  0.9871010
  0.4  2          0.6               0.75        50      0.9456534  0.3727273  0.9981609
  0.4  2          0.6               0.75       100      0.9305098  0.4109091  0.9926310
  0.4  2          0.6               0.75       150      0.9236036  0.3927273  0.9917093
  0.4  2          0.6               1.00        50      0.9319896  0.3327273  0.9981609
  0.4  2          0.6               1.00       100      0.9274503  0.3745455  0.9972393
  0.4  2          0.6               1.00       150      0.9213707  0.3927273  0.9953959
  0.4  2          0.8               0.50        50      0.9133157  0.4109091  0.9926310
  0.4  2          0.8               0.50       100      0.9182920  0.4509091  0.9898660
  0.4  2          0.8               0.50       150      0.9012422  0.4509091  0.9889443
  0.4  2          0.8               0.75        50      0.9238750  0.3327273  0.9963176
  0.4  2          0.8               0.75       100      0.9146449  0.4109091  0.9935526
  0.4  2          0.8               0.75       150      0.9074166  0.4109091  0.9926310
  0.4  2          0.8               1.00        50      0.9351752  0.3163636  0.9981609
  0.4  2          0.8               1.00       100      0.9360151  0.3927273  0.9981567
  0.4  2          0.8               1.00       150      0.9326024  0.4327273  0.9953959
  0.4  3          0.6               0.50        50      0.9161229  0.3872727  0.9944785
  0.4  3          0.6               0.50       100      0.9210144  0.4290909  0.9963218
  0.4  3          0.6               0.50       150      0.9208401  0.4309091  0.9953959
  0.4  3          0.6               0.75        50      0.9207937  0.3745455  0.9972350
  0.4  3          0.6               0.75       100      0.9094863  0.3945455  0.9963134
  0.4  3          0.6               0.75       150      0.9097528  0.4145455  0.9944700
  0.4  3          0.6               1.00        50      0.9343578  0.3527273  0.9981609
  0.4  3          0.6               1.00       100      0.9284209  0.3345455  0.9944743
  0.4  3          0.6               1.00       150      0.9250292  0.3345455  0.9963176
  0.4  3          0.8               0.50        50      0.9200020  0.3872727  0.9935568
  0.4  3          0.8               0.50       100      0.9146182  0.3690909  0.9907961
  0.4  3          0.8               0.50       150      0.9148568  0.4090909  0.9908045
  0.4  3          0.8               0.75        50      0.9245866  0.3909091  0.9953917
  0.4  3          0.8               0.75       100      0.9163867  0.3727273  0.9935526
  0.4  3          0.8               0.75       150      0.9151257  0.3727273  0.9944743
  0.4  3          0.8               1.00        50      0.9210353  0.3327273  0.9981567
  0.4  3          0.8               1.00       100      0.9160487  0.3327273  0.9953917
  0.4  3          0.8               1.00       150      0.9200771  0.3327273  0.9963134

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 2, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.7      0.2
  positive      2.8     95.3
                            
 Accuracy (average) : 0.9701

[1] "TRAIN accuracy: 0.97009674582234"
[1] "TRAIN +precision: 0.971326164874552"
[1] "TRAIN -precision: 0.904761904761905"
[1] "TRAIN specifity: 0.372549019607843"
[1] "TRAIN sensitivity: 0.998158379373849"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       11        3
            positive        7      358
[1] "TEST accuracy: 0.973614775725594"
[1] "TEST +precision: 0.980821917808219"
[1] "TEST -precision: 0.785714285714286"
[1] "TEST specifity: 0.611111111111111"
[1] "TEST sensitivity: 0.991689750692521"
