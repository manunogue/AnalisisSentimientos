[1] "DATASET NAME: HRB_Bi_IR_2"
[1] "TRAIN INSTANCES: 1345"
[1] "TEST INSTANCES: 332"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 4.79423499107361"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1345 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1075, 1076, 1076, 1076, 1077 
Resampling results:

  ROC        Sens       Spec     
  0.9782022  0.9397576  0.9551062

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.8      2.8
  positive      2.2     60.1
                            
 Accuracy (average) : 0.9494

[1] "TRAIN accuracy: 0.949442379182156"
[1] "TRAIN +precision: 0.964243146603099"
[1] "TRAIN -precision: 0.924901185770751"
[1] "TRAIN specifity: 0.939759036144578"
[1] "TRAIN sensitivity: 0.955135773317591"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       21       11
            positive       25      275
[1] "TEST accuracy: 0.891566265060241"
[1] "TEST +precision: 0.916666666666667"
[1] "TEST -precision: 0.65625"
[1] "TEST specifity: 0.456521739130435"
[1] "TEST sensitivity: 0.961538461538462"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.54128173589706"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1345 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1076, 1077, 1076, 1075, 1076 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7964229  0.5162020  0.9280265
  0.010  2  0.7497500  0.4540606  0.9386077
  0.010  3  0.7372986  0.4159596  0.9374661
  0.255  1  0.8763406  0.6525657  0.9456735
  0.255  2  0.8586852  0.5984040  0.9516046
  0.255  3  0.8383191  0.5522222  0.9539715
  0.500  1  0.8798442  0.6606263  0.9456735
  0.500  2  0.8721441  0.6124646  0.9575009
  0.500  3  0.8558234  0.5663636  0.9551410

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     24.5      3.4
  positive     12.6     59.6
                            
 Accuracy (average) : 0.8401

[1] "TRAIN accuracy: 0.840148698884758"
[1] "TRAIN +precision: 0.825773195876289"
[1] "TRAIN -precision: 0.877333333333333"
[1] "TRAIN specifity: 0.660642570281124"
[1] "TRAIN sensitivity: 0.9456906729634"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6       11
            positive       40      275
[1] "TEST accuracy: 0.846385542168675"
[1] "TEST +precision: 0.873015873015873"
[1] "TEST -precision: 0.352941176470588"
[1] "TEST specifity: 0.130434782608696"
[1] "TEST sensitivity: 0.961538461538462"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 5.85045521656672"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1345 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1076, 1077, 1076, 1076, 1075 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8313748  0.3692727  0.9775566
  0.3  1          0.6               0.50       100      0.9051801  0.5537980  0.9586634
  0.3  1          0.6               0.50       150      0.9268688  0.6684040  0.9456596
  0.3  1          0.6               0.75        50      0.8497912  0.3613131  0.9775566
  0.3  1          0.6               0.75       100      0.9072962  0.5578788  0.9645806
  0.3  1          0.6               0.75       150      0.9247345  0.6563434  0.9574869
  0.3  1          0.6               1.00        50      0.8392710  0.3331717  0.9834598
  0.3  1          0.6               1.00       100      0.9027767  0.5618990  0.9728368
  0.3  1          0.6               1.00       150      0.9295081  0.6141616  0.9669335
  0.3  1          0.8               0.50        50      0.8556902  0.3773535  0.9645667
  0.3  1          0.8               0.50       100      0.9030519  0.5577778  0.9551270
  0.3  1          0.8               0.50       150      0.9263240  0.6504040  0.9574939
  0.3  1          0.8               0.75        50      0.8502616  0.3071111  0.9822833
  0.3  1          0.8               0.75       100      0.9104145  0.5819596  0.9692865
  0.3  1          0.8               0.75       150      0.9333569  0.6402828  0.9633832
  0.3  1          0.8               1.00        50      0.8437331  0.3392323  0.9834528
  0.3  1          0.8               1.00       100      0.9039482  0.5518788  0.9692934
  0.3  1          0.8               1.00       150      0.9324315  0.6262222  0.9704769
  0.3  2          0.6               0.50        50      0.9022324  0.5276970  0.9633832
  0.3  2          0.6               0.50       100      0.9403155  0.7327879  0.9480334
  0.3  2          0.6               0.50       150      0.9478078  0.7970101  0.9468569
  0.3  2          0.6               0.75        50      0.9111075  0.5598788  0.9716533
  0.3  2          0.6               0.75       100      0.9428299  0.7206061  0.9598399
  0.3  2          0.6               0.75       150      0.9526567  0.7890101  0.9551270
  0.3  2          0.6               1.00        50      0.9053241  0.5979394  0.9716464
  0.3  2          0.6               1.00       100      0.9441265  0.6944646  0.9669335
  0.3  2          0.6               1.00       150      0.9525453  0.7708485  0.9645597
  0.3  2          0.8               0.50        50      0.9108774  0.5378384  0.9680891
  0.3  2          0.8               0.50       100      0.9401312  0.7206667  0.9633763
  0.3  2          0.8               0.50       150      0.9475038  0.7849697  0.9515698
  0.3  2          0.8               0.75        50      0.9116593  0.5599192  0.9692934
  0.3  2          0.8               0.75       100      0.9442492  0.7226263  0.9586634
  0.3  2          0.8               0.75       150      0.9522874  0.7830303  0.9610303
  0.3  2          0.8               1.00        50      0.9089757  0.5758788  0.9716533
  0.3  2          0.8               1.00       100      0.9443545  0.6803838  0.9681030
  0.3  2          0.8               1.00       150      0.9532585  0.7708687  0.9669266
  0.3  3          0.6               0.50        50      0.9305801  0.6522828  0.9586495
  0.3  3          0.6               0.50       100      0.9496434  0.7811313  0.9527741
  0.3  3          0.6               0.50       150      0.9573868  0.8212121  0.9492308
  0.3  3          0.6               0.75        50      0.9368257  0.6382424  0.9610164
  0.3  3          0.6               0.75       100      0.9534316  0.7708889  0.9551131
  0.3  3          0.6               0.75       150      0.9573312  0.8252323  0.9515907
  0.3  3          0.6               1.00        50      0.9271349  0.6502222  0.9681100
  0.3  3          0.6               1.00       100      0.9517903  0.7809495  0.9622207
  0.3  3          0.6               1.00       150      0.9571888  0.8191717  0.9574869
  0.3  3          0.8               0.50        50      0.9307369  0.6665253  0.9681170
  0.3  3          0.8               0.50       100      0.9515129  0.7909293  0.9515976
  0.3  3          0.8               0.50       150      0.9534895  0.8210909  0.9480613
  0.3  3          0.8               0.75        50      0.9331720  0.6562828  0.9622068
  0.3  3          0.8               0.75       100      0.9532539  0.7950303  0.9610094
  0.3  3          0.8               0.75       150      0.9582705  0.8231111  0.9515976
  0.3  3          0.8               1.00        50      0.9367546  0.6141212  0.9669335
  0.3  3          0.8               1.00       100      0.9535252  0.7808687  0.9633832
  0.3  3          0.8               1.00       150      0.9587917  0.8131515  0.9598399
  0.4  1          0.6               0.50        50      0.8631402  0.4675758  0.9728437
  0.4  1          0.6               0.50       100      0.9166545  0.6263232  0.9539575
  0.4  1          0.6               0.50       150      0.9351815  0.6985051  0.9492308
  0.4  1          0.6               0.75        50      0.8620853  0.4515152  0.9681239
  0.4  1          0.6               0.75       100      0.9175339  0.6363232  0.9586982
  0.4  1          0.6               0.75       150      0.9381978  0.7186869  0.9551340
  0.4  1          0.6               1.00        50      0.8648883  0.4454747  0.9740202
  0.4  1          0.6               1.00       100      0.9234422  0.6202020  0.9681100
  0.4  1          0.6               1.00       150      0.9406000  0.6944646  0.9681100
  0.4  1          0.8               0.50        50      0.8831627  0.4876970  0.9645736
  0.4  1          0.8               0.50       100      0.9201080  0.6321414  0.9491960
  0.4  1          0.8               0.50       150      0.9403442  0.7285657  0.9515907
  0.4  1          0.8               0.75        50      0.8602593  0.4396364  0.9693004
  0.4  1          0.8               0.75       100      0.9205061  0.6342222  0.9575009
  0.4  1          0.8               0.75       150      0.9403066  0.7347879  0.9527602
  0.4  1          0.8               1.00        50      0.8639299  0.4354545  0.9752036
  0.4  1          0.8               1.00       100      0.9183721  0.6182626  0.9657431
  0.4  1          0.8               1.00       150      0.9412142  0.7064444  0.9645597
  0.4  2          0.6               0.50        50      0.9213190  0.6342424  0.9563105
  0.4  2          0.6               0.50       100      0.9460748  0.7608889  0.9468709
  0.4  2          0.6               0.50       150      0.9520540  0.7970101  0.9433136
  0.4  2          0.6               0.75        50      0.9233860  0.6161818  0.9622068
  0.4  2          0.6               0.75       100      0.9505840  0.7648687  0.9551270
  0.4  2          0.6               0.75       150      0.9541220  0.8231717  0.9527741
  0.4  2          0.6               1.00        50      0.9248965  0.6060808  0.9669335
  0.4  2          0.6               1.00       100      0.9523153  0.7587475  0.9645458
  0.4  2          0.6               1.00       150      0.9566233  0.8090909  0.9598538
  0.4  2          0.8               0.50        50      0.9154817  0.6220606  0.9456874
  0.4  2          0.8               0.50       100      0.9464843  0.7769899  0.9516116
  0.4  2          0.8               0.50       150      0.9492983  0.8251515  0.9516046
  0.4  2          0.8               0.75        50      0.9221521  0.6121010  0.9657570
  0.4  2          0.8               0.75       100      0.9502185  0.7709293  0.9551410
  0.4  2          0.8               0.75       150      0.9575427  0.8151717  0.9504072
  0.4  2          0.8               1.00        50      0.9228287  0.6080606  0.9692795
  0.4  2          0.8               1.00       100      0.9520472  0.7689091  0.9680961
  0.4  2          0.8               1.00       150      0.9566203  0.8090707  0.9610303
  0.4  3          0.6               0.50        50      0.9354235  0.6804242  0.9586704
  0.4  3          0.6               0.50       100      0.9542520  0.8211515  0.9551479
  0.4  3          0.6               0.50       150      0.9538349  0.8392929  0.9551270
  0.4  3          0.6               0.75        50      0.9457235  0.7186465  0.9574661
  0.4  3          0.6               0.75       100      0.9556432  0.8151111  0.9563035
  0.4  3          0.6               0.75       150      0.9566655  0.8473333  0.9480613
  0.4  3          0.6               1.00        50      0.9437518  0.7044646  0.9657362
  0.4  3          0.6               1.00       100      0.9587888  0.8151515  0.9622068
  0.4  3          0.6               1.00       150      0.9623431  0.8432929  0.9551340
  0.4  3          0.8               0.50        50      0.9387493  0.7226667  0.9598260
  0.4  3          0.8               0.50       100      0.9525339  0.8232525  0.9562966
  0.4  3          0.8               0.50       150      0.9548114  0.8473333  0.9480473
  0.4  3          0.8               0.75        50      0.9423701  0.7206667  0.9622068
  0.4  3          0.8               0.75       100      0.9556727  0.8271717  0.9515837
  0.4  3          0.8               0.75       150      0.9596591  0.8473131  0.9539436
  0.4  3          0.8               1.00        50      0.9451720  0.7084444  0.9681030
  0.4  3          0.8               1.00       100      0.9562155  0.8110909  0.9621928
  0.4  3          0.8               1.00       150      0.9601061  0.8432929  0.9598399

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     31.2      2.8
  positive      5.8     60.1
                            
 Accuracy (average) : 0.9138

[1] "TRAIN accuracy: 0.913754646840149"
[1] "TRAIN +precision: 0.91206313416009"
[1] "TRAIN -precision: 0.91703056768559"
[1] "TRAIN specifity: 0.843373493975904"
[1] "TRAIN sensitivity: 0.955135773317591"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       18        9
            positive       28      277
[1] "TEST accuracy: 0.88855421686747"
[1] "TEST +precision: 0.908196721311475"
[1] "TEST -precision: 0.666666666666667"
[1] "TEST specifity: 0.391304347826087"
[1] "TEST sensitivity: 0.968531468531469"
