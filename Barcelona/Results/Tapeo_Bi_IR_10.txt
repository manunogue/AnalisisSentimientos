[1] "DATASET NAME: Tapeo_Bi_IR_10"
[1] "TRAIN INSTANCES: 1088"
[1] "TEST INSTANCES: 333"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.72345805168152"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1088 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 870, 870, 870, 871, 871 
Resampling results:

  ROC        Sens       Spec     
  0.9954776  0.9766154  0.9916612

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.6      0.7
  positive      0.3     87.4
                            
 Accuracy (average) : 0.9899

[1] "TRAIN accuracy: 0.989889705882353"
[1] "TRAIN +precision: 0.99685534591195"
[1] "TRAIN -precision: 0.940298507462687"
[1] "TRAIN specifity: 0.976744186046511"
[1] "TRAIN sensitivity: 0.991657977059437"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        3
            positive        8      321
[1] "TEST accuracy: 0.966966966966967"
[1] "TEST +precision: 0.975683890577508"
[1] "TEST -precision: 0.25"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.990740740740741"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.44652833541234"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1088 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 870, 870, 871, 871, 870 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.5074792  0.0080000  0.9989583
  0.010  2  0.5000000  0.0000000  1.0000000
  0.010  3  0.5000000  0.0000000  1.0000000
  0.255  1  0.6854651  0.2172308  0.9979167
  0.255  2  0.6613242  0.1861538  0.9989583
  0.255  3  0.6369951  0.1470769  0.9989583
  0.500  1  0.7172185  0.2326154  0.9979167
  0.500  2  0.6946817  0.2015385  0.9989583
  0.500  3  0.6904566  0.1704615  0.9989583

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      2.8      0.2
  positive      9.1     88.0
                            
 Accuracy (average) : 0.9072

[1] "TRAIN accuracy: 0.907169117647059"
[1] "TRAIN +precision: 0.90625"
[1] "TRAIN -precision: 0.9375"
[1] "TRAIN specifity: 0.232558139534884"
[1] "TRAIN sensitivity: 0.997914494264859"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        9      324
[1] "TEST accuracy: 0.972972972972973"
[1] "TEST +precision: 0.972972972972973"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.65776251554489"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1088 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 871, 871, 870, 870, 870 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8112298  0.1701538  0.9979167
  0.3  1          0.6               0.50       100      0.8639917  0.2793846  0.9916612
  0.3  1          0.6               0.50       150      0.8930084  0.3640000  0.9885253
  0.3  1          0.6               0.75        50      0.8828166  0.2393846  0.9968750
  0.3  1          0.6               0.75       100      0.9149364  0.4418462  0.9937445
  0.3  1          0.6               0.75       150      0.9310069  0.5267692  0.9937391
  0.3  1          0.6               1.00        50      0.8740914  0.2473846  0.9968750
  0.3  1          0.6               1.00       100      0.9158835  0.3643077  0.9958333
  0.3  1          0.6               1.00       150      0.9397583  0.4806154  0.9937391
  0.3  1          0.8               0.50        50      0.8222001  0.1701538  0.9958279
  0.3  1          0.8               0.50       100      0.8756365  0.3104615  0.9916503
  0.3  1          0.8               0.50       150      0.8912291  0.3880000  0.9906086
  0.3  1          0.8               0.75        50      0.8752477  0.2864615  0.9958333
  0.3  1          0.8               0.75       100      0.9123126  0.4107692  0.9916558
  0.3  1          0.8               0.75       150      0.9332805  0.5501538  0.9906086
  0.3  1          0.8               1.00        50      0.8775278  0.2396923  0.9968750
  0.3  1          0.8               1.00       100      0.9207030  0.3873846  0.9958333
  0.3  1          0.8               1.00       150      0.9414476  0.4652308  0.9937391
  0.3  2          0.6               0.50        50      0.8765765  0.2784615  0.9916503
  0.3  2          0.6               0.50       100      0.9062909  0.3556923  0.9874836
  0.3  2          0.6               0.50       150      0.9159834  0.4335385  0.9885253
  0.3  2          0.6               0.75        50      0.9005452  0.3729231  0.9937445
  0.3  2          0.6               0.75       100      0.9362710  0.5347692  0.9916503
  0.3  2          0.6               0.75       150      0.9394693  0.5581538  0.9885308
  0.3  2          0.6               1.00        50      0.9222650  0.4184615  0.9958333
  0.3  2          0.6               1.00       100      0.9512134  0.6430769  0.9937391
  0.3  2          0.6               1.00       150      0.9571259  0.6590769  0.9906141
  0.3  2          0.8               0.50        50      0.8762377  0.3261538  0.9927029
  0.3  2          0.8               0.50       100      0.9074652  0.4572308  0.9885308
  0.3  2          0.8               0.50       150      0.9188436  0.4726154  0.9906195
  0.3  2          0.8               0.75        50      0.9034761  0.4184615  0.9927029
  0.3  2          0.8               0.75       100      0.9210328  0.5726154  0.9906141
  0.3  2          0.8               0.75       150      0.9334914  0.6110769  0.9874836
  0.3  2          0.8               1.00        50      0.9164717  0.4412308  0.9958333
  0.3  2          0.8               1.00       100      0.9456081  0.6046154  0.9937391
  0.3  2          0.8               1.00       150      0.9545638  0.6590769  0.9906086
  0.3  3          0.6               0.50        50      0.9063151  0.3726154  0.9906086
  0.3  3          0.6               0.50       100      0.9144838  0.4655385  0.9874782
  0.3  3          0.6               0.50       150      0.9273289  0.5276923  0.9895670
  0.3  3          0.6               0.75        50      0.9386049  0.5809231  0.9916503
  0.3  3          0.6               0.75       100      0.9500555  0.6898462  0.9916503
  0.3  3          0.6               0.75       150      0.9505844  0.7058462  0.9926974
  0.3  3          0.6               1.00        50      0.9472676  0.5424615  0.9958279
  0.3  3          0.6               1.00       100      0.9595903  0.6747692  0.9947862
  0.3  3          0.6               1.00       150      0.9616182  0.7212308  0.9926974
  0.3  3          0.8               0.50        50      0.9093599  0.4341538  0.9895670
  0.3  3          0.8               0.50       100      0.9145593  0.5193846  0.9874891
  0.3  3          0.8               0.50       150      0.9183626  0.5507692  0.9906195
  0.3  3          0.8               0.75        50      0.9328916  0.5507692  0.9916558
  0.3  3          0.8               0.75       100      0.9438084  0.6513846  0.9885253
  0.3  3          0.8               0.75       150      0.9498629  0.6904615  0.9885308
  0.3  3          0.8               1.00        50      0.9461499  0.5504615  0.9947808
  0.3  3          0.8               1.00       100      0.9568540  0.6747692  0.9937445
  0.3  3          0.8               1.00       150      0.9583212  0.7292308  0.9906195
  0.4  1          0.6               0.50        50      0.8463831  0.2393846  0.9927029
  0.4  1          0.6               0.50       100      0.8982273  0.3720000  0.9916558
  0.4  1          0.6               0.50       150      0.9088878  0.4578462  0.9916612
  0.4  1          0.6               0.75        50      0.8866532  0.3412308  0.9968750
  0.4  1          0.6               0.75       100      0.9122494  0.4412308  0.9926974
  0.4  1          0.6               0.75       150      0.9271381  0.5421538  0.9916558
  0.4  1          0.6               1.00        50      0.8918110  0.3015385  0.9968750
  0.4  1          0.6               1.00       100      0.9239151  0.4504615  0.9958333
  0.4  1          0.6               1.00       150      0.9435266  0.5584615  0.9947808
  0.4  1          0.8               0.50        50      0.8457087  0.2323077  0.9926974
  0.4  1          0.8               0.50       100      0.8919310  0.3873846  0.9895724
  0.4  1          0.8               0.50       150      0.9126951  0.4652308  0.9895724
  0.4  1          0.8               0.75        50      0.8849661  0.2787692  0.9937500
  0.4  1          0.8               0.75       100      0.9195111  0.4729231  0.9937445
  0.4  1          0.8               0.75       150      0.9324693  0.5427692  0.9916558
  0.4  1          0.8               1.00        50      0.8855953  0.3101538  0.9968750
  0.4  1          0.8               1.00       100      0.9261515  0.4341538  0.9937391
  0.4  1          0.8               1.00       150      0.9466767  0.5196923  0.9947808
  0.4  2          0.6               0.50        50      0.8831407  0.3252308  0.9916558
  0.4  2          0.6               0.50       100      0.9053749  0.4255385  0.9885253
  0.4  2          0.6               0.50       150      0.9110664  0.4803077  0.9895724
  0.4  2          0.6               0.75        50      0.9108960  0.4572308  0.9937445
  0.4  2          0.6               0.75       100      0.9400329  0.6046154  0.9916558
  0.4  2          0.6               0.75       150      0.9426858  0.6818462  0.9895670
  0.4  2          0.6               1.00        50      0.9225219  0.4963077  0.9937391
  0.4  2          0.6               1.00       100      0.9507953  0.5972308  0.9926974
  0.4  2          0.6               1.00       150      0.9502071  0.6676923  0.9916503
  0.4  2          0.8               0.50        50      0.8928940  0.4110769  0.9947917
  0.4  2          0.8               0.50       100      0.9160642  0.5033846  0.9906195
  0.4  2          0.8               0.50       150      0.9222462  0.5430769  0.9916612
  0.4  2          0.8               0.75        50      0.9249368  0.5347692  0.9937391
  0.4  2          0.8               0.75       100      0.9459857  0.6203077  0.9895670
  0.4  2          0.8               0.75       150      0.9496398  0.6981538  0.9906141
  0.4  2          0.8               1.00        50      0.9264896  0.4809231  0.9926974
  0.4  2          0.8               1.00       100      0.9511143  0.5892308  0.9906141
  0.4  2          0.8               1.00       150      0.9483623  0.6593846  0.9916612
  0.4  3          0.6               0.50        50      0.9100812  0.4181538  0.9916612
  0.4  3          0.6               0.50       100      0.9216276  0.5181538  0.9874836
  0.4  3          0.6               0.50       150      0.9239769  0.5569231  0.9874891
  0.4  3          0.6               0.75        50      0.9370480  0.5975385  0.9937391
  0.4  3          0.6               0.75       100      0.9448011  0.6824615  0.9926974
  0.4  3          0.6               0.75       150      0.9466288  0.6978462  0.9916558
  0.4  3          0.6               1.00        50      0.9498829  0.6436923  0.9926974
  0.4  3          0.6               1.00       100      0.9550682  0.7292308  0.9927029
  0.4  3          0.6               1.00       150      0.9567781  0.7292308  0.9916558
  0.4  3          0.8               0.50        50      0.9157806  0.5190769  0.9906086
  0.4  3          0.8               0.50       100      0.9307146  0.6190769  0.9916558
  0.4  3          0.8               0.50       150      0.9339151  0.6267692  0.9885253
  0.4  3          0.8               0.75        50      0.9334042  0.5578462  0.9906141
  0.4  3          0.8               0.75       100      0.9413738  0.6815385  0.9874836
  0.4  3          0.8               0.75       150      0.9431921  0.7046154  0.9874891
  0.4  3          0.8               1.00        50      0.9460069  0.6123077  0.9937391
  0.4  3          0.8               1.00       100      0.9553617  0.7138462  0.9885253
  0.4  3          0.8               1.00       150      0.9562963  0.7372308  0.9885253

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      8.5      0.6
  positive      3.3     87.5
                            
 Accuracy (average) : 0.9605

[1] "TRAIN accuracy: 0.960477941176471"
[1] "TRAIN +precision: 0.963562753036437"
[1] "TRAIN -precision: 0.93"
[1] "TRAIN specifity: 0.720930232558139"
[1] "TRAIN sensitivity: 0.992700729927007"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        1
            positive        7      323
[1] "TEST accuracy: 0.975975975975976"
[1] "TEST +precision: 0.978787878787879"
[1] "TEST -precision: 0.666666666666667"
[1] "TEST specifity: 0.222222222222222"
[1] "TEST sensitivity: 0.996913580246914"
