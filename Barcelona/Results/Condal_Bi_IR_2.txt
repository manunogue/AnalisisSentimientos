[1] "DATASET NAME: Condal_Bi_IR_2"
[1] "TRAIN INSTANCES: 3471"
[1] "TEST INSTANCES: 795"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 15.9205801486969"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

3471 samples
 720 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2776, 2777, 2776, 2777, 2778 
Resampling results:

  ROC        Sens      Spec    
  0.9957163  0.983239  0.984199

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.8      1.0
  positive      0.6     64.6
                            
 Accuracy (average) : 0.9839

[1] "TRAIN accuracy: 0.983866320944973"
[1] "TRAIN +precision: 0.991158267020336"
[1] "TRAIN -precision: 0.970223325062035"
[1] "TRAIN specifity: 0.983235540653814"
[1] "TRAIN sensitivity: 0.984196663740123"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       16        9
            positive       30      740
[1] "TEST accuracy: 0.950943396226415"
[1] "TEST +precision: 0.961038961038961"
[1] "TEST -precision: 0.64"
[1] "TEST specifity: 0.347826086956522"
[1] "TEST sensitivity: 0.987983978638184"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 12.3455643494924"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

3471 samples
 720 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2776, 2777, 2777, 2777, 2777 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9386067  0.8013959  0.9697166
  0.010  2  0.9394922  0.8013959  0.9697166
  0.010  3  0.9422597  0.8013959  0.9784933
  0.255  1  0.9468499  0.8122956  0.9741026
  0.255  2  0.9491969  0.8122956  0.9741016
  0.255  3  0.9501674  0.8114553  0.9771737
  0.500  1  0.9540799  0.8173236  0.9749807
  0.500  2  0.9559728  0.8156429  0.9758579
  0.500  3  0.9575951  0.8114553  0.9802468

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     27.9      1.3
  positive      6.5     64.3
                            
 Accuracy (average) : 0.9222

[1] "TRAIN accuracy: 0.922212618841832"
[1] "TRAIN +precision: 0.908462164361269"
[1] "TRAIN -precision: 0.955577492596249"
[1] "TRAIN specifity: 0.811399832355407"
[1] "TRAIN sensitivity: 0.980245829675154"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       11       14
            positive       35      735
[1] "TEST accuracy: 0.938364779874214"
[1] "TEST +precision: 0.954545454545455"
[1] "TEST -precision: 0.44"
[1] "TEST specifity: 0.239130434782609"
[1] "TEST sensitivity: 0.981308411214953"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 20.2510919332504"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

3471 samples
 720 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2776, 2777, 2776, 2778, 2777 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8927630  0.4324778  0.9846347
  0.3  1          0.6               0.50       100      0.9396339  0.6546746  0.9793715
  0.3  1          0.6               0.50       150      0.9680235  0.7099821  0.9758570
  0.3  1          0.6               0.75        50      0.8965737  0.4266376  0.9868325
  0.3  1          0.6               0.75       100      0.9459288  0.6722619  0.9811288
  0.3  1          0.6               0.75       150      0.9674710  0.7468584  0.9784953
  0.3  1          0.6               1.00        50      0.8982479  0.4392251  0.9907837
  0.3  1          0.6               1.00       100      0.9391331  0.6739144  0.9820050
  0.3  1          0.6               1.00       150      0.9633818  0.7309166  0.9806912
  0.3  1          0.8               0.50        50      0.8977292  0.4249815  0.9881473
  0.3  1          0.8               0.50       100      0.9455478  0.6621743  0.9767361
  0.3  1          0.8               0.50       150      0.9679598  0.7284343  0.9732302
  0.3  1          0.8               0.75        50      0.9032618  0.4492669  0.9903451
  0.3  1          0.8               0.75       100      0.9468469  0.6562990  0.9824426
  0.3  1          0.8               0.75       150      0.9674508  0.7351289  0.9754203
  0.3  1          0.8               1.00        50      0.8996669  0.4534440  0.9899055
  0.3  1          0.8               1.00       100      0.9415758  0.6571534  0.9837613
  0.3  1          0.8               1.00       150      0.9633769  0.7359481  0.9811297
  0.3  2          0.6               0.50        50      0.9494034  0.6647129  0.9784962
  0.3  2          0.6               0.50       100      0.9773473  0.7996695  0.9758570
  0.3  2          0.6               0.50       150      0.9862228  0.8818185  0.9719057
  0.3  2          0.6               0.75        50      0.9489196  0.6638796  0.9837594
  0.3  2          0.6               0.75       100      0.9799266  0.8247952  0.9820050
  0.3  2          0.6               0.75       150      0.9880576  0.8918674  0.9793696
  0.3  2          0.6               1.00        50      0.9535675  0.6529693  0.9863958
  0.3  2          0.6               1.00       100      0.9818221  0.8265005  0.9863948
  0.3  2          0.6               1.00       150      0.9889195  0.8818326  0.9846385
  0.3  2          0.8               0.50        50      0.9499414  0.6873633  0.9815645
  0.3  2          0.8               0.50       100      0.9804018  0.8021624  0.9784885
  0.3  2          0.8               0.50       150      0.9876846  0.9077775  0.9727800
  0.3  2          0.8               0.75        50      0.9517048  0.6705707  0.9820069
  0.3  2          0.8               0.75       100      0.9799525  0.8457930  0.9806834
  0.3  2          0.8               0.75       150      0.9896401  0.9036004  0.9811249
  0.3  2          0.8               1.00        50      0.9500566  0.6630358  0.9841990
  0.3  2          0.8               1.00       100      0.9817687  0.8365740  0.9855167
  0.3  2          0.8               1.00       150      0.9895269  0.8826483  0.9841970
  0.3  3          0.6               0.50        50      0.9710634  0.7485039  0.9811259
  0.3  3          0.6               0.50       100      0.9884758  0.9002567  0.9745441
  0.3  3          0.6               0.50       150      0.9917639  0.9421364  0.9732186
  0.3  3          0.6               0.75        50      0.9751069  0.8046869  0.9841990
  0.3  3          0.6               0.75       100      0.9914240  0.8969199  0.9820050
  0.3  3          0.6               0.75       150      0.9939442  0.9438205  0.9833208
  0.3  3          0.6               1.00        50      0.9770156  0.7753419  0.9837623
  0.3  3          0.6               1.00       100      0.9914854  0.8952393  0.9850742
  0.3  3          0.6               1.00       150      0.9944046  0.9387891  0.9841961
  0.3  3          0.8               0.50        50      0.9740755  0.7727893  0.9789368
  0.3  3          0.8               0.50       100      0.9896251  0.9035864  0.9798091
  0.3  3          0.8               0.50       150      0.9924757  0.9471854  0.9762946
  0.3  3          0.8               0.75        50      0.9790208  0.7904328  0.9833218
  0.3  3          0.8               0.75       100      0.9903479  0.9102774  0.9798082
  0.3  3          0.8               0.75       150      0.9938342  0.9597447  0.9820012
  0.3  3          0.8               1.00        50      0.9767418  0.7921240  0.9846395
  0.3  3          0.8               1.00       100      0.9917899  0.8985514  0.9837594
  0.3  3          0.8               1.00       150      0.9946577  0.9463134  0.9837584
  0.4  1          0.6               0.50        50      0.9095107  0.6085897  0.9771843
  0.4  1          0.6               0.50       100      0.9586775  0.6999508  0.9705880
  0.4  1          0.6               0.50       150      0.9736902  0.8030308  0.9714691
  0.4  1          0.6               0.75        50      0.9137525  0.6328434  0.9820060
  0.4  1          0.6               0.75       100      0.9583133  0.6940684  0.9780596
  0.4  1          0.6               0.75       150      0.9707697  0.7988116  0.9727906
  0.4  1          0.6               1.00        50      0.9171245  0.6068704  0.9846404
  0.4  1          0.6               1.00       100      0.9564782  0.6882036  0.9798120
  0.4  1          0.6               1.00       150      0.9713822  0.7912239  0.9771785
  0.4  1          0.8               0.50        50      0.9125615  0.5883724  0.9784933
  0.4  1          0.8               0.50       100      0.9645787  0.7041067  0.9727858
  0.4  1          0.8               0.50       150      0.9730777  0.8022221  0.9723472
  0.4  1          0.8               0.75        50      0.9143270  0.6554798  0.9789368
  0.4  1          0.8               0.75       100      0.9588765  0.7058296  0.9780548
  0.4  1          0.8               0.75       150      0.9752092  0.8013466  0.9692828
  0.4  1          0.8               1.00        50      0.9171412  0.6068317  0.9842028
  0.4  1          0.8               1.00       100      0.9562606  0.7007806  0.9780528
  0.4  1          0.8               1.00       150      0.9740876  0.7912345  0.9776171
  0.4  2          0.6               0.50        50      0.9581248  0.6864878  0.9688336
  0.4  2          0.6               0.50       100      0.9852134  0.8742695  0.9732206
  0.4  2          0.6               0.50       150      0.9898364  0.9480046  0.9701494
  0.4  2          0.6               0.75        50      0.9652762  0.6999051  0.9811259
  0.4  2          0.6               0.75       100      0.9859280  0.8675539  0.9780519
  0.4  2          0.6               0.75       150      0.9913141  0.9254035  0.9771737
  0.4  2          0.6               1.00        50      0.9679667  0.7225484  0.9855186
  0.4  2          0.6               1.00       100      0.9878059  0.8826413  0.9824436
  0.4  2          0.6               1.00       150      0.9927353  0.9220175  0.9833189
  0.4  2          0.8               0.50        50      0.9653787  0.6923807  0.9784943
  0.4  2          0.8               0.50       100      0.9861216  0.8818115  0.9714681
  0.4  2          0.8               0.50       150      0.9905559  0.9471678  0.9723434
  0.4  2          0.8               0.75        50      0.9670977  0.7326149  0.9780586
  0.4  2          0.8               0.75       100      0.9864419  0.8859850  0.9780538
  0.4  2          0.8               0.75       150      0.9910118  0.9379593  0.9789300
  0.4  2          0.8               1.00        50      0.9651303  0.7217433  0.9842019
  0.4  2          0.8               1.00       100      0.9882760  0.8717556  0.9833179
  0.4  2          0.8               1.00       150      0.9930871  0.9312577  0.9846366
  0.4  3          0.6               0.50        50      0.9802221  0.8340319  0.9758598
  0.4  3          0.6               0.50       100      0.9913440  0.9337576  0.9754174
  0.4  3          0.6               0.50       150      0.9935712  0.9706515  0.9740997
  0.4  3          0.6               0.75        50      0.9820369  0.8482859  0.9815655
  0.4  3          0.6               0.75       100      0.9930206  0.9304209  0.9828803
  0.4  3          0.6               0.75       150      0.9947087  0.9689709  0.9793657
  0.4  3          0.6               1.00        50      0.9839366  0.8407405  0.9833189
  0.4  3          0.6               1.00       100      0.9936527  0.9287297  0.9850742
  0.4  3          0.6               1.00       150      0.9955523  0.9681270  0.9824407
  0.4  3          0.8               0.50        50      0.9783827  0.8264618  0.9754203
  0.4  3          0.8               0.50       100      0.9910451  0.9396259  0.9767341
  0.4  3          0.8               0.50       150      0.9930351  0.9731620  0.9780490
  0.4  3          0.8               0.75        50      0.9833396  0.8642277  0.9828822
  0.4  3          0.8               0.75       100      0.9932283  0.9412995  0.9811288
  0.4  3          0.8               0.75       150      0.9944438  0.9689603  0.9802448
  0.4  3          0.8               1.00        50      0.9846024  0.8306916  0.9863968
  0.4  3          0.8               1.00       100      0.9942690  0.9454801  0.9833208
  0.4  3          0.8               1.00       150      0.9959020  0.9706480  0.9833208

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.4      1.1
  positive      1.0     64.5
                           
 Accuracy (average) : 0.979

[1] "TRAIN accuracy: 0.978968596946125"
[1] "TRAIN +precision: 0.984615384615385"
[1] "TRAIN -precision: 0.968227424749164"
[1] "TRAIN specifity: 0.970662196144174"
[1] "TRAIN sensitivity: 0.983318700614574"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       19       11
            positive       27      738
[1] "TEST accuracy: 0.952201257861635"
[1] "TEST +precision: 0.964705882352941"
[1] "TEST -precision: 0.633333333333333"
[1] "TEST specifity: 0.41304347826087"
[1] "TEST sensitivity: 0.985313751668892"
