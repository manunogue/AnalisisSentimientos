[1] "DATASET NAME: Teresa_Uni_IR_10"
[1] "TRAIN INSTANCES: 1241"
[1] "TEST INSTANCES: 379"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.80171680450439"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1241 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 993, 992, 993, 993, 993 
Resampling results:

  ROC        Sens       Spec     
  0.9909023  0.9225806  0.9935526

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.5      0.6
  positive      1.0     86.9
                            
 Accuracy (average) : 0.9847

[1] "TRAIN accuracy: 0.984689766317486"
[1] "TRAIN +precision: 0.989000916590284"
[1] "TRAIN -precision: 0.953333333333333"
[1] "TRAIN specifity: 0.92258064516129"
[1] "TRAIN sensitivity: 0.993554327808471"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       10        2
            positive        8      359
[1] "TEST accuracy: 0.973614775725594"
[1] "TEST +precision: 0.978201634877384"
[1] "TEST -precision: 0.833333333333333"
[1] "TEST specifity: 0.555555555555556"
[1] "TEST sensitivity: 0.994459833795014"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.77930573622386"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1241 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 992, 993, 993, 993, 993 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8562262  0.7032258  0.9834186
  0.010  2  0.8491367  0.6774194  0.9834228
  0.010  3  0.8374266  0.6516129  0.9825054
  0.255  1  0.9366267  0.8516129  0.9815753
  0.255  2  0.9424546  0.8322581  0.9815795
  0.255  3  0.9407155  0.8193548  0.9778929
  0.500  1  0.9607777  0.8967742  0.9815753
  0.500  2  0.9668581  0.8774194  0.9825012
  0.500  3  0.9433036  0.8258065  0.9788145

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.0      1.5
  positive      1.5     86.0
                            
 Accuracy (average) : 0.9694

[1] "TRAIN accuracy: 0.969379532634972"
[1] "TRAIN +precision: 0.982504604051565"
[1] "TRAIN -precision: 0.87741935483871"
[1] "TRAIN specifity: 0.87741935483871"
[1] "TRAIN sensitivity: 0.982504604051565"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        7        5
            positive       11      356
[1] "TEST accuracy: 0.95778364116095"
[1] "TEST +precision: 0.970027247956403"
[1] "TEST -precision: 0.583333333333333"
[1] "TEST specifity: 0.388888888888889"
[1] "TEST sensitivity: 0.986149584487535"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.77883878151576"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1241 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 993, 993, 992, 993, 993 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9724022  0.5677419  0.9953917
  0.3  1          0.6               0.50       100      0.9874999  0.8000000  0.9935484
  0.3  1          0.6               0.50       150      0.9916354  0.8516129  0.9898618
  0.3  1          0.6               0.75        50      0.9737485  0.6258065  0.9963134
  0.3  1          0.6               0.75       100      0.9908141  0.7935484  0.9917051
  0.3  1          0.6               0.75       150      0.9953983  0.8645161  0.9917051
  0.3  1          0.6               1.00        50      0.9763844  0.5806452  0.9972350
  0.3  1          0.6               1.00       100      0.9890199  0.7741935  0.9935526
  0.3  1          0.6               1.00       150      0.9939409  0.8193548  0.9907876
  0.3  1          0.8               0.50        50      0.9786657  0.6064516  0.9944700
  0.3  1          0.8               0.50       100      0.9902451  0.7806452  0.9907834
  0.3  1          0.8               0.50       150      0.9947453  0.8516129  0.9898618
  0.3  1          0.8               0.75        50      0.9753978  0.6193548  0.9917051
  0.3  1          0.8               0.75       100      0.9902308  0.8000000  0.9917051
  0.3  1          0.8               0.75       150      0.9939740  0.8451613  0.9889401
  0.3  1          0.8               1.00        50      0.9767395  0.5806452  0.9972350
  0.3  1          0.8               1.00       100      0.9898478  0.7741935  0.9944700
  0.3  1          0.8               1.00       150      0.9941487  0.8387097  0.9926267
  0.3  2          0.6               0.50        50      0.9918151  0.8064516  0.9972350
  0.3  2          0.6               0.50       100      0.9950803  0.9419355  0.9907834
  0.3  2          0.6               0.50       150      0.9961142  0.9677419  0.9880184
  0.3  2          0.6               0.75        50      0.9909212  0.8129032  0.9944700
  0.3  2          0.6               0.75       100      0.9971792  0.9290323  0.9935484
  0.3  2          0.6               0.75       150      0.9979199  0.9806452  0.9944700
  0.3  2          0.6               1.00        50      0.9949659  0.8129032  0.9953917
  0.3  2          0.6               1.00       100      0.9982775  0.9483871  0.9926267
  0.3  2          0.6               1.00       150      0.9988119  0.9677419  0.9926267
  0.3  2          0.8               0.50        50      0.9938147  0.8258065  0.9935526
  0.3  2          0.8               0.50       100      0.9974482  0.8967742  0.9944700
  0.3  2          0.8               0.50       150      0.9979205  0.9677419  0.9898660
  0.3  2          0.8               0.75        50      0.9949497  0.8129032  0.9917093
  0.3  2          0.8               0.75       100      0.9976833  0.9483871  0.9935526
  0.3  2          0.8               0.75       150      0.9979191  0.9806452  0.9898660
  0.3  2          0.8               1.00        50      0.9950839  0.8322581  0.9963134
  0.3  2          0.8               1.00       100      0.9981294  0.9483871  0.9926310
  0.3  2          0.8               1.00       150      0.9987518  0.9548387  0.9926310
  0.3  3          0.6               0.50        50      0.9953688  0.9032258  0.9898618
  0.3  3          0.6               0.50       100      0.9964383  0.9677419  0.9871052
  0.3  3          0.6               0.50       150      0.9975046  0.9806452  0.9880269
  0.3  3          0.6               0.75        50      0.9972672  0.8967742  0.9935484
  0.3  3          0.6               0.75       100      0.9985737  0.9612903  0.9889443
  0.3  3          0.6               0.75       150      0.9989597  0.9741935  0.9871010
  0.3  3          0.6               1.00        50      0.9977421  0.9032258  0.9935484
  0.3  3          0.6               1.00       100      0.9989297  0.9741935  0.9926267
  0.3  3          0.6               1.00       150      0.9989594  0.9870968  0.9917051
  0.3  3          0.8               0.50        50      0.9948651  0.8580645  0.9953917
  0.3  3          0.8               0.50       100      0.9973572  0.9548387  0.9917093
  0.3  3          0.8               0.50       150      0.9971187  0.9741935  0.9907876
  0.3  3          0.8               0.75        50      0.9983362  0.9032258  0.9944700
  0.3  3          0.8               0.75       100      0.9985145  0.9741935  0.9935526
  0.3  3          0.8               0.75       150      0.9987516  0.9741935  0.9926310
  0.3  3          0.8               1.00        50      0.9982472  0.9161290  0.9963134
  0.3  3          0.8               1.00       100      0.9991083  0.9741935  0.9935526
  0.3  3          0.8               1.00       150      0.9989297  0.9870968  0.9907876
  0.4  1          0.6               0.50        50      0.9824281  0.6838710  0.9907834
  0.4  1          0.6               0.50       100      0.9929935  0.8193548  0.9926267
  0.4  1          0.6               0.50       150      0.9958433  0.9032258  0.9907834
  0.4  1          0.6               0.75        50      0.9811698  0.6645161  0.9907876
  0.4  1          0.6               0.75       100      0.9920029  0.8516129  0.9907834
  0.4  1          0.6               0.75       150      0.9957552  0.9161290  0.9917051
  0.4  1          0.6               1.00        50      0.9838783  0.6967742  0.9944700
  0.4  1          0.6               1.00       100      0.9927534  0.8193548  0.9907834
  0.4  1          0.6               1.00       150      0.9956624  0.8645161  0.9880184
  0.4  1          0.8               0.50        50      0.9826523  0.6645161  0.9898618
  0.4  1          0.8               0.50       100      0.9933195  0.8516129  0.9898618
  0.4  1          0.8               0.50       150      0.9942974  0.9032258  0.9861751
  0.4  1          0.8               0.75        50      0.9854935  0.7032258  0.9926267
  0.4  1          0.8               0.75       100      0.9933475  0.8387097  0.9907834
  0.4  1          0.8               0.75       150      0.9967937  0.9161290  0.9898618
  0.4  1          0.8               1.00        50      0.9832544  0.6516129  0.9944700
  0.4  1          0.8               1.00       100      0.9924288  0.8129032  0.9917051
  0.4  1          0.8               1.00       150      0.9955140  0.8580645  0.9898618
  0.4  2          0.6               0.50        50      0.9950115  0.8193548  0.9898660
  0.4  2          0.6               0.50       100      0.9961415  0.9419355  0.9926310
  0.4  2          0.6               0.50       150      0.9962311  0.9677419  0.9907876
  0.4  2          0.6               0.75        50      0.9957848  0.8709677  0.9898618
  0.4  2          0.6               0.75       100      0.9983370  0.9483871  0.9907834
  0.4  2          0.6               0.75       150      0.9983359  0.9741935  0.9880227
  0.4  2          0.6               1.00        50      0.9961231  0.8645161  0.9935484
  0.4  2          0.6               1.00       100      0.9981870  0.9612903  0.9926310
  0.4  2          0.6               1.00       150      0.9985137  0.9806452  0.9907876
  0.4  2          0.8               0.50        50      0.9942707  0.8580645  0.9889401
  0.4  2          0.8               0.50       100      0.9961995  0.9483871  0.9871010
  0.4  2          0.8               0.50       150      0.9968821  0.9741935  0.9871010
  0.4  2          0.8               0.75        50      0.9966729  0.8838710  0.9907876
  0.4  2          0.8               0.75       100      0.9983364  0.9741935  0.9898660
  0.4  2          0.8               0.75       150      0.9983060  0.9806452  0.9898660
  0.4  2          0.8               1.00        50      0.9963312  0.8903226  0.9935484
  0.4  2          0.8               1.00       100      0.9985437  0.9483871  0.9935484
  0.4  2          0.8               1.00       150      0.9987516  0.9741935  0.9898660
  0.4  3          0.6               0.50        50      0.9972702  0.9032258  0.9944700
  0.4  3          0.6               0.50       100      0.9980705  0.9677419  0.9944700
  0.4  3          0.6               0.50       150      0.9981578  0.9677419  0.9898702
  0.4  3          0.6               0.75        50      0.9989913  0.9483871  0.9972350
  0.4  3          0.6               0.75       100      0.9994953  0.9806452  0.9917093
  0.4  3          0.6               0.75       150      0.9996732  0.9806452  0.9907876
  0.4  3          0.6               1.00        50      0.9983056  0.9483871  0.9963134
  0.4  3          0.6               1.00       100      0.9990786  0.9612903  0.9917093
  0.4  3          0.6               1.00       150      0.9990489  0.9870968  0.9898702
  0.4  3          0.8               0.50        50      0.9978922  0.9290323  0.9917093
  0.4  3          0.8               0.50       100      0.9983964  0.9741935  0.9926310
  0.4  3          0.8               0.50       150      0.9985143  0.9741935  0.9926310
  0.4  3          0.8               0.75        50      0.9987829  0.9483871  0.9944700
  0.4  3          0.8               0.75       100      0.9994648  0.9741935  0.9917051
  0.4  3          0.8               0.75       150      0.9994054  0.9741935  0.9926267
  0.4  3          0.8               1.00        50      0.9974146  0.9483871  0.9907876
  0.4  3          0.8               1.00       100      0.9983948  0.9870968  0.9898660
  0.4  3          0.8               1.00       150      0.9984245  0.9870968  0.9880269

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     12.2      0.8
  positive      0.2     86.7
                            
 Accuracy (average) : 0.9895

[1] "TRAIN accuracy: 0.989524576954069"
[1] "TRAIN +precision: 0.997219647822057"
[1] "TRAIN -precision: 0.938271604938272"
[1] "TRAIN specifity: 0.980645161290323"
[1] "TRAIN sensitivity: 0.990791896869245"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       11        4
            positive        7      357
[1] "TEST accuracy: 0.970976253298153"
[1] "TEST +precision: 0.980769230769231"
[1] "TEST -precision: 0.733333333333333"
[1] "TEST specifity: 0.611111111111111"
[1] "TEST sensitivity: 0.988919667590028"
