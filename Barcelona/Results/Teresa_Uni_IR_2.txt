[1] "DATASET NAME: Teresa_Uni_IR_2"
[1] "TRAIN INSTANCES: 1655"
[1] "TEST INSTANCES: 379"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 5.36286211013794"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1655 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1324, 1324, 1323, 1325, 1324 
Resampling results:

  ROC        Sens  Spec     
  0.9991599  1     0.9963176

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.4      0.2
  positive      0.0     65.4
                            
 Accuracy (average) : 0.9976

[1] "TRAIN accuracy: 0.997583081570997"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.993019197207679"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.996316758747698"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9        0
            positive        9      361
[1] "TEST accuracy: 0.976253298153034"
[1] "TEST +precision: 0.975675675675676"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.30828581651052"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1655 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1324, 1325, 1324, 1324, 1323 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.9862762  1     0.9732930
  0.010  2  0.9909286  1     0.9732930
  0.010  3  0.9933797  1     0.9677631
  0.255  1  0.9860933  1     0.9742147
  0.255  2  0.9917536  1     0.9751363
  0.255  3  0.9948491  1     0.9778929
  0.500  1  0.9875382  1     0.9760580
  0.500  2  0.9920138  1     0.9751363
  0.500  3  0.9942267  1     0.9788145

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.4      1.5
  positive      0.0     64.2
                            
 Accuracy (average) : 0.9855

[1] "TRAIN accuracy: 0.985498489425982"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.959527824620573"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.977900552486188"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       12       11
            positive        6      350
[1] "TEST accuracy: 0.955145118733509"
[1] "TEST +precision: 0.98314606741573"
[1] "TEST -precision: 0.521739130434783"
[1] "TEST specifity: 0.666666666666667"
[1] "TEST sensitivity: 0.969529085872576"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 6.27390450239182"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1655 samples
 698 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1324, 1324, 1324, 1324, 1324 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9869086  0.8629095  0.9806663
  0.3  1          0.6               0.50       100      0.9954374  0.9473063  0.9769797
  0.3  1          0.6               0.50       150      0.9967161  0.9894271  0.9843445
  0.3  1          0.6               0.75        50      0.9881677  0.8857941  0.9797446
  0.3  1          0.6               0.75       100      0.9951129  0.9508151  0.9797446
  0.3  1          0.6               0.75       150      0.9968848  0.9771930  0.9806663
  0.3  1          0.6               1.00        50      0.9876415  0.8822854  0.9797573
  0.3  1          0.6               1.00       100      0.9942315  0.9489986  0.9815880
  0.3  1          0.6               1.00       150      0.9968941  0.9719298  0.9806705
  0.3  1          0.8               0.50        50      0.9867423  0.8910262  0.9723756
  0.3  1          0.8               0.50       100      0.9950319  0.9595404  0.9806663
  0.3  1          0.8               0.50       150      0.9971369  0.9789008  0.9797446
  0.3  1          0.8               0.75        50      0.9861137  0.8822233  0.9751533
  0.3  1          0.8               0.75       100      0.9947319  0.9630958  0.9797446
  0.3  1          0.8               0.75       150      0.9964404  0.9771930  0.9806663
  0.3  1          0.8               1.00        50      0.9883975  0.8769912  0.9797573
  0.3  1          0.8               1.00       100      0.9945394  0.9437354  0.9815922
  0.3  1          0.8               1.00       150      0.9967724  0.9719298  0.9815922
  0.3  2          0.6               0.50        50      0.9974357  0.9736687  0.9834355
  0.3  2          0.6               0.50       100      0.9986822  1.0000000  0.9815922
  0.3  2          0.6               0.50       150      0.9986901  1.0000000  0.9843572
  0.3  2          0.6               0.75        50      0.9980180  0.9719298  0.9825054
  0.3  2          0.6               0.75       100      0.9995634  1.0000000  0.9880311
  0.3  2          0.6               0.75       150      0.9993209  1.0000000  0.9861920
  0.3  2          0.6               1.00        50      0.9982928  0.9666201  0.9852704
  0.3  2          0.6               1.00       100      0.9991104  1.0000000  0.9880227
  0.3  2          0.6               1.00       150      0.9992724  1.0000000  0.9871052
  0.3  2          0.8               0.50        50      0.9980345  0.9666201  0.9843487
  0.3  2          0.8               0.50       100      0.9988276  1.0000000  0.9889485
  0.3  2          0.8               0.50       150      0.9992966  1.0000000  0.9871137
  0.3  2          0.8               0.75        50      0.9981475  0.9718832  0.9834270
  0.3  2          0.8               0.75       100      0.9990217  1.0000000  0.9871095
  0.3  2          0.8               0.75       150      0.9991915  1.0000000  0.9871095
  0.3  2          0.8               1.00        50      0.9982367  0.9824561  0.9852704
  0.3  2          0.8               1.00       100      0.9994422  1.0000000  0.9871052
  0.3  2          0.8               1.00       150      0.9994098  1.0000000  0.9871095
  0.3  3          0.6               0.50        50      0.9985365  1.0000000  0.9871052
  0.3  3          0.6               0.50       100      0.9992885  1.0000000  0.9880311
  0.3  3          0.6               0.50       150      0.9986903  1.0000000  0.9871095
  0.3  3          0.6               0.75        50      0.9994664  1.0000000  0.9917093
  0.3  3          0.6               0.75       100      0.9997817  1.0000000  0.9926267
  0.3  3          0.6               0.75       150      0.9994745  1.0000000  0.9898744
  0.3  3          0.6               1.00        50      0.9997413  1.0000000  0.9935484
  0.3  3          0.6               1.00       100      0.9998868  1.0000000  0.9917051
  0.3  3          0.6               1.00       150      1.0000000  1.0000000  0.9907876
  0.3  3          0.8               0.50        50      0.9994907  1.0000000  0.9889570
  0.3  3          0.8               0.50       100      0.9996362  1.0000000  0.9871137
  0.3  3          0.8               0.50       150      0.9994987  1.0000000  0.9880311
  0.3  3          0.8               0.75        50      0.9990945  1.0000000  0.9880353
  0.3  3          0.8               0.75       100      0.9993694  1.0000000  0.9907876
  0.3  3          0.8               0.75       150      0.9991430  1.0000000  0.9898660
  0.3  3          0.8               1.00        50      0.9995068  1.0000000  0.9898702
  0.3  3          0.8               1.00       100      0.9998787  1.0000000  0.9889485
  0.3  3          0.8               1.00       150      0.9998383  1.0000000  0.9889485
  0.4  1          0.6               0.50        50      0.9908064  0.9156497  0.9788272
  0.4  1          0.6               0.50       100      0.9960937  0.9613414  0.9779013
  0.4  1          0.6               0.50       150      0.9971124  1.0000000  0.9825012
  0.4  1          0.6               0.75        50      0.9902535  0.9015836  0.9806748
  0.4  1          0.6               0.75       100      0.9967648  0.9736376  0.9815837
  0.4  1          0.6               0.75       150      0.9982128  1.0000000  0.9806663
  0.4  1          0.6               1.00        50      0.9912894  0.9156187  0.9779140
  0.4  1          0.6               1.00       100      0.9956239  0.9666201  0.9843487
  0.4  1          0.6               1.00       150      0.9971849  0.9929825  0.9815880
  0.4  1          0.8               0.50        50      0.9893967  0.9278994  0.9696191
  0.4  1          0.8               0.50       100      0.9957206  0.9824096  0.9742189
  0.4  1          0.8               0.50       150      0.9967717  1.0000000  0.9769797
  0.4  1          0.8               0.75        50      0.9908416  0.8980438  0.9751448
  0.4  1          0.8               0.75       100      0.9956728  0.9754231  0.9806621
  0.4  1          0.8               0.75       150      0.9975255  1.0000000  0.9825054
  0.4  1          0.8               1.00        50      0.9905305  0.9068468  0.9779098
  0.4  1          0.8               1.00       100      0.9960848  0.9666201  0.9834313
  0.4  1          0.8               1.00       150      0.9972013  1.0000000  0.9806705
  0.4  2          0.6               0.50        50      0.9986173  1.0000000  0.9852619
  0.4  2          0.6               0.50       100      0.9989409  1.0000000  0.9834313
  0.4  2          0.6               0.50       150      0.9985769  1.0000000  0.9852746
  0.4  2          0.6               0.75        50      0.9978730  1.0000000  0.9815880
  0.4  2          0.6               0.75       100      0.9989490  1.0000000  0.9861878
  0.4  2          0.6               0.75       150      0.9986822  1.0000000  0.9861878
  0.4  2          0.6               1.00        50      0.9980189  0.9894737  0.9834313
  0.4  2          0.6               1.00       100      0.9985124  1.0000000  0.9880269
  0.4  2          0.6               1.00       150      0.9989005  1.0000000  0.9889485
  0.4  2          0.8               0.50        50      0.9986576  0.9894737  0.9806705
  0.4  2          0.8               0.50       100      0.9990379  1.0000000  0.9871052
  0.4  2          0.8               0.50       150      0.9992239  1.0000000  0.9797489
  0.4  2          0.8               0.75        50      0.9984961  1.0000000  0.9825012
  0.4  2          0.8               0.75       100      0.9992805  1.0000000  0.9861878
  0.4  2          0.8               0.75       150      0.9992158  1.0000000  0.9861920
  0.4  2          0.8               1.00        50      0.9987708  1.0000000  0.9852704
  0.4  2          0.8               1.00       100      0.9991107  1.0000000  0.9898660
  0.4  2          0.8               1.00       150      0.9991834  1.0000000  0.9907876
  0.4  3          0.6               0.50        50      0.9993209  1.0000000  0.9889443
  0.4  3          0.6               0.50       100      0.9989731  1.0000000  0.9889485
  0.4  3          0.6               0.50       150      0.9987466  1.0000000  0.9889485
  0.4  3          0.6               0.75        50      0.9996443  1.0000000  0.9917135
  0.4  3          0.6               0.75       100      0.9996362  1.0000000  0.9898744
  0.4  3          0.6               0.75       150      0.9996038  1.0000000  0.9880311
  0.4  3          0.6               1.00        50      0.9997817  1.0000000  0.9907919
  0.4  3          0.6               1.00       100      0.9998141  1.0000000  0.9907919
  0.4  3          0.6               1.00       150      0.9996281  1.0000000  0.9889528
  0.4  3          0.8               0.50        50      0.9986089  1.0000000  0.9852661
  0.4  3          0.8               0.50       100      0.9985280  1.0000000  0.9880311
  0.4  3          0.8               0.50       150      0.9986334  1.0000000  0.9815880
  0.4  3          0.8               0.75        50      0.9992239  1.0000000  0.9917051
  0.4  3          0.8               0.75       100      0.9993451  1.0000000  0.9917135
  0.4  3          0.8               0.75       150      0.9992885  1.0000000  0.9898702
  0.4  3          0.8               1.00        50      0.9995149  1.0000000  0.9880311
  0.4  3          0.8               1.00       100      0.9996443  1.0000000  0.9898702
  0.4  3          0.8               1.00       150      0.9996766  1.0000000  0.9907919

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.4      0.6
  positive      0.0     65.0
                           
 Accuracy (average) : 0.994

[1] "TRAIN accuracy: 0.993957703927492"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.98272884283247"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.990791896869245"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       12        3
            positive        6      358
[1] "TEST accuracy: 0.976253298153034"
[1] "TEST +precision: 0.983516483516483"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.666666666666667"
[1] "TEST sensitivity: 0.991689750692521"
