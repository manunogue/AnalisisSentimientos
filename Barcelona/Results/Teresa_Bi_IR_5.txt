[1] "DATASET NAME: Teresa_Bi_IR_5"
[1] "TRAIN INSTANCES: 1344"
[1] "TEST INSTANCES: 379"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.09331798553467"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1344 samples
 671 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1075, 1076, 1075, 1075, 1075 
Resampling results:

  ROC       Sens       Spec     
  0.995953  0.9457014  0.9953917

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.2      0.4
  positive      1.0     80.4
                            
 Accuracy (average) : 0.9859

[1] "TRAIN accuracy: 0.985863095238095"
[1] "TRAIN +precision: 0.987202925045704"
[1] "TRAIN -precision: 0.98"
[1] "TRAIN specifity: 0.945945945945946"
[1] "TRAIN sensitivity: 0.995391705069124"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        4
            positive       12      358
[1] "TEST accuracy: 0.95778364116095"
[1] "TEST +precision: 0.967567567567568"
[1] "TEST -precision: 0.555555555555556"
[1] "TEST specifity: 0.294117647058824"
[1] "TEST sensitivity: 0.988950276243094"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.57297268311183"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1344 samples
 671 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1076, 1075, 1075, 1075, 1075 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7162755  0.2589744  0.9953917
  0.010  2  0.7109358  0.2512066  0.9953917
  0.010  3  0.6743578  0.1932127  0.9953917
  0.255  1  0.8045292  0.3358220  0.9944700
  0.255  2  0.8044222  0.3358220  0.9944700
  0.255  3  0.7688633  0.2816742  0.9953917
  0.500  1  0.8240385  0.3473605  0.9944700
  0.500  2  0.8239315  0.3473605  0.9944700
  0.500  3  0.7993084  0.2971342  0.9926267

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      6.7      0.4
  positive     12.6     80.3
                            
 Accuracy (average) : 0.8698

[1] "TRAIN accuracy: 0.869791666666667"
[1] "TRAIN +precision: 0.864583333333333"
[1] "TRAIN -precision: 0.9375"
[1] "TRAIN specifity: 0.347490347490348"
[1] "TRAIN sensitivity: 0.994470046082949"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        3
            positive       16      359
[1] "TEST accuracy: 0.949868073878628"
[1] "TEST +precision: 0.957333333333333"
[1] "TEST -precision: 0.25"
[1] "TEST specifity: 0.0588235294117647"
[1] "TEST sensitivity: 0.99171270718232"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.26422641674678"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1344 samples
 671 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1075, 1075, 1076, 1075, 1075 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8593699  0.2509804  0.9981567
  0.3  1          0.6               0.50       100      0.9157386  0.4093514  0.9963134
  0.3  1          0.6               0.50       150      0.9324426  0.5288839  0.9907834
  0.3  1          0.6               0.75        50      0.8701000  0.2316742  0.9963134
  0.3  1          0.6               0.75       100      0.9209670  0.4709653  0.9953917
  0.3  1          0.6               0.75       150      0.9491081  0.5791855  0.9935484
  0.3  1          0.6               1.00        50      0.8658562  0.3014329  0.9972350
  0.3  1          0.6               1.00       100      0.9280501  0.4634238  0.9953917
  0.3  1          0.6               1.00       150      0.9500500  0.5752640  0.9963134
  0.3  1          0.8               0.50        50      0.8716376  0.2046757  0.9963134
  0.3  1          0.8               0.50       100      0.9289028  0.4095023  0.9963134
  0.3  1          0.8               0.50       150      0.9407217  0.5443439  0.9935484
  0.3  1          0.8               0.75        50      0.8774466  0.2974359  0.9963134
  0.3  1          0.8               0.75       100      0.9321109  0.4825792  0.9953917
  0.3  1          0.8               0.75       150      0.9470901  0.6099548  0.9944700
  0.3  1          0.8               1.00        50      0.8700539  0.2706637  0.9972350
  0.3  1          0.8               1.00       100      0.9236837  0.4710407  0.9953917
  0.3  1          0.8               1.00       150      0.9535262  0.5831071  0.9963134
  0.3  2          0.6               0.50        50      0.9215815  0.3823529  0.9944700
  0.3  2          0.6               0.50       100      0.9474705  0.5907994  0.9917051
  0.3  2          0.6               0.50       150      0.9564996  0.6718703  0.9898618
  0.3  2          0.6               0.75        50      0.9357801  0.4441931  0.9972350
  0.3  2          0.6               0.75       100      0.9584501  0.6680241  0.9953917
  0.3  2          0.6               0.75       150      0.9661087  0.7027149  0.9935484
  0.3  2          0.6               1.00        50      0.9373105  0.4748115  0.9963134
  0.3  2          0.6               1.00       100      0.9598866  0.6718703  0.9944700
  0.3  2          0.6               1.00       150      0.9697316  0.6988688  0.9963134
  0.3  2          0.8               0.50        50      0.9132911  0.4170437  0.9944700
  0.3  2          0.8               0.50       100      0.9473622  0.5676471  0.9917051
  0.3  2          0.8               0.50       150      0.9565100  0.6795626  0.9889401
  0.3  2          0.8               0.75        50      0.9326786  0.4825792  0.9953917
  0.3  2          0.8               0.75       100      0.9559187  0.6717949  0.9917051
  0.3  2          0.8               0.75       150      0.9651999  0.7334842  0.9926267
  0.3  2          0.8               1.00        50      0.9373517  0.4709653  0.9953917
  0.3  2          0.8               1.00       100      0.9612387  0.6794872  0.9953917
  0.3  2          0.8               1.00       150      0.9679948  0.7104072  0.9944700
  0.3  3          0.6               0.50        50      0.9359927  0.4942685  0.9935484
  0.3  3          0.6               0.50       100      0.9561378  0.6252640  0.9917051
  0.3  3          0.6               0.50       150      0.9608623  0.7065611  0.9898618
  0.3  3          0.6               0.75        50      0.9494250  0.6024887  0.9944700
  0.3  3          0.6               0.75       100      0.9670253  0.7142534  0.9953917
  0.3  3          0.6               0.75       150      0.9704108  0.7644042  0.9917051
  0.3  3          0.6               1.00        50      0.9559446  0.5944947  0.9972350
  0.3  3          0.6               1.00       100      0.9703627  0.7257919  0.9944700
  0.3  3          0.6               1.00       150      0.9745814  0.7644042  0.9935484
  0.3  3          0.8               0.50        50      0.9445559  0.5134238  0.9889401
  0.3  3          0.8               0.50       100      0.9575587  0.6796380  0.9889401
  0.3  3          0.8               0.50       150      0.9603794  0.7412519  0.9907834
  0.3  3          0.8               0.75        50      0.9527556  0.6139517  0.9944700
  0.3  3          0.8               0.75       100      0.9657832  0.7296380  0.9926267
  0.3  3          0.8               0.75       150      0.9686990  0.7797888  0.9926267
  0.3  3          0.8               1.00        50      0.9591445  0.5946456  0.9972350
  0.3  3          0.8               1.00       100      0.9707610  0.7219457  0.9944700
  0.3  3          0.8               1.00       150      0.9752549  0.7720965  0.9953917
  0.4  1          0.6               0.50        50      0.8679995  0.3015837  0.9963134
  0.4  1          0.6               0.50       100      0.9215997  0.5288084  0.9917051
  0.4  1          0.6               0.50       150      0.9450393  0.6101810  0.9898618
  0.4  1          0.6               0.75        50      0.8939496  0.3205128  0.9944700
  0.4  1          0.6               0.75       100      0.9392129  0.5445701  0.9963134
  0.4  1          0.6               0.75       150      0.9526473  0.6679487  0.9963134
  0.4  1          0.6               1.00        50      0.8857680  0.3361237  0.9963134
  0.4  1          0.6               1.00       100      0.9444203  0.5635747  0.9953917
  0.4  1          0.6               1.00       150      0.9574504  0.6564857  0.9944700
  0.4  1          0.8               0.50        50      0.8840717  0.3322021  0.9963134
  0.4  1          0.8               0.50       100      0.9296208  0.5018100  0.9935484
  0.4  1          0.8               0.50       150      0.9460103  0.6293363  0.9935484
  0.4  1          0.8               0.75        50      0.8857928  0.3091252  0.9953917
  0.4  1          0.8               0.75       100      0.9441998  0.5677225  0.9944700
  0.4  1          0.8               0.75       150      0.9524845  0.6757164  0.9917051
  0.4  1          0.8               1.00        50      0.8825872  0.3478130  0.9963134
  0.4  1          0.8               1.00       100      0.9396595  0.5751131  0.9963134
  0.4  1          0.8               1.00       150      0.9578914  0.6718703  0.9944700
  0.4  2          0.6               0.50        50      0.9299266  0.4788084  0.9917051
  0.4  2          0.6               0.50       100      0.9526671  0.6716440  0.9889401
  0.4  2          0.6               0.50       150      0.9595810  0.6872549  0.9898618
  0.4  2          0.6               0.75        50      0.9460491  0.5598793  0.9953917
  0.4  2          0.6               0.75       100      0.9592056  0.6950226  0.9926267
  0.4  2          0.6               0.75       150      0.9668901  0.7489442  0.9935484
  0.4  2          0.6               1.00        50      0.9426947  0.5636501  0.9944700
  0.4  2          0.6               1.00       100      0.9635359  0.7180995  0.9944700
  0.4  2          0.6               1.00       150      0.9710216  0.7567119  0.9917051
  0.4  2          0.8               0.50        50      0.9262888  0.5019608  0.9926267
  0.4  2          0.8               0.50       100      0.9498356  0.6525641  0.9889401
  0.4  2          0.8               0.50       150      0.9536001  0.7101810  0.9898618
  0.4  2          0.8               0.75        50      0.9443408  0.5597285  0.9917051
  0.4  2          0.8               0.75       100      0.9644654  0.7141780  0.9926267
  0.4  2          0.8               0.75       150      0.9713097  0.7565611  0.9944700
  0.4  2          0.8               1.00        50      0.9476800  0.5599548  0.9981567
  0.4  2          0.8               1.00       100      0.9646967  0.6950226  0.9963134
  0.4  2          0.8               1.00       150      0.9715029  0.7528658  0.9944700
  0.4  3          0.6               0.50        50      0.9421953  0.5636501  0.9935484
  0.4  3          0.6               0.50       100      0.9588197  0.6717195  0.9880184
  0.4  3          0.6               0.50       150      0.9605529  0.7684012  0.9907834
  0.4  3          0.6               0.75        50      0.9596618  0.6524887  0.9963134
  0.4  3          0.6               0.75       100      0.9691640  0.7296380  0.9926267
  0.4  3          0.6               0.75       150      0.9706720  0.7680995  0.9907834
  0.4  3          0.6               1.00        50      0.9643358  0.6680241  0.9963134
  0.4  3          0.6               1.00       100      0.9759298  0.7490196  0.9926267
  0.4  3          0.6               1.00       150      0.9770760  0.7951735  0.9926267
  0.4  3          0.8               0.50        50      0.9421355  0.5713424  0.9917051
  0.4  3          0.8               0.50       100      0.9555068  0.7025641  0.9917051
  0.4  3          0.8               0.50       150      0.9606456  0.7256410  0.9898618
  0.4  3          0.8               0.75        50      0.9563769  0.6717195  0.9953917
  0.4  3          0.8               0.75       100      0.9687757  0.7450226  0.9907834
  0.4  3          0.8               0.75       150      0.9716706  0.8065611  0.9926267
  0.4  3          0.8               1.00        50      0.9610879  0.6911765  0.9972350
  0.4  3          0.8               1.00       100      0.9755486  0.7605581  0.9963134
  0.4  3          0.8               1.00       150      0.9762443  0.8144042  0.9944700

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     15.3      0.6
  positive      3.9     80.1
                            
 Accuracy (average) : 0.9546

[1] "TRAIN accuracy: 0.954613095238095"
[1] "TRAIN +precision: 0.953097345132743"
[1] "TRAIN -precision: 0.962616822429907"
[1] "TRAIN specifity: 0.795366795366795"
[1] "TRAIN sensitivity: 0.992626728110599"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        3
            positive       13      359
[1] "TEST accuracy: 0.95778364116095"
[1] "TEST +precision: 0.96505376344086"
[1] "TEST -precision: 0.571428571428571"
[1] "TEST specifity: 0.235294117647059"
[1] "TEST sensitivity: 0.99171270718232"
