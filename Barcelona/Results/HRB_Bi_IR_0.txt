[1] "DATASET NAME: HRB_Bi_IR_0"
[1] "TRAIN INSTANCES: 995"
[1] "TEST INSTANCES: 332"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.67545413970947"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

995 samples
825 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 795, 796, 796, 796, 797 
Resampling results:

  ROC        Sens       Spec     
  0.8768489  0.4462069  0.9705186

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      6.6      2.5
  positive      8.2     82.6
                            
 Accuracy (average) : 0.8925

[1] "TRAIN accuracy: 0.892462311557789"
[1] "TRAIN +precision: 0.90929203539823"
[1] "TRAIN -precision: 0.725274725274725"
[1] "TRAIN specifity: 0.445945945945946"
[1] "TRAIN sensitivity: 0.970484061393152"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       18        7
            positive       28      279
[1] "TEST accuracy: 0.894578313253012"
[1] "TEST +precision: 0.908794788273616"
[1] "TEST -precision: 0.72"
[1] "TEST specifity: 0.391304347826087"
[1] "TEST sensitivity: 0.975524475524476"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.83882433573405"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

995 samples
825 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 796, 796, 796, 795, 797 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5000000  0.00000000  1.0000000
  0.010  2  0.5000000  0.00000000  1.0000000
  0.010  3  0.5000000  0.00000000  1.0000000
  0.255  1  0.5012700  0.04045977  0.9952732
  0.255  2  0.5045849  0.04735632  0.9976331
  0.255  3  0.4958471  0.00000000  0.9988166
  0.500  1  0.5833975  0.06045977  0.9858127
  0.500  2  0.6118091  0.05379310  0.9810790
  0.500  3  0.5488666  0.02000000  0.9834320

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.8      1.6
  positive     14.1     83.5
                            
 Accuracy (average) : 0.8432

[1] "TRAIN accuracy: 0.84321608040201"
[1] "TRAIN +precision: 0.855818743563337"
[1] "TRAIN -precision: 0.333333333333333"
[1] "TRAIN specifity: 0.0540540540540541"
[1] "TRAIN sensitivity: 0.981109799291617"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        3
            positive       45      283
[1] "TEST accuracy: 0.855421686746988"
[1] "TEST +precision: 0.86280487804878"
[1] "TEST -precision: 0.25"
[1] "TEST specifity: 0.0217391304347826"
[1] "TEST sensitivity: 0.989510489510489"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.30617160002391"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

995 samples
825 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 796, 796, 796, 795, 797 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.6927947  0.03356322  0.9940968
  0.3  1          0.6               0.50       100      0.7260164  0.07402299  0.9917299
  0.3  1          0.6               0.50       150      0.7333466  0.08114943  0.9893700
  0.3  1          0.6               0.75        50      0.7193000  0.04045977  0.9988166
  0.3  1          0.6               0.75       100      0.7397805  0.06781609  0.9964567
  0.3  1          0.6               0.75       150      0.7641841  0.10206897  0.9929133
  0.3  1          0.6               1.00        50      0.7053260  0.03379310  0.9988235
  0.3  1          0.6               1.00       100      0.7453726  0.08804598  0.9976401
  0.3  1          0.6               1.00       150      0.7693253  0.10137931  0.9964567
  0.3  1          0.8               0.50        50      0.6969239  0.02712644  0.9964567
  0.3  1          0.8               0.50       100      0.7307563  0.07448276  0.9870240
  0.3  1          0.8               0.50       150      0.7402454  0.10114943  0.9846432
  0.3  1          0.8               0.75        50      0.7073762  0.04068966  0.9964567
  0.3  1          0.8               0.75       100      0.7317063  0.07448276  0.9964497
  0.3  1          0.8               0.75       150      0.7486913  0.08804598  0.9929064
  0.3  1          0.8               1.00        50      0.7081523  0.05402299  0.9988166
  0.3  1          0.8               1.00       100      0.7515287  0.09494253  0.9964567
  0.3  1          0.8               1.00       150      0.7695223  0.11540230  0.9964567
  0.3  2          0.6               0.50        50      0.7142465  0.06091954  0.9929203
  0.3  2          0.6               0.50       100      0.7471448  0.10114943  0.9834528
  0.3  2          0.6               0.50       150      0.7501544  0.12137931  0.9716464
  0.3  2          0.6               0.75        50      0.7336056  0.08160920  0.9917299
  0.3  2          0.6               0.75       100      0.7699239  0.10183908  0.9905465
  0.3  2          0.6               0.75       150      0.7743738  0.12206897  0.9858127
  0.3  2          0.6               1.00        50      0.7383795  0.10827586  1.0000000
  0.3  2          0.6               1.00       100      0.7804070  0.12206897  0.9964567
  0.3  2          0.6               1.00       150      0.7866218  0.14896552  0.9881935
  0.3  2          0.8               0.50        50      0.7181317  0.08160920  0.9917438
  0.3  2          0.8               0.50       100      0.7382601  0.10183908  0.9799165
  0.3  2          0.8               0.50       150      0.7560163  0.11517241  0.9810860
  0.3  2          0.8               0.75        50      0.7406637  0.05402299  0.9940828
  0.3  2          0.8               0.75       100      0.7649164  0.09471264  0.9881866
  0.3  2          0.8               0.75       150      0.7717747  0.12873563  0.9799095
  0.3  2          0.8               1.00        50      0.7416369  0.10827586  0.9952732
  0.3  2          0.8               1.00       100      0.7771045  0.11517241  0.9964567
  0.3  2          0.8               1.00       150      0.7814545  0.12873563  0.9917369
  0.3  3          0.6               0.50        50      0.7535397  0.08114943  0.9881935
  0.3  3          0.6               0.50       100      0.7525270  0.09471264  0.9846432
  0.3  3          0.6               0.50       150      0.7687390  0.10160920  0.9787191
  0.3  3          0.6               0.75        50      0.7529553  0.09517241  0.9893700
  0.3  3          0.6               0.75       100      0.7681088  0.13517241  0.9834668
  0.3  3          0.6               0.75       150      0.7644999  0.14229885  0.9763801
  0.3  3          0.6               1.00        50      0.7591123  0.10850575  0.9964636
  0.3  3          0.6               1.00       100      0.7855560  0.13517241  0.9952872
  0.3  3          0.6               1.00       150      0.7800820  0.15563218  0.9846432
  0.3  3          0.8               0.50        50      0.7228240  0.08758621  0.9869962
  0.3  3          0.8               0.50       100      0.7377995  0.13494253  0.9798956
  0.3  3          0.8               0.50       150      0.7337806  0.13494253  0.9775426
  0.3  3          0.8               0.75        50      0.7516287  0.09494253  0.9929133
  0.3  3          0.8               0.75       100      0.7728065  0.14919540  0.9858267
  0.3  3          0.8               0.75       150      0.7666568  0.16229885  0.9787330
  0.3  3          0.8               1.00        50      0.7681242  0.10827586  0.9952732
  0.3  3          0.8               1.00       100      0.7866781  0.12850575  0.9917369
  0.3  3          0.8               1.00       150      0.7888057  0.13540230  0.9810929
  0.4  1          0.6               0.50        50      0.7114603  0.04068966  0.9905604
  0.4  1          0.6               0.50       100      0.7256274  0.07402299  0.9846363
  0.4  1          0.6               0.50       150      0.7449617  0.10781609  0.9834528
  0.4  1          0.6               0.75        50      0.7175870  0.05402299  0.9964567
  0.4  1          0.6               0.75       100      0.7543621  0.10206897  0.9917369
  0.4  1          0.6               0.75       150      0.7668889  0.10850575  0.9881935
  0.4  1          0.6               1.00        50      0.7236509  0.06758621  0.9988166
  0.4  1          0.6               1.00       100      0.7642821  0.10160920  0.9976331
  0.4  1          0.6               1.00       150      0.7799715  0.10160920  0.9952802
  0.4  1          0.8               0.50        50      0.6929298  0.06758621  0.9964567
  0.4  1          0.8               0.50       100      0.7274377  0.08781609  0.9858267
  0.4  1          0.8               0.50       150      0.7473416  0.11494253  0.9740202
  0.4  1          0.8               0.75        50      0.7015160  0.04735632  0.9964497
  0.4  1          0.8               0.75       100      0.7489011  0.07448276  0.9917299
  0.4  1          0.8               0.75       150      0.7519202  0.10160920  0.9810929
  0.4  1          0.8               1.00        50      0.7236549  0.06758621  0.9988166
  0.4  1          0.8               1.00       100      0.7709282  0.11563218  0.9964567
  0.4  1          0.8               1.00       150      0.7886349  0.10873563  0.9952802
  0.4  2          0.6               0.50        50      0.7198013  0.06091954  0.9893700
  0.4  2          0.6               0.50       100      0.7380416  0.09517241  0.9775287
  0.4  2          0.6               0.50       150      0.7472740  0.12183908  0.9704490
  0.4  2          0.6               0.75        50      0.7577977  0.08160920  0.9905604
  0.4  2          0.6               0.75       100      0.7770130  0.13563218  0.9775566
  0.4  2          0.6               0.75       150      0.7684737  0.15586207  0.9787400
  0.4  2          0.6               1.00        50      0.7651722  0.10137931  0.9952732
  0.4  2          0.6               1.00       100      0.7871803  0.12183908  0.9917299
  0.4  2          0.6               1.00       150      0.7866472  0.12873563  0.9822833
  0.4  2          0.8               0.50        50      0.7353797  0.08804598  0.9858197
  0.4  2          0.8               0.50       100      0.7648187  0.11517241  0.9787261
  0.4  2          0.8               0.50       150      0.7607131  0.12873563  0.9787330
  0.4  2          0.8               0.75        50      0.7436807  0.09471264  0.9893630
  0.4  2          0.8               0.75       100      0.7704389  0.12873563  0.9834668
  0.4  2          0.8               0.75       150      0.7684448  0.15540230  0.9799304
  0.4  2          0.8               1.00        50      0.7578143  0.10160920  0.9964567
  0.4  2          0.8               1.00       100      0.7846110  0.12850575  0.9929133
  0.4  2          0.8               1.00       150      0.7801230  0.14206897  0.9881866
  0.4  3          0.6               0.50        50      0.7361904  0.08827586  0.9893630
  0.4  3          0.6               0.50       100      0.7605666  0.10160920  0.9869962
  0.4  3          0.6               0.50       150      0.7609471  0.11494253  0.9787191
  0.4  3          0.6               0.75        50      0.7705304  0.12206897  0.9881796
  0.4  3          0.6               0.75       100      0.7807932  0.14919540  0.9799025
  0.4  3          0.6               0.75       150      0.7753064  0.14919540  0.9763592
  0.4  3          0.6               1.00        50      0.7691019  0.12183908  0.9988166
  0.4  3          0.6               1.00       100      0.7870454  0.14873563  0.9858336
  0.4  3          0.6               1.00       150      0.7822522  0.16206897  0.9775426
  0.4  3          0.8               0.50        50      0.7551080  0.08781609  0.9846363
  0.4  3          0.8               0.50       100      0.7570539  0.12850575  0.9822555
  0.4  3          0.8               0.50       150      0.7632146  0.14160920  0.9716185
  0.4  3          0.8               0.75        50      0.7585988  0.10160920  0.9858267
  0.4  3          0.8               0.75       100      0.7600261  0.11494253  0.9728298
  0.4  3          0.8               0.75       150      0.7562098  0.12183908  0.9740063
  0.4  3          0.8               1.00        50      0.7654488  0.12183908  0.9976401
  0.4  3          0.8               1.00       100      0.7805989  0.14206897  0.9834668
  0.4  3          0.8               1.00       150      0.7801271  0.15540230  0.9763731

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      2.0      1.6
  positive     12.9     83.5
                            
 Accuracy (average) : 0.8553

[1] "TRAIN accuracy: 0.855276381909548"
[1] "TRAIN +precision: 0.866527632950991"
[1] "TRAIN -precision: 0.555555555555555"
[1] "TRAIN specifity: 0.135135135135135"
[1] "TRAIN sensitivity: 0.981109799291617"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        6
            positive       40      280
[1] "TEST accuracy: 0.86144578313253"
[1] "TEST +precision: 0.875"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.130434782608696"
[1] "TEST sensitivity: 0.979020979020979"
