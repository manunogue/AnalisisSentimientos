[1] "DATASET NAME: Teresa_Bi_IR_0"
[1] "TRAIN INSTANCES: 1137"
[1] "TEST INSTANCES: 379"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.23059606552124"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1137 samples
 671 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 909, 910, 909, 910, 910 
Resampling results:

  ROC        Sens       Spec     
  0.8674864  0.1727273  0.9963134

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.8      0.4
  positive      3.8     95.1
                            
 Accuracy (average) : 0.9587

[1] "TRAIN accuracy: 0.958663148636763"
[1] "TRAIN +precision: 0.961743772241993"
[1] "TRAIN -precision: 0.692307692307692"
[1] "TRAIN specifity: 0.173076923076923"
[1] "TRAIN sensitivity: 0.9963133640553"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        0
            positive       11      362
[1] "TEST accuracy: 0.970976253298153"
[1] "TEST +precision: 0.970509383378016"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.352941176470588"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.46146608193715"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1137 samples
 671 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 910, 909, 909, 910, 910 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec    
  0.010  1  0.5000000  0.00000000  1.000000
  0.010  2  0.5000000  0.00000000  1.000000
  0.010  3  0.5000000  0.00000000  1.000000
  0.255  1  0.5023041  0.00000000  1.000000
  0.255  2  0.5000000  0.00000000  1.000000
  0.255  3  0.5000000  0.00000000  1.000000
  0.500  1  0.5267658  0.03818182  0.997235
  0.500  2  0.4831713  0.00000000  1.000000
  0.500  3  0.4976959  0.00000000  1.000000

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.2      0.3
  positive      4.4     95.2
                            
 Accuracy (average) : 0.9534

[1] "TRAIN accuracy: 0.953386103781882"
[1] "TRAIN +precision: 0.95583038869258"
[1] "TRAIN -precision: 0.4"
[1] "TRAIN specifity: 0.0384615384615385"
[1] "TRAIN sensitivity: 0.997235023041475"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        1
            positive       17      361
[1] "TEST accuracy: 0.952506596306069"
[1] "TEST +precision: 0.955026455026455"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.997237569060773"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.84046403169632"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1137 samples
 671 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 909, 910, 910, 909, 910 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.6225304  0.00000000  1.0000000
  0.3  1          0.6               0.50       100      0.6330247  0.00000000  0.9990783
  0.3  1          0.6               0.50       150      0.6494428  0.00000000  0.9990783
  0.3  1          0.6               0.75        50      0.6825974  0.02000000  0.9990783
  0.3  1          0.6               0.75       100      0.6800796  0.02000000  0.9981567
  0.3  1          0.6               0.75       150      0.6764474  0.02000000  0.9990783
  0.3  1          0.6               1.00        50      0.6641977  0.01818182  0.9981567
  0.3  1          0.6               1.00       100      0.6917553  0.03818182  0.9963134
  0.3  1          0.6               1.00       150      0.6861793  0.03818182  0.9963134
  0.3  1          0.8               0.50        50      0.6167826  0.00000000  1.0000000
  0.3  1          0.8               0.50       100      0.6408923  0.00000000  1.0000000
  0.3  1          0.8               0.50       150      0.6408923  0.00000000  0.9990783
  0.3  1          0.8               0.75        50      0.6692040  0.00000000  0.9963134
  0.3  1          0.8               0.75       100      0.6816464  0.00000000  0.9963134
  0.3  1          0.8               0.75       150      0.6812652  0.00000000  0.9963134
  0.3  1          0.8               1.00        50      0.6559489  0.01818182  0.9981567
  0.3  1          0.8               1.00       100      0.6859112  0.03818182  0.9963134
  0.3  1          0.8               1.00       150      0.6781399  0.03818182  0.9963134
  0.3  2          0.6               0.50        50      0.6016087  0.00000000  1.0000000
  0.3  2          0.6               0.50       100      0.6219690  0.00000000  0.9990783
  0.3  2          0.6               0.50       150      0.6266192  0.00000000  0.9990783
  0.3  2          0.6               0.75        50      0.6906116  0.00000000  0.9972350
  0.3  2          0.6               0.75       100      0.7001299  0.00000000  0.9963134
  0.3  2          0.6               0.75       150      0.7004902  0.01818182  0.9963134
  0.3  2          0.6               1.00        50      0.6994009  0.03818182  0.9963134
  0.3  2          0.6               1.00       100      0.6939925  0.05636364  0.9953917
  0.3  2          0.6               1.00       150      0.6944072  0.05636364  0.9953917
  0.3  2          0.8               0.50        50      0.6455677  0.00000000  0.9990783
  0.3  2          0.8               0.50       100      0.6490406  0.00000000  0.9981567
  0.3  2          0.8               0.50       150      0.6567742  0.00000000  0.9981567
  0.3  2          0.8               0.75        50      0.6979682  0.03818182  0.9972350
  0.3  2          0.8               0.75       100      0.6962547  0.03818182  0.9972350
  0.3  2          0.8               0.75       150      0.6992501  0.03818182  0.9963134
  0.3  2          0.8               1.00        50      0.6976959  0.01818182  0.9972350
  0.3  2          0.8               1.00       100      0.6969795  0.05636364  0.9953917
  0.3  2          0.8               1.00       150      0.6962003  0.05636364  0.9953917
  0.3  3          0.6               0.50        50      0.6459824  0.00000000  1.0000000
  0.3  3          0.6               0.50       100      0.6590323  0.00000000  1.0000000
  0.3  3          0.6               0.50       150      0.6643067  0.00000000  0.9990783
  0.3  3          0.6               0.75        50      0.6947088  0.01818182  0.9963134
  0.3  3          0.6               0.75       100      0.6973398  0.01818182  0.9963134
  0.3  3          0.6               0.75       150      0.7123209  0.01818182  0.9972350
  0.3  3          0.6               1.00        50      0.7188647  0.03818182  0.9963134
  0.3  3          0.6               1.00       100      0.7070800  0.05636364  0.9963134
  0.3  3          0.6               1.00       150      0.7105237  0.05636364  0.9972350
  0.3  3          0.8               0.50        50      0.6408211  0.00000000  1.0000000
  0.3  3          0.8               0.50       100      0.6698785  0.00000000  1.0000000
  0.3  3          0.8               0.50       150      0.6857436  0.02000000  1.0000000
  0.3  3          0.8               0.75        50      0.6900587  0.03818182  0.9972350
  0.3  3          0.8               0.75       100      0.6951864  0.03818182  0.9972350
  0.3  3          0.8               0.75       150      0.6972685  0.03818182  0.9972350
  0.3  3          0.8               1.00        50      0.7066778  0.03818182  0.9953917
  0.3  3          0.8               1.00       100      0.6979095  0.05636364  0.9953917
  0.3  3          0.8               1.00       150      0.7008421  0.05636364  0.9963134
  0.4  1          0.6               0.50        50      0.6452032  0.00000000  0.9981567
  0.4  1          0.6               0.50       100      0.6352702  0.00000000  0.9981567
  0.4  1          0.6               0.50       150      0.6565145  0.00000000  0.9981567
  0.4  1          0.6               0.75        50      0.6737411  0.02000000  0.9981567
  0.4  1          0.6               0.75       100      0.6764055  0.02000000  0.9981567
  0.4  1          0.6               0.75       150      0.6681986  0.02000000  0.9981567
  0.4  1          0.6               1.00        50      0.6724885  0.01818182  0.9981567
  0.4  1          0.6               1.00       100      0.6920821  0.03818182  0.9963134
  0.4  1          0.6               1.00       150      0.6947340  0.03818182  0.9963134
  0.4  1          0.8               0.50        50      0.6499497  0.00000000  0.9990783
  0.4  1          0.8               0.50       100      0.6447675  0.00000000  0.9981567
  0.4  1          0.8               0.50       150      0.6857436  0.00000000  0.9981567
  0.4  1          0.8               0.75        50      0.6612401  0.00000000  0.9972350
  0.4  1          0.8               0.75       100      0.6638375  0.00000000  0.9963134
  0.4  1          0.8               0.75       150      0.6800000  0.00000000  0.9963134
  0.4  1          0.8               1.00        50      0.6751948  0.01818182  0.9981567
  0.4  1          0.8               1.00       100      0.6930289  0.03818182  0.9963134
  0.4  1          0.8               1.00       150      0.6928069  0.03818182  0.9963134
  0.4  2          0.6               0.50        50      0.6435107  0.00000000  1.0000000
  0.4  2          0.6               0.50       100      0.6586008  0.00000000  0.9981567
  0.4  2          0.6               0.50       150      0.6463301  0.00000000  0.9981567
  0.4  2          0.6               0.75        50      0.6855802  0.03818182  0.9972350
  0.4  2          0.6               0.75       100      0.6936364  0.03818182  0.9972350
  0.4  2          0.6               0.75       150      0.6861793  0.03818182  0.9972350
  0.4  2          0.6               1.00        50      0.6939380  0.03818182  0.9963134
  0.4  2          0.6               1.00       100      0.6971387  0.03818182  0.9963134
  0.4  2          0.6               1.00       150      0.6947717  0.03818182  0.9963134
  0.4  2          0.8               0.50        50      0.6400293  0.00000000  0.9981567
  0.4  2          0.8               0.50       100      0.6378844  0.00000000  0.9981567
  0.4  2          0.8               0.50       150      0.6454922  0.00000000  0.9963134
  0.4  2          0.8               0.75        50      0.6827566  0.01818182  0.9972350
  0.4  2          0.8               0.75       100      0.6777587  0.01818182  0.9972350
  0.4  2          0.8               0.75       150      0.6757981  0.01818182  0.9972350
  0.4  2          0.8               1.00        50      0.6974990  0.03818182  0.9953917
  0.4  2          0.8               1.00       100      0.6935861  0.05636364  0.9953917
  0.4  2          0.8               1.00       150      0.6981483  0.05636364  0.9953917
  0.4  3          0.6               0.50        50      0.6490197  0.00000000  0.9990783
  0.4  3          0.6               0.50       100      0.6610557  0.00000000  0.9990783
  0.4  3          0.6               0.50       150      0.6852870  0.00000000  0.9981567
  0.4  3          0.6               0.75        50      0.7086804  0.00000000  0.9963134
  0.4  3          0.6               0.75       100      0.7036866  0.01818182  0.9953917
  0.4  3          0.6               0.75       150      0.7057101  0.01818182  0.9953917
  0.4  3          0.6               1.00        50      0.7167323  0.03636364  0.9953917
  0.4  3          0.6               1.00       100      0.7173230  0.03636364  0.9953917
  0.4  3          0.6               1.00       150      0.7211688  0.03636364  0.9963134
  0.4  3          0.8               0.50        50      0.6526896  0.00000000  1.0000000
  0.4  3          0.8               0.50       100      0.6829703  0.00000000  1.0000000
  0.4  3          0.8               0.50       150      0.6570214  0.00000000  1.0000000
  0.4  3          0.8               0.75        50      0.6807667  0.01818182  0.9972350
  0.4  3          0.8               0.75       100      0.6657729  0.01818182  0.9972350
  0.4  3          0.8               0.75       150      0.6761248  0.01818182  0.9972350
  0.4  3          0.8               1.00        50      0.6974361  0.03818182  0.9953917
  0.4  3          0.8               1.00       100      0.7055048  0.05636364  0.9972350
  0.4  3          0.8               1.00       150      0.7047675  0.03636364  0.9972350

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.2      0.4
  positive      4.4     95.1
                            
 Accuracy (average) : 0.9525

[1] "TRAIN accuracy: 0.952506596306069"
[1] "TRAIN +precision: 0.95579133510168"
[1] "TRAIN -precision: 0.333333333333333"
[1] "TRAIN specifity: 0.0384615384615385"
[1] "TRAIN sensitivity: 0.9963133640553"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        3
            positive       15      359
[1] "TEST accuracy: 0.952506596306069"
[1] "TEST +precision: 0.959893048128342"
[1] "TEST -precision: 0.4"
[1] "TEST specifity: 0.117647058823529"
[1] "TEST sensitivity: 0.99171270718232"
