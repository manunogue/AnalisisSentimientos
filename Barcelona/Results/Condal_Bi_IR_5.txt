[1] "DATASET NAME: Condal_Bi_IR_5"
[1] "TRAIN INSTANCES: 2819"
[1] "TEST INSTANCES: 795"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 8.24229216575623"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

2819 samples
 720 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2255, 2254, 2256, 2255, 2256 
Resampling results:

  ROC        Sens       Spec     
  0.9956961  0.9630309  0.9868267

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.5      1.1
  positive      0.7     79.7
                            
 Accuracy (average) : 0.9823

[1] "TRAIN accuracy: 0.98226321390564"
[1] "TRAIN +precision: 0.991181657848324"
[1] "TRAIN -precision: 0.945553539019964"
[1] "TRAIN specifity: 0.963031423290203"
[1] "TRAIN sensitivity: 0.986830553116769"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       16        7
            positive       30      742
[1] "TEST accuracy: 0.953459119496855"
[1] "TEST +precision: 0.961139896373057"
[1] "TEST -precision: 0.695652173913043"
[1] "TEST specifity: 0.347826086956522"
[1] "TEST sensitivity: 0.990654205607477"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 4.87068186601003"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

2819 samples
 720 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2256, 2255, 2255, 2256, 2254 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7665207  0.4232756  0.9859476
  0.010  2  0.7508900  0.3992525  0.9859476
  0.010  3  0.7264721  0.3696228  0.9907798
  0.255  1  0.8673930  0.5175331  0.9811230
  0.255  2  0.8591125  0.5027693  0.9846376
  0.255  3  0.8605766  0.4861026  0.9890245
  0.500  1  0.9004694  0.5286103  0.9824407
  0.500  2  0.8931764  0.5101427  0.9881463
  0.500  3  0.8861345  0.4953279  0.9899026

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.1      1.4
  positive      9.0     79.4
                            
 Accuracy (average) : 0.8954

[1] "TRAIN accuracy: 0.895352962043278"
[1] "TRAIN +precision: 0.897713598074609"
[1] "TRAIN -precision: 0.877300613496933"
[1] "TRAIN specifity: 0.528650646950092"
[1] "TRAIN sensitivity: 0.982440737489025"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        9
            positive       41      740
[1] "TEST accuracy: 0.937106918238994"
[1] "TEST +precision: 0.947503201024328"
[1] "TEST -precision: 0.357142857142857"
[1] "TEST specifity: 0.108695652173913"
[1] "TEST sensitivity: 0.987983978638184"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 10.9321509480476"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

2819 samples
 720 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2255, 2255, 2255, 2255, 2256 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8766308  0.2180258  0.9995604
  0.3  1          0.6               0.50       100      0.9279516  0.4269113  0.9956083
  0.3  1          0.6               0.50       150      0.9472645  0.5618417  0.9925361
  0.3  1          0.6               0.75        50      0.8801816  0.2641182  1.0000000
  0.3  1          0.6               0.75       100      0.9374376  0.4842508  0.9973636
  0.3  1          0.6               0.75       150      0.9488100  0.5877336  0.9956083
  0.3  1          0.6               1.00        50      0.8805696  0.2772001  1.0000000
  0.3  1          0.6               1.00       100      0.9360999  0.4878865  0.9969240
  0.3  1          0.6               1.00       150      0.9483215  0.5877336  0.9951677
  0.3  1          0.8               0.50        50      0.8795296  0.1995923  0.9995614
  0.3  1          0.8               0.50       100      0.9330093  0.4879205  0.9956092
  0.3  1          0.8               0.50       150      0.9471734  0.5544512  0.9920985
  0.3  1          0.8               0.75        50      0.8893985  0.2347604  0.9995604
  0.3  1          0.8               0.75       100      0.9409290  0.4822970  0.9969250
  0.3  1          0.8               0.75       150      0.9505268  0.5988787  0.9934133
  0.3  1          0.8               1.00        50      0.8815754  0.2679579  0.9991218
  0.3  1          0.8               1.00       100      0.9350109  0.4860177  0.9964854
  0.3  1          0.8               1.00       150      0.9495224  0.5914373  0.9951677
  0.3  2          0.6               0.50        50      0.9297224  0.4490996  0.9960478
  0.3  2          0.6               0.50       100      0.9584719  0.6228848  0.9916599
  0.3  2          0.6               0.50       150      0.9679860  0.7097689  0.9885840
  0.3  2          0.6               0.75        50      0.9362957  0.4713048  0.9964845
  0.3  2          0.6               0.75       100      0.9594166  0.6580020  0.9925342
  0.3  2          0.6               0.75       150      0.9722087  0.7190792  0.9907818
  0.3  2          0.6               1.00        50      0.9360194  0.4989297  0.9969240
  0.3  2          0.6               1.00       100      0.9614251  0.6635916  0.9942896
  0.3  2          0.6               1.00       150      0.9721672  0.7300883  0.9929738
  0.3  2          0.8               0.50        50      0.9297665  0.4582909  0.9956102
  0.3  2          0.8               0.50       100      0.9618088  0.6266055  0.9885878
  0.3  2          0.8               0.50       150      0.9698047  0.7411995  0.9894660
  0.3  2          0.8               0.75        50      0.9365801  0.4564560  0.9956083
  0.3  2          0.8               0.75       100      0.9605416  0.6653755  0.9916580
  0.3  2          0.8               0.75       150      0.9714789  0.7375297  0.9903412
  0.3  2          0.8               1.00        50      0.9414228  0.4878525  0.9964854
  0.3  2          0.8               1.00       100      0.9624778  0.6414033  0.9951687
  0.3  2          0.8               1.00       150      0.9735282  0.7153585  0.9938519
  0.3  3          0.6               0.50        50      0.9461680  0.5563371  0.9938539
  0.3  3          0.6               0.50       100      0.9664827  0.7097859  0.9899036
  0.3  3          0.6               0.50       150      0.9734343  0.8003568  0.9859505
  0.3  3          0.6               0.75        50      0.9541220  0.5803432  0.9942915
  0.3  3          0.6               0.75       100      0.9735394  0.7319572  0.9899026
  0.3  3          0.6               0.75       150      0.9788409  0.8059123  0.9899036
  0.3  3          0.6               1.00        50      0.9561358  0.6099218  0.9969240
  0.3  3          0.6               1.00       100      0.9767517  0.7578152  0.9938529
  0.3  3          0.6               1.00       150      0.9829817  0.8021747  0.9925381
  0.3  3          0.8               0.50        50      0.9486406  0.5692661  0.9942905
  0.3  3          0.8               0.50       100      0.9705443  0.7394495  0.9890216
  0.3  3          0.8               0.50       150      0.9740571  0.8097010  0.9855099
  0.3  3          0.8               0.75        50      0.9523830  0.6044512  0.9938519
  0.3  3          0.8               0.75       100      0.9742609  0.7411825  0.9916599
  0.3  3          0.8               0.75       150      0.9776883  0.8170404  0.9907808
  0.3  3          0.8               1.00        50      0.9544924  0.5969589  0.9956073
  0.3  3          0.8               1.00       100      0.9766371  0.7319232  0.9925352
  0.3  3          0.8               1.00       150      0.9834873  0.8077642  0.9912204
  0.4  1          0.6               0.50        50      0.8983963  0.3935780  0.9991218
  0.4  1          0.6               0.50       100      0.9379638  0.5433571  0.9929786
  0.4  1          0.6               0.50       150      0.9543157  0.6321441  0.9877097
  0.4  1          0.6               0.75        50      0.8962617  0.3825518  0.9964864
  0.4  1          0.6               0.75       100      0.9452406  0.5544003  0.9925342
  0.4  1          0.6               0.75       150      0.9561510  0.6672783  0.9907789
  0.4  1          0.6               1.00        50      0.9056871  0.3733265  0.9982418
  0.4  1          0.6               1.00       100      0.9454206  0.5636595  0.9956063
  0.4  1          0.6               1.00       150      0.9569205  0.6561672  0.9929728
  0.4  1          0.8               0.50        50      0.8961283  0.3843357  0.9956073
  0.4  1          0.8               0.50       100      0.9411581  0.5193680  0.9916561
  0.4  1          0.8               0.50       150      0.9568878  0.6283894  0.9877068
  0.4  1          0.8               0.75        50      0.8971356  0.3917431  0.9969260
  0.4  1          0.8               0.75       100      0.9480384  0.5711179  0.9929738
  0.4  1          0.8               0.75       150      0.9581680  0.6598879  0.9903412
  0.4  1          0.8               1.00        50      0.9056150  0.3954298  0.9991209
  0.4  1          0.8               1.00       100      0.9449798  0.5765715  0.9951677
  0.4  1          0.8               1.00       150      0.9582383  0.6580530  0.9934124
  0.4  2          0.6               0.50        50      0.9409320  0.4989127  0.9916580
  0.4  2          0.6               0.50       100      0.9659924  0.7134557  0.9907798
  0.4  2          0.6               0.50       150      0.9712420  0.7893306  0.9877077
  0.4  2          0.6               0.75        50      0.9482009  0.5581210  0.9947311
  0.4  2          0.6               0.75       100      0.9671008  0.7282705  0.9894631
  0.4  2          0.6               0.75       150      0.9750256  0.7911145  0.9877077
  0.4  2          0.6               1.00        50      0.9464520  0.5711179  0.9951677
  0.4  2          0.6               1.00       100      0.9689434  0.7134896  0.9947291
  0.4  2          0.6               1.00       150      0.9796063  0.7818722  0.9934124
  0.4  2          0.8               0.50        50      0.9379629  0.5636765  0.9934143
  0.4  2          0.8               0.50       100      0.9669542  0.6987088  0.9899026
  0.4  2          0.8               0.50       150      0.9721177  0.7799864  0.9868305
  0.4  2          0.8               0.75        50      0.9410205  0.5673632  0.9925371
  0.4  2          0.8               0.75       100      0.9674761  0.7190452  0.9903403
  0.4  2          0.8               0.75       150      0.9749634  0.7985049  0.9885849
  0.4  2          0.8               1.00        50      0.9465711  0.5673802  0.9951677
  0.4  2          0.8               1.00       100      0.9690745  0.7300714  0.9920966
  0.4  2          0.8               1.00       150      0.9792601  0.7910975  0.9903422
  0.4  3          0.6               0.50        50      0.9535510  0.6229188  0.9920985
  0.4  3          0.6               0.50       100      0.9716392  0.8003908  0.9863890
  0.4  3          0.6               0.50       150      0.9759589  0.8262827  0.9841922
  0.4  3          0.6               0.75        50      0.9616186  0.6654094  0.9903422
  0.4  3          0.6               0.75       100      0.9760783  0.7837241  0.9890235
  0.4  3          0.6               0.75       150      0.9801307  0.8465851  0.9837555
  0.4  3          0.6               1.00        50      0.9629063  0.6580020  0.9964864
  0.4  3          0.6               1.00       100      0.9808403  0.7836901  0.9938529
  0.4  3          0.6               1.00       150      0.9849562  0.8373259  0.9903403
  0.4  3          0.8               0.50        50      0.9569969  0.6246687  0.9916570
  0.4  3          0.8               0.50       100      0.9714686  0.7893306  0.9868315
  0.4  3          0.8               0.50       150      0.9755422  0.8336052  0.9841941
  0.4  3          0.8               0.75        50      0.9596197  0.6838770  0.9929738
  0.4  3          0.8               0.75       100      0.9755359  0.8040265  0.9885859
  0.4  3          0.8               0.75       150      0.9799083  0.8539925  0.9872701
  0.4  3          0.8               1.00        50      0.9660910  0.6764866  0.9956083
  0.4  3          0.8               1.00       100      0.9823965  0.7948182  0.9916599
  0.4  3          0.8               1.00       150      0.9861298  0.8447503  0.9872701

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     16.2      1.0
  positive      3.0     79.8
                            
 Accuracy (average) : 0.9599

[1] "TRAIN accuracy: 0.959914863426747"
[1] "TRAIN +precision: 0.963994856408058"
[1] "TRAIN -precision: 0.940329218106996"
[1] "TRAIN specifity: 0.844731977818854"
[1] "TRAIN sensitivity: 0.987269534679543"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       14        4
            positive       32      745
[1] "TEST accuracy: 0.954716981132075"
[1] "TEST +precision: 0.958815958815959"
[1] "TEST -precision: 0.777777777777778"
[1] "TEST specifity: 0.304347826086957"
[1] "TEST sensitivity: 0.994659546061415"
