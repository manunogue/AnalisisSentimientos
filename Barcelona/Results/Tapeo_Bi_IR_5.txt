[1] "DATASET NAME: Tapeo_Bi_IR_5"
[1] "TRAIN INSTANCES: 1180"
[1] "TEST INSTANCES: 333"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.94012308120728"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1180 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 944, 944, 944, 945, 943 
Resampling results:

  ROC        Sens       Spec     
  0.9979837  0.9774747  0.9937391

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.3      0.5
  positive      0.4     80.8
                            
 Accuracy (average) : 0.9907

[1] "TRAIN accuracy: 0.990677966101695"
[1] "TRAIN +precision: 0.994780793319415"
[1] "TRAIN -precision: 0.972972972972973"
[1] "TRAIN specifity: 0.97737556561086"
[1] "TRAIN sensitivity: 0.993743482794578"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        3
            positive        7      321
[1] "TEST accuracy: 0.96996996996997"
[1] "TEST +precision: 0.978658536585366"
[1] "TEST -precision: 0.4"
[1] "TEST specifity: 0.222222222222222"
[1] "TEST sensitivity: 0.990740740740741"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.33972154855728"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1180 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 944, 944, 945, 944, 943 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.6536020  0.2308081  0.9947862
  0.010  2  0.6536020  0.2308081  0.9947862
  0.010  3  0.6333492  0.2080808  0.9979112
  0.255  1  0.7484338  0.3302020  0.9968695
  0.255  2  0.7484338  0.3302020  0.9968695
  0.255  3  0.7191504  0.2939394  0.9968695
  0.500  1  0.7650681  0.3302020  0.9968695
  0.500  2  0.7650681  0.3302020  0.9968695
  0.500  3  0.7607441  0.3166667  0.9968695

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      6.2      0.3
  positive     12.5     81.0
                           
 Accuracy (average) : 0.872

[1] "TRAIN accuracy: 0.872033898305085"
[1] "TRAIN +precision: 0.865942028985507"
[1] "TRAIN -precision: 0.960526315789474"
[1] "TRAIN specifity: 0.330316742081448"
[1] "TRAIN sensitivity: 0.996871741397289"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        4
            positive        9      320
[1] "TEST accuracy: 0.960960960960961"
[1] "TEST +precision: 0.972644376899696"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.987654320987654"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.81252421538035"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1180 samples
 622 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 944, 944, 944, 943, 945 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9140422  0.3715152  0.9895779
  0.3  1          0.6               0.50       100      0.9490868  0.5973737  0.9885308
  0.3  1          0.6               0.50       150      0.9535044  0.7152525  0.9864474
  0.3  1          0.6               0.75        50      0.9334799  0.3758586  0.9927029
  0.3  1          0.6               0.75       100      0.9567806  0.6248485  0.9874891
  0.3  1          0.6               0.75       150      0.9628844  0.7872727  0.9854058
  0.3  1          0.6               1.00        50      0.9372683  0.4258586  0.9916612
  0.3  1          0.6               1.00       100      0.9568576  0.6110101  0.9885362
  0.3  1          0.6               1.00       150      0.9650861  0.7331313  0.9885308
  0.3  1          0.8               0.50        50      0.9168113  0.3526263  0.9927029
  0.3  1          0.8               0.50       100      0.9481096  0.5978788  0.9895724
  0.3  1          0.8               0.50       150      0.9545896  0.7197980  0.9864474
  0.3  1          0.8               0.75        50      0.9322408  0.3985859  0.9927083
  0.3  1          0.8               0.75       100      0.9563999  0.6335354  0.9885362
  0.3  1          0.8               0.75       150      0.9638058  0.7920202  0.9895779
  0.3  1          0.8               1.00        50      0.9318279  0.3985859  0.9906195
  0.3  1          0.8               1.00       100      0.9583571  0.6111111  0.9854058
  0.3  1          0.8               1.00       150      0.9677753  0.7331313  0.9885308
  0.3  2          0.6               0.50        50      0.9524691  0.5746465  0.9906141
  0.3  2          0.6               0.50       100      0.9649623  0.7692929  0.9895779
  0.3  2          0.6               0.50       150      0.9690618  0.8415152  0.9854003
  0.3  2          0.6               0.75        50      0.9638703  0.6515152  0.9874945
  0.3  2          0.6               0.75       100      0.9707466  0.8687879  0.9854058
  0.3  2          0.6               0.75       150      0.9737400  0.8824242  0.9885362
  0.3  2          0.6               1.00        50      0.9610022  0.6292929  0.9885362
  0.3  2          0.6               1.00       100      0.9710150  0.8415152  0.9895779
  0.3  2          0.6               1.00       150      0.9769091  0.8596970  0.9906195
  0.3  2          0.8               0.50        50      0.9461895  0.6379798  0.9916612
  0.3  2          0.8               0.50       100      0.9596446  0.7827273  0.9874891
  0.3  2          0.8               0.50       150      0.9618009  0.8416162  0.9854058
  0.3  2          0.8               0.75        50      0.9661893  0.6201010  0.9895724
  0.3  2          0.8               0.75       100      0.9720073  0.8642424  0.9864420
  0.3  2          0.8               0.75       150      0.9744699  0.8915152  0.9854003
  0.3  2          0.8               1.00        50      0.9621968  0.6428283  0.9864474
  0.3  2          0.8               1.00       100      0.9754876  0.8551515  0.9874891
  0.3  2          0.8               1.00       150      0.9793795  0.8778788  0.9885308
  0.3  3          0.6               0.50        50      0.9641868  0.6561616  0.9874836
  0.3  3          0.6               0.50       100      0.9683763  0.8009091  0.9864420
  0.3  3          0.6               0.50       150      0.9676612  0.8281818  0.9843586
  0.3  3          0.6               0.75        50      0.9624327  0.7603030  0.9874891
  0.3  3          0.6               0.75       100      0.9722154  0.8600000  0.9885362
  0.3  3          0.6               0.75       150      0.9737922  0.8868687  0.9864529
  0.3  3          0.6               1.00        50      0.9730508  0.7648485  0.9885308
  0.3  3          0.6               1.00       100      0.9802964  0.8823232  0.9885362
  0.3  3          0.6               1.00       150      0.9820872  0.9005051  0.9854058
  0.3  3          0.8               0.50        50      0.9613520  0.7333333  0.9864474
  0.3  3          0.8               0.50       100      0.9687049  0.8190909  0.9864474
  0.3  3          0.8               0.50       150      0.9696610  0.8372727  0.9822753
  0.3  3          0.8               0.75        50      0.9686381  0.7918182  0.9885308
  0.3  3          0.8               0.75       100      0.9754828  0.8824242  0.9874891
  0.3  3          0.8               0.75       150      0.9765197  0.9005051  0.9833224
  0.3  3          0.8               1.00        50      0.9705897  0.7694949  0.9895779
  0.3  3          0.8               1.00       100      0.9788902  0.8778788  0.9906195
  0.3  3          0.8               1.00       150      0.9811150  0.9050505  0.9854112
  0.4  1          0.6               0.50        50      0.9314206  0.4935354  0.9885308
  0.4  1          0.6               0.50       100      0.9559432  0.7328283  0.9895724
  0.4  1          0.6               0.50       150      0.9636748  0.7739394  0.9843641
  0.4  1          0.6               0.75        50      0.9410545  0.4846465  0.9885362
  0.4  1          0.6               0.75       100      0.9577938  0.6967677  0.9874891
  0.4  1          0.6               0.75       150      0.9632895  0.8324242  0.9864474
  0.4  1          0.6               1.00        50      0.9491250  0.4845455  0.9895833
  0.4  1          0.6               1.00       100      0.9663486  0.6971717  0.9885308
  0.4  1          0.6               1.00       150      0.9717443  0.8097980  0.9885308
  0.4  1          0.8               0.50        50      0.9298394  0.4616162  0.9854058
  0.4  1          0.8               0.50       100      0.9488544  0.7013131  0.9854058
  0.4  1          0.8               0.50       150      0.9557824  0.7738384  0.9833224
  0.4  1          0.8               0.75        50      0.9422525  0.5205051  0.9885362
  0.4  1          0.8               0.75       100      0.9603431  0.7149495  0.9864474
  0.4  1          0.8               0.75       150      0.9634708  0.8325253  0.9874945
  0.4  1          0.8               1.00        50      0.9446846  0.4708081  0.9895779
  0.4  1          0.8               1.00       100      0.9628171  0.6835354  0.9885308
  0.4  1          0.8               1.00       150      0.9689147  0.7874747  0.9885308
  0.4  2          0.6               0.50        50      0.9528525  0.6561616  0.9895724
  0.4  2          0.6               0.50       100      0.9628180  0.8052525  0.9864474
  0.4  2          0.6               0.50       150      0.9643960  0.8188889  0.9885362
  0.4  2          0.6               0.75        50      0.9594621  0.7106061  0.9854058
  0.4  2          0.6               0.75       100      0.9671652  0.8733333  0.9854058
  0.4  2          0.6               0.75       150      0.9714045  0.8868687  0.9833115
  0.4  2          0.6               1.00        50      0.9655162  0.7152525  0.9885362
  0.4  2          0.6               1.00       100      0.9750316  0.8596970  0.9906195
  0.4  2          0.6               1.00       150      0.9777819  0.8914141  0.9885362
  0.4  2          0.8               0.50        50      0.9489642  0.6743434  0.9895724
  0.4  2          0.8               0.50       100      0.9605014  0.8188889  0.9874891
  0.4  2          0.8               0.50       150      0.9623413  0.8415152  0.9864420
  0.4  2          0.8               0.75        50      0.9662227  0.7513131  0.9874891
  0.4  2          0.8               0.75       100      0.9694858  0.8642424  0.9864474
  0.4  2          0.8               0.75       150      0.9715641  0.8778788  0.9874945
  0.4  2          0.8               1.00        50      0.9668553  0.7105051  0.9854058
  0.4  2          0.8               1.00       100      0.9768730  0.8733333  0.9895779
  0.4  2          0.8               1.00       150      0.9777810  0.9050505  0.9864529
  0.4  3          0.6               0.50        50      0.9638010  0.7555556  0.9864474
  0.4  3          0.6               0.50       100      0.9682844  0.8551515  0.9864474
  0.4  3          0.6               0.50       150      0.9701474  0.8687879  0.9854058
  0.4  3          0.6               0.75        50      0.9709171  0.8415152  0.9874891
  0.4  3          0.6               0.75       100      0.9739388  0.8868687  0.9854003
  0.4  3          0.6               0.75       150      0.9750494  0.8914141  0.9833170
  0.4  3          0.6               1.00        50      0.9787853  0.8597980  0.9885362
  0.4  3          0.6               1.00       100      0.9831961  0.9186869  0.9843641
  0.4  3          0.6               1.00       150      0.9844625  0.9232323  0.9854058
  0.4  3          0.8               0.50        50      0.9564003  0.7872727  0.9854003
  0.4  3          0.8               0.50       100      0.9633943  0.8369697  0.9833170
  0.4  3          0.8               0.50       150      0.9634376  0.8459596  0.9854058
  0.4  3          0.8               0.75        50      0.9659859  0.8596970  0.9895779
  0.4  3          0.8               0.75       100      0.9718797  0.8868687  0.9843695
  0.4  3          0.8               0.75       150      0.9735351  0.8914141  0.9833279
  0.4  3          0.8               1.00        50      0.9756782  0.8687879  0.9885362
  0.4  3          0.8               1.00       100      0.9796928  0.9050505  0.9843695
  0.4  3          0.8               1.00       150      0.9815754  0.9050505  0.9822808

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     17.3      1.2
  positive      1.4     80.1
                            
 Accuracy (average) : 0.9737

[1] "TRAIN accuracy: 0.973728813559322"
[1] "TRAIN +precision: 0.982328482328482"
[1] "TRAIN -precision: 0.935779816513762"
[1] "TRAIN specifity: 0.923076923076923"
[1] "TRAIN sensitivity: 0.985401459854015"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        4
            positive        7      320
[1] "TEST accuracy: 0.966966966966967"
[1] "TEST +precision: 0.978593272171254"
[1] "TEST -precision: 0.333333333333333"
[1] "TEST specifity: 0.222222222222222"
[1] "TEST sensitivity: 0.987654320987654"
