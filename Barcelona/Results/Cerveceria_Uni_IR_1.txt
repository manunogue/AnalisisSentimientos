[1] "DATASET NAME: Cerveceria_Uni_IR_1"
[1] "TRAIN INSTANCES: 5500"
[1] "TEST INSTANCES: 968"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 50.8536500930786"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

5500 samples
 654 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 4400, 4400, 4400, 4400, 4400 
Resampling results:

  ROC        Sens  Spec     
  0.9976655  1     0.9887273

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.6
  positive      0.0     49.4
                            
 Accuracy (average) : 0.9944

[1] "TRAIN accuracy: 0.994363636363636"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.988852930600503"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.988727272727273"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       21       11
            positive       25      911
[1] "TEST accuracy: 0.962809917355372"
[1] "TEST +precision: 0.973290598290598"
[1] "TEST -precision: 0.65625"
[1] "TEST specifity: 0.456521739130435"
[1] "TEST sensitivity: 0.988069414316703"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 9.6845467487971"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

5500 samples
 654 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 4400, 4400, 4400, 4400, 4400 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.9758317  1     0.9483636
  0.010  2  0.9768691  1     0.9480000
  0.010  3  0.9767203  1     0.9454545
  0.255  1  0.9810486  1     0.9549091
  0.255  2  0.9821511  1     0.9545455
  0.255  3  0.9796255  1     0.9523636
  0.500  1  0.9828099  1     0.9574545
  0.500  2  0.9838955  1     0.9570909
  0.500  3  0.9808701  1     0.9541818

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      2.1
  positive      0.0     47.9
                            
 Accuracy (average) : 0.9785

[1] "TRAIN accuracy: 0.978545454545454"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.958856345885635"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.957090909090909"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       18       30
            positive       28      892
[1] "TEST accuracy: 0.940082644628099"
[1] "TEST +precision: 0.969565217391304"
[1] "TEST -precision: 0.375"
[1] "TEST specifity: 0.391304347826087"
[1] "TEST sensitivity: 0.967462039045553"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 18.0373593489329"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

5500 samples
 654 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 4400, 4400, 4400, 4400, 4400 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9599223  0.8658182  0.9050909
  0.3  1          0.6               0.50       100      0.9804162  0.9272727  0.9265455
  0.3  1          0.6               0.50       150      0.9868902  0.9650909  0.9345455
  0.3  1          0.6               0.75        50      0.9597603  0.8465455  0.9123636
  0.3  1          0.6               0.75       100      0.9810734  0.9167273  0.9334545
  0.3  1          0.6               0.75       150      0.9873980  0.9498182  0.9396364
  0.3  1          0.6               1.00        50      0.9601848  0.8614545  0.9109091
  0.3  1          0.6               1.00       100      0.9808165  0.9196364  0.9352727
  0.3  1          0.6               1.00       150      0.9877352  0.9436364  0.9469091
  0.3  1          0.8               0.50        50      0.9595481  0.8774545  0.8952727
  0.3  1          0.8               0.50       100      0.9809299  0.9432727  0.9229091
  0.3  1          0.8               0.50       150      0.9874740  0.9640000  0.9316364
  0.3  1          0.8               0.75        50      0.9602807  0.8749091  0.8981818
  0.3  1          0.8               0.75       100      0.9816046  0.9229091  0.9341818
  0.3  1          0.8               0.75       150      0.9884195  0.9632727  0.9458182
  0.3  1          0.8               1.00        50      0.9610152  0.8618182  0.9181818
  0.3  1          0.8               1.00       100      0.9810621  0.9141818  0.9374545
  0.3  1          0.8               1.00       150      0.9875613  0.9541818  0.9440000
  0.3  2          0.6               0.50        50      0.9857818  0.9483636  0.9276364
  0.3  2          0.6               0.50       100      0.9947154  0.9923636  0.9578182
  0.3  2          0.6               0.50       150      0.9963722  1.0000000  0.9632727
  0.3  2          0.6               0.75        50      0.9864817  0.9461818  0.9381818
  0.3  2          0.6               0.75       100      0.9945174  0.9956364  0.9585455
  0.3  2          0.6               0.75       150      0.9959365  0.9985455  0.9665455
  0.3  2          0.6               1.00        50      0.9867137  0.9538182  0.9298182
  0.3  2          0.6               1.00       100      0.9949306  0.9945455  0.9570909
  0.3  2          0.6               1.00       150      0.9965104  1.0000000  0.9654545
  0.3  2          0.8               0.50        50      0.9860496  0.9494545  0.9312727
  0.3  2          0.8               0.50       100      0.9943253  0.9941818  0.9534545
  0.3  2          0.8               0.50       150      0.9960721  0.9985455  0.9650909
  0.3  2          0.8               0.75        50      0.9868278  0.9436364  0.9338182
  0.3  2          0.8               0.75       100      0.9946909  0.9938182  0.9534545
  0.3  2          0.8               0.75       150      0.9961514  0.9985455  0.9658182
  0.3  2          0.8               1.00        50      0.9861167  0.9523636  0.9330909
  0.3  2          0.8               1.00       100      0.9948017  0.9912727  0.9618182
  0.3  2          0.8               1.00       150      0.9964383  1.0000000  0.9625455
  0.3  3          0.6               0.50        50      0.9935848  0.9909091  0.9501818
  0.3  3          0.6               0.50       100      0.9970321  1.0000000  0.9676364
  0.3  3          0.6               0.50       150      0.9975021  1.0000000  0.9763636
  0.3  3          0.6               0.75        50      0.9954334  0.9901818  0.9545455
  0.3  3          0.6               0.75       100      0.9980754  1.0000000  0.9709091
  0.3  3          0.6               0.75       150      0.9983319  1.0000000  0.9752727
  0.3  3          0.6               1.00        50      0.9949365  0.9912727  0.9563636
  0.3  3          0.6               1.00       100      0.9975531  1.0000000  0.9749091
  0.3  3          0.6               1.00       150      0.9982288  1.0000000  0.9770909
  0.3  3          0.8               0.50        50      0.9949226  0.9905455  0.9512727
  0.3  3          0.8               0.50       100      0.9974830  0.9985455  0.9712727
  0.3  3          0.8               0.50       150      0.9977263  1.0000000  0.9767273
  0.3  3          0.8               0.75        50      0.9947749  0.9890909  0.9512727
  0.3  3          0.8               0.75       100      0.9977098  1.0000000  0.9734545
  0.3  3          0.8               0.75       150      0.9981164  1.0000000  0.9789091
  0.3  3          0.8               1.00        50      0.9951940  0.9941818  0.9607273
  0.3  3          0.8               1.00       100      0.9973177  1.0000000  0.9716364
  0.3  3          0.8               1.00       150      0.9980502  1.0000000  0.9770909
  0.4  1          0.6               0.50        50      0.9676446  0.8741818  0.9134545
  0.4  1          0.6               0.50       100      0.9851990  0.9549091  0.9316364
  0.4  1          0.6               0.50       150      0.9908261  0.9829091  0.9440000
  0.4  1          0.6               0.75        50      0.9696407  0.8840000  0.9236364
  0.4  1          0.6               0.75       100      0.9861626  0.9509091  0.9421818
  0.4  1          0.6               0.75       150      0.9904783  0.9821818  0.9458182
  0.4  1          0.6               1.00        50      0.9688083  0.8858182  0.9240000
  0.4  1          0.6               1.00       100      0.9861583  0.9396364  0.9418182
  0.4  1          0.6               1.00       150      0.9907081  0.9778182  0.9512727
  0.4  1          0.8               0.50        50      0.9706155  0.8967273  0.9170909
  0.4  1          0.8               0.50       100      0.9860393  0.9632727  0.9294545
  0.4  1          0.8               0.50       150      0.9904932  0.9832727  0.9432727
  0.4  1          0.8               0.75        50      0.9708651  0.8963636  0.9160000
  0.4  1          0.8               0.75       100      0.9863633  0.9541818  0.9341818
  0.4  1          0.8               0.75       150      0.9910952  0.9723636  0.9494545
  0.4  1          0.8               1.00        50      0.9697504  0.8843636  0.9305455
  0.4  1          0.8               1.00       100      0.9861937  0.9487273  0.9421818
  0.4  1          0.8               1.00       150      0.9904684  0.9730909  0.9483636
  0.4  2          0.6               0.50        50      0.9896198  0.9701818  0.9352727
  0.4  2          0.6               0.50       100      0.9953137  0.9970909  0.9610909
  0.4  2          0.6               0.50       150      0.9967894  1.0000000  0.9698182
  0.4  2          0.6               0.75        50      0.9903342  0.9690909  0.9407273
  0.4  2          0.6               0.75       100      0.9955074  0.9985455  0.9610909
  0.4  2          0.6               0.75       150      0.9969620  0.9985455  0.9680000
  0.4  2          0.6               1.00        50      0.9897964  0.9705455  0.9429091
  0.4  2          0.6               1.00       100      0.9955094  0.9963636  0.9618182
  0.4  2          0.6               1.00       150      0.9969864  1.0000000  0.9683636
  0.4  2          0.8               0.50        50      0.9900731  0.9789091  0.9392727
  0.4  2          0.8               0.50       100      0.9961117  0.9985455  0.9618182
  0.4  2          0.8               0.50       150      0.9969693  1.0000000  0.9694545
  0.4  2          0.8               0.75        50      0.9908790  0.9778182  0.9443636
  0.4  2          0.8               0.75       100      0.9964602  1.0000000  0.9632727
  0.4  2          0.8               0.75       150      0.9974565  1.0000000  0.9690909
  0.4  2          0.8               1.00        50      0.9912767  0.9803636  0.9480000
  0.4  2          0.8               1.00       100      0.9964463  0.9956364  0.9632727
  0.4  2          0.8               1.00       150      0.9977124  1.0000000  0.9705455
  0.4  3          0.6               0.50        50      0.9964740  0.9970909  0.9560000
  0.4  3          0.6               0.50       100      0.9981745  1.0000000  0.9752727
  0.4  3          0.6               0.50       150      0.9984046  1.0000000  0.9821818
  0.4  3          0.6               0.75        50      0.9959775  0.9960000  0.9596364
  0.4  3          0.6               0.75       100      0.9980192  1.0000000  0.9727273
  0.4  3          0.6               0.75       150      0.9983121  1.0000000  0.9767273
  0.4  3          0.6               1.00        50      0.9966314  0.9981818  0.9589091
  0.4  3          0.6               1.00       100      0.9983980  1.0000000  0.9741818
  0.4  3          0.6               1.00       150      0.9986202  1.0000000  0.9810909
  0.4  3          0.8               0.50        50      0.9962466  0.9978182  0.9585455
  0.4  3          0.8               0.50       100      0.9979861  1.0000000  0.9723636
  0.4  3          0.8               0.50       150      0.9984542  1.0000000  0.9774545
  0.4  3          0.8               0.75        50      0.9969693  0.9960000  0.9625455
  0.4  3          0.8               0.75       100      0.9985917  1.0000000  0.9767273
  0.4  3          0.8               0.75       150      0.9986506  1.0000000  0.9800000
  0.4  3          0.8               1.00        50      0.9965514  0.9970909  0.9607273
  0.4  3          0.8               1.00       100      0.9980674  1.0000000  0.9745455
  0.4  3          0.8               1.00       150      0.9984086  1.0000000  0.9810909

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative       50        1
  positive        0       49
                          
 Accuracy (average) : 0.99

[1] "TRAIN accuracy: 0.99"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.980392156862745"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.98"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       33       17
            positive       13      905
[1] "TEST accuracy: 0.96900826446281"
[1] "TEST +precision: 0.985838779956427"
[1] "TEST -precision: 0.66"
[1] "TEST specifity: 0.717391304347826"
[1] "TEST sensitivity: 0.981561822125813"
