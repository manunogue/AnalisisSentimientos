[1] "DATASET NAME: HRB_Bi_IR_5"
[1] "TRAIN INSTANCES: 1135"
[1] "TEST INSTANCES: 332"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 4.01756501197815"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1135 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 907, 909, 907, 908, 909 
Resampling results:

  ROC        Sens       Spec     
  0.9632537  0.8404114  0.9657988

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     21.3      2.6
  positive      4.1     72.1
                            
 Accuracy (average) : 0.9339

[1] "TRAIN accuracy: 0.933920704845815"
[1] "TRAIN +precision: 0.946759259259259"
[1] "TRAIN -precision: 0.892988929889299"
[1] "TRAIN specifity: 0.840277777777778"
[1] "TRAIN sensitivity: 0.965761511216057"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       17        8
            positive       29      278
[1] "TEST accuracy: 0.88855421686747"
[1] "TEST +precision: 0.905537459283388"
[1] "TEST -precision: 0.68"
[1] "TEST specifity: 0.369565217391304"
[1] "TEST sensitivity: 0.972027972027972"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.17949816783269"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1135 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 907, 908, 908, 908, 909 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5851978  0.15269208  0.9905674
  0.010  2  0.5852588  0.15269208  0.9905674
  0.010  3  0.5358694  0.07271627  0.9929203
  0.255  1  0.7819318  0.43042952  0.9622276
  0.255  2  0.7439762  0.35759226  0.9693004
  0.255  3  0.7239949  0.30907441  0.9752245
  0.500  1  0.7998687  0.45136116  0.9586982
  0.500  2  0.7798166  0.38892922  0.9669405
  0.500  3  0.7450482  0.31941924  0.9704908

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.5      3.1
  positive     13.9     71.5
                          
 Accuracy (average) : 0.83

[1] "TRAIN accuracy: 0.829955947136564"
[1] "TRAIN +precision: 0.837113402061856"
[1] "TRAIN -precision: 0.787878787878788"
[1] "TRAIN specifity: 0.451388888888889"
[1] "TRAIN sensitivity: 0.958677685950413"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0       11
            positive       46      275
[1] "TEST accuracy: 0.828313253012048"
[1] "TEST +precision: 0.856697819314642"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.961538461538462"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.66450873215993"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1135 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 908, 908, 908, 909, 907 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.7954622  0.1493648  0.9929064
  0.3  1          0.6               0.50       100      0.8542340  0.2920145  0.9799234
  0.3  1          0.6               0.50       150      0.8771710  0.3853600  0.9752036
  0.3  1          0.6               0.75        50      0.8120871  0.1704779  0.9976331
  0.3  1          0.6               0.75       100      0.8573649  0.3194192  0.9834668
  0.3  1          0.6               0.75       150      0.8805348  0.3994555  0.9787400
  0.3  1          0.6               1.00        50      0.8209444  0.1390805  0.9952802
  0.3  1          0.6               1.00       100      0.8600404  0.2848155  0.9870101
  0.3  1          0.6               1.00       150      0.8818602  0.4027828  0.9846572
  0.3  1          0.8               0.50        50      0.8129770  0.1596491  0.9917369
  0.3  1          0.8               0.50       100      0.8541907  0.2881428  0.9846363
  0.3  1          0.8               0.50       150      0.8687215  0.3646098  0.9810860
  0.3  1          0.8               0.75        50      0.8094554  0.1563823  0.9929203
  0.3  1          0.8               0.75       100      0.8602861  0.3194797  0.9870101
  0.3  1          0.8               0.75       150      0.8752783  0.4028433  0.9846363
  0.3  1          0.8               1.00        50      0.8236389  0.1390805  0.9952802
  0.3  1          0.8               1.00       100      0.8615833  0.2848155  0.9893770
  0.3  1          0.8               1.00       150      0.8795612  0.3921960  0.9846502
  0.3  2          0.6               0.50        50      0.8484022  0.3300665  0.9846502
  0.3  2          0.6               0.50       100      0.8814108  0.4376286  0.9799234
  0.3  2          0.6               0.50       150      0.8949011  0.4757411  0.9728298
  0.3  2          0.6               0.75        50      0.8559944  0.3056261  0.9870310
  0.3  2          0.6               0.75       100      0.8915850  0.4653962  0.9681100
  0.3  2          0.6               0.75       150      0.9147803  0.5210526  0.9680961
  0.3  2          0.6               1.00        50      0.8608976  0.3196007  0.9870171
  0.3  2          0.6               1.00       100      0.8989771  0.4687840  0.9822903
  0.3  2          0.6               1.00       150      0.9150721  0.5209921  0.9704699
  0.3  2          0.8               0.50        50      0.8541653  0.2882638  0.9811138
  0.3  2          0.8               0.50       100      0.8872888  0.4309135  0.9751897
  0.3  2          0.8               0.50       150      0.8991047  0.4895342  0.9669057
  0.3  2          0.8               0.75        50      0.8502879  0.3229885  0.9846502
  0.3  2          0.8               0.75       100      0.8955088  0.4897157  0.9751897
  0.3  2          0.8               0.75       150      0.9114752  0.5313975  0.9751688
  0.3  2          0.8               1.00        50      0.8647624  0.3194797  0.9870240
  0.3  2          0.8               1.00       100      0.8986706  0.4618270  0.9799304
  0.3  2          0.8               1.00       150      0.9173653  0.5174229  0.9728298
  0.3  3          0.6               0.50        50      0.8682752  0.3300060  0.9799095
  0.3  3          0.6               0.50       100      0.8938628  0.4721718  0.9645527
  0.3  3          0.6               0.50       150      0.9007351  0.5070175  0.9574521
  0.3  3          0.6               0.75        50      0.8822199  0.3991531  0.9870171
  0.3  3          0.6               0.75       100      0.9114890  0.5140956  0.9728159
  0.3  3          0.6               0.75       150      0.9232661  0.5695100  0.9704490
  0.3  3          0.6               1.00        50      0.8803885  0.4165759  0.9834737
  0.3  3          0.6               1.00       100      0.9138902  0.5139746  0.9681100
  0.3  3          0.6               1.00       150      0.9273304  0.5625529  0.9680961
  0.3  3          0.8               0.50        50      0.8728651  0.3784634  0.9751967
  0.3  3          0.8               0.50       100      0.9004735  0.4825771  0.9621928
  0.3  3          0.8               0.50       150      0.9086392  0.5243194  0.9704699
  0.3  3          0.8               0.75        50      0.8860481  0.4200847  0.9858336
  0.3  3          0.8               0.75       100      0.9131258  0.5451906  0.9763662
  0.3  3          0.8               0.75       150      0.9245643  0.5728373  0.9657222
  0.3  3          0.8               1.00        50      0.8852961  0.4235935  0.9822973
  0.3  3          0.8               1.00       100      0.9168291  0.5174229  0.9692865
  0.3  3          0.8               1.00       150      0.9269296  0.5660617  0.9633693
  0.4  1          0.6               0.50        50      0.8133416  0.2362371  0.9869962
  0.4  1          0.6               0.50       100      0.8572187  0.3889897  0.9846363
  0.4  1          0.6               0.50       150      0.8867926  0.4373866  0.9775566
  0.4  1          0.6               0.75        50      0.8303040  0.2710829  0.9846572
  0.4  1          0.6               0.75       100      0.8720841  0.3924380  0.9763940
  0.4  1          0.6               0.75       150      0.8961321  0.4791289  0.9740132
  0.4  1          0.6               1.00        50      0.8349822  0.2395644  0.9893700
  0.4  1          0.6               1.00       100      0.8760118  0.3644888  0.9846572
  0.4  1          0.6               1.00       150      0.8999008  0.4584392  0.9752036
  0.4  1          0.8               0.50        50      0.8230900  0.2398064  0.9893700
  0.4  1          0.8               0.50       100      0.8664237  0.3889292  0.9740132
  0.4  1          0.8               0.50       150      0.8854933  0.4515426  0.9716464
  0.4  1          0.8               0.75        50      0.8252938  0.2431942  0.9858197
  0.4  1          0.8               0.75       100      0.8705165  0.3750756  0.9728368
  0.4  1          0.8               0.75       150      0.8939851  0.4826981  0.9716464
  0.4  1          0.8               1.00        50      0.8374388  0.2255293  0.9893700
  0.4  1          0.8               1.00       100      0.8756200  0.3611615  0.9846572
  0.4  1          0.8               1.00       150      0.8923671  0.4410163  0.9787470
  0.4  2          0.6               0.50        50      0.8695209  0.3437992  0.9811069
  0.4  2          0.6               0.50       100      0.8949433  0.4793708  0.9728298
  0.4  2          0.6               0.50       150      0.9061199  0.5349062  0.9621859
  0.4  2          0.6               0.75        50      0.8726356  0.3716273  0.9822833
  0.4  2          0.6               0.75       100      0.9102712  0.5140351  0.9728228
  0.4  2          0.6               0.75       150      0.9219302  0.5557774  0.9680752
  0.4  2          0.6               1.00        50      0.8788121  0.3648518  0.9846572
  0.4  2          0.6               1.00       100      0.9107017  0.5243799  0.9763731
  0.4  2          0.6               1.00       150      0.9271570  0.5556564  0.9704629
  0.4  2          0.8               0.50        50      0.8527844  0.3578342  0.9751967
  0.4  2          0.8               0.50       100      0.8912183  0.4827586  0.9692934
  0.4  2          0.8               0.50       150      0.9049463  0.5104053  0.9669057
  0.4  2          0.8               0.75        50      0.8720472  0.3819722  0.9822903
  0.4  2          0.8               0.75       100      0.9049192  0.5450696  0.9669266
  0.4  2          0.8               0.75       150      0.9192705  0.5938899  0.9621859
  0.4  2          0.8               1.00        50      0.8789834  0.3892922  0.9858406
  0.4  2          0.8               1.00       100      0.9093464  0.5245614  0.9728298
  0.4  2          0.8               1.00       150      0.9254733  0.5591652  0.9704699
  0.4  3          0.6               0.50        50      0.8641653  0.4274047  0.9704629
  0.4  3          0.6               0.50       100      0.9005027  0.4965517  0.9669126
  0.4  3          0.6               0.50       150      0.9057230  0.5310950  0.9645458
  0.4  3          0.6               0.75        50      0.8932149  0.4618270  0.9692865
  0.4  3          0.6               0.75       100      0.9166701  0.5347852  0.9680752
  0.4  3          0.6               0.75       150      0.9237624  0.5900786  0.9609885
  0.4  3          0.6               1.00        50      0.8932940  0.4652148  0.9811208
  0.4  3          0.6               1.00       100      0.9252090  0.5696310  0.9704629
  0.4  3          0.6               1.00       150      0.9314243  0.6249849  0.9657222
  0.4  3          0.8               0.50        50      0.8679908  0.4755596  0.9728368
  0.4  3          0.8               0.50       100      0.8948312  0.5000000  0.9598260
  0.4  3          0.8               0.50       150      0.8994237  0.5450091  0.9562826
  0.4  3          0.8               0.75        50      0.8892807  0.4757411  0.9763801
  0.4  3          0.8               0.75       100      0.9181101  0.5624319  0.9551062
  0.4  3          0.8               0.75       150      0.9233374  0.6075620  0.9527393
  0.4  3          0.8               1.00        50      0.8949841  0.4758621  0.9763801
  0.4  3          0.8               1.00       100      0.9268723  0.5624924  0.9716533
  0.4  3          0.8               1.00       150      0.9316643  0.6074410  0.9680891

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     15.4      2.4
  positive     10.0     72.2
                            
 Accuracy (average) : 0.8767

[1] "TRAIN accuracy: 0.876651982378855"
[1] "TRAIN +precision: 0.878885316184352"
[1] "TRAIN -precision: 0.866336633663366"
[1] "TRAIN specifity: 0.607638888888889"
[1] "TRAIN sensitivity: 0.968122786304604"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       17        7
            positive       29      279
[1] "TEST accuracy: 0.891566265060241"
[1] "TEST +precision: 0.905844155844156"
[1] "TEST -precision: 0.708333333333333"
[1] "TEST specifity: 0.369565217391304"
[1] "TEST sensitivity: 0.975524475524476"
