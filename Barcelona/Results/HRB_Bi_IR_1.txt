[1] "DATASET NAME: HRB_Bi_IR_1"
[1] "TRAIN INSTANCES: 1694"
[1] "TEST INSTANCES: 332"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 5.78402400016785"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1694 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1355, 1356, 1354, 1356, 1355 
Resampling results:

  ROC        Sens       Spec     
  0.9853436  0.9669405  0.9563522

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     48.3      2.2
  positive      1.7     47.8
                            
 Accuracy (average) : 0.9616

[1] "TRAIN accuracy: 0.961629279811098"
[1] "TRAIN +precision: 0.966587112171838"
[1] "TRAIN -precision: 0.956775700934579"
[1] "TRAIN specifity: 0.966942148760331"
[1] "TRAIN sensitivity: 0.956316410861865"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       17        8
            positive       29      278
[1] "TEST accuracy: 0.88855421686747"
[1] "TEST +precision: 0.905537459283388"
[1] "TEST -precision: 0.68"
[1] "TEST specifity: 0.369565217391304"
[1] "TEST sensitivity: 0.972027972027972"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 3.37076111634572"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1694 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1355, 1355, 1355, 1355, 1356 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9202832  0.8004664  0.8902193
  0.010  2  0.9175657  0.7863140  0.8878594
  0.010  3  0.9094911  0.7355586  0.9126210
  0.255  1  0.9393389  0.8075740  0.9303585
  0.255  2  0.9426740  0.7969509  0.9350992
  0.255  3  0.9315502  0.7733449  0.9421859
  0.500  1  0.9401441  0.8099408  0.9350644
  0.500  2  0.9501614  0.7993178  0.9480543
  0.500  3  0.9394194  0.7721615  0.9598677

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     40.0      2.6
  positive     10.0     47.4
                            
 Accuracy (average) : 0.8737

[1] "TRAIN accuracy: 0.873671782762692"
[1] "TRAIN +precision: 0.825282631038027"
[1] "TRAIN -precision: 0.938973647711512"
[1] "TRAIN specifity: 0.799291617473436"
[1] "TRAIN sensitivity: 0.948051948051948"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9       16
            positive       37      270
[1] "TEST accuracy: 0.840361445783133"
[1] "TEST +precision: 0.879478827361563"
[1] "TEST -precision: 0.36"
[1] "TEST specifity: 0.195652173913043"
[1] "TEST sensitivity: 0.944055944055944"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 6.79231671889623"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1694 samples
 825 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1356, 1356, 1356, 1354, 1354 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8589215  0.7296833  0.8169231
  0.3  1          0.6               0.50       100      0.9193244  0.8406335  0.8370693
  0.3  1          0.6               0.50       150      0.9446937  0.8499965  0.8854995
  0.3  1          0.6               0.75        50      0.8668434  0.7142917  0.8382457
  0.3  1          0.6               0.75       100      0.9262162  0.8158301  0.8983850
  0.3  1          0.6               0.75       150      0.9517866  0.8418378  0.9066899
  0.3  1          0.6               1.00        50      0.8659004  0.6483188  0.8959554
  0.3  1          0.6               1.00       100      0.9306045  0.7875461  0.9267734
  0.3  1          0.6               1.00       150      0.9545771  0.8193387  0.9338670
  0.3  1          0.8               0.50        50      0.8628760  0.7070519  0.8159415
  0.3  1          0.8               0.50       100      0.9266781  0.8382805  0.8747790
  0.3  1          0.8               0.50       150      0.9455174  0.8501218  0.8984407
  0.3  1          0.8               0.75        50      0.8643067  0.6812391  0.8618239
  0.3  1          0.8               0.75       100      0.9191289  0.8075670  0.9007936
  0.3  1          0.8               0.75       150      0.9487171  0.8500940  0.9043578
  0.3  1          0.8               1.00        50      0.8662869  0.6683815  0.8735955
  0.3  1          0.8               1.00       100      0.9321770  0.8028542  0.9244135
  0.3  1          0.8               1.00       150      0.9541220  0.8170205  0.9374104
  0.3  2          0.6               0.50        50      0.9200172  0.8393735  0.8548625
  0.3  2          0.6               0.50       100      0.9573847  0.8961156  0.8996241
  0.3  2          0.6               0.50       150      0.9694344  0.9149809  0.9161782
  0.3  2          0.6               0.75        50      0.9282729  0.8016916  0.9031326
  0.3  2          0.6               0.75       100      0.9651705  0.8819353  0.9291472
  0.3  2          0.6               0.75       150      0.9755067  0.9102819  0.9350574
  0.3  2          0.6               1.00        50      0.9269718  0.7863070  0.9291124
  0.3  2          0.6               1.00       100      0.9641943  0.8464601  0.9421232
  0.3  2          0.6               1.00       150      0.9754377  0.9008284  0.9456596
  0.3  2          0.8               0.50        50      0.9185687  0.8406126  0.8559485
  0.3  2          0.8               0.50       100      0.9600492  0.8961086  0.9031953
  0.3  2          0.8               0.50       150      0.9692785  0.9173756  0.9196937
  0.3  2          0.8               0.75        50      0.9323701  0.8264393  0.8865715
  0.3  2          0.8               0.75       100      0.9642468  0.8854229  0.9243996
  0.3  2          0.8               0.75       150      0.9735052  0.9138183  0.9362200
  0.3  2          0.8               1.00        50      0.9312536  0.8005151  0.9255691
  0.3  2          0.8               1.00       100      0.9629956  0.8618308  0.9386077
  0.3  2          0.8               1.00       150      0.9765070  0.9008214  0.9492168
  0.3  3          0.6               0.50        50      0.9461898  0.8406126  0.8783293
  0.3  3          0.6               0.50       100      0.9713024  0.9008214  0.9173268
  0.3  3          0.6               0.50       150      0.9770228  0.9480543  0.9315071
  0.3  3          0.6               0.75        50      0.9563739  0.8429864  0.9244205
  0.3  3          0.6               0.75       100      0.9745206  0.9185381  0.9338462
  0.3  3          0.6               0.75       150      0.9800078  0.9444901  0.9432997
  0.3  3          0.6               1.00        50      0.9600854  0.8418030  0.9385868
  0.3  3          0.6               1.00       100      0.9762809  0.9008493  0.9551270
  0.3  3          0.6               1.00       150      0.9824543  0.9315280  0.9551201
  0.3  3          0.8               0.50        50      0.9457171  0.8512496  0.8830212
  0.3  3          0.8               0.50       100      0.9709311  0.9303167  0.9208702
  0.3  3          0.8               0.50       150      0.9764128  0.9421371  0.9279638
  0.3  3          0.8               0.75        50      0.9575337  0.8583084  0.9255969
  0.3  3          0.8               0.75       100      0.9763065  0.9126488  0.9397772
  0.3  3          0.8               0.75       150      0.9800880  0.9480473  0.9421511
  0.3  3          0.8               1.00        50      0.9571554  0.8452837  0.9362200
  0.3  3          0.8               1.00       100      0.9777523  0.9138113  0.9456596
  0.3  3          0.8               1.00       150      0.9815711  0.9397703  0.9456666
  0.4  1          0.6               0.50        50      0.8693203  0.7367838  0.8381900
  0.4  1          0.6               0.50       100      0.9320061  0.8665785  0.8605848
  0.4  1          0.6               0.50       150      0.9545210  0.8465298  0.9043300
  0.4  1          0.6               0.75        50      0.8888190  0.7779812  0.8194570
  0.4  1          0.6               0.75       100      0.9390763  0.8476993  0.9031674
  0.4  1          0.6               0.75       150      0.9585742  0.8630630  0.9137696
  0.4  1          0.6               1.00        50      0.8905113  0.7156283  0.8935816
  0.4  1          0.6               1.00       100      0.9461665  0.8370762  0.9232440
  0.4  1          0.6               1.00       150      0.9605473  0.8406196  0.9303167
  0.4  1          0.8               0.50        50      0.8765840  0.7283954  0.8406265
  0.4  1          0.8               0.50       100      0.9320258  0.8654229  0.8570971
  0.4  1          0.8               0.50       150      0.9564027  0.8772224  0.9078733
  0.4  1          0.8               0.75        50      0.8825981  0.7378489  0.8572085
  0.4  1          0.8               0.75       100      0.9431967  0.8594779  0.8913261
  0.4  1          0.8               0.75       150      0.9615896  0.8677898  0.9255830
  0.4  1          0.8               1.00        50      0.8884852  0.7097041  0.8924052
  0.4  1          0.8               1.00       100      0.9449108  0.8323495  0.9149669
  0.4  1          0.8               1.00       150      0.9612191  0.8417960  0.9338601
  0.4  2          0.6               0.50        50      0.9430041  0.8583223  0.8902402
  0.4  2          0.6               0.50       100      0.9654520  0.9067316  0.9114654
  0.4  2          0.6               0.50       150      0.9742814  0.9468430  0.9232510
  0.4  2          0.6               0.75        50      0.9477645  0.8358858  0.9161156
  0.4  2          0.6               0.75       100      0.9725448  0.9090846  0.9267734
  0.4  2          0.6               0.75       150      0.9762194  0.9291403  0.9291263
  0.4  2          0.6               1.00        50      0.9478021  0.8476645  0.9220258
  0.4  2          0.6               1.00       100      0.9730933  0.8949321  0.9444901
  0.4  2          0.6               1.00       150      0.9786599  0.9209050  0.9444831
  0.4  2          0.8               0.50        50      0.9301302  0.8122868  0.8984476
  0.4  2          0.8               0.50       100      0.9640615  0.9019979  0.9090637
  0.4  2          0.8               0.50       150      0.9721037  0.9386077  0.9220814
  0.4  2          0.8               0.75        50      0.9474884  0.8654159  0.8948973
  0.4  2          0.8               0.75       100      0.9698658  0.9043578  0.9303167
  0.4  2          0.8               0.75       150      0.9778754  0.9326975  0.9326906
  0.4  2          0.8               1.00        50      0.9508740  0.8488549  0.9291124
  0.4  2          0.8               1.00       100      0.9734355  0.8937417  0.9468430
  0.4  2          0.8               1.00       150      0.9791182  0.9197007  0.9492168
  0.4  3          0.6               0.50        50      0.9598231  0.8654090  0.9185172
  0.4  3          0.6               0.50       100      0.9752457  0.9362339  0.9244274
  0.4  3          0.6               0.50       150      0.9778661  0.9539506  0.9315280
  0.4  3          0.6               0.75        50      0.9626380  0.8842812  0.9326766
  0.4  3          0.6               0.75       100      0.9774767  0.9327115  0.9350365
  0.4  3          0.6               0.75       150      0.9804504  0.9468639  0.9456874
  0.4  3          0.6               1.00        50      0.9643214  0.8523982  0.9421441
  0.4  3          0.6               1.00       100      0.9815984  0.9362339  0.9551270
  0.4  3          0.6               1.00       150      0.9850724  0.9492168  0.9468569
  0.4  3          0.8               0.50        50      0.9611980  0.8796102  0.9125931
  0.4  3          0.8               0.50       100      0.9748246  0.9421302  0.9386008
  0.4  3          0.8               0.50       150      0.9777077  0.9492168  0.9279777
  0.4  3          0.8               0.75        50      0.9666405  0.8842673  0.9291124
  0.4  3          0.8               0.75       100      0.9778929  0.9279708  0.9362409
  0.4  3          0.8               0.75       150      0.9813024  0.9504003  0.9338740
  0.4  3          0.8               1.00        50      0.9671501  0.8665715  0.9397564
  0.4  3          0.8               1.00       100      0.9805398  0.9291681  0.9527532
  0.4  3          0.8               1.00       150      0.9838344  0.9480334  0.9527602

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     47.5      2.7
  positive      2.5     47.3
                            
 Accuracy (average) : 0.9481

[1] "TRAIN accuracy: 0.948051948051948"
[1] "TRAIN +precision: 0.949112426035503"
[1] "TRAIN -precision: 0.946996466431095"
[1] "TRAIN specifity: 0.949232585596222"
[1] "TRAIN sensitivity: 0.946871310507674"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       17       12
            positive       29      274
[1] "TEST accuracy: 0.876506024096386"
[1] "TEST +precision: 0.904290429042904"
[1] "TEST -precision: 0.586206896551724"
[1] "TEST specifity: 0.369565217391304"
[1] "TEST sensitivity: 0.958041958041958"
