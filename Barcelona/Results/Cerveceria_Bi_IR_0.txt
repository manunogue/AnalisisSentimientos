[1] "DATASET NAME: Cerveceria_Bi_IR_0"
[1] "TRAIN INSTANCES: 2902"
[1] "TEST INSTANCES: 968"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 19.4583768844604"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

2902 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2322, 2321, 2322, 2321, 2322 
Resampling results:

  ROC        Sens       Spec     
  0.8280512  0.1128079  0.9978261

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.6      0.2
  positive      4.3     94.9
                            
 Accuracy (average) : 0.9545

[1] "TRAIN accuracy: 0.954514128187457"
[1] "TRAIN +precision: 0.95625"
[1] "TRAIN -precision: 0.727272727272727"
[1] "TRAIN specifity: 0.112676056338028"
[1] "TRAIN sensitivity: 0.997826086956522"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        0
            positive       50      912
[1] "TEST accuracy: 0.948347107438017"
[1] "TEST +precision: 0.948024948024948"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.107142857142857"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 4.63632953166962"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

2902 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2321, 2322, 2322, 2321, 2322 
Resampling results across tuning parameters:

  C      M  ROC        Sens  Spec     
  0.010  1  0.5000000  0     1.0000000
  0.010  2  0.5000000  0     1.0000000
  0.010  3  0.5000000  0     1.0000000
  0.255  1  0.4985507  0     0.9992754
  0.255  2  0.4985507  0     0.9992754
  0.255  3  0.5000000  0     1.0000000
  0.500  1  0.5866250  0     0.9960145
  0.500  2  0.5409485  0     0.9989130
  0.500  3  0.5000000  0     1.0000000

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.0      0.4
  positive      4.9     94.7
                            
 Accuracy (average) : 0.9473

[1] "TRAIN accuracy: 0.947277739490007"
[1] "TRAIN +precision: 0.950882047734348"
[1] "TRAIN -precision: 0"
[1] "TRAIN specifity: 0"
[1] "TRAIN sensitivity: 0.996014492753623"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        1
            positive       56      911
[1] "TEST accuracy: 0.941115702479339"
[1] "TEST +precision: 0.942088934850052"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.99890350877193"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 10.6194020191828"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

2902 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2321, 2321, 2322, 2322, 2322 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens         Spec     
  0.3  1          0.6               0.50        50      0.6875698  0.000000000  1.0000000
  0.3  1          0.6               0.50       100      0.7125515  0.000000000  0.9989130
  0.3  1          0.6               0.50       150      0.7316676  0.000000000  0.9978261
  0.3  1          0.6               0.75        50      0.7076415  0.014285714  0.9992754
  0.3  1          0.6               0.75       100      0.7411816  0.021182266  0.9985507
  0.3  1          0.6               0.75       150      0.7639899  0.028325123  0.9971014
  0.3  1          0.6               1.00        50      0.7208699  0.007142857  1.0000000
  0.3  1          0.6               1.00       100      0.7518346  0.014285714  1.0000000
  0.3  1          0.6               1.00       150      0.7724029  0.021428571  0.9996377
  0.3  1          0.8               0.50        50      0.7047072  0.007142857  0.9992754
  0.3  1          0.8               0.50       100      0.7280186  0.014285714  0.9989130
  0.3  1          0.8               0.50       150      0.7244324  0.021182266  0.9985507
  0.3  1          0.8               0.75        50      0.7143203  0.014285714  1.0000000
  0.3  1          0.8               0.75       100      0.7495168  0.014039409  0.9981884
  0.3  1          0.8               0.75       150      0.7627849  0.021182266  0.9974638
  0.3  1          0.8               1.00        50      0.7243936  0.014285714  0.9992754
  0.3  1          0.8               1.00       100      0.7591327  0.028325123  0.9992754
  0.3  1          0.8               1.00       150      0.7736156  0.035467980  0.9989130
  0.3  2          0.6               0.50        50      0.7171283  0.014285714  1.0000000
  0.3  2          0.6               0.50       100      0.7376040  0.034975369  0.9974638
  0.3  2          0.6               0.50       150      0.7428917  0.028078818  0.9967391
  0.3  2          0.6               0.75        50      0.7537936  0.007142857  0.9981884
  0.3  2          0.6               0.75       100      0.7800571  0.049261084  0.9974638
  0.3  2          0.6               0.75       150      0.7858876  0.049507389  0.9963768
  0.3  2          0.6               1.00        50      0.7625042  0.021182266  0.9992754
  0.3  2          0.6               1.00       100      0.7865953  0.049507389  0.9981884
  0.3  2          0.6               1.00       150      0.8050531  0.077586207  0.9978261
  0.3  2          0.8               0.50        50      0.7246571  0.007142857  0.9985507
  0.3  2          0.8               0.50       100      0.7358261  0.021182266  0.9967391
  0.3  2          0.8               0.50       150      0.7441498  0.049507389  0.9960145
  0.3  2          0.8               0.75        50      0.7400070  0.028078818  0.9978261
  0.3  2          0.8               0.75       100      0.7679198  0.056157635  0.9971014
  0.3  2          0.8               0.75       150      0.7762891  0.070443350  0.9960145
  0.3  2          0.8               1.00        50      0.7617589  0.021182266  0.9989130
  0.3  2          0.8               1.00       100      0.7809963  0.042610837  0.9974638
  0.3  2          0.8               1.00       150      0.7970225  0.077832512  0.9978261
  0.3  3          0.6               0.50        50      0.7481536  0.000000000  0.9985507
  0.3  3          0.6               0.50       100      0.7512505  0.021182266  0.9981884
  0.3  3          0.6               0.50       150      0.7533575  0.028325123  0.9974638
  0.3  3          0.6               0.75        50      0.7619666  0.014285714  0.9974638
  0.3  3          0.6               0.75       100      0.7907461  0.049261084  0.9967391
  0.3  3          0.6               0.75       150      0.7875042  0.070443350  0.9960145
  0.3  3          0.6               1.00        50      0.7732444  0.042364532  0.9996377
  0.3  3          0.6               1.00       100      0.8007628  0.056403941  0.9981884
  0.3  3          0.6               1.00       150      0.8006751  0.091379310  0.9963768
  0.3  3          0.8               0.50        50      0.7318153  0.014039409  0.9981884
  0.3  3          0.8               0.50       100      0.7499172  0.042118227  0.9952899
  0.3  3          0.8               0.50       150      0.7614699  0.049261084  0.9952899
  0.3  3          0.8               0.75        50      0.7673641  0.027832512  0.9971014
  0.3  3          0.8               0.75       100      0.7828956  0.069950739  0.9963768
  0.3  3          0.8               0.75       150      0.7879665  0.084482759  0.9945652
  0.3  3          0.8               1.00        50      0.7749360  0.035221675  0.9985507
  0.3  3          0.8               1.00       100      0.8000033  0.077586207  0.9967391
  0.3  3          0.8               1.00       150      0.8022745  0.084482759  0.9956522
  0.4  1          0.6               0.50        50      0.6811757  0.000000000  1.0000000
  0.4  1          0.6               0.50       100      0.7153423  0.007142857  0.9992754
  0.4  1          0.6               0.50       150      0.7300080  0.014285714  0.9985507
  0.4  1          0.6               0.75        50      0.7150855  0.007142857  0.9992754
  0.4  1          0.6               0.75       100      0.7514200  0.028325123  0.9978261
  0.4  1          0.6               0.75       150      0.7603689  0.035221675  0.9971014
  0.4  1          0.6               1.00        50      0.7285978  0.007142857  0.9992754
  0.4  1          0.6               1.00       100      0.7623171  0.014285714  0.9992754
  0.4  1          0.6               1.00       150      0.7748331  0.021428571  0.9985507
  0.4  1          0.8               0.50        50      0.6858055  0.006896552  1.0000000
  0.4  1          0.8               0.50       100      0.7094805  0.035221675  0.9981884
  0.4  1          0.8               0.50       150      0.7336147  0.035221675  0.9981884
  0.4  1          0.8               0.75        50      0.7155541  0.007142857  0.9989130
  0.4  1          0.8               0.75       100      0.7536993  0.042118227  0.9981884
  0.4  1          0.8               0.75       150      0.7743889  0.028078818  0.9967391
  0.4  1          0.8               1.00        50      0.7285786  0.007142857  0.9989130
  0.4  1          0.8               1.00       100      0.7644553  0.021182266  0.9985507
  0.4  1          0.8               1.00       150      0.7765602  0.028325123  0.9981884
  0.4  2          0.6               0.50        50      0.7191688  0.006896552  0.9996377
  0.4  2          0.6               0.50       100      0.7322053  0.020935961  0.9981884
  0.4  2          0.6               0.50       150      0.7443220  0.020935961  0.9974638
  0.4  2          0.6               0.75        50      0.7569019  0.014039409  0.9978261
  0.4  2          0.6               0.75       100      0.7796026  0.049507389  0.9945652
  0.4  2          0.6               0.75       150      0.7799509  0.077586207  0.9949275
  0.4  2          0.6               1.00        50      0.7721289  0.035221675  0.9992754
  0.4  2          0.6               1.00       100      0.7979430  0.049261084  0.9981884
  0.4  2          0.6               1.00       150      0.8042369  0.070197044  0.9967391
  0.4  2          0.8               0.50        50      0.7086334  0.007142857  0.9967391
  0.4  2          0.8               0.50       100      0.7392906  0.028571429  0.9952899
  0.4  2          0.8               0.50       150      0.7377126  0.035714286  0.9952899
  0.4  2          0.8               0.75        50      0.7612049  0.027832512  0.9971014
  0.4  2          0.8               0.75       100      0.7729039  0.048768473  0.9956522
  0.4  2          0.8               0.75       150      0.7755906  0.063054187  0.9942029
  0.4  2          0.8               1.00        50      0.7716883  0.035221675  0.9981884
  0.4  2          0.8               1.00       100      0.7964275  0.063300493  0.9974638
  0.4  2          0.8               1.00       150      0.8025318  0.077339901  0.9963768
  0.4  3          0.6               0.50        50      0.7550546  0.021182266  0.9978261
  0.4  3          0.6               0.50       100      0.7613628  0.035221675  0.9963768
  0.4  3          0.6               0.50       150      0.7631001  0.049507389  0.9967391
  0.4  3          0.6               0.75        50      0.7736081  0.035221675  0.9974638
  0.4  3          0.6               0.75       100      0.7835863  0.091625616  0.9949275
  0.4  3          0.6               0.75       150      0.7790689  0.098768473  0.9938406
  0.4  3          0.6               1.00        50      0.7895889  0.056650246  0.9971014
  0.4  3          0.6               1.00       100      0.8033122  0.077339901  0.9956522
  0.4  3          0.6               1.00       150      0.8004417  0.098275862  0.9942029
  0.4  3          0.8               0.50        50      0.7349171  0.021182266  0.9963768
  0.4  3          0.8               0.50       100      0.7499224  0.063300493  0.9956522
  0.4  3          0.8               0.50       150      0.7657292  0.063546798  0.9960145
  0.4  3          0.8               0.75        50      0.7754993  0.034975369  0.9971014
  0.4  3          0.8               0.75       100      0.7803337  0.070443350  0.9952899
  0.4  3          0.8               0.75       150      0.7842717  0.070443350  0.9956522
  0.4  3          0.8               1.00        50      0.7862210  0.042364532  0.9974638
  0.4  3          0.8               1.00       100      0.8008980  0.077339901  0.9956522
  0.4  3          0.8               1.00       150      0.7966660  0.112807882  0.9938406

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 2, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.4      0.2
  positive      4.5     94.9
                            
 Accuracy (average) : 0.9528

[1] "TRAIN accuracy: 0.952791178497588"
[1] "TRAIN +precision: 0.954592720970537"
[1] "TRAIN -precision: 0.647058823529412"
[1] "TRAIN specifity: 0.0774647887323944"
[1] "TRAIN sensitivity: 0.997826086956522"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        3
            positive       52      909
[1] "TEST accuracy: 0.943181818181818"
[1] "TEST +precision: 0.945889698231009"
[1] "TEST -precision: 0.571428571428571"
[1] "TEST specifity: 0.0714285714285714"
[1] "TEST sensitivity: 0.996710526315789"
