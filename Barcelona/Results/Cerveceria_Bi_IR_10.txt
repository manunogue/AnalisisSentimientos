[1] "DATASET NAME: Cerveceria_Bi_IR_10"
[1] "TRAIN INSTANCES: 3164"
[1] "TEST INSTANCES: 968"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 29.5412230491638"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

3164 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2531, 2531, 2531, 2532, 2531 
Resampling results:

  ROC        Sens       Spec     
  0.9420228  0.5998457  0.9677536

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      7.6      2.8
  positive      5.1     84.4
                            
 Accuracy (average) : 0.9207

[1] "TRAIN accuracy: 0.920670037926675"
[1] "TRAIN +precision: 0.942816801976703"
[1] "TRAIN -precision: 0.731117824773414"
[1] "TRAIN specifity: 0.599009900990099"
[1] "TRAIN sensitivity: 0.967753623188406"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       23       31
            positive       33      881
[1] "TEST accuracy: 0.933884297520661"
[1] "TEST +precision: 0.963894967177243"
[1] "TEST -precision: 0.425925925925926"
[1] "TEST specifity: 0.410714285714286"
[1] "TEST sensitivity: 0.966008771929825"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 5.6202797849973"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

3164 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2532, 2531, 2531, 2531, 2531 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5757517  0.13879630  0.9971014
  0.010  2  0.5651675  0.12641975  0.9974638
  0.010  3  0.5496218  0.09166667  0.9989130
  0.255  1  0.8064166  0.35635802  0.9934783
  0.255  2  0.7781742  0.31429012  0.9934783
  0.255  3  0.7420487  0.26728395  0.9938406
  0.500  1  0.8546891  0.39358025  0.9920290
  0.500  2  0.8332398  0.34404321  0.9927536
  0.500  3  0.8123795  0.28950617  0.9905797

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      5.0      0.7
  positive      7.7     86.5
                            
 Accuracy (average) : 0.9156

[1] "TRAIN accuracy: 0.915613147914033"
[1] "TRAIN +precision: 0.917867918203151"
[1] "TRAIN -precision: 0.878453038674033"
[1] "TRAIN specifity: 0.393564356435644"
[1] "TRAIN sensitivity: 0.992028985507246"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        5        6
            positive       51      906
[1] "TEST accuracy: 0.941115702479339"
[1] "TEST +precision: 0.946708463949843"
[1] "TEST -precision: 0.454545454545455"
[1] "TEST specifity: 0.0892857142857143"
[1] "TEST sensitivity: 0.993421052631579"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 10.4016790469488"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

3164 samples
 690 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2531, 2531, 2532, 2531, 2531 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.8165458  0.09660494  0.9978261
  0.3  1          0.6               0.50       100      0.8600226  0.19796296  0.9949275
  0.3  1          0.6               0.50       150      0.8857985  0.29938272  0.9920290
  0.3  1          0.6               0.75        50      0.8432541  0.10398148  0.9989130
  0.3  1          0.6               0.75       100      0.8843945  0.18077160  0.9952899
  0.3  1          0.6               0.75       150      0.8988689  0.31194444  0.9942029
  0.3  1          0.6               1.00        50      0.8456244  0.10401235  0.9992754
  0.3  1          0.6               1.00       100      0.8908065  0.18570988  0.9971014
  0.3  1          0.6               1.00       150      0.9067329  0.27240741  0.9960145
  0.3  1          0.8               0.50        50      0.8262118  0.09407407  0.9978261
  0.3  1          0.8               0.50       100      0.8678505  0.23515432  0.9949275
  0.3  1          0.8               0.50       150      0.8802939  0.29469136  0.9916667
  0.3  1          0.8               0.75        50      0.8312416  0.10651235  0.9981884
  0.3  1          0.8               0.75       100      0.8801926  0.21302469  0.9956522
  0.3  1          0.8               0.75       150      0.8963335  0.29956790  0.9934783
  0.3  1          0.8               1.00        50      0.8468300  0.10651235  0.9989130
  0.3  1          0.8               1.00       100      0.8902423  0.17824074  0.9971014
  0.3  1          0.8               1.00       150      0.9072339  0.27737654  0.9963768
  0.3  2          0.6               0.50        50      0.8590035  0.20543210  0.9952899
  0.3  2          0.6               0.50       100      0.8955007  0.37882716  0.9923913
  0.3  2          0.6               0.50       150      0.9062708  0.47527778  0.9909420
  0.3  2          0.6               0.75        50      0.8785075  0.16836420  0.9971014
  0.3  2          0.6               0.75       100      0.9081359  0.38132716  0.9942029
  0.3  2          0.6               0.75       150      0.9237535  0.49503086  0.9909420
  0.3  2          0.6               1.00        50      0.8884034  0.17833333  0.9971014
  0.3  2          0.6               1.00       100      0.9158286  0.37382716  0.9945652
  0.3  2          0.6               1.00       150      0.9304045  0.47027778  0.9927536
  0.3  2          0.8               0.50        50      0.8636193  0.23527778  0.9960145
  0.3  2          0.8               0.50       100      0.8962529  0.37879630  0.9913043
  0.3  2          0.8               0.50       150      0.9097829  0.47527778  0.9891304
  0.3  2          0.8               0.75        50      0.8813575  0.17827160  0.9956522
  0.3  2          0.8               0.75       100      0.9058768  0.37873457  0.9920290
  0.3  2          0.8               0.75       150      0.9193194  0.49753086  0.9891304
  0.3  2          0.8               1.00        50      0.8936698  0.15604938  0.9971014
  0.3  2          0.8               1.00       100      0.9168323  0.36635802  0.9942029
  0.3  2          0.8               1.00       150      0.9330327  0.48768519  0.9916667
  0.3  3          0.6               0.50        50      0.8781284  0.29216049  0.9945652
  0.3  3          0.6               0.50       100      0.9087304  0.45790123  0.9898551
  0.3  3          0.6               0.50       150      0.9170474  0.54453704  0.9869565
  0.3  3          0.6               0.75        50      0.8978091  0.31929012  0.9952899
  0.3  3          0.6               0.75       100      0.9239542  0.50500000  0.9916667
  0.3  3          0.6               0.75       150      0.9344125  0.57919753  0.9891304
  0.3  3          0.6               1.00        50      0.9038011  0.31194444  0.9945652
  0.3  3          0.6               1.00       100      0.9304908  0.46537037  0.9923913
  0.3  3          0.6               1.00       150      0.9445869  0.55947531  0.9905797
  0.3  3          0.8               0.50        50      0.8821870  0.30700617  0.9942029
  0.3  3          0.8               0.50       100      0.9116755  0.49500000  0.9876812
  0.3  3          0.8               0.50       150      0.9206570  0.55197531  0.9847826
  0.3  3          0.8               0.75        50      0.8977457  0.29466049  0.9952899
  0.3  3          0.8               0.75       100      0.9224837  0.49006173  0.9898551
  0.3  3          0.8               0.75       150      0.9326383  0.56182099  0.9884058
  0.3  3          0.8               1.00        50      0.9097044  0.27728395  0.9945652
  0.3  3          0.8               1.00       100      0.9348496  0.49003086  0.9923913
  0.3  3          0.8               1.00       150      0.9468461  0.55691358  0.9927536
  0.4  1          0.6               0.50        50      0.8354139  0.12879630  0.9971014
  0.4  1          0.6               0.50       100      0.8712367  0.29691358  0.9934783
  0.4  1          0.6               0.50       150      0.8931192  0.41827160  0.9894928
  0.4  1          0.6               0.75        50      0.8496846  0.15354938  0.9963768
  0.4  1          0.6               0.75       100      0.8897460  0.31203704  0.9931159
  0.4  1          0.6               0.75       150      0.9051817  0.40854938  0.9905797
  0.4  1          0.6               1.00        50      0.8544097  0.14376543  0.9981884
  0.4  1          0.6               1.00       100      0.9017276  0.26743827  0.9956522
  0.4  1          0.6               1.00       150      0.9115696  0.33679012  0.9949275
  0.4  1          0.8               0.50        50      0.8292319  0.14858025  0.9952899
  0.4  1          0.8               0.50       100      0.8787276  0.29456790  0.9923913
  0.4  1          0.8               0.50       150      0.8930540  0.39361111  0.9869565
  0.4  1          0.8               0.75        50      0.8575961  0.15361111  0.9967391
  0.4  1          0.8               0.75       100      0.8931636  0.28734568  0.9942029
  0.4  1          0.8               0.75       150      0.9043824  0.38382716  0.9905797
  0.4  1          0.8               1.00        50      0.8541730  0.13385802  0.9974638
  0.4  1          0.8               1.00       100      0.8997034  0.26740741  0.9967391
  0.4  1          0.8               1.00       150      0.9124999  0.36151235  0.9931159
  0.4  2          0.6               0.50        50      0.8622320  0.27219136  0.9905797
  0.4  2          0.6               0.50       100      0.8916910  0.44546296  0.9869565
  0.4  2          0.6               0.50       150      0.9092234  0.53706790  0.9858696
  0.4  2          0.6               0.75        50      0.8938416  0.30450617  0.9934783
  0.4  2          0.6               0.75       100      0.9155108  0.46040123  0.9913043
  0.4  2          0.6               0.75       150      0.9291328  0.55200617  0.9880435
  0.4  2          0.6               1.00        50      0.9007344  0.28725309  0.9960145
  0.4  2          0.6               1.00       100      0.9297648  0.43567901  0.9927536
  0.4  2          0.6               1.00       150      0.9403156  0.53950617  0.9905797
  0.4  2          0.8               0.50        50      0.8658277  0.29712963  0.9942029
  0.4  2          0.8               0.50       100      0.9073850  0.46780864  0.9876812
  0.4  2          0.8               0.50       150      0.9191224  0.55953704  0.9855072
  0.4  2          0.8               0.75        50      0.8911575  0.29959877  0.9934783
  0.4  2          0.8               0.75       100      0.9175040  0.45058642  0.9927536
  0.4  2          0.8               0.75       150      0.9275507  0.56182099  0.9894928
  0.4  2          0.8               1.00        50      0.9039194  0.28725309  0.9960145
  0.4  2          0.8               1.00       100      0.9270553  0.47768519  0.9931159
  0.4  2          0.8               1.00       150      0.9419470  0.55191358  0.9931159
  0.4  3          0.6               0.50        50      0.8901684  0.38373457  0.9902174
  0.4  3          0.6               0.50       100      0.9109536  0.51728395  0.9862319
  0.4  3          0.6               0.50       150      0.9271186  0.58907407  0.9858696
  0.4  3          0.6               0.75        50      0.9068592  0.40101852  0.9916667
  0.4  3          0.6               0.75       100      0.9320595  0.56435185  0.9894928
  0.4  3          0.6               0.75       150      0.9422313  0.62882716  0.9855072
  0.4  3          0.6               1.00        50      0.9179344  0.39361111  0.9927536
  0.4  3          0.6               1.00       100      0.9435389  0.53453704  0.9909420
  0.4  3          0.6               1.00       150      0.9532714  0.61885802  0.9880435
  0.4  3          0.8               0.50        50      0.8915914  0.37379630  0.9905797
  0.4  3          0.8               0.50       100      0.9164078  0.52475309  0.9851449
  0.4  3          0.8               0.50       150      0.9231549  0.60407407  0.9822464
  0.4  3          0.8               0.75        50      0.9076630  0.38617284  0.9916667
  0.4  3          0.8               0.75       100      0.9334854  0.55944444  0.9884058
  0.4  3          0.8               0.75       150      0.9402800  0.62882716  0.9855072
  0.4  3          0.8               1.00        50      0.9169500  0.37385802  0.9945652
  0.4  3          0.8               1.00       100      0.9419701  0.54203704  0.9920290
  0.4  3          0.8               1.00       150      0.9535649  0.61635802  0.9902174

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      7.9      0.9
  positive      4.9     86.4
                            
 Accuracy (average) : 0.9425

[1] "TRAIN accuracy: 0.942477876106195"
[1] "TRAIN +precision: 0.946329639889197"
[1] "TRAIN -precision: 0.902173913043478"
[1] "TRAIN specifity: 0.616336633663366"
[1] "TRAIN sensitivity: 0.990217391304348"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15        8
            positive       41      904
[1] "TEST accuracy: 0.949380165289256"
[1] "TEST +precision: 0.956613756613757"
[1] "TEST -precision: 0.652173913043478"
[1] "TEST specifity: 0.267857142857143"
[1] "TEST sensitivity: 0.991228070175439"
