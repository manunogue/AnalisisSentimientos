[1] "DATASET NAME: Cerveceria_Uni_IR_2"
[1] "TRAIN INSTANCES: 4201"
[1] "TEST INSTANCES: 968"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 38.8429629802704"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

4201 samples
 654 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 3361, 3360, 3361, 3361, 3361 
Resampling results:

  ROC        Sens  Spec     
  0.9960345  1     0.9865455

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.5      0.9
  positive      0.0     64.6
                            
 Accuracy (average) : 0.9912

[1] "TRAIN accuracy: 0.991192573196858"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.975134408602151"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.986545454545455"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       21       11
            positive       25      911
[1] "TEST accuracy: 0.962809917355372"
[1] "TEST +precision: 0.973290598290598"
[1] "TEST -precision: 0.65625"
[1] "TEST specifity: 0.456521739130435"
[1] "TEST sensitivity: 0.988069414316703"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 8.24115110238393"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

4201 samples
 654 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 3361, 3361, 3361, 3361, 3360 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9600269  0.9559118  0.9549091
  0.010  2  0.9599883  0.9552222  0.9530909
  0.010  3  0.9622319  0.9545325  0.9523636
  0.255  1  0.9788546  0.9944828  0.9618182
  0.255  2  0.9793218  0.9931034  0.9610909
  0.255  3  0.9802067  0.9917289  0.9592727
  0.500  1  0.9804357  0.9979310  0.9621818
  0.500  2  0.9811644  0.9979310  0.9610909
  0.500  3  0.9807139  0.9931082  0.9592727

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.5      2.5
  positive      0.1     62.9
                            
 Accuracy (average) : 0.9738

[1] "TRAIN accuracy: 0.973815758152821"
[1] "TRAIN +precision: 0.998866213151927"
[1] "TRAIN -precision: 0.931189710610932"
[1] "TRAIN specifity: 0.997932460372157"
[1] "TRAIN sensitivity: 0.961090909090909"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       15       25
            positive       31      897
[1] "TEST accuracy: 0.942148760330578"
[1] "TEST +precision: 0.966594827586207"
[1] "TEST -precision: 0.375"
[1] "TEST specifity: 0.326086956521739"
[1] "TEST sensitivity: 0.972885032537961"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 13.8395424842834"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

4201 samples
 654 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 3361, 3360, 3361, 3361, 3361 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9560169  0.7167840  0.9741818
  0.3  1          0.6               0.50       100      0.9795368  0.8091362  0.9760000
  0.3  1          0.6               0.50       150      0.9868115  0.8738974  0.9723636
  0.3  1          0.6               0.75        50      0.9579906  0.7250409  0.9781818
  0.3  1          0.6               0.75       100      0.9787140  0.7974168  0.9763636
  0.3  1          0.6               0.75       150      0.9856661  0.8518379  0.9716364
  0.3  1          0.6               1.00        50      0.9579705  0.7202228  0.9792727
  0.3  1          0.6               1.00       100      0.9768934  0.7877829  0.9789091
  0.3  1          0.6               1.00       150      0.9852687  0.8456357  0.9756364
  0.3  1          0.8               0.50        50      0.9568662  0.7126508  0.9760000
  0.3  1          0.8               0.50       100      0.9791986  0.8139472  0.9745455
  0.3  1          0.8               0.50       150      0.9868717  0.8587250  0.9730909
  0.3  1          0.8               0.75        50      0.9585029  0.7202346  0.9789091
  0.3  1          0.8               0.75       100      0.9794736  0.8056855  0.9749091
  0.3  1          0.8               0.75       150      0.9862060  0.8470198  0.9749091
  0.3  1          0.8               1.00        50      0.9580181  0.7229767  0.9803636
  0.3  1          0.8               1.00       100      0.9774529  0.7891551  0.9792727
  0.3  1          0.8               1.00       150      0.9856318  0.8532101  0.9778182
  0.3  2          0.6               0.50        50      0.9849721  0.8435786  0.9734545
  0.3  2          0.6               0.50       100      0.9937135  0.9455646  0.9774545
  0.3  2          0.6               0.50       150      0.9957272  0.9834649  0.9785455
  0.3  2          0.6               0.75        50      0.9848585  0.8573694  0.9785455
  0.3  2          0.6               0.75       100      0.9939791  0.9455765  0.9789091
  0.3  2          0.6               0.75       150      0.9960463  0.9772627  0.9821818
  0.3  2          0.6               1.00        50      0.9835724  0.8408295  0.9792727
  0.3  2          0.6               1.00       100      0.9932603  0.9304159  0.9789091
  0.3  2          0.6               1.00       150      0.9956535  0.9669226  0.9781818
  0.3  2          0.8               0.50        50      0.9854918  0.8449627  0.9738182
  0.3  2          0.8               0.50       100      0.9933313  0.9469463  0.9741818
  0.3  2          0.8               0.50       150      0.9953043  0.9896623  0.9730909
  0.3  2          0.8               0.75        50      0.9862738  0.8429032  0.9774545
  0.3  2          0.8               0.75       100      0.9942669  0.9517715  0.9763636
  0.3  2          0.8               0.75       150      0.9960405  0.9862211  0.9796364
  0.3  2          0.8               1.00        50      0.9853991  0.8435786  0.9792727
  0.3  2          0.8               1.00       100      0.9940084  0.9359213  0.9778182
  0.3  2          0.8               1.00       150      0.9956292  0.9744970  0.9818182
  0.3  3          0.6               0.50        50      0.9932568  0.9324754  0.9781818
  0.3  3          0.6               0.50       100      0.9965629  0.9827657  0.9792727
  0.3  3          0.6               0.50       150      0.9977784  0.9979310  0.9792727
  0.3  3          0.6               0.75        50      0.9944154  0.9324683  0.9792727
  0.3  3          0.6               0.75       100      0.9970799  0.9862069  0.9836364
  0.3  3          0.6               0.75       150      0.9977022  0.9986207  0.9836364
  0.3  3          0.6               1.00        50      0.9933868  0.9242161  0.9763636
  0.3  3          0.6               1.00       100      0.9968126  0.9924162  0.9818182
  0.3  3          0.6               1.00       150      0.9974541  0.9986207  0.9832727
  0.3  3          0.8               0.50        50      0.9943589  0.9228179  0.9821818
  0.3  3          0.8               0.50       100      0.9972995  0.9951724  0.9840000
  0.3  3          0.8               0.50       150      0.9976137  0.9986207  0.9840000
  0.3  3          0.8               0.75        50      0.9941129  0.9372864  0.9767273
  0.3  3          0.8               0.75       100      0.9972336  0.9938002  0.9814545
  0.3  3          0.8               0.75       150      0.9978706  0.9986207  0.9832727
  0.3  3          0.8               1.00        50      0.9943553  0.9283564  0.9785455
  0.3  3          0.8               1.00       100      0.9975288  0.9924209  0.9807273
  0.3  3          0.8               1.00       150      0.9981248  0.9986207  0.9840000
  0.4  1          0.6               0.50        50      0.9664282  0.7671004  0.9727273
  0.4  1          0.6               0.50       100      0.9857336  0.8511672  0.9727273
  0.4  1          0.6               0.50       150      0.9901659  0.9000972  0.9723636
  0.4  1          0.6               0.75        50      0.9676275  0.7608911  0.9745455
  0.4  1          0.6               0.75       100      0.9846266  0.8421898  0.9763636
  0.4  1          0.6               0.75       150      0.9898236  0.8849129  0.9727273
  0.4  1          0.6               1.00        50      0.9660994  0.7684726  0.9770909
  0.4  1          0.6               1.00       100      0.9837614  0.8353075  0.9789091
  0.4  1          0.6               1.00       150      0.9891067  0.8856073  0.9763636
  0.4  1          0.8               0.50        50      0.9684844  0.7574452  0.9730909
  0.4  1          0.8               0.50       100      0.9839545  0.8442683  0.9730909
  0.4  1          0.8               0.50       150      0.9894607  0.8876597  0.9720000
  0.4  1          0.8               0.75        50      0.9668908  0.7595047  0.9734545
  0.4  1          0.8               0.75       100      0.9836093  0.8463230  0.9749091
  0.4  1          0.8               0.75       150      0.9892855  0.8918142  0.9716364
  0.4  1          0.8               1.00        50      0.9661843  0.7622680  0.9785455
  0.4  1          0.8               1.00       100      0.9840874  0.8387581  0.9774545
  0.4  1          0.8               1.00       150      0.9896261  0.8876739  0.9756364
  0.4  2          0.6               0.50        50      0.9880253  0.8766394  0.9734545
  0.4  2          0.6               0.50       100      0.9943519  0.9744899  0.9741818
  0.4  2          0.6               0.50       150      0.9955216  0.9944851  0.9767273
  0.4  2          0.6               0.75        50      0.9889629  0.8883801  0.9749091
  0.4  2          0.6               0.75       100      0.9951784  0.9820808  0.9749091
  0.4  2          0.6               0.75       150      0.9963540  0.9944828  0.9807273
  0.4  2          0.6               1.00        50      0.9898322  0.8890579  0.9774545
  0.4  2          0.6               1.00       100      0.9958183  0.9655481  0.9789091
  0.4  2          0.6               1.00       150      0.9967350  0.9958621  0.9800000
  0.4  2          0.8               0.50        50      0.9903858  0.8932077  0.9738182
  0.4  2          0.8               0.50       100      0.9956013  0.9772556  0.9800000
  0.4  2          0.8               0.50       150      0.9969452  0.9986207  0.9796364
  0.4  2          0.8               0.75        50      0.9911245  0.8931982  0.9763636
  0.4  2          0.8               0.75       100      0.9951999  0.9751819  0.9767273
  0.4  2          0.8               0.75       150      0.9964262  0.9951724  0.9778182
  0.4  2          0.8               1.00        50      0.9896987  0.8924920  0.9749091
  0.4  2          0.8               1.00       100      0.9955964  0.9751937  0.9781818
  0.4  2          0.8               1.00       150      0.9969309  0.9903448  0.9825455
  0.4  3          0.6               0.50        50      0.9946116  0.9641593  0.9774545
  0.4  3          0.6               0.50       100      0.9968065  0.9944899  0.9800000
  0.4  3          0.6               0.50       150      0.9972653  0.9979310  0.9800000
  0.4  3          0.6               0.75        50      0.9955130  0.9621021  0.9781818
  0.4  3          0.6               0.75       100      0.9974909  0.9965517  0.9818182
  0.4  3          0.6               0.75       150      0.9978957  0.9986207  0.9829091
  0.4  3          0.6               1.00        50      0.9959317  0.9641806  0.9796364
  0.4  3          0.6               1.00       100      0.9978627  0.9979310  0.9821818
  0.4  3          0.6               1.00       150      0.9981147  1.0000000  0.9821818
  0.4  3          0.8               0.50        50      0.9953042  0.9641616  0.9763636
  0.4  3          0.8               0.50       100      0.9971439  0.9979310  0.9800000
  0.4  3          0.8               0.50       150      0.9975853  0.9979310  0.9818182
  0.4  3          0.8               0.75        50      0.9957176  0.9744970  0.9752727
  0.4  3          0.8               0.75       100      0.9979145  0.9979310  0.9800000
  0.4  3          0.8               0.75       150      0.9980544  0.9986207  0.9821818
  0.4  3          0.8               1.00        50      0.9956539  0.9689845  0.9774545
  0.4  3          0.8               1.00       100      0.9978277  0.9986207  0.9818182
  0.4  3          0.8               1.00       150      0.9983596  1.0000000  0.9836364

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.5      1.1
  positive      0.0     64.4
                            
 Accuracy (average) : 0.9893

[1] "TRAIN accuracy: 0.989288264698881"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.969919786096257"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.983636363636364"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       30       10
            positive       16      912
[1] "TEST accuracy: 0.973140495867769"
[1] "TEST +precision: 0.982758620689655"
[1] "TEST -precision: 0.75"
[1] "TEST specifity: 0.652173913043478"
[1] "TEST sensitivity: 0.989154013015184"
