[1] "DATASET NAME: HRM_Uni_IR_1"
[1] "TRAIN INSTANCES: 582"
[1] "TEST INSTANCES: 112"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.87148499488831"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

582 samples
747 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 466, 465, 466, 465, 466 
Resampling results:

  ROC  Sens  Spec     
  1    1     0.9862653

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      0.7
  positive      0.0     49.3
                            
 Accuracy (average) : 0.9931

[1] "TRAIN accuracy: 0.993127147766323"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.986440677966102"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.986254295532646"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        1
            positive       12       93
[1] "TEST accuracy: 0.883928571428571"
[1] "TEST +precision: 0.885714285714286"
[1] "TEST -precision: 0.857142857142857"
[1] "TEST specifity: 0.333333333333333"
[1] "TEST sensitivity: 0.98936170212766"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.23008641799291"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

582 samples
747 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 466, 465, 466, 465, 466 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9310103  0.9317358  0.9037405
  0.010  2  0.9279777  0.9317358  0.9037405
  0.010  3  0.9353408  0.9316189  0.9104033
  0.255  1  0.9631396  0.9932203  0.9037405
  0.255  2  0.9662428  0.9932203  0.9071303
  0.255  3  0.9612099  0.9863238  0.9104033
  0.500  1  0.9609993  0.9932203  0.9037405
  0.500  2  0.9644295  0.9932203  0.9071303
  0.500  3  0.9612099  0.9863238  0.9104033

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     49.7      4.6
  positive      0.3     45.4
                            
 Accuracy (average) : 0.9502

[1] "TRAIN accuracy: 0.950171821305842"
[1] "TRAIN +precision: 0.992481203007519"
[1] "TRAIN -precision: 0.914556962025316"
[1] "TRAIN specifity: 0.993127147766323"
[1] "TRAIN sensitivity: 0.907216494845361"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        7        7
            positive       11       87
[1] "TEST accuracy: 0.839285714285714"
[1] "TEST +precision: 0.887755102040816"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.388888888888889"
[1] "TEST sensitivity: 0.925531914893617"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.77310436566671"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

582 samples
747 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 466, 466, 465, 465, 466 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9805070  0.9173583  0.9347750
  0.3  1          0.6               0.50       100      0.9950221  0.9931034  0.9622443
  0.3  1          0.6               0.50       150      0.9992271  1.0000000  0.9587960
  0.3  1          0.6               0.75        50      0.9815983  0.9347165  0.9519579
  0.3  1          0.6               0.75       100      0.9945978  0.9758621  0.9587376
  0.3  1          0.6               0.75       150      0.9974465  1.0000000  0.9587376
  0.3  1          0.6               1.00        50      0.9839724  0.9209234  0.9451198
  0.3  1          0.6               1.00       100      0.9932314  0.9793103  0.9621859
  0.3  1          0.6               1.00       150      0.9950795  0.9827586  0.9552893
  0.3  1          0.8               0.50        50      0.9759613  0.9208065  0.9347165
  0.3  1          0.8               0.50       100      0.9931165  0.9758621  0.9347165
  0.3  1          0.8               0.50       150      0.9948296  1.0000000  0.9517826
  0.3  1          0.8               0.75        50      0.9825253  0.9415546  0.9279369
  0.3  1          0.8               0.75       100      0.9940043  0.9827586  0.9587376
  0.3  1          0.8               0.75       150      0.9964983  1.0000000  0.9552893
  0.3  1          0.8               1.00        50      0.9833995  0.9277031  0.9485681
  0.3  1          0.8               1.00       100      0.9932899  0.9793103  0.9587376
  0.3  1          0.8               1.00       150      0.9954957  0.9896552  0.9621859
  0.3  2          0.6               0.50        50      0.9943731  0.9828171  0.9416131
  0.3  2          0.6               0.50       100      0.9987051  1.0000000  0.9553477
  0.3  2          0.6               0.50       150      0.9996433  1.0000000  0.9588545
  0.3  2          0.6               0.75        50      0.9971830  0.9827586  0.9587960
  0.3  2          0.6               0.75       100      0.9990538  1.0000000  0.9725307
  0.3  2          0.6               0.75       150      0.9979353  1.0000000  0.9656341
  0.3  2          0.6               1.00        50      0.9979806  0.9827586  0.9588545
  0.3  2          0.6               1.00       100      0.9995838  1.0000000  0.9725891
  0.3  2          0.6               1.00       150      0.9998811  1.0000000  0.9690824
  0.3  2          0.8               0.50        50      0.9973045  0.9966102  0.9621859
  0.3  2          0.8               0.50       100      0.9994065  1.0000000  0.9553477
  0.3  2          0.8               0.50       150      0.9995879  1.0000000  0.9587960
  0.3  2          0.8               0.75        50      0.9962131  0.9896552  0.9553477
  0.3  2          0.8               0.75       100      0.9990538  1.0000000  0.9656926
  0.3  2          0.8               0.75       150      0.9992271  1.0000000  0.9691409
  0.3  2          0.8               1.00        50      0.9959345  0.9827586  0.9622443
  0.3  2          0.8               1.00       100      0.9992271  1.0000000  0.9622443
  0.3  2          0.8               1.00       150      0.9992271  1.0000000  0.9622443
  0.3  3          0.6               0.50        50      0.9988109  1.0000000  0.9381648
  0.3  3          0.6               0.50       100      0.9997048  1.0000000  0.9485096
  0.3  3          0.6               0.50       150      0.9998237  1.0000000  0.9450614
  0.3  3          0.6               0.75        50      0.9986507  1.0000000  0.9656926
  0.3  3          0.6               0.75       100      1.0000000  1.0000000  0.9656926
  0.3  3          0.6               0.75       150      0.9999405  1.0000000  0.9485096
  0.3  3          0.6               1.00        50      0.9990518  1.0000000  0.9622443
  0.3  3          0.6               1.00       100      1.0000000  1.0000000  0.9622443
  0.3  3          0.6               1.00       150      1.0000000  1.0000000  0.9622443
  0.3  3          0.8               0.50        50      0.9988109  1.0000000  0.9621859
  0.3  3          0.8               0.50       100      0.9998811  1.0000000  0.9451198
  0.3  3          0.8               0.50       150      0.9999405  1.0000000  0.9520164
  0.3  3          0.8               0.75        50      0.9992271  1.0000000  0.9587960
  0.3  3          0.8               0.75       100      1.0000000  1.0000000  0.9587376
  0.3  3          0.8               0.75       150      1.0000000  1.0000000  0.9587960
  0.3  3          0.8               1.00        50      0.9980380  1.0000000  0.9690824
  0.3  3          0.8               1.00       100      0.9998811  1.0000000  0.9690824
  0.3  3          0.8               1.00       150      1.0000000  1.0000000  0.9656341
  0.4  1          0.6               0.50        50      0.9862699  0.9517826  0.9209234
  0.4  1          0.6               0.50       100      0.9959804  0.9896552  0.9485096
  0.4  1          0.6               0.50       150      0.9985762  0.9965517  0.9622443
  0.4  1          0.6               0.75        50      0.9895096  0.9414378  0.9518995
  0.4  1          0.6               0.75       100      0.9962011  0.9896552  0.9587960
  0.4  1          0.6               0.75       150      0.9980975  1.0000000  0.9587376
  0.4  1          0.6               1.00        50      0.9890470  0.9517826  0.9518995
  0.4  1          0.6               1.00       100      0.9939549  0.9827586  0.9621859
  0.4  1          0.6               1.00       150      0.9972148  1.0000000  0.9621859
  0.4  1          0.8               0.50        50      0.9887145  0.9517241  0.9140269
  0.4  1          0.8               0.50       100      0.9974188  1.0000000  0.9519579
  0.4  1          0.8               0.50       150      0.9991082  1.0000000  0.9623027
  0.4  1          0.8               0.75        50      0.9859615  0.9517241  0.9416131
  0.4  1          0.8               0.75       100      0.9957305  1.0000000  0.9621859
  0.4  1          0.8               0.75       150      0.9982164  1.0000000  0.9690824
  0.4  1          0.8               1.00        50      0.9890430  0.9518410  0.9586791
  0.4  1          0.8               1.00       100      0.9955027  0.9896552  0.9621859
  0.4  1          0.8               1.00       150      0.9973266  1.0000000  0.9656341
  0.4  2          0.6               0.50        50      0.9971100  1.0000000  0.9552893
  0.4  2          0.6               0.50       100      0.9987545  1.0000000  0.9519579
  0.4  2          0.6               0.50       150      0.9985147  1.0000000  0.9416131
  0.4  2          0.6               0.75        50      0.9988119  0.9931034  0.9587960
  0.4  2          0.6               0.75       100      0.9997027  1.0000000  0.9657510
  0.4  2          0.6               0.75       150      1.0000000  1.0000000  0.9656926
  0.4  2          0.6               1.00        50      0.9988704  1.0000000  0.9690824
  0.4  2          0.6               1.00       100      0.9998811  1.0000000  0.9656341
  0.4  2          0.6               1.00       150      0.9997622  1.0000000  0.9587960
  0.4  2          0.8               0.50        50      0.9975030  1.0000000  0.9587376
  0.4  2          0.8               0.50       100      0.9993460  1.0000000  0.9552309
  0.4  2          0.8               0.50       150      0.9997622  1.0000000  0.9485096
  0.4  2          0.8               0.75        50      0.9975765  1.0000000  0.9621859
  0.4  2          0.8               0.75       100      0.9992976  1.0000000  0.9621859
  0.4  2          0.8               0.75       150      0.9984200  1.0000000  0.9655757
  0.4  2          0.8               1.00        50      0.9958534  1.0000000  0.9656926
  0.4  2          0.8               1.00       100      0.9988724  1.0000000  0.9656341
  0.4  2          0.8               1.00       150      0.9987515  1.0000000  0.9587960
  0.4  3          0.6               0.50        50      0.9983948  1.0000000  0.9415546
  0.4  3          0.6               0.50       100      0.9994649  1.0000000  0.9381064
  0.4  3          0.6               0.50       150      0.9992866  1.0000000  0.9415546
  0.4  3          0.6               0.75        50      0.9995838  1.0000000  0.9759205
  0.4  3          0.6               0.75       100      0.9998216  1.0000000  0.9621859
  0.4  3          0.6               0.75       150      0.9998821  1.0000000  0.9621859
  0.4  3          0.6               1.00        50      0.9978940  1.0000000  0.9622443
  0.4  3          0.6               1.00       100      0.9995244  1.0000000  0.9656926
  0.4  3          0.6               1.00       150      0.9997632  1.0000000  0.9657510
  0.4  3          0.8               0.50        50      0.9979494  1.0000000  0.9621274
  0.4  3          0.8               0.50       100      0.9976602  1.0000000  0.9587376
  0.4  3          0.8               0.50       150      0.9975433  1.0000000  0.9483928
  0.4  3          0.8               0.75        50      0.9998811  1.0000000  0.9690240
  0.4  3          0.8               0.75       100      1.0000000  1.0000000  0.9656926
  0.4  3          0.8               0.75       150      1.0000000  1.0000000  0.9587960
  0.4  3          0.8               1.00        50      0.9997027  1.0000000  0.9587960
  0.4  3          0.8               1.00       100      0.9998811  1.0000000  0.9656926
  0.4  3          0.8               1.00       150      0.9998216  1.0000000  0.9691409

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     50.0      1.7
  positive      0.0     48.3
                            
 Accuracy (average) : 0.9828

[1] "TRAIN accuracy: 0.982817869415808"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.966777408637874"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.965635738831615"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       13        3
            positive        5       91
[1] "TEST accuracy: 0.928571428571429"
[1] "TEST +precision: 0.947916666666667"
[1] "TEST -precision: 0.8125"
[1] "TEST specifity: 0.722222222222222"
[1] "TEST sensitivity: 0.968085106382979"
