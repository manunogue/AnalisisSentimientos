[1] "DATASET NAME: TCT_Bi_IR_0"
[1] "TRAIN INSTANCES: 673"
[1] "TEST INSTANCES: 225"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.61319303512573"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

673 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 539, 538, 539, 538, 538 
Resampling results:

  ROC        Sens       Spec     
  0.9301698  0.3027778  0.9952381

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.9      0.4
  positive      4.5     93.2
                           
 Accuracy (average) : 0.951

[1] "TRAIN accuracy: 0.950965824665676"
[1] "TRAIN +precision: 0.954337899543379"
[1] "TRAIN -precision: 0.8125"
[1] "TRAIN specifity: 0.302325581395349"
[1] "TRAIN sensitivity: 0.995238095238095"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        3
            positive       11      205
[1] "TEST accuracy: 0.937777777777778"
[1] "TEST +precision: 0.949074074074074"
[1] "TEST -precision: 0.666666666666667"
[1] "TEST specifity: 0.352941176470588"
[1] "TEST sensitivity: 0.985576923076923"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.57603863477707"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

673 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 538, 539, 539, 538, 538 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5000000  0.00000000  1.0000000
  0.010  2  0.5000000  0.00000000  1.0000000
  0.010  3  0.5000000  0.00000000  1.0000000
  0.255  1  0.5158730  0.00000000  1.0000000
  0.255  2  0.5119048  0.00000000  1.0000000
  0.255  3  0.5119048  0.00000000  1.0000000
  0.500  1  0.5114087  0.02222222  0.9984127
  0.500  2  0.5372134  0.02222222  1.0000000
  0.500  3  0.5119048  0.00000000  1.0000000

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.1      0.0
  positive      6.2     93.6
                            
 Accuracy (average) : 0.9376

[1] "TRAIN accuracy: 0.937592867756315"
[1] "TRAIN +precision: 0.9375"
[1] "TRAIN -precision: 1"
[1] "TRAIN specifity: 0.0232558139534884"
[1] "TRAIN sensitivity: 1"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       17      208
[1] "TEST accuracy: 0.924444444444444"
[1] "TEST +precision: 0.924444444444444"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.029427699248"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

673 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 538, 539, 538, 538, 539 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7288250  0.04722222  0.9968254
  0.3  1          0.6               0.50       100      0.7460428  0.06944444  0.9968254
  0.3  1          0.6               0.50       150      0.7494268  0.11388889  0.9968254
  0.3  1          0.6               0.75        50      0.7652668  0.04444444  1.0000000
  0.3  1          0.6               0.75       100      0.7853175  0.06944444  0.9952381
  0.3  1          0.6               0.75       150      0.7879850  0.09166667  0.9952381
  0.3  1          0.6               1.00        50      0.7387676  0.00000000  0.9984127
  0.3  1          0.6               1.00       100      0.7612434  0.06944444  0.9920635
  0.3  1          0.6               1.00       150      0.7689264  0.09166667  0.9888889
  0.3  1          0.8               0.50        50      0.7234347  0.09166667  0.9968254
  0.3  1          0.8               0.50       100      0.7450066  0.09166667  0.9968254
  0.3  1          0.8               0.50       150      0.7463624  0.11666667  0.9968254
  0.3  1          0.8               0.75        50      0.7403660  0.06666667  0.9936508
  0.3  1          0.8               0.75       100      0.7653108  0.09444444  0.9904762
  0.3  1          0.8               0.75       150      0.7699956  0.09444444  0.9904762
  0.3  1          0.8               1.00        50      0.7431327  0.00000000  0.9984127
  0.3  1          0.8               1.00       100      0.7655864  0.09444444  0.9936508
  0.3  1          0.8               1.00       150      0.7742394  0.11666667  0.9904762
  0.3  2          0.6               0.50        50      0.7074405  0.04722222  0.9968254
  0.3  2          0.6               0.50       100      0.7144841  0.09166667  0.9968254
  0.3  2          0.6               0.50       150      0.7318342  0.06944444  0.9968254
  0.3  2          0.6               0.75        50      0.7666997  0.04444444  0.9936508
  0.3  2          0.6               0.75       100      0.7773699  0.11666667  0.9888889
  0.3  2          0.6               0.75       150      0.7698964  0.11388889  0.9904762
  0.3  2          0.6               1.00        50      0.7655093  0.06944444  0.9920635
  0.3  2          0.6               1.00       100      0.7725529  0.09166667  0.9904762
  0.3  2          0.6               1.00       150      0.7753968  0.09166667  0.9904762
  0.3  2          0.8               0.50        50      0.7500441  0.06944444  0.9984127
  0.3  2          0.8               0.50       100      0.7540785  0.09166667  0.9952381
  0.3  2          0.8               0.50       150      0.7504189  0.09166667  0.9952381
  0.3  2          0.8               0.75        50      0.7626213  0.09444444  0.9873016
  0.3  2          0.8               0.75       100      0.7802138  0.06944444  0.9888889
  0.3  2          0.8               0.75       150      0.7860780  0.09166667  0.9888889
  0.3  2          0.8               1.00        50      0.7708554  0.09166667  0.9888889
  0.3  2          0.8               1.00       100      0.7792769  0.11388889  0.9888889
  0.3  2          0.8               1.00       150      0.7771825  0.13611111  0.9888889
  0.3  3          0.6               0.50        50      0.7154762  0.02222222  1.0000000
  0.3  3          0.6               0.50       100      0.7190807  0.04722222  0.9952381
  0.3  3          0.6               0.50       150      0.7409281  0.06944444  0.9952381
  0.3  3          0.6               0.75        50      0.7458884  0.06666667  0.9984127
  0.3  3          0.6               0.75       100      0.7446759  0.11666667  0.9952381
  0.3  3          0.6               0.75       150      0.7453483  0.11666667  0.9936508
  0.3  3          0.6               1.00        50      0.7808201  0.06944444  0.9888889
  0.3  3          0.6               1.00       100      0.7881614  0.11388889  0.9888889
  0.3  3          0.6               1.00       150      0.7895062  0.11388889  0.9888889
  0.3  3          0.8               0.50        50      0.7539021  0.09166667  0.9968254
  0.3  3          0.8               0.50       100      0.7458113  0.06944444  0.9936508
  0.3  3          0.8               0.50       150      0.7573854  0.09166667  0.9936508
  0.3  3          0.8               0.75        50      0.7541887  0.09166667  0.9904762
  0.3  3          0.8               0.75       100      0.7595679  0.11388889  0.9888889
  0.3  3          0.8               0.75       150      0.7619268  0.11388889  0.9904762
  0.3  3          0.8               1.00        50      0.7798060  0.11388889  0.9857143
  0.3  3          0.8               1.00       100      0.7774250  0.11388889  0.9873016
  0.3  3          0.8               1.00       150      0.7817901  0.13611111  0.9873016
  0.4  1          0.6               0.50        50      0.6914021  0.04722222  0.9968254
  0.4  1          0.6               0.50       100      0.6958995  0.05000000  0.9952381
  0.4  1          0.6               0.50       150      0.7204586  0.05000000  0.9936508
  0.4  1          0.6               0.75        50      0.7589286  0.09166667  0.9936508
  0.4  1          0.6               0.75       100      0.7592372  0.09166667  0.9904762
  0.4  1          0.6               0.75       150      0.7697090  0.11666667  0.9904762
  0.4  1          0.6               1.00        50      0.7590498  0.00000000  0.9984127
  0.4  1          0.6               1.00       100      0.7787588  0.09166667  0.9952381
  0.4  1          0.6               1.00       150      0.7824295  0.11388889  0.9920635
  0.4  1          0.8               0.50        50      0.6929894  0.04722222  0.9968254
  0.4  1          0.8               0.50       100      0.7256834  0.04722222  0.9952381
  0.4  1          0.8               0.50       150      0.7379519  0.04722222  0.9968254
  0.4  1          0.8               0.75        50      0.7671407  0.04444444  0.9952381
  0.4  1          0.8               0.75       100      0.7758598  0.09444444  0.9952381
  0.4  1          0.8               0.75       150      0.7827160  0.06944444  0.9936508
  0.4  1          0.8               1.00        50      0.7548170  0.02222222  0.9984127
  0.4  1          0.8               1.00       100      0.7778108  0.13888889  0.9904762
  0.4  1          0.8               1.00       150      0.7817460  0.13888889  0.9888889
  0.4  2          0.6               0.50        50      0.6990631  0.04722222  0.9968254
  0.4  2          0.6               0.50       100      0.7059303  0.04722222  0.9952381
  0.4  2          0.6               0.50       150      0.7104718  0.09166667  0.9936508
  0.4  2          0.6               0.75        50      0.7655534  0.09444444  0.9888889
  0.4  2          0.6               0.75       100      0.7733796  0.09444444  0.9888889
  0.4  2          0.6               0.75       150      0.7812831  0.09166667  0.9904762
  0.4  2          0.6               1.00        50      0.7767306  0.09444444  0.9920635
  0.4  2          0.6               1.00       100      0.7890212  0.13888889  0.9904762
  0.4  2          0.6               1.00       150      0.7877646  0.13888889  0.9904762
  0.4  2          0.8               0.50        50      0.7380181  0.09166667  0.9952381
  0.4  2          0.8               0.50       100      0.7244048  0.09166667  0.9968254
  0.4  2          0.8               0.50       150      0.7433862  0.11388889  0.9952381
  0.4  2          0.8               0.75        50      0.7508708  0.09166667  0.9904762
  0.4  2          0.8               0.75       100      0.7593034  0.11388889  0.9857143
  0.4  2          0.8               0.75       150      0.7578042  0.13888889  0.9888889
  0.4  2          0.8               1.00        50      0.7721340  0.11666667  0.9888889
  0.4  2          0.8               1.00       100      0.7833774  0.13888889  0.9904762
  0.4  2          0.8               1.00       150      0.7800044  0.13888889  0.9904762
  0.4  3          0.6               0.50        50      0.6885913  0.13888889  0.9936508
  0.4  3          0.6               0.50       100      0.6998016  0.11388889  0.9952381
  0.4  3          0.6               0.50       150      0.6917108  0.09166667  0.9968254
  0.4  3          0.6               0.75        50      0.7673391  0.09166667  0.9888889
  0.4  3          0.6               0.75       100      0.7672729  0.09166667  0.9888889
  0.4  3          0.6               0.75       150      0.7557650  0.09166667  0.9873016
  0.4  3          0.6               1.00        50      0.7849427  0.13888889  0.9888889
  0.4  3          0.6               1.00       100      0.7876102  0.13888889  0.9904762
  0.4  3          0.6               1.00       150      0.7868827  0.13888889  0.9904762
  0.4  3          0.8               0.50        50      0.7278219  0.04444444  0.9968254
  0.4  3          0.8               0.50       100      0.7206900  0.06666667  0.9952381
  0.4  3          0.8               0.50       150      0.7414131  0.08888889  0.9952381
  0.4  3          0.8               0.75        50      0.7590719  0.11388889  0.9904762
  0.4  3          0.8               0.75       100      0.7641534  0.11388889  0.9888889
  0.4  3          0.8               0.75       150      0.7626764  0.13611111  0.9920635
  0.4  3          0.8               1.00        50      0.7714727  0.09166667  0.9888889
  0.4  3          0.8               1.00       100      0.7808201  0.11388889  0.9888889
  0.4  3          0.8               1.00       150      0.7735450  0.11388889  0.9904762

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      0.7      1.0
  positive      5.6     92.6
                            
 Accuracy (average) : 0.9331

[1] "TRAIN accuracy: 0.933135215453195"
[1] "TRAIN +precision: 0.942511346444781"
[1] "TRAIN -precision: 0.416666666666667"
[1] "TRAIN specifity: 0.116279069767442"
[1] "TRAIN sensitivity: 0.988888888888889"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        2
            positive       17      206
[1] "TEST accuracy: 0.915555555555556"
[1] "TEST +precision: 0.923766816143498"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.990384615384615"
