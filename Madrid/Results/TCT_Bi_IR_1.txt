[1] "DATASET NAME: TCT_Bi_IR_1"
[1] "TRAIN INSTANCES: 1260"
[1] "TEST INSTANCES: 225"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 4.2640380859375"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1260 samples
 940 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1008, 1008, 1008, 1008, 1008 
Resampling results:

  ROC        Sens      Spec     
  0.9983308  0.968254  0.9936508

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     48.4      0.3
  positive      1.6     49.7
                           
 Accuracy (average) : 0.981

[1] "TRAIN accuracy: 0.980952380952381"
[1] "TRAIN +precision: 0.969040247678019"
[1] "TRAIN -precision: 0.993485342019544"
[1] "TRAIN specifity: 0.968253968253968"
[1] "TRAIN sensitivity: 0.993650793650794"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6        0
            positive       11      208
[1] "TEST accuracy: 0.951111111111111"
[1] "TEST +precision: 0.949771689497717"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.352941176470588"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.65046043395996"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1260 samples
 940 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1008, 1008, 1008, 1008, 1008 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9581948  0.9047619  0.9555556
  0.010  2  0.9582640  0.9047619  0.9539683
  0.010  3  0.9602167  0.9047619  0.9603175
  0.255  1  0.9655392  0.9095238  0.9825397
  0.255  2  0.9662195  0.9095238  0.9809524
  0.255  3  0.9670824  0.9095238  0.9777778
  0.500  1  0.9671580  0.9095238  0.9841270
  0.500  2  0.9688209  0.9095238  0.9825397
  0.500  3  0.9693626  0.9095238  0.9777778

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     45.5      1.1
  positive      4.5     48.9
                            
 Accuracy (average) : 0.9437

[1] "TRAIN accuracy: 0.943650793650794"
[1] "TRAIN +precision: 0.915304606240713"
[1] "TRAIN -precision: 0.976149914821124"
[1] "TRAIN specifity: 0.90952380952381"
[1] "TRAIN sensitivity: 0.977777777777778"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        2
            positive       15      206
[1] "TEST accuracy: 0.924444444444444"
[1] "TEST +precision: 0.932126696832579"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.117647058823529"
[1] "TEST sensitivity: 0.990384615384615"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 5.56683823267619"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1260 samples
 940 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1008, 1008, 1008, 1008, 1008 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9549131  0.8158730  0.9587302
  0.3  1          0.6               0.50       100      0.9725498  0.9206349  0.9603175
  0.3  1          0.6               0.50       150      0.9803288  0.9571429  0.9587302
  0.3  1          0.6               0.75        50      0.9569035  0.8476190  0.9587302
  0.3  1          0.6               0.75       100      0.9776707  0.9365079  0.9587302
  0.3  1          0.6               0.75       150      0.9833963  0.9571429  0.9634921
  0.3  1          0.6               1.00        50      0.9523180  0.8380952  0.9571429
  0.3  1          0.6               1.00       100      0.9799887  0.9222222  0.9603175
  0.3  1          0.6               1.00       150      0.9845679  0.9571429  0.9666667
  0.3  1          0.8               0.50        50      0.9550454  0.8317460  0.9539683
  0.3  1          0.8               0.50       100      0.9716616  0.9285714  0.9587302
  0.3  1          0.8               0.50       150      0.9800139  0.9539683  0.9603175
  0.3  1          0.8               0.75        50      0.9578231  0.8396825  0.9587302
  0.3  1          0.8               0.75       100      0.9774943  0.9317460  0.9587302
  0.3  1          0.8               0.75       150      0.9827790  0.9571429  0.9634921
  0.3  1          0.8               1.00        50      0.9523495  0.8365079  0.9555556
  0.3  1          0.8               1.00       100      0.9806122  0.9301587  0.9603175
  0.3  1          0.8               1.00       150      0.9851222  0.9571429  0.9714286
  0.3  2          0.6               0.50        50      0.9699546  0.9238095  0.9555556
  0.3  2          0.6               0.50       100      0.9852356  0.9682540  0.9650794
  0.3  2          0.6               0.50       150      0.9882653  0.9682540  0.9666667
  0.3  2          0.6               0.75        50      0.9770723  0.9412698  0.9603175
  0.3  2          0.6               0.75       100      0.9880889  0.9682540  0.9698413
  0.3  2          0.6               0.75       150      0.9906085  0.9682540  0.9682540
  0.3  2          0.6               1.00        50      0.9807508  0.9460317  0.9650794
  0.3  2          0.6               1.00       100      0.9891030  0.9682540  0.9761905
  0.3  2          0.6               1.00       150      0.9909990  0.9682540  0.9793651
  0.3  2          0.8               0.50        50      0.9761779  0.9222222  0.9603175
  0.3  2          0.8               0.50       100      0.9855253  0.9571429  0.9666667
  0.3  2          0.8               0.50       150      0.9897014  0.9682540  0.9698413
  0.3  2          0.8               0.75        50      0.9792769  0.9396825  0.9619048
  0.3  2          0.8               0.75       100      0.9876732  0.9682540  0.9682540
  0.3  2          0.8               0.75       150      0.9905707  0.9682540  0.9714286
  0.3  2          0.8               1.00        50      0.9806374  0.9428571  0.9634921
  0.3  2          0.8               1.00       100      0.9890779  0.9682540  0.9761905
  0.3  2          0.8               1.00       150      0.9908541  0.9682540  0.9777778
  0.3  3          0.6               0.50        50      0.9820673  0.9571429  0.9634921
  0.3  3          0.6               0.50       100      0.9891975  0.9682540  0.9666667
  0.3  3          0.6               0.50       150      0.9899093  0.9682540  0.9682540
  0.3  3          0.6               0.75        50      0.9856261  0.9682540  0.9666667
  0.3  3          0.6               0.75       100      0.9897770  0.9682540  0.9714286
  0.3  3          0.6               0.75       150      0.9914210  0.9682540  0.9730159
  0.3  3          0.6               1.00        50      0.9857395  0.9571429  0.9698413
  0.3  3          0.6               1.00       100      0.9913769  0.9682540  0.9746032
  0.3  3          0.6               1.00       150      0.9920761  0.9682540  0.9793651
  0.3  3          0.8               0.50        50      0.9826405  0.9571429  0.9634921
  0.3  3          0.8               0.50       100      0.9892542  0.9682540  0.9682540
  0.3  3          0.8               0.50       150      0.9901864  0.9682540  0.9666667
  0.3  3          0.8               0.75        50      0.9851285  0.9571429  0.9650794
  0.3  3          0.8               0.75       100      0.9906526  0.9682540  0.9698413
  0.3  3          0.8               0.75       150      0.9911439  0.9682540  0.9730159
  0.3  3          0.8               1.00        50      0.9862749  0.9571429  0.9682540
  0.3  3          0.8               1.00       100      0.9910557  0.9682540  0.9777778
  0.3  3          0.8               1.00       150      0.9917171  0.9682540  0.9793651
  0.4  1          0.6               0.50        50      0.9641912  0.8968254  0.9571429
  0.4  1          0.6               0.50       100      0.9790690  0.9571429  0.9666667
  0.4  1          0.6               0.50       150      0.9856324  0.9571429  0.9634921
  0.4  1          0.6               0.75        50      0.9657911  0.8761905  0.9619048
  0.4  1          0.6               0.75       100      0.9817397  0.9571429  0.9634921
  0.4  1          0.6               0.75       150      0.9863694  0.9682540  0.9650794
  0.4  1          0.6               1.00        50      0.9635425  0.8920635  0.9587302
  0.4  1          0.6               1.00       100      0.9798186  0.9460317  0.9619048
  0.4  1          0.6               1.00       150      0.9869300  0.9682540  0.9714286
  0.4  1          0.8               0.50        50      0.9597632  0.8825397  0.9428571
  0.4  1          0.8               0.50       100      0.9774817  0.9571429  0.9587302
  0.4  1          0.8               0.50       150      0.9837365  0.9682540  0.9587302
  0.4  1          0.8               0.75        50      0.9619363  0.8793651  0.9587302
  0.4  1          0.8               0.75       100      0.9778219  0.9571429  0.9650794
  0.4  1          0.8               0.75       150      0.9862119  0.9682540  0.9682540
  0.4  1          0.8               1.00        50      0.9695641  0.8888889  0.9587302
  0.4  1          0.8               1.00       100      0.9826909  0.9571429  0.9666667
  0.4  1          0.8               1.00       150      0.9863064  0.9682540  0.9714286
  0.4  2          0.6               0.50        50      0.9821744  0.9523810  0.9666667
  0.4  2          0.6               0.50       100      0.9880134  0.9682540  0.9666667
  0.4  2          0.6               0.50       150      0.9896384  0.9682540  0.9650794
  0.4  2          0.6               0.75        50      0.9824452  0.9476190  0.9650794
  0.4  2          0.6               0.75       100      0.9891408  0.9682540  0.9698413
  0.4  2          0.6               0.75       150      0.9910809  0.9682540  0.9730159
  0.4  2          0.6               1.00        50      0.9835097  0.9492063  0.9634921
  0.4  2          0.6               1.00       100      0.9902494  0.9682540  0.9777778
  0.4  2          0.6               1.00       150      0.9915596  0.9682540  0.9809524
  0.4  2          0.8               0.50        50      0.9773998  0.9571429  0.9587302
  0.4  2          0.8               0.50       100      0.9887377  0.9682540  0.9650794
  0.4  2          0.8               0.50       150      0.9899408  0.9682540  0.9650794
  0.4  2          0.8               0.75        50      0.9804296  0.9412698  0.9650794
  0.4  2          0.8               0.75       100      0.9897455  0.9682540  0.9714286
  0.4  2          0.8               0.75       150      0.9912006  0.9682540  0.9714286
  0.4  2          0.8               1.00        50      0.9839506  0.9571429  0.9682540
  0.4  2          0.8               1.00       100      0.9900479  0.9682540  0.9746032
  0.4  2          0.8               1.00       150      0.9914336  0.9682540  0.9809524
  0.4  3          0.6               0.50        50      0.9843474  0.9571429  0.9682540
  0.4  3          0.6               0.50       100      0.9905266  0.9682540  0.9698413
  0.4  3          0.6               0.50       150      0.9911250  0.9682540  0.9666667
  0.4  3          0.6               0.75        50      0.9887881  0.9682540  0.9698413
  0.4  3          0.6               0.75       100      0.9915407  0.9682540  0.9730159
  0.4  3          0.6               0.75       150      0.9922840  0.9682540  0.9746032
  0.4  3          0.6               1.00        50      0.9886054  0.9682540  0.9746032
  0.4  3          0.6               1.00       100      0.9919942  0.9682540  0.9777778
  0.4  3          0.6               1.00       150      0.9921706  0.9682540  0.9761905
  0.4  3          0.8               0.50        50      0.9865142  0.9682540  0.9650794
  0.4  3          0.8               0.50       100      0.9900038  0.9682540  0.9714286
  0.4  3          0.8               0.50       150      0.9909549  0.9682540  0.9714286
  0.4  3          0.8               0.75        50      0.9872890  0.9682540  0.9682540
  0.4  3          0.8               0.75       100      0.9914462  0.9682540  0.9714286
  0.4  3          0.8               0.75       150      0.9922336  0.9682540  0.9714286
  0.4  3          0.8               1.00        50      0.9881393  0.9682540  0.9730159
  0.4  3          0.8               1.00       100      0.9915911  0.9682540  0.9761905
  0.4  3          0.8               1.00       150      0.9924981  0.9682540  0.9746032

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     48.4      1.3
  positive      1.6     48.7
                            
 Accuracy (average) : 0.9714

[1] "TRAIN accuracy: 0.971428571428571"
[1] "TRAIN +precision: 0.968454258675079"
[1] "TRAIN -precision: 0.97444089456869"
[1] "TRAIN specifity: 0.968253968253968"
[1] "TRAIN sensitivity: 0.974603174603175"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        1
            positive       13      207
[1] "TEST accuracy: 0.937777777777778"
[1] "TEST +precision: 0.940909090909091"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.235294117647059"
[1] "TEST sensitivity: 0.995192307692308"
