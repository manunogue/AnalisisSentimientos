[1] "DATASET NAME: Botin_Bi_IR_10"
[1] "TRAIN INSTANCES: 1838"
[1] "TEST INSTANCES: 573"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 6.73057794570923"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1838 samples
 834 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1470, 1470, 1471, 1470, 1471 
Resampling results:

  ROC        Sens       Spec     
  0.9327327  0.7202883  0.9658912

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     14.6      2.7
  positive      5.7     77.0
                            
 Accuracy (average) : 0.9162

[1] "TRAIN accuracy: 0.916213275299238"
[1] "TRAIN +precision: 0.931578947368421"
[1] "TRAIN -precision: 0.842767295597484"
[1] "TRAIN specifity: 0.720430107526882"
[1] "TRAIN sensitivity: 0.965893587994543"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       42       15
            positive       50      466
[1] "TEST accuracy: 0.886561954624782"
[1] "TEST +precision: 0.903100775193798"
[1] "TEST -precision: 0.736842105263158"
[1] "TEST specifity: 0.456521739130435"
[1] "TEST sensitivity: 0.968814968814969"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 3.75581285158793"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1838 samples
 834 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1470, 1470, 1470, 1471, 1471 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.5841657  0.1990631  0.9761278
  0.010  2  0.5918886  0.1909550  0.9727148
  0.010  3  0.5915784  0.1829550  0.9727171
  0.255  1  0.7234277  0.3602523  0.9508857
  0.255  2  0.7076420  0.2877838  0.9577024
  0.255  3  0.6664557  0.2448288  0.9563395
  0.500  1  0.7467973  0.3790991  0.9611200
  0.500  2  0.7526347  0.3145225  0.9597571
  0.500  3  0.7498910  0.2902703  0.9583896

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      6.4      3.2
  positive     13.9     76.6
                            
 Accuracy (average) : 0.8292

[1] "TRAIN accuracy: 0.829162132752992"
[1] "TRAIN +precision: 0.846570397111913"
[1] "TRAIN -precision: 0.664772727272727"
[1] "TRAIN specifity: 0.314516129032258"
[1] "TRAIN sensitivity: 0.959754433833561"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9       15
            positive       83      466
[1] "TEST accuracy: 0.828970331588133"
[1] "TEST +precision: 0.848816029143898"
[1] "TEST -precision: 0.375"
[1] "TEST specifity: 0.0978260869565217"
[1] "TEST sensitivity: 0.968814968814969"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 8.23022161722183"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1838 samples
 834 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1470, 1471, 1470, 1471, 1470 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.7867908  0.1800360  0.9884098
  0.3  1          0.6               0.50       100      0.8346802  0.2904865  0.9788558
  0.3  1          0.6               0.50       150      0.8428133  0.3388468  0.9768173
  0.3  1          0.6               0.75        50      0.7873051  0.1827027  0.9856725
  0.3  1          0.6               0.75       100      0.8412074  0.2903063  0.9843189
  0.3  1          0.6               0.75       150      0.8602308  0.3360360  0.9795454
  0.3  1          0.6               1.00        50      0.7878469  0.1343423  0.9972743
  0.3  1          0.6               1.00       100      0.8417650  0.2498739  0.9952335
  0.3  1          0.6               1.00       150      0.8647792  0.3225946  0.9850038
  0.3  1          0.8               0.50        50      0.7885371  0.1990631  0.9836317
  0.3  1          0.8               0.50       100      0.8287650  0.2636396  0.9815862
  0.3  1          0.8               0.50       150      0.8480658  0.3522523  0.9802210
  0.3  1          0.8               0.75        50      0.7835158  0.1640000  0.9877180
  0.3  1          0.8               0.75       100      0.8374647  0.2716036  0.9822711
  0.3  1          0.8               0.75       150      0.8622693  0.3145225  0.9815885
  0.3  1          0.8               1.00        50      0.7931796  0.1424144  0.9972743
  0.3  1          0.8               1.00       100      0.8419320  0.2634234  0.9904553
  0.3  1          0.8               1.00       150      0.8632704  0.3145225  0.9850015
  0.3  2          0.6               0.50        50      0.8369410  0.2876396  0.9856795
  0.3  2          0.6               0.50       100      0.8596675  0.4167207  0.9713589
  0.3  2          0.6               0.50       150      0.8683241  0.4355315  0.9727171
  0.3  2          0.6               0.75        50      0.8390616  0.2741982  0.9781732
  0.3  2          0.6               0.75       100      0.8750857  0.3871351  0.9795431
  0.3  2          0.6               0.75       150      0.8912788  0.4545586  0.9802257
  0.3  2          0.6               1.00        50      0.8427687  0.2849730  0.9897750
  0.3  2          0.6               1.00       100      0.8789821  0.3790631  0.9822688
  0.3  2          0.6               1.00       150      0.8882610  0.4437477  0.9788628
  0.3  2          0.8               0.50        50      0.8313950  0.2794234  0.9836294
  0.3  2          0.8               0.50       100      0.8552782  0.3791712  0.9727195
  0.3  2          0.8               0.50       150      0.8664727  0.4195676  0.9740847
  0.3  2          0.8               0.75        50      0.8330034  0.2984505  0.9809013
  0.3  2          0.8               0.75       100      0.8744117  0.3979820  0.9795431
  0.3  2          0.8               0.75       150      0.8836073  0.4491532  0.9774976
  0.3  2          0.8               1.00        50      0.8451909  0.3092613  0.9843166
  0.3  2          0.8               1.00       100      0.8794048  0.3844685  0.9829514
  0.3  2          0.8               1.00       150      0.8931847  0.4383063  0.9802257
  0.3  3          0.6               0.50        50      0.8410277  0.3550991  0.9774907
  0.3  3          0.6               0.50       100      0.8647993  0.4276036  0.9740847
  0.3  3          0.6               0.50       150      0.8757004  0.4652252  0.9699914
  0.3  3          0.6               0.75        50      0.8547879  0.3494775  0.9802234
  0.3  3          0.6               0.75       100      0.8883412  0.4600360  0.9829514
  0.3  3          0.6               0.75       150      0.8951548  0.5003243  0.9761324
  0.3  3          0.6               1.00        50      0.8694542  0.3387027  0.9795431
  0.3  3          0.6               1.00       100      0.8873799  0.4356036  0.9788582
  0.3  3          0.6               1.00       150      0.8971167  0.4786667  0.9761324
  0.3  3          0.8               0.50        50      0.8450443  0.3469550  0.9802257
  0.3  3          0.8               0.50       100      0.8575297  0.4193874  0.9733997
  0.3  3          0.8               0.50       150      0.8743804  0.4651532  0.9713566
  0.3  3          0.8               0.75        50      0.8560105  0.3577297  0.9815909
  0.3  3          0.8               0.75       100      0.8849900  0.4384865  0.9774930
  0.3  3          0.8               0.75       150      0.8916446  0.5001441  0.9727241
  0.3  3          0.8               1.00        50      0.8662469  0.3548829  0.9809083
  0.3  3          0.8               1.00       100      0.8872276  0.4383784  0.9781779
  0.3  3          0.8               1.00       150      0.8995490  0.4814414  0.9740916
  0.4  1          0.6               0.50        50      0.8072248  0.2044324  0.9849992
  0.4  1          0.6               0.50       100      0.8423641  0.3334414  0.9781732
  0.4  1          0.6               0.50       150      0.8567787  0.3549550  0.9686239
  0.4  1          0.6               0.75        50      0.8051270  0.2473153  0.9836363
  0.4  1          0.6               0.75       100      0.8497214  0.3226306  0.9788558
  0.4  1          0.6               0.75       150      0.8672158  0.3981261  0.9795454
  0.4  1          0.6               1.00        50      0.8079702  0.1880360  0.9965963
  0.4  1          0.6               1.00       100      0.8603384  0.3118198  0.9850038
  0.4  1          0.6               1.00       150      0.8790155  0.3494054  0.9849969
  0.4  1          0.8               0.50        50      0.8016455  0.2579820  0.9829491
  0.4  1          0.8               0.50       100      0.8337214  0.3683243  0.9727218
  0.4  1          0.8               0.50       150      0.8518376  0.3953514  0.9761301
  0.4  1          0.8               0.75        50      0.8125149  0.2446486  0.9815862
  0.4  1          0.8               0.75       100      0.8519044  0.3171892  0.9809059
  0.4  1          0.8               0.75       150      0.8710917  0.4033153  0.9802280
  0.4  1          0.8               1.00        50      0.8120906  0.1827387  0.9965963
  0.4  1          0.8               1.00       100      0.8596070  0.2929369  0.9849992
  0.4  1          0.8               1.00       150      0.8784234  0.3602883  0.9843212
  0.4  2          0.6               0.50        50      0.8346926  0.3334054  0.9781709
  0.4  2          0.6               0.50       100      0.8584921  0.4302703  0.9720369
  0.4  2          0.6               0.50       150      0.8737227  0.4490811  0.9720415
  0.4  2          0.6               0.75        50      0.8572257  0.3442162  0.9774930
  0.4  2          0.6               0.75       100      0.8810072  0.4276757  0.9747649
  0.4  2          0.6               0.75       150      0.8872266  0.4814775  0.9699891
  0.4  2          0.6               1.00        50      0.8643363  0.3414775  0.9849992
  0.4  2          0.6               1.00       100      0.8875508  0.4194955  0.9802234
  0.4  2          0.6               1.00       150      0.8948425  0.4545586  0.9788628
  0.4  2          0.8               0.50        50      0.8400583  0.3577297  0.9795384
  0.4  2          0.8               0.50       100      0.8664704  0.4087568  0.9734044
  0.4  2          0.8               0.50       150      0.8765816  0.4624865  0.9740893
  0.4  2          0.8               0.75        50      0.8479592  0.3145586  0.9788582
  0.4  2          0.8               0.75       100      0.8783276  0.4410450  0.9774976
  0.4  2          0.8               0.75       150      0.8858031  0.4653333  0.9734044
  0.4  2          0.8               1.00        50      0.8608598  0.3144865  0.9843189
  0.4  2          0.8               1.00       100      0.8868820  0.4033514  0.9795454
  0.4  2          0.8               1.00       150      0.8958262  0.4518919  0.9815932
  0.4  3          0.6               0.50        50      0.8545108  0.3684324  0.9768057
  0.4  3          0.6               0.50       100      0.8699382  0.4464144  0.9727171
  0.4  3          0.6               0.50       150      0.8797280  0.4867748  0.9652179
  0.4  3          0.6               0.75        50      0.8692531  0.3898018  0.9829514
  0.4  3          0.6               0.75       100      0.8942267  0.4706306  0.9720415
  0.4  3          0.6               0.75       150      0.9001213  0.5081441  0.9699961
  0.4  3          0.6               1.00        50      0.8751834  0.3925405  0.9788582
  0.4  3          0.6               1.00       100      0.8973046  0.4760360  0.9795431
  0.4  3          0.6               1.00       150      0.9041374  0.5162523  0.9747672
  0.4  3          0.8               0.50        50      0.8484750  0.3657297  0.9747626
  0.4  3          0.8               0.50       100      0.8716106  0.4518198  0.9706786
  0.4  3          0.8               0.50       150      0.8755073  0.5056216  0.9631678
  0.4  3          0.8               0.75        50      0.8740274  0.3899099  0.9802210
  0.4  3          0.8               0.75       100      0.8888575  0.4787748  0.9754522
  0.4  3          0.8               0.75       150      0.8946089  0.5216577  0.9699937
  0.4  3          0.8               1.00        50      0.8766057  0.3952432  0.9774930
  0.4  3          0.8               1.00       100      0.8978561  0.4705946  0.9761324
  0.4  3          0.8               1.00       150      0.9037268  0.5136577  0.9740870

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.4      2.0
  positive      9.8     77.7
                            
 Accuracy (average) : 0.8819

[1] "TRAIN accuracy: 0.881936887921654"
[1] "TRAIN +precision: 0.888129272840273"
[1] "TRAIN -precision: 0.838427947598253"
[1] "TRAIN specifity: 0.516129032258065"
[1] "TRAIN sensitivity: 0.974761255115962"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       23       11
            positive       69      470
[1] "TEST accuracy: 0.860383944153578"
[1] "TEST +precision: 0.871985157699443"
[1] "TEST -precision: 0.676470588235294"
[1] "TEST specifity: 0.25"
[1] "TEST sensitivity: 0.977130977130977"
