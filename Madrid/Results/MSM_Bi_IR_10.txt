[1] "DATASET NAME: MSM_Bi_IR_10"
[1] "TRAIN INSTANCES: 1965"
[1] "TEST INSTANCES: 600"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 9.75793409347534"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1965 samples
 583 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1571, 1572, 1572, 1572, 1573 
Resampling results:

  ROC        Sens       Spec     
  0.9796646  0.8875116  0.9878929

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.4      1.1
  positive      1.3     87.2
                            
 Accuracy (average) : 0.9761

[1] "TRAIN accuracy: 0.976081424936387"
[1] "TRAIN +precision: 0.9850488786659"
[1] "TRAIN -precision: 0.907079646017699"
[1] "TRAIN specifity: 0.887445887445887"
[1] "TRAIN sensitivity: 0.987889273356401"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2       13
            positive       16      569
[1] "TEST accuracy: 0.951666666666667"
[1] "TEST +precision: 0.972649572649573"
[1] "TEST -precision: 0.133333333333333"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.97766323024055"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.98571746746699"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1965 samples
 583 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1573, 1572, 1572, 1571, 1572 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7397901  0.4287697  0.9901967
  0.010  2  0.7384533  0.4372803  0.9884643
  0.010  3  0.7375486  0.4372803  0.9873116
  0.255  1  0.8485795  0.5713228  0.9884676
  0.255  2  0.8460145  0.5585569  0.9878896
  0.255  3  0.8472771  0.5455134  0.9855808
  0.500  1  0.8656074  0.5842738  0.9884676
  0.500  2  0.8646181  0.5715079  0.9896187
  0.500  3  0.8627026  0.5541166  0.9855808

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      6.9      1.0
  positive      4.9     87.2
                           
 Accuracy (average) : 0.941

[1] "TRAIN accuracy: 0.940966921119593"
[1] "TRAIN +precision: 0.946961325966851"
[1] "TRAIN -precision: 0.870967741935484"
[1] "TRAIN specifity: 0.584415584415584"
[1] "TRAIN sensitivity: 0.988465974625144"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        9
            positive       16      573
[1] "TEST accuracy: 0.958333333333333"
[1] "TEST +precision: 0.972835314091681"
[1] "TEST -precision: 0.181818181818182"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.984536082474227"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 5.80213284889857"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1965 samples
 583 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1572, 1572, 1571, 1573, 1572 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8499598  0.3679001  0.9901934
  0.3  1          0.6               0.50       100      0.8764039  0.4585569  0.9890373
  0.3  1          0.6               0.50       150      0.8946380  0.4931545  0.9873082
  0.3  1          0.6               0.75        50      0.8522446  0.3893617  0.9901967
  0.3  1          0.6               0.75       100      0.8939813  0.4932470  0.9896187
  0.3  1          0.6               0.75       150      0.9070258  0.5235893  0.9901951
  0.3  1          0.6               1.00        50      0.8520365  0.3897317  0.9913461
  0.3  1          0.6               1.00       100      0.8979116  0.4888992  0.9901917
  0.3  1          0.6               1.00       150      0.9136295  0.5193340  0.9907681
  0.3  1          0.8               0.50        50      0.8479303  0.3723404  0.9896170
  0.3  1          0.8               0.50       100      0.8825927  0.4716929  0.9884626
  0.3  1          0.8               0.50       150      0.8960198  0.4975948  0.9873082
  0.3  1          0.8               0.75        50      0.8472070  0.3984274  0.9913478
  0.3  1          0.8               0.75       100      0.8848250  0.4845513  0.9907714
  0.3  1          0.8               0.75       150      0.9026943  0.5062905  0.9913478
  0.3  1          0.8               1.00        50      0.8563688  0.4026827  0.9907681
  0.3  1          0.8               1.00       100      0.8996338  0.4932470  0.9901917
  0.3  1          0.8               1.00       150      0.9142986  0.5193340  0.9907681
  0.3  2          0.6               0.50        50      0.8887801  0.4542091  0.9890407
  0.3  2          0.6               0.50       100      0.9044355  0.5149861  0.9890423
  0.3  2          0.6               0.50       150      0.9198121  0.5236818  0.9890407
  0.3  2          0.6               0.75        50      0.8851589  0.5019426  0.9896154
  0.3  2          0.6               0.75       100      0.9186326  0.5367253  0.9890390
  0.3  2          0.6               0.75       150      0.9315654  0.5845513  0.9873082
  0.3  2          0.6               1.00        50      0.9008782  0.4844588  0.9925039
  0.3  2          0.6               1.00       100      0.9292820  0.5409806  0.9930802
  0.3  2          0.6               1.00       150      0.9434635  0.5583719  0.9896204
  0.3  2          0.8               0.50        50      0.8872354  0.4542091  0.9896170
  0.3  2          0.8               0.50       100      0.9087290  0.5193340  0.9896170
  0.3  2          0.8               0.50       150      0.9164977  0.5323774  0.9878846
  0.3  2          0.8               0.75        50      0.8970864  0.4845513  0.9919258
  0.3  2          0.8               0.75       100      0.9220925  0.5280296  0.9884660
  0.3  2          0.8               0.75       150      0.9328545  0.5671600  0.9878913
  0.3  2          0.8               1.00        50      0.9034068  0.5018501  0.9907681
  0.3  2          0.8               1.00       100      0.9309226  0.5453284  0.9925005
  0.3  2          0.8               1.00       150      0.9439824  0.5583719  0.9890423
  0.3  3          0.6               0.50        50      0.9101781  0.4888992  0.9907698
  0.3  3          0.6               0.50       100      0.9211535  0.5367253  0.9873116
  0.3  3          0.6               0.50       150      0.9256857  0.5497687  0.9873116
  0.3  3          0.6               0.75        50      0.9204176  0.5366327  0.9901951
  0.3  3          0.6               0.75       100      0.9361589  0.5757632  0.9907731
  0.3  3          0.6               0.75       150      0.9417463  0.5973173  0.9884643
  0.3  3          0.6               1.00        50      0.9222617  0.5148936  0.9919225
  0.3  3          0.6               1.00       100      0.9485500  0.5669750  0.9896170
  0.3  3          0.6               1.00       150      0.9520611  0.5887142  0.9867352
  0.3  3          0.8               0.50        50      0.9019481  0.5193340  0.9896187
  0.3  3          0.8               0.50       100      0.9251872  0.5453284  0.9901934
  0.3  3          0.8               0.50       150      0.9268335  0.5539315  0.9873116
  0.3  3          0.8               0.75        50      0.9152925  0.5193340  0.9907714
  0.3  3          0.8               0.75       100      0.9369931  0.5714154  0.9884660
  0.3  3          0.8               0.75       150      0.9411664  0.5974098  0.9873116
  0.3  3          0.8               1.00        50      0.9247933  0.5540241  0.9913478
  0.3  3          0.8               1.00       100      0.9436651  0.5714154  0.9884660
  0.3  3          0.8               1.00       150      0.9504124  0.5931545  0.9884643
  0.4  1          0.6               0.50        50      0.8619533  0.4153562  0.9890357
  0.4  1          0.6               0.50       100      0.8925931  0.4715079  0.9873099
  0.4  1          0.6               0.50       150      0.9018653  0.5149861  0.9884643
  0.4  1          0.6               0.75        50      0.8621387  0.4456984  0.9919225
  0.4  1          0.6               0.75       100      0.9002339  0.5019426  0.9901917
  0.4  1          0.6               0.75       150      0.9148317  0.5236818  0.9878896
  0.4  1          0.6               1.00        50      0.8668412  0.4286772  0.9913461
  0.4  1          0.6               1.00       100      0.9072289  0.5193340  0.9901917
  0.4  1          0.6               1.00       150      0.9227365  0.5236818  0.9901934
  0.4  1          0.8               0.50        50      0.8685122  0.4153562  0.9884610
  0.4  1          0.8               0.50       100      0.8860957  0.5019426  0.9884660
  0.4  1          0.8               0.50       150      0.9069453  0.5062905  0.9884610
  0.4  1          0.8               0.75        50      0.8600322  0.4630897  0.9901934
  0.4  1          0.8               0.75       100      0.8913118  0.5019426  0.9884643
  0.4  1          0.8               0.75       150      0.9108370  0.5236818  0.9867352
  0.4  1          0.8               1.00        50      0.8697613  0.4501388  0.9913478
  0.4  1          0.8               1.00       100      0.9098513  0.5106383  0.9907714
  0.4  1          0.8               1.00       150      0.9264766  0.5236818  0.9901951
  0.4  2          0.6               0.50        50      0.8924257  0.4888992  0.9884660
  0.4  2          0.6               0.50       100      0.9119209  0.5280296  0.9884643
  0.4  2          0.6               0.50       150      0.9214179  0.5367253  0.9884676
  0.4  2          0.6               0.75        50      0.9011415  0.5193340  0.9907698
  0.4  2          0.6               0.75       100      0.9250089  0.5541166  0.9873116
  0.4  2          0.6               0.75       150      0.9339500  0.5845513  0.9878879
  0.4  2          0.6               1.00        50      0.9113415  0.5236818  0.9919225
  0.4  2          0.6               1.00       100      0.9390499  0.5497687  0.9884643
  0.4  2          0.6               1.00       150      0.9483296  0.5799260  0.9867352
  0.4  2          0.8               0.50        50      0.8984058  0.4758557  0.9907681
  0.4  2          0.8               0.50       100      0.9187329  0.5149861  0.9873116
  0.4  2          0.8               0.50       150      0.9272668  0.5454209  0.9890390
  0.4  2          0.8               0.75        50      0.9034531  0.5236818  0.9890390
  0.4  2          0.8               0.75       100      0.9282740  0.5497687  0.9873132
  0.4  2          0.8               0.75       150      0.9354749  0.6103608  0.9855858
  0.4  2          0.8               1.00        50      0.9118656  0.5279371  0.9919242
  0.4  2          0.8               1.00       100      0.9387593  0.5453284  0.9896187
  0.4  2          0.8               1.00       150      0.9480596  0.5801110  0.9884660
  0.4  3          0.6               0.50        50      0.9128399  0.5019426  0.9896154
  0.4  3          0.6               0.50       100      0.9266940  0.5323774  0.9901934
  0.4  3          0.6               0.50       150      0.9289779  0.5670675  0.9867319
  0.4  3          0.6               0.75        50      0.9191581  0.5322849  0.9884660
  0.4  3          0.6               0.75       100      0.9371688  0.5888067  0.9896220
  0.4  3          0.6               0.75       150      0.9428055  0.6103608  0.9878913
  0.4  3          0.6               1.00        50      0.9342701  0.5453284  0.9919258
  0.4  3          0.6               1.00       100      0.9486465  0.5801110  0.9890440
  0.4  3          0.6               1.00       150      0.9516319  0.6278446  0.9890423
  0.4  3          0.8               0.50        50      0.9147645  0.5235893  0.9873132
  0.4  3          0.8               0.50       100      0.9262135  0.5409806  0.9907714
  0.4  3          0.8               0.50       150      0.9328254  0.5670675  0.9890390
  0.4  3          0.8               0.75        50      0.9259900  0.5280296  0.9901951
  0.4  3          0.8               0.75       100      0.9420979  0.5975948  0.9861605
  0.4  3          0.8               0.75       150      0.9434215  0.6191489  0.9884660
  0.4  3          0.8               1.00        50      0.9317852  0.5453284  0.9919242
  0.4  3          0.8               1.00       100      0.9480575  0.5844588  0.9896187
  0.4  3          0.8               1.00       150      0.9537084  0.6234043  0.9896204

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      7.3      0.9
  positive      4.4     87.3
                            
 Accuracy (average) : 0.9466

[1] "TRAIN accuracy: 0.946564885496183"
[1] "TRAIN +precision: 0.951747088186356"
[1] "TRAIN -precision: 0.888888888888889"
[1] "TRAIN specifity: 0.623376623376623"
[1] "TRAIN sensitivity: 0.98961937716263"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        4
            positive       16      578
[1] "TEST accuracy: 0.966666666666667"
[1] "TEST +precision: 0.973063973063973"
[1] "TEST -precision: 0.333333333333333"
[1] "TEST specifity: 0.111111111111111"
[1] "TEST sensitivity: 0.993127147766323"
