[1] "DATASET NAME: HRM_Bi_IR_5"
[1] "TRAIN INSTANCES: 384"
[1] "TEST INSTANCES: 112"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.23602604866028"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

384 samples
964 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 307, 308, 307, 306, 308 
Resampling results:

  ROC        Sens  Spec    
  0.9489399  0.74  0.993043

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.5      0.5
  positive      6.5     74.5
                            
 Accuracy (average) : 0.9297

[1] "TRAIN accuracy: 0.9296875"
[1] "TRAIN +precision: 0.919614147909968"
[1] "TRAIN -precision: 0.972602739726027"
[1] "TRAIN specifity: 0.739583333333333"
[1] "TRAIN sensitivity: 0.993055555555556"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        1
            positive       11       96
[1] "TEST accuracy: 0.892857142857143"
[1] "TEST +precision: 0.897196261682243"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.266666666666667"
[1] "TEST sensitivity: 0.989690721649485"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.38252364794413"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

384 samples
964 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 307, 307, 307, 307, 308 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5384755  0.08421053  0.9931034
  0.010  2  0.5384755  0.08421053  0.9931034
  0.010  3  0.5403811  0.08421053  0.9965517
  0.255  1  0.7262832  0.30263158  0.9896552
  0.255  2  0.6874004  0.25052632  0.9931034
  0.255  3  0.6498967  0.20842105  1.0000000
  0.500  1  0.7488928  0.33421053  0.9861464
  0.500  2  0.7146412  0.27157895  0.9930430
  0.500  3  0.6685358  0.21894737  0.9895342

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      8.3      1.0
  positive     16.7     74.0
                            
 Accuracy (average) : 0.8229

[1] "TRAIN accuracy: 0.822916666666667"
[1] "TRAIN +precision: 0.816091954022989"
[1] "TRAIN -precision: 0.888888888888889"
[1] "TRAIN specifity: 0.333333333333333"
[1] "TRAIN sensitivity: 0.986111111111111"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       15       97
[1] "TEST accuracy: 0.866071428571429"
[1] "TEST +precision: 0.866071428571429"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.34384391705195"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

384 samples
964 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 307, 306, 308, 308, 307 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.7030901  0.11421053  0.9895947
  0.3  1          0.6               0.50       100      0.7553765  0.20947368  0.9895947
  0.3  1          0.6               0.50       150      0.7856430  0.18842105  0.9895947
  0.3  1          0.6               0.75        50      0.7846016  0.22000000  0.9895947
  0.3  1          0.6               0.75       100      0.7976932  0.24105263  0.9895947
  0.3  1          0.6               0.75       150      0.7767581  0.25157895  0.9895947
  0.3  1          0.6               1.00        50      0.7735592  0.21947368  0.9930430
  0.3  1          0.6               1.00       100      0.8034484  0.26105263  0.9895947
  0.3  1          0.6               1.00       150      0.8101778  0.28210526  0.9895947
  0.3  1          0.8               0.50        50      0.7466884  0.12578947  0.9860859
  0.3  1          0.8               0.50       100      0.7781887  0.19894737  0.9895947
  0.3  1          0.8               0.50       150      0.7883419  0.23052632  0.9895947
  0.3  1          0.8               0.75        50      0.7822607  0.26052632  0.9895947
  0.3  1          0.8               0.75       100      0.8080087  0.29263158  0.9895947
  0.3  1          0.8               0.75       150      0.8149588  0.31421053  0.9895947
  0.3  1          0.8               1.00        50      0.7654768  0.24947368  0.9895947
  0.3  1          0.8               1.00       100      0.7960541  0.29157895  0.9895947
  0.3  1          0.8               1.00       150      0.8170180  0.28210526  0.9860859
  0.3  2          0.6               0.50        50      0.7166051  0.16789474  0.9895947
  0.3  2          0.6               0.50       100      0.7612567  0.22000000  0.9895947
  0.3  2          0.6               0.50       150      0.7669233  0.23052632  0.9895947
  0.3  2          0.6               0.75        50      0.7860385  0.25157895  0.9825771
  0.3  2          0.6               0.75       100      0.8062613  0.28315789  0.9860859
  0.3  2          0.6               0.75       150      0.8138721  0.28315789  0.9895947
  0.3  2          0.6               1.00        50      0.8058411  0.28210526  0.9895947
  0.3  2          0.6               1.00       100      0.8253917  0.30315789  0.9895947
  0.3  2          0.6               1.00       150      0.8243994  0.32421053  0.9895947
  0.3  2          0.8               0.50        50      0.7617593  0.17789474  0.9860859
  0.3  2          0.8               0.50       100      0.7700654  0.24105263  0.9826376
  0.3  2          0.8               0.50       150      0.7801582  0.26210526  0.9861464
  0.3  2          0.8               0.75        50      0.7840270  0.27210526  0.9861464
  0.3  2          0.8               0.75       100      0.8113664  0.30315789  0.9861464
  0.3  2          0.8               0.75       150      0.8080299  0.30368421  0.9861464
  0.3  2          0.8               1.00        50      0.8067920  0.30210526  0.9895947
  0.3  2          0.8               1.00       100      0.8226500  0.30315789  0.9895947
  0.3  2          0.8               1.00       150      0.8262716  0.31368421  0.9895947
  0.3  3          0.6               0.50        50      0.7667682  0.13631579  0.9895947
  0.3  3          0.6               0.50       100      0.7697464  0.22052632  0.9895947
  0.3  3          0.6               0.50       150      0.7873750  0.25210526  0.9826981
  0.3  3          0.6               0.75        50      0.8042292  0.25157895  0.9861464
  0.3  3          0.6               0.75       100      0.8032584  0.28315789  0.9861464
  0.3  3          0.6               0.75       150      0.8111328  0.28315789  0.9861464
  0.3  3          0.6               1.00        50      0.8224260  0.31368421  0.9895947
  0.3  3          0.6               1.00       100      0.8219458  0.32421053  0.9895947
  0.3  3          0.6               1.00       150      0.8197825  0.34526316  0.9895947
  0.3  3          0.8               0.50        50      0.7452415  0.18842105  0.9860859
  0.3  3          0.8               0.50       100      0.7953483  0.29210526  0.9860859
  0.3  3          0.8               0.50       150      0.7974794  0.29210526  0.9825771
  0.3  3          0.8               0.75        50      0.8077388  0.29315789  0.9860859
  0.3  3          0.8               0.75       100      0.8130625  0.30368421  0.9860859
  0.3  3          0.8               0.75       150      0.8252093  0.30368421  0.9895947
  0.3  3          0.8               1.00        50      0.8232798  0.31368421  0.9895947
  0.3  3          0.8               1.00       100      0.8258965  0.32421053  0.9895947
  0.3  3          0.8               1.00       150      0.8216554  0.31368421  0.9895947
  0.4  1          0.6               0.50        50      0.7223711  0.09421053  0.9895947
  0.4  1          0.6               0.50       100      0.7426836  0.20947368  0.9860859
  0.4  1          0.6               0.50       150      0.7862629  0.22000000  0.9860859
  0.4  1          0.6               0.75        50      0.7847752  0.23052632  0.9895947
  0.4  1          0.6               0.75       100      0.8070175  0.28263158  0.9895947
  0.4  1          0.6               0.75       150      0.7985455  0.28263158  0.9895947
  0.4  1          0.6               1.00        50      0.7739133  0.27105263  0.9895947
  0.4  1          0.6               1.00       100      0.7952917  0.29210526  0.9860859
  0.4  1          0.6               1.00       150      0.8068414  0.27210526  0.9860859
  0.4  1          0.8               0.50        50      0.7837668  0.14631579  0.9895947
  0.4  1          0.8               0.50       100      0.7763315  0.22000000  0.9895947
  0.4  1          0.8               0.50       150      0.7788653  0.26210526  0.9861464
  0.4  1          0.8               0.75        50      0.7723487  0.25052632  0.9895947
  0.4  1          0.8               0.75       100      0.7874065  0.30263158  0.9895947
  0.4  1          0.8               0.75       150      0.8048628  0.27210526  0.9860859
  0.4  1          0.8               1.00        50      0.7722367  0.24052632  0.9895947
  0.4  1          0.8               1.00       100      0.7999863  0.29157895  0.9860859
  0.4  1          0.8               1.00       150      0.8095972  0.27157895  0.9860859
  0.4  2          0.6               0.50        50      0.7406187  0.23052632  0.9895947
  0.4  2          0.6               0.50       100      0.7695429  0.23052632  0.9895947
  0.4  2          0.6               0.50       150      0.7653559  0.25157895  0.9860859
  0.4  2          0.6               0.75        50      0.8009182  0.26157895  0.9895947
  0.4  2          0.6               0.75       100      0.8033856  0.28263158  0.9860859
  0.4  2          0.6               0.75       150      0.8095558  0.29315789  0.9860859
  0.4  2          0.6               1.00        50      0.8123824  0.28210526  0.9860859
  0.4  2          0.6               1.00       100      0.8265644  0.31368421  0.9895947
  0.4  2          0.6               1.00       150      0.8219586  0.32421053  0.9895947
  0.4  2          0.8               0.50        50      0.7393907  0.20947368  0.9895947
  0.4  2          0.8               0.50       100      0.7387043  0.22000000  0.9895947
  0.4  2          0.8               0.50       150      0.7639648  0.26210526  0.9895947
  0.4  2          0.8               0.75        50      0.8106248  0.28210526  0.9895947
  0.4  2          0.8               0.75       100      0.8190645  0.30315789  0.9895947
  0.4  2          0.8               0.75       150      0.8143263  0.32315789  0.9895947
  0.4  2          0.8               1.00        50      0.8104575  0.28210526  0.9895947
  0.4  2          0.8               1.00       100      0.8248678  0.31368421  0.9895947
  0.4  2          0.8               1.00       150      0.8231304  0.33473684  0.9895947
  0.4  3          0.6               0.50        50      0.7576268  0.19894737  0.9826376
  0.4  3          0.6               0.50       100      0.7788805  0.22000000  0.9860859
  0.4  3          0.6               0.50       150      0.7834397  0.24105263  0.9825771
  0.4  3          0.6               0.75        50      0.8021601  0.28315789  0.9825771
  0.4  3          0.6               0.75       100      0.7923846  0.28315789  0.9860859
  0.4  3          0.6               0.75       150      0.8108722  0.29368421  0.9860859
  0.4  3          0.6               1.00        50      0.8281024  0.35578947  0.9895947
  0.4  3          0.6               1.00       100      0.8222303  0.34526316  0.9861464
  0.4  3          0.6               1.00       150      0.8215130  0.32473684  0.9861464
  0.4  3          0.8               0.50        50      0.7624850  0.21000000  0.9895947
  0.4  3          0.8               0.50       100      0.7643942  0.24105263  0.9860859
  0.4  3          0.8               0.50       150      0.7652280  0.24105263  0.9826376
  0.4  3          0.8               0.75        50      0.8134750  0.26157895  0.9826376
  0.4  3          0.8               0.75       100      0.8270811  0.30368421  0.9826376
  0.4  3          0.8               0.75       150      0.8131034  0.30368421  0.9826376
  0.4  3          0.8               1.00        50      0.8283506  0.36526316  0.9860859
  0.4  3          0.8               1.00       100      0.8232068  0.34526316  0.9860859
  0.4  3          0.8               1.00       150      0.8159882  0.38736842  0.9860859

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      9.1      1.0
  positive     15.9     74.0
                            
 Accuracy (average) : 0.8307

[1] "TRAIN accuracy: 0.830729166666667"
[1] "TRAIN +precision: 0.823188405797101"
[1] "TRAIN -precision: 0.897435897435897"
[1] "TRAIN specifity: 0.364583333333333"
[1] "TRAIN sensitivity: 0.986111111111111"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       15       97
[1] "TEST accuracy: 0.866071428571429"
[1] "TEST +precision: 0.866071428571429"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
