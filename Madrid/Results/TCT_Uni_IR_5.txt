[1] "DATASET NAME: TCT_Uni_IR_5"
[1] "TRAIN INSTANCES: 791"
[1] "TEST INSTANCES: 225"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.69810199737549"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

791 samples
725 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 633, 633, 633, 632, 633 
Resampling results:

  ROC        Sens     Spec     
  0.9997024  0.98125  0.9936633

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     19.7      0.5
  positive      0.4     79.4
                            
 Accuracy (average) : 0.9912

[1] "TRAIN accuracy: 0.991150442477876"
[1] "TRAIN +precision: 0.995245641838352"
[1] "TRAIN -precision: 0.975"
[1] "TRAIN specifity: 0.981132075471698"
[1] "TRAIN sensitivity: 0.993670886075949"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       12        1
            positive        7      205
[1] "TEST accuracy: 0.964444444444444"
[1] "TEST +precision: 0.966981132075472"
[1] "TEST -precision: 0.923076923076923"
[1] "TEST specifity: 0.631578947368421"
[1] "TEST sensitivity: 0.995145631067961"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.19016946951548"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

791 samples
725 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 633, 633, 632, 633, 633 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8252171  0.6856855  0.9509561
  0.010  2  0.8240723  0.6792339  0.9509561
  0.010  3  0.8266418  0.6604839  0.9525559
  0.255  1  0.9545727  0.9250000  0.9446319
  0.255  2  0.9550078  0.9060484  0.9462192
  0.255  3  0.9373768  0.8116935  0.9509936
  0.500  1  0.9598554  0.9375000  0.9446319
  0.500  2  0.9602658  0.9185484  0.9462192
  0.500  3  0.9430854  0.8116935  0.9509936

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.5      4.3
  positive      1.6     75.6
                            
 Accuracy (average) : 0.9406

[1] "TRAIN accuracy: 0.940581542351454"
[1] "TRAIN +precision: 0.978723404255319"
[1] "TRAIN -precision: 0.811111111111111"
[1] "TRAIN specifity: 0.918238993710692"
[1] "TRAIN sensitivity: 0.94620253164557"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9        6
            positive       10      200
[1] "TEST accuracy: 0.928888888888889"
[1] "TEST +precision: 0.952380952380952"
[1] "TEST -precision: 0.6"
[1] "TEST specifity: 0.473684210526316"
[1] "TEST sensitivity: 0.970873786407767"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.91707051595052"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

791 samples
725 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 632, 633, 632, 633, 634 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9803192  0.7675403  0.9889264
  0.3  1          0.6               0.50       100      0.9911447  0.8368952  0.9873516
  0.3  1          0.6               0.50       150      0.9936715  0.8685484  0.9889389
  0.3  1          0.6               0.75        50      0.9807493  0.7991935  0.9857518
  0.3  1          0.6               0.75       100      0.9886614  0.8493952  0.9857518
  0.3  1          0.6               0.75       150      0.9927259  0.9247984  0.9889264
  0.3  1          0.6               1.00        50      0.9809012  0.7612903  0.9841770
  0.3  1          0.6               1.00       100      0.9891959  0.8493952  0.9810149
  0.3  1          0.6               1.00       150      0.9912294  0.8868952  0.9826147
  0.3  1          0.8               0.50        50      0.9807696  0.7487903  0.9826147
  0.3  1          0.8               0.50       100      0.9918413  0.8560484  0.9873516
  0.3  1          0.8               0.50       150      0.9945116  0.9312500  0.9905262
  0.3  1          0.8               0.75        50      0.9821229  0.7925403  0.9873391
  0.3  1          0.8               0.75       100      0.9920833  0.8618952  0.9857643
  0.3  1          0.8               0.75       150      0.9930770  0.8993952  0.9873516
  0.3  1          0.8               1.00        50      0.9819430  0.7554435  0.9857518
  0.3  1          0.8               1.00       100      0.9888471  0.8493952  0.9825897
  0.3  1          0.8               1.00       150      0.9915778  0.8868952  0.9810274
  0.3  2          0.6               0.50        50      0.9919314  0.8308468  0.9889264
  0.3  2          0.6               0.50       100      0.9955943  0.9245968  0.9889264
  0.3  2          0.6               0.50       150      0.9966828  0.9625000  0.9873516
  0.3  2          0.6               0.75        50      0.9909215  0.8495968  0.9889139
  0.3  2          0.6               0.75       100      0.9950018  0.9562500  0.9873516
  0.3  2          0.6               0.75       150      0.9948995  0.9625000  0.9905137
  0.3  2          0.6               1.00        50      0.9918743  0.8493952  0.9889139
  0.3  2          0.6               1.00       100      0.9934589  0.9437500  0.9873391
  0.3  2          0.6               1.00       150      0.9940550  0.9687500  0.9889264
  0.3  2          0.8               0.50        50      0.9906948  0.8431452  0.9889264
  0.3  2          0.8               0.50       100      0.9942046  0.9312500  0.9889264
  0.3  2          0.8               0.50       150      0.9950487  0.9625000  0.9889389
  0.3  2          0.8               0.75        50      0.9925715  0.9062500  0.9873516
  0.3  2          0.8               0.75       100      0.9954467  0.9562500  0.9905137
  0.3  2          0.8               0.75       150      0.9944046  0.9625000  0.9905137
  0.3  2          0.8               1.00        50      0.9926248  0.8683468  0.9889139
  0.3  2          0.8               1.00       100      0.9939578  0.9375000  0.9873391
  0.3  2          0.8               1.00       150      0.9946011  0.9625000  0.9873391
  0.3  3          0.6               0.50        50      0.9936176  0.8937500  0.9889389
  0.3  3          0.6               0.50       100      0.9948561  0.9500000  0.9889389
  0.3  3          0.6               0.50       150      0.9953971  0.9750000  0.9889389
  0.3  3          0.6               0.75        50      0.9965403  0.9312500  0.9936883
  0.3  3          0.6               0.75       100      0.9957431  0.9750000  0.9936883
  0.3  3          0.6               0.75       150      0.9960868  0.9750000  0.9936883
  0.3  3          0.6               1.00        50      0.9951436  0.9312500  0.9905137
  0.3  3          0.6               1.00       100      0.9961333  0.9625000  0.9921010
  0.3  3          0.6               1.00       150      0.9963813  0.9625000  0.9920885
  0.3  3          0.8               0.50        50      0.9943107  0.8685484  0.9889264
  0.3  3          0.8               0.50       100      0.9965793  0.9437500  0.9889264
  0.3  3          0.8               0.50       150      0.9971722  0.9562500  0.9905137
  0.3  3          0.8               0.75        50      0.9963919  0.9187500  0.9889264
  0.3  3          0.8               0.75       100      0.9973308  0.9687500  0.9936883
  0.3  3          0.8               0.75       150      0.9976241  0.9687500  0.9921010
  0.3  3          0.8               1.00        50      0.9942054  0.9375000  0.9873516
  0.3  3          0.8               1.00       100      0.9962844  0.9625000  0.9873516
  0.3  3          0.8               1.00       150      0.9969293  0.9687500  0.9873391
  0.4  1          0.6               0.50        50      0.9832479  0.8183468  0.9810149
  0.4  1          0.6               0.50       100      0.9907499  0.8808468  0.9841770
  0.4  1          0.6               0.50       150      0.9931259  0.9437500  0.9841770
  0.4  1          0.6               0.75        50      0.9865121  0.8243952  0.9889139
  0.4  1          0.6               0.75       100      0.9911818  0.9185484  0.9873391
  0.4  1          0.6               0.75       150      0.9937668  0.9437500  0.9889389
  0.4  1          0.6               1.00        50      0.9855617  0.8056452  0.9810149
  0.4  1          0.6               1.00       100      0.9913853  0.8681452  0.9826022
  0.4  1          0.6               1.00       150      0.9922350  0.9187500  0.9810399
  0.4  1          0.8               0.50        50      0.9899107  0.8304435  0.9857768
  0.4  1          0.8               0.50       100      0.9934214  0.8875000  0.9889389
  0.4  1          0.8               0.50       150      0.9951033  0.9250000  0.9889514
  0.4  1          0.8               0.75        50      0.9864196  0.8181452  0.9889139
  0.4  1          0.8               0.75       100      0.9913401  0.9122984  0.9841770
  0.4  1          0.8               0.75       150      0.9938160  0.9500000  0.9841770
  0.4  1          0.8               1.00        50      0.9882204  0.8243952  0.9841645
  0.4  1          0.8               1.00       100      0.9914357  0.8868952  0.9810274
  0.4  1          0.8               1.00       150      0.9926314  0.9122984  0.9842020
  0.4  2          0.6               0.50        50      0.9910783  0.8872984  0.9873391
  0.4  2          0.6               0.50       100      0.9925689  0.9625000  0.9920885
  0.4  2          0.6               0.50       150      0.9912256  0.9625000  0.9857643
  0.4  2          0.6               0.75        50      0.9948018  0.8556452  0.9889264
  0.4  2          0.6               0.75       100      0.9948983  0.9500000  0.9936883
  0.4  2          0.6               0.75       150      0.9955424  0.9687500  0.9936883
  0.4  2          0.6               1.00        50      0.9941057  0.8995968  0.9841770
  0.4  2          0.6               1.00       100      0.9948538  0.9687500  0.9873516
  0.4  2          0.6               1.00       150      0.9952986  0.9687500  0.9889264
  0.4  2          0.8               0.50        50      0.9932632  0.8685484  0.9921010
  0.4  2          0.8               0.50       100      0.9942538  0.9562500  0.9873391
  0.4  2          0.8               0.50       150      0.9939518  0.9750000  0.9873391
  0.4  2          0.8               0.75        50      0.9948005  0.9245968  0.9857518
  0.4  2          0.8               0.75       100      0.9964391  0.9625000  0.9905137
  0.4  2          0.8               0.75       150      0.9975757  0.9750000  0.9873391
  0.4  2          0.8               1.00        50      0.9935093  0.9120968  0.9889264
  0.4  2          0.8               1.00       100      0.9958419  0.9750000  0.9889264
  0.4  2          0.8               1.00       150      0.9957412  0.9750000  0.9857518
  0.4  3          0.6               0.50        50      0.9957892  0.9437500  0.9873516
  0.4  3          0.6               0.50       100      0.9972718  0.9750000  0.9873516
  0.4  3          0.6               0.50       150      0.9968258  0.9750000  0.9841770
  0.4  3          0.6               0.75        50      0.9957408  0.9562500  0.9873391
  0.4  3          0.6               0.75       100      0.9974245  0.9750000  0.9889264
  0.4  3          0.6               0.75       150      0.9983639  0.9750000  0.9873391
  0.4  3          0.6               1.00        50      0.9966832  0.9625000  0.9889264
  0.4  3          0.6               1.00       100      0.9972761  0.9625000  0.9905137
  0.4  3          0.6               1.00       150      0.9978206  0.9625000  0.9905137
  0.4  3          0.8               0.50        50      0.9957896  0.9372984  0.9889264
  0.4  3          0.8               0.50       100      0.9971281  0.9687500  0.9873516
  0.4  3          0.8               0.50       150      0.9969324  0.9750000  0.9889389
  0.4  3          0.8               0.75        50      0.9942023  0.9687500  0.9873641
  0.4  3          0.8               0.75       100      0.9947924  0.9687500  0.9857643
  0.4  3          0.8               0.75       150      0.9961321  0.9687500  0.9873516
  0.4  3          0.8               1.00        50      0.9951479  0.9687500  0.9873391
  0.4  3          0.8               1.00       100      0.9961868  0.9750000  0.9905137
  0.4  3          0.8               1.00       150      0.9974745  0.9750000  0.9889264

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     19.6      1.0
  positive      0.5     78.9
                            
 Accuracy (average) : 0.9848

[1] "TRAIN accuracy: 0.984829329962073"
[1] "TRAIN +precision: 0.993630573248408"
[1] "TRAIN -precision: 0.950920245398773"
[1] "TRAIN specifity: 0.974842767295597"
[1] "TRAIN sensitivity: 0.987341772151899"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       10        4
            positive        9      202
[1] "TEST accuracy: 0.942222222222222"
[1] "TEST +precision: 0.957345971563981"
[1] "TEST -precision: 0.714285714285714"
[1] "TEST specifity: 0.526315789473684"
[1] "TEST sensitivity: 0.980582524271845"
