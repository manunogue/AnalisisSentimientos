[1] "DATASET NAME: HRM_Uni_IR_5"
[1] "TRAIN INSTANCES: 385"
[1] "TEST INSTANCES: 112"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 1.9049859046936"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

385 samples
747 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 307, 309, 308, 308, 308 
Resampling results:

  ROC        Sens       Spec     
  0.9733346  0.8923977  0.9827586

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     21.8      1.3
  positive      2.6     74.3
                           
 Accuracy (average) : 0.961

[1] "TRAIN accuracy: 0.961038961038961"
[1] "TRAIN +precision: 0.966216216216216"
[1] "TRAIN -precision: 0.943820224719101"
[1] "TRAIN specifity: 0.893617021276596"
[1] "TRAIN sensitivity: 0.982817869415808"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9        2
            positive        9       92
[1] "TEST accuracy: 0.901785714285714"
[1] "TEST +precision: 0.910891089108911"
[1] "TEST -precision: 0.818181818181818"
[1] "TEST specifity: 0.5"
[1] "TEST sensitivity: 0.978723404255319"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.04832481940587"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

385 samples
747 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 308, 308, 308, 308, 308 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.7527599  0.5754386  0.9279953
  0.010  2  0.7531214  0.5543860  0.9246055
  0.010  3  0.7415881  0.5228070  0.9280538
  0.255  1  0.8285594  0.7555556  0.9108124
  0.255  2  0.7961853  0.6812865  0.9074226
  0.255  3  0.8078378  0.6175439  0.9451783
  0.500  1  0.8308827  0.7660819  0.9108124
  0.500  2  0.8195609  0.7345029  0.9074226
  0.500  3  0.8300117  0.6385965  0.9451783

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     18.7      6.8
  positive      5.7     68.8
                            
 Accuracy (average) : 0.8753

[1] "TRAIN accuracy: 0.875324675324675"
[1] "TRAIN +precision: 0.923344947735192"
[1] "TRAIN -precision: 0.73469387755102"
[1] "TRAIN specifity: 0.765957446808511"
[1] "TRAIN sensitivity: 0.910652920962199"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        6       10
            positive       12       84
[1] "TEST accuracy: 0.803571428571429"
[1] "TEST +precision: 0.875"
[1] "TEST -precision: 0.375"
[1] "TEST specifity: 0.333333333333333"
[1] "TEST sensitivity: 0.893617021276596"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.06705858310064"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

385 samples
747 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 308, 308, 307, 309, 308 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9532365  0.6181287  0.9896552
  0.3  1          0.6               0.50       100      0.9671676  0.7666667  0.9759205
  0.3  1          0.6               0.50       150      0.9675406  0.7771930  0.9759790
  0.3  1          0.6               0.75        50      0.9484471  0.6719298  0.9760374
  0.3  1          0.6               0.75       100      0.9725511  0.7245614  0.9759790
  0.3  1          0.6               0.75       150      0.9771455  0.7561404  0.9724722
  0.3  1          0.6               1.00        50      0.9555803  0.6286550  0.9794272
  0.3  1          0.6               1.00       100      0.9704178  0.7245614  0.9794272
  0.3  1          0.6               1.00       150      0.9748120  0.7777778  0.9725891
  0.3  1          0.8               0.50        50      0.9523504  0.6286550  0.9690240
  0.3  1          0.8               0.50       100      0.9633801  0.7350877  0.9656926
  0.3  1          0.8               0.50       150      0.9663825  0.7982456  0.9690240
  0.3  1          0.8               0.75        50      0.9491902  0.6391813  0.9725307
  0.3  1          0.8               0.75       100      0.9738848  0.7666667  0.9794272
  0.3  1          0.8               0.75       150      0.9766911  0.8087719  0.9759205
  0.3  1          0.8               1.00        50      0.9534091  0.6181287  0.9759790
  0.3  1          0.8               1.00       100      0.9690361  0.7356725  0.9760374
  0.3  1          0.8               1.00       150      0.9732955  0.7777778  0.9725891
  0.3  2          0.6               0.50        50      0.9632203  0.6707602  0.9793688
  0.3  2          0.6               0.50       100      0.9680408  0.8093567  0.9725307
  0.3  2          0.6               0.50       150      0.9734547  0.8304094  0.9725307
  0.3  2          0.6               0.75        50      0.9731467  0.7350877  0.9828755
  0.3  2          0.6               0.75       100      0.9809321  0.8298246  0.9690824
  0.3  2          0.6               0.75       150      0.9809089  0.8409357  0.9760374
  0.3  2          0.6               1.00        50      0.9720206  0.7356725  0.9828171
  0.3  2          0.6               1.00       100      0.9779787  0.8093567  0.9759790
  0.3  2          0.6               1.00       150      0.9813183  0.8514620  0.9725307
  0.3  2          0.8               0.50        50      0.9693779  0.7339181  0.9759790
  0.3  2          0.8               0.50       100      0.9736919  0.7988304  0.9725307
  0.3  2          0.8               0.50       150      0.9798962  0.8508772  0.9725891
  0.3  2          0.8               0.75        50      0.9707030  0.7666667  0.9794272
  0.3  2          0.8               0.75       100      0.9761806  0.8198830  0.9725891
  0.3  2          0.8               0.75       150      0.9794390  0.8619883  0.9726476
  0.3  2          0.8               1.00        50      0.9730410  0.7140351  0.9862653
  0.3  2          0.8               1.00       100      0.9806677  0.7982456  0.9758621
  0.3  2          0.8               1.00       150      0.9815436  0.8298246  0.9690240
  0.3  3          0.6               0.50        50      0.9703926  0.7350877  0.9829340
  0.3  3          0.6               0.50       100      0.9711046  0.8304094  0.9656926
  0.3  3          0.6               0.50       150      0.9765702  0.8409357  0.9691993
  0.3  3          0.6               0.75        50      0.9738269  0.7982456  0.9793688
  0.3  3          0.6               0.75       100      0.9803530  0.8514620  0.9691409
  0.3  3          0.6               0.75       150      0.9798839  0.8725146  0.9690824
  0.3  3          0.6               1.00        50      0.9786833  0.7777778  0.9862069
  0.3  3          0.6               1.00       100      0.9824975  0.8514620  0.9793688
  0.3  3          0.6               1.00       150      0.9832103  0.8514620  0.9828171
  0.3  3          0.8               0.50        50      0.9789971  0.7777778  0.9794272
  0.3  3          0.8               0.50       100      0.9767333  0.8309942  0.9656341
  0.3  3          0.8               0.50       150      0.9798427  0.8520468  0.9655757
  0.3  3          0.8               0.75        50      0.9787355  0.7877193  0.9931619
  0.3  3          0.8               0.75       100      0.9847473  0.8619883  0.9829340
  0.3  3          0.8               0.75       150      0.9839967  0.8619883  0.9794272
  0.3  3          0.8               1.00        50      0.9747248  0.8198830  0.9827586
  0.3  3          0.8               1.00       100      0.9810206  0.8514620  0.9724722
  0.3  3          0.8               1.00       150      0.9831800  0.8830409  0.9690824
  0.4  1          0.6               0.50        50      0.9526082  0.6391813  0.9725307
  0.4  1          0.6               0.50       100      0.9656482  0.7666667  0.9691409
  0.4  1          0.6               0.50       150      0.9633739  0.7771930  0.9587960
  0.4  1          0.6               0.75        50      0.9607261  0.7035088  0.9691409
  0.4  1          0.6               0.75       100      0.9772939  0.7456140  0.9759790
  0.4  1          0.6               0.75       150      0.9767895  0.7982456  0.9656926
  0.4  1          0.6               1.00        50      0.9640616  0.6707602  0.9759790
  0.4  1          0.6               1.00       100      0.9745588  0.7777778  0.9759790
  0.4  1          0.6               1.00       150      0.9764774  0.7982456  0.9760374
  0.4  1          0.8               0.50        50      0.9550490  0.6181287  0.9724722
  0.4  1          0.8               0.50       100      0.9670978  0.7561404  0.9655757
  0.4  1          0.8               0.50       150      0.9670317  0.7771930  0.9690240
  0.4  1          0.8               0.75        50      0.9626233  0.6076023  0.9793688
  0.4  1          0.8               0.75       100      0.9777813  0.7877193  0.9690240
  0.4  1          0.8               0.75       150      0.9753121  0.7877193  0.9690240
  0.4  1          0.8               1.00        50      0.9639223  0.6929825  0.9794272
  0.4  1          0.8               1.00       100      0.9739467  0.7777778  0.9794272
  0.4  1          0.8               1.00       150      0.9778028  0.7982456  0.9725891
  0.4  2          0.6               0.50        50      0.9638929  0.7561404  0.9724722
  0.4  2          0.6               0.50       100      0.9738625  0.7561404  0.9793688
  0.4  2          0.6               0.50       150      0.9733009  0.8093567  0.9724722
  0.4  2          0.6               0.75        50      0.9736167  0.7877193  0.9759205
  0.4  2          0.6               0.75       100      0.9742762  0.7982456  0.9759205
  0.4  2          0.6               0.75       150      0.9769621  0.8514620  0.9725307
  0.4  2          0.6               1.00        50      0.9743715  0.7666667  0.9759790
  0.4  2          0.6               1.00       100      0.9823770  0.8304094  0.9725307
  0.4  2          0.6               1.00       150      0.9830473  0.8409357  0.9725307
  0.4  2          0.8               0.50        50      0.9649700  0.7883041  0.9656926
  0.4  2          0.8               0.50       100      0.9676831  0.8514620  0.9553477
  0.4  2          0.8               0.50       150      0.9712664  0.8941520  0.9657510
  0.4  2          0.8               0.75        50      0.9758832  0.7877193  0.9656341
  0.4  2          0.8               0.75       100      0.9791957  0.8514620  0.9690824
  0.4  2          0.8               0.75       150      0.9784053  0.8725146  0.9622443
  0.4  2          0.8               1.00        50      0.9706909  0.7666667  0.9897136
  0.4  2          0.8               1.00       100      0.9800238  0.8514620  0.9759790
  0.4  2          0.8               1.00       150      0.9845496  0.8514620  0.9794272
  0.4  3          0.6               0.50        50      0.9629424  0.7561404  0.9690240
  0.4  3          0.6               0.50       100      0.9732385  0.8409357  0.9656926
  0.4  3          0.6               0.50       150      0.9727918  0.8508772  0.9690824
  0.4  3          0.6               0.75        50      0.9798343  0.8093567  0.9759205
  0.4  3          0.6               0.75       100      0.9810854  0.8619883  0.9725307
  0.4  3          0.6               0.75       150      0.9825373  0.8830409  0.9725307
  0.4  3          0.6               1.00        50      0.9847124  0.8514620  0.9793688
  0.4  3          0.6               1.00       100      0.9855279  0.8725146  0.9793688
  0.4  3          0.6               1.00       150      0.9862578  0.9040936  0.9828171
  0.4  3          0.8               0.50        50      0.9698482  0.8192982  0.9725307
  0.4  3          0.8               0.50       100      0.9734051  0.8309942  0.9759790
  0.4  3          0.8               0.50       150      0.9687904  0.8415205  0.9691409
  0.4  3          0.8               0.75        50      0.9777381  0.8093567  0.9725891
  0.4  3          0.8               0.75       100      0.9764352  0.8514620  0.9759790
  0.4  3          0.8               0.75       150      0.9742039  0.8935673  0.9725307
  0.4  3          0.8               1.00        50      0.9851330  0.8409357  0.9794272
  0.4  3          0.8               1.00       100      0.9872792  0.8619883  0.9793688
  0.4  3          0.8               1.00       150      0.9845359  0.9040936  0.9759790

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     21.0      1.6
  positive      3.4     74.0
                            
 Accuracy (average) : 0.9506

[1] "TRAIN accuracy: 0.950649350649351"
[1] "TRAIN +precision: 0.956375838926175"
[1] "TRAIN -precision: 0.931034482758621"
[1] "TRAIN specifity: 0.861702127659574"
[1] "TRAIN sensitivity: 0.979381443298969"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       12        3
            positive        6       91
[1] "TEST accuracy: 0.919642857142857"
[1] "TEST +precision: 0.938144329896907"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.666666666666667"
[1] "TEST sensitivity: 0.968085106382979"
