[1] "DATASET NAME: ElSur_Uni_IR_10"
[1] "TRAIN INSTANCES: 1300"
[1] "TEST INSTANCES: 396"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.34852600097656"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1300 samples
 684 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1040, 1040, 1040, 1040, 1040 
Resampling results:

  ROC        Sens       Spec     
  0.9982217  0.9706349  0.9991379

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.3      0.1
  positive      0.3     89.3
                            
 Accuracy (average) : 0.9962

[1] "TRAIN accuracy: 0.996153846153846"
[1] "TRAIN +precision: 0.99656652360515"
[1] "TRAIN -precision: 0.992592592592593"
[1] "TRAIN specifity: 0.971014492753623"
[1] "TRAIN sensitivity: 0.999139414802065"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        5      391
[1] "TEST accuracy: 0.987373737373737"
[1] "TEST +precision: 0.987373737373737"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.75679939985275"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1300 samples
 684 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1040, 1041, 1040, 1039, 1040 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8411729  0.6537037  0.9870801
  0.010  2  0.8417310  0.6537037  0.9853596
  0.010  3  0.8229034  0.6092593  0.9870838
  0.255  1  0.9764523  0.9423280  0.9853596
  0.255  2  0.9771238  0.9208995  0.9836392
  0.255  3  0.9744289  0.8851852  0.9819188
  0.500  1  0.9857965  0.9637566  0.9853596
  0.500  2  0.9864680  0.9423280  0.9836392
  0.500  3  0.9744289  0.8851852  0.9819188

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.0      1.5
  positive      0.6     87.9
                            
 Accuracy (average) : 0.9792

[1] "TRAIN accuracy: 0.979230769230769"
[1] "TRAIN +precision: 0.993049522154648"
[1] "TRAIN -precision: 0.87248322147651"
[1] "TRAIN specifity: 0.942028985507246"
[1] "TRAIN sensitivity: 0.983648881239243"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        4
            positive        5      387
[1] "TEST accuracy: 0.977272727272727"
[1] "TEST +precision: 0.987244897959184"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.989769820971867"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.61222271521886"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1300 samples
 684 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1039, 1040, 1041, 1040, 1040 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9954616  0.8095238  0.9922562
  0.3  1          0.6               0.50       100      0.9974556  0.9634921  0.9939766
  0.3  1          0.6               0.50       150      0.9980600  0.9777778  0.9931108
  0.3  1          0.6               0.75        50      0.9970043  0.8320106  0.9948350
  0.3  1          0.6               0.75       100      0.9984601  0.9634921  0.9939766
  0.3  1          0.6               0.75       150      0.9984292  0.9777778  0.9948350
  0.3  1          0.6               1.00        50      0.9973368  0.8537037  0.9939766
  0.3  1          0.6               1.00       100      0.9989190  0.9634921  0.9957008
  0.3  1          0.6               1.00       150      0.9991077  0.9925926  0.9931145
  0.3  1          0.8               0.50        50      0.9950868  0.7952381  0.9948350
  0.3  1          0.8               0.50       100      0.9973826  0.9560847  0.9965554
  0.3  1          0.8               0.50       150      0.9978741  0.9777778  0.9948313
  0.3  1          0.8               0.75        50      0.9970962  0.8465608  0.9948350
  0.3  1          0.8               0.75       100      0.9982766  0.9783069  0.9957008
  0.3  1          0.8               0.75       150      0.9983392  0.9854497  0.9956971
  0.3  1          0.8               1.00        50      0.9970988  0.8317460  0.9939766
  0.3  1          0.8               1.00       100      0.9987691  0.9634921  0.9957008
  0.3  1          0.8               1.00       150      0.9989547  0.9783069  0.9939766
  0.3  2          0.6               0.50        50      0.9982283  0.9634921  0.9956971
  0.3  2          0.6               0.50       100      0.9981455  1.0000000  0.9965554
  0.3  2          0.6               0.50       150      0.9977379  1.0000000  0.9948313
  0.3  2          0.6               0.75        50      0.9991070  0.9854497  0.9948350
  0.3  2          0.6               0.75       100      0.9987094  1.0000000  0.9939729
  0.3  2          0.6               0.75       150      0.9984327  1.0000000  0.9931145
  0.3  2          0.6               1.00        50      0.9989255  0.9783069  0.9965591
  0.3  2          0.6               1.00       100      0.9990475  1.0000000  0.9956934
  0.3  2          0.6               1.00       150      0.9986476  1.0000000  0.9956934
  0.3  2          0.8               0.50        50      0.9983070  0.9708995  0.9956971
  0.3  2          0.8               0.50       100      0.9984022  1.0000000  0.9931108
  0.3  2          0.8               0.50       150      0.9984635  1.0000000  0.9922488
  0.3  2          0.8               0.75        50      0.9988623  0.9783069  0.9956971
  0.3  2          0.8               0.75       100      0.9987089  1.0000000  0.9965554
  0.3  2          0.8               0.75       150      0.9985248  1.0000000  0.9948350
  0.3  2          0.8               1.00        50      0.9994117  0.9634921  0.9957008
  0.3  2          0.8               1.00       100      0.9990481  1.0000000  0.9948350
  0.3  2          0.8               1.00       150      0.9984635  1.0000000  0.9948350
  0.3  3          0.6               0.50        50      0.9994774  0.9851852  0.9965554
  0.3  3          0.6               0.50       100      0.9990164  1.0000000  0.9974175
  0.3  3          0.6               0.50       150      0.9987702  1.0000000  0.9965591
  0.3  3          0.6               0.75        50      0.9997537  1.0000000  0.9982796
  0.3  3          0.6               0.75       100      0.9992613  1.0000000  0.9982796
  0.3  3          0.6               0.75       150      0.9991691  1.0000000  0.9965591
  0.3  3          0.6               1.00        50      0.9998772  1.0000000  0.9956971
  0.3  3          0.6               1.00       100      0.9993842  1.0000000  0.9965554
  0.3  3          0.6               1.00       150      0.9991691  1.0000000  0.9948313
  0.3  3          0.8               0.50        50      0.9994452  1.0000000  0.9965554
  0.3  3          0.8               0.50       100      0.9986781  1.0000000  0.9956971
  0.3  3          0.8               0.50       150      0.9984635  1.0000000  0.9965591
  0.3  3          0.8               0.75        50      0.9996620  1.0000000  0.9956971
  0.3  3          0.8               0.75       100      0.9989554  1.0000000  0.9965591
  0.3  3          0.8               0.75       150      0.9985253  1.0000000  0.9965591
  0.3  3          0.8               1.00        50      0.9995690  1.0000000  0.9965591
  0.3  3          0.8               1.00       100      0.9991381  1.0000000  0.9974212
  0.3  3          0.8               1.00       150      0.9991381  1.0000000  0.9974212
  0.4  1          0.6               0.50        50      0.9963586  0.9124339  0.9939729
  0.4  1          0.6               0.50       100      0.9977735  0.9634921  0.9939729
  0.4  1          0.6               0.50       150      0.9973833  1.0000000  0.9905320
  0.4  1          0.6               0.75        50      0.9971597  0.9124339  0.9939766
  0.4  1          0.6               0.75       100      0.9989229  0.9851852  0.9931145
  0.4  1          0.6               0.75       150      0.9983071  1.0000000  0.9922525
  0.4  1          0.6               1.00        50      0.9977121  0.9190476  0.9948387
  0.4  1          0.6               1.00       100      0.9994757  0.9854497  0.9948387
  0.4  1          0.6               1.00       150      0.9988602  0.9925926  0.9931145
  0.4  1          0.8               0.50        50      0.9961864  0.9203704  0.9931145
  0.4  1          0.8               0.50       100      0.9971319  0.9854497  0.9939729
  0.4  1          0.8               0.50       150      0.9972893  1.0000000  0.9931071
  0.4  1          0.8               0.75        50      0.9981667  0.9412698  0.9965591
  0.4  1          0.8               0.75       100      0.9988332  0.9928571  0.9922562
  0.4  1          0.8               0.75       150      0.9980293  1.0000000  0.9922525
  0.4  1          0.8               1.00        50      0.9976489  0.9267196  0.9948387
  0.4  1          0.8               1.00       100      0.9995373  0.9783069  0.9939766
  0.4  1          0.8               1.00       150      0.9989527  1.0000000  0.9913904
  0.4  2          0.6               0.50        50      0.9986468  0.9928571  0.9922525
  0.4  2          0.6               0.50       100      0.9983626  1.0000000  0.9913867
  0.4  2          0.6               0.50       150      0.9981722  1.0000000  0.9931108
  0.4  2          0.6               0.75        50      0.9995080  0.9925926  0.9956971
  0.4  2          0.6               0.75       100      0.9988928  1.0000000  0.9948350
  0.4  2          0.6               0.75       150      0.9986476  1.0000000  0.9956971
  0.4  2          0.6               1.00        50      0.9991410  1.0000000  0.9965591
  0.4  2          0.6               1.00       100      0.9984330  1.0000000  0.9956971
  0.4  2          0.6               1.00       150      0.9985253  1.0000000  0.9948350
  0.4  2          0.8               0.50        50      0.9984828  0.9703704  0.9948350
  0.4  2          0.8               0.50       100      0.9983710  1.0000000  0.9922525
  0.4  2          0.8               0.50       150      0.9982796  1.0000000  0.9939692
  0.4  2          0.8               0.75        50      0.9985854  1.0000000  0.9956971
  0.4  2          0.8               0.75       100      0.9984943  1.0000000  0.9939729
  0.4  2          0.8               0.75       150      0.9982796  1.0000000  0.9939729
  0.4  2          0.8               1.00        50      0.9991082  1.0000000  0.9948387
  0.4  2          0.8               1.00       100      0.9986782  1.0000000  0.9939766
  0.4  2          0.8               1.00       150      0.9985556  1.0000000  0.9931145
  0.4  3          0.6               0.50        50      0.9989489  0.9851852  0.9956971
  0.4  3          0.6               0.50       100      0.9989540  1.0000000  0.9957008
  0.4  3          0.6               0.50       150      0.9990460  1.0000000  0.9939766
  0.4  3          0.6               0.75        50      0.9985199  1.0000000  0.9956934
  0.4  3          0.6               0.75       100      0.9983409  1.0000000  0.9956971
  0.4  3          0.6               0.75       150      0.9982796  1.0000000  0.9956971
  0.4  3          0.6               1.00        50      0.9994766  1.0000000  0.9965554
  0.4  3          0.6               1.00       100      0.9991687  1.0000000  0.9948350
  0.4  3          0.6               1.00       150      0.9991687  1.0000000  0.9965554
  0.4  3          0.8               0.50        50      0.9990154  1.0000000  0.9913978
  0.4  3          0.8               0.50       100      0.9989209  1.0000000  0.9939766
  0.4  3          0.8               0.50       150      0.9988620  1.0000000  0.9939766
  0.4  3          0.8               0.75        50      0.9988016  1.0000000  0.9965554
  0.4  3          0.8               0.75       100      0.9983104  1.0000000  0.9956971
  0.4  3          0.8               0.75       150      0.9983104  1.0000000  0.9956971
  0.4  3          0.8               1.00        50      0.9995382  1.0000000  0.9974175
  0.4  3          0.8               1.00       100      0.9991687  1.0000000  0.9965554
  0.4  3          0.8               1.00       150      0.9991687  1.0000000  0.9965554

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.6      0.4
  positive      0.0     89.0
                            
 Accuracy (average) : 0.9962

[1] "TRAIN accuracy: 0.996153846153846"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.965034965034965"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.995697074010327"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        3        1
            positive        2      390
[1] "TEST accuracy: 0.992424242424242"
[1] "TEST +precision: 0.994897959183674"
[1] "TEST -precision: 0.75"
[1] "TEST specifity: 0.6"
[1] "TEST sensitivity: 0.997442455242967"
