[1] "DATASET NAME: TCT_Uni_IR_2"
[1] "TRAIN INSTANCES: 969"
[1] "TEST INSTANCES: 225"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.04626393318176"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

969 samples
725 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 775, 774, 776, 775, 776 
Resampling results:

  ROC        Sens  Spec     
  0.9986799  1     0.9952631

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.8      0.3
  positive      0.0     64.9
                            
 Accuracy (average) : 0.9969

[1] "TRAIN accuracy: 0.996904024767802"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.991176470588235"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.995253164556962"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9        1
            positive       10      205
[1] "TEST accuracy: 0.951111111111111"
[1] "TEST +precision: 0.953488372093023"
[1] "TEST -precision: 0.9"
[1] "TEST specifity: 0.473684210526316"
[1] "TEST sensitivity: 0.995145631067961"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.35385763645172"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

969 samples
725 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 776, 776, 776, 774, 774 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9672649  0.9611940  0.9430446
  0.010  2  0.9678068  0.9611940  0.9414698
  0.010  3  0.9470176  0.9343284  0.9398950
  0.255  1  0.9819733  1.0000000  0.9509436
  0.255  2  0.9834229  1.0000000  0.9477940
  0.255  3  0.9829174  0.9880597  0.9493688
  0.500  1  0.9819733  1.0000000  0.9509436
  0.500  2  0.9834229  1.0000000  0.9477940
  0.500  3  0.9829174  0.9880597  0.9493688

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 2.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.8      3.4
  positive      0.0     61.8
                            
 Accuracy (average) : 0.9659

[1] "TRAIN accuracy: 0.96594427244582"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.910810810810811"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.947784810126582"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        9       12
            positive       10      194
[1] "TEST accuracy: 0.902222222222222"
[1] "TEST +precision: 0.950980392156863"
[1] "TEST -precision: 0.428571428571429"
[1] "TEST specifity: 0.473684210526316"
[1] "TEST sensitivity: 0.941747572815534"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 3.45221418142319"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

969 samples
725 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 776, 776, 774, 776, 774 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9876750  0.8904741  0.9699413
  0.3  1          0.6               0.50       100      0.9939910  0.9763828  0.9810274
  0.3  1          0.6               0.50       150      0.9954276  0.9911765  0.9857768
  0.3  1          0.6               0.75        50      0.9878488  0.8844162  0.9731409
  0.3  1          0.6               0.75       100      0.9932432  0.9792362  0.9794526
  0.3  1          0.6               0.75       150      0.9941879  0.9911765  0.9778528
  0.3  1          0.6               1.00        50      0.9896768  0.8606234  0.9778403
  0.3  1          0.6               1.00       100      0.9931341  0.9852063  0.9778528
  0.3  1          0.6               1.00       150      0.9930162  0.9911765  0.9810274
  0.3  1          0.8               0.50        50      0.9887366  0.8606673  0.9730909
  0.3  1          0.8               0.50       100      0.9940152  0.9911765  0.9794526
  0.3  1          0.8               0.50       150      0.9953717  0.9911765  0.9762655
  0.3  1          0.8               0.75        50      0.9886008  0.8666813  0.9778528
  0.3  1          0.8               0.75       100      0.9930420  0.9852063  0.9794276
  0.3  1          0.8               0.75       150      0.9948848  0.9881914  0.9826147
  0.3  1          0.8               1.00        50      0.9895964  0.8932836  0.9794276
  0.3  1          0.8               1.00       100      0.9924399  0.9852063  0.9746782
  0.3  1          0.8               1.00       150      0.9937615  0.9911765  0.9810274
  0.3  2          0.6               0.50        50      0.9954566  0.9852063  0.9763030
  0.3  2          0.6               0.50       100      0.9968014  1.0000000  0.9826272
  0.3  2          0.6               0.50       150      0.9962877  1.0000000  0.9841770
  0.3  2          0.6               0.75        50      0.9947722  0.9911765  0.9810274
  0.3  2          0.6               0.75       100      0.9960875  1.0000000  0.9857768
  0.3  2          0.6               0.75       150      0.9965797  1.0000000  0.9857768
  0.3  2          0.6               1.00        50      0.9952322  0.9911765  0.9842020
  0.3  2          0.6               1.00       100      0.9947816  1.0000000  0.9857768
  0.3  2          0.6               1.00       150      0.9953864  1.0000000  0.9842020
  0.3  2          0.8               0.50        50      0.9953629  0.9823529  0.9746782
  0.3  2          0.8               0.50       100      0.9963641  1.0000000  0.9857643
  0.3  2          0.8               0.50       150      0.9969430  1.0000000  0.9826022
  0.3  2          0.8               0.75        50      0.9954207  0.9911765  0.9794401
  0.3  2          0.8               0.75       100      0.9959222  1.0000000  0.9857518
  0.3  2          0.8               0.75       150      0.9964213  1.0000000  0.9873391
  0.3  2          0.8               1.00        50      0.9944001  0.9911765  0.9810274
  0.3  2          0.8               1.00       100      0.9957761  1.0000000  0.9841895
  0.3  2          0.8               1.00       150      0.9962171  1.0000000  0.9857768
  0.3  3          0.6               0.50        50      0.9983145  0.9911765  0.9746782
  0.3  3          0.6               0.50       100      0.9985482  1.0000000  0.9841895
  0.3  3          0.6               0.50       150      0.9987976  1.0000000  0.9857643
  0.3  3          0.6               0.75        50      0.9977954  1.0000000  0.9826147
  0.3  3          0.6               0.75       100      0.9978364  1.0000000  0.9841895
  0.3  3          0.6               0.75       150      0.9985807  1.0000000  0.9841895
  0.3  3          0.6               1.00        50      0.9972489  1.0000000  0.9873516
  0.3  3          0.6               1.00       100      0.9979879  1.0000000  0.9889264
  0.3  3          0.6               1.00       150      0.9982248  1.0000000  0.9873391
  0.3  3          0.8               0.50        50      0.9977169  1.0000000  0.9857643
  0.3  3          0.8               0.50       100      0.9978478  1.0000000  0.9889264
  0.3  3          0.8               0.50       150      0.9981758  1.0000000  0.9857643
  0.3  3          0.8               0.75        50      0.9963247  1.0000000  0.9841770
  0.3  3          0.8               0.75       100      0.9972489  1.0000000  0.9857768
  0.3  3          0.8               0.75       150      0.9981659  1.0000000  0.9873516
  0.3  3          0.8               1.00        50      0.9968509  1.0000000  0.9857768
  0.3  3          0.8               1.00       100      0.9974752  1.0000000  0.9873516
  0.3  3          0.8               1.00       150      0.9979210  1.0000000  0.9873516
  0.4  1          0.6               0.50        50      0.9908382  0.9318262  0.9731034
  0.4  1          0.6               0.50       100      0.9954146  0.9911765  0.9762780
  0.4  1          0.6               0.50       150      0.9956451  0.9911765  0.9810274
  0.4  1          0.6               0.75        50      0.9915285  0.9348112  0.9699538
  0.4  1          0.6               0.75       100      0.9937785  0.9911765  0.9794401
  0.4  1          0.6               0.75       150      0.9948486  0.9911765  0.9810274
  0.4  1          0.6               1.00        50      0.9910997  0.9437665  0.9778528
  0.4  1          0.6               1.00       100      0.9929693  0.9911765  0.9810274
  0.4  1          0.6               1.00       150      0.9934863  0.9911765  0.9826022
  0.4  1          0.8               0.50        50      0.9916264  0.9466637  0.9683540
  0.4  1          0.8               0.50       100      0.9953866  0.9911765  0.9810274
  0.4  1          0.8               0.50       150      0.9959608  1.0000000  0.9841895
  0.4  1          0.8               0.75        50      0.9923219  0.9467954  0.9762780
  0.4  1          0.8               0.75       100      0.9948606  0.9911765  0.9826022
  0.4  1          0.8               0.75       150      0.9954007  0.9911765  0.9825897
  0.4  1          0.8               1.00        50      0.9912492  0.9615452  0.9762655
  0.4  1          0.8               1.00       100      0.9929004  0.9911765  0.9826022
  0.4  1          0.8               1.00       150      0.9942042  0.9911765  0.9841895
  0.4  2          0.6               0.50        50      0.9949974  0.9911765  0.9810399
  0.4  2          0.6               0.50       100      0.9972758  1.0000000  0.9826022
  0.4  2          0.6               0.50       150      0.9962818  1.0000000  0.9794151
  0.4  2          0.6               0.75        50      0.9970602  0.9911765  0.9857643
  0.4  2          0.6               0.75       100      0.9980360  1.0000000  0.9889264
  0.4  2          0.6               0.75       150      0.9981545  1.0000000  0.9905137
  0.4  2          0.6               1.00        50      0.9950760  0.9911765  0.9826022
  0.4  2          0.6               1.00       100      0.9953981  1.0000000  0.9810399
  0.4  2          0.6               1.00       150      0.9962619  1.0000000  0.9841895
  0.4  2          0.8               0.50        50      0.9955226  0.9911765  0.9857768
  0.4  2          0.8               0.50       100      0.9965768  1.0000000  0.9810149
  0.4  2          0.8               0.50       150      0.9970442  1.0000000  0.9810024
  0.4  2          0.8               0.75        50      0.9954739  0.9911765  0.9731409
  0.4  2          0.8               0.75       100      0.9966393  1.0000000  0.9842020
  0.4  2          0.8               0.75       150      0.9961466  1.0000000  0.9857643
  0.4  2          0.8               1.00        50      0.9965483  0.9911765  0.9825897
  0.4  2          0.8               1.00       100      0.9975763  1.0000000  0.9889264
  0.4  2          0.8               1.00       150      0.9979421  1.0000000  0.9857768
  0.4  3          0.6               0.50        50      0.9973825  1.0000000  0.9873391
  0.4  3          0.6               0.50       100      0.9987476  1.0000000  0.9810024
  0.4  3          0.6               0.50       150      0.9988407  1.0000000  0.9825897
  0.4  3          0.6               0.75        50      0.9972140  1.0000000  0.9794651
  0.4  3          0.6               0.75       100      0.9975268  1.0000000  0.9873516
  0.4  3          0.6               0.75       150      0.9982043  1.0000000  0.9873516
  0.4  3          0.6               1.00        50      0.9970562  1.0000000  0.9841770
  0.4  3          0.6               1.00       100      0.9975473  1.0000000  0.9905137
  0.4  3          0.6               1.00       150      0.9988466  1.0000000  0.9889264
  0.4  3          0.8               0.50        50      0.9974933  1.0000000  0.9746657
  0.4  3          0.8               0.50       100      0.9970562  1.0000000  0.9778278
  0.4  3          0.8               0.50       150      0.9975031  1.0000000  0.9762530
  0.4  3          0.8               0.75        50      0.9959581  1.0000000  0.9873516
  0.4  3          0.8               0.75       100      0.9968446  1.0000000  0.9873266
  0.4  3          0.8               0.75       150      0.9968262  1.0000000  0.9889139
  0.4  3          0.8               1.00        50      0.9971472  1.0000000  0.9873516
  0.4  3          0.8               1.00       100      0.9974541  1.0000000  0.9873391
  0.4  3          0.8               1.00       150      0.9983206  1.0000000  0.9873391

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     34.8      0.7
  positive      0.0     64.5
                            
 Accuracy (average) : 0.9928

[1] "TRAIN accuracy: 0.992776057791538"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.979651162790698"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.988924050632911"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative       10        4
            positive        9      202
[1] "TEST accuracy: 0.942222222222222"
[1] "TEST +precision: 0.957345971563981"
[1] "TEST -precision: 0.714285714285714"
[1] "TEST specifity: 0.526315789473684"
[1] "TEST sensitivity: 0.980582524271845"
