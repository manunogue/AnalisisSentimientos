[1] "DATASET NAME: ElSur_Bi_IR_2"
[1] "TRAIN INSTANCES: 1756"
[1] "TEST INSTANCES: 396"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.92273187637329"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1756 samples
 617 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1405, 1404, 1405, 1405, 1405 
Resampling results:

  ROC        Sens  Spec     
  0.9965591  1     0.9922599

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.8      0.5
  positive      0.0     65.7
                            
 Accuracy (average) : 0.9949

[1] "TRAIN accuracy: 0.994874715261959"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.985049833887043"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.992261392949269"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        1
            positive        5      389
[1] "TEST accuracy: 0.984848484848485"
[1] "TEST +precision: 0.987309644670051"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.166666666666667"
[1] "TEST sensitivity: 0.997435897435897"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.06207238435745"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1756 samples
 617 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1405, 1405, 1405, 1404, 1405 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.9850772  0.9797892  0.9810567
  0.010  2  0.9850772  0.9797892  0.9810567
  0.010  3  0.9857366  0.9797892  0.9827808
  0.255  1  0.9857763  0.9797892  0.9827808
  0.255  2  0.9857763  0.9797892  0.9827808
  0.255  3  0.9857366  0.9797892  0.9827808
  0.500  1  0.9861349  0.9797892  0.9827808
  0.500  2  0.9861349  0.9797892  0.9827808
  0.500  3  0.9857366  0.9797892  0.9827808

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.1      1.1
  positive      0.7     65.1
                            
 Accuracy (average) : 0.9818

[1] "TRAIN accuracy: 0.981776765375854"
[1] "TRAIN +precision: 0.98961038961039"
[1] "TRAIN -precision: 0.966722129783694"
[1] "TRAIN specifity: 0.979763912310287"
[1] "TRAIN sensitivity: 0.98280309544282"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        2        4
            positive        4      386
[1] "TEST accuracy: 0.97979797979798"
[1] "TEST +precision: 0.98974358974359"
[1] "TEST -precision: 0.333333333333333"
[1] "TEST specifity: 0.333333333333333"
[1] "TEST sensitivity: 0.98974358974359"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 5.47417479753494"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1756 samples
 617 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1404, 1404, 1406, 1405, 1405 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9894125  0.7742487  0.9853781
  0.3  1          0.6               0.50       100      0.9936802  0.9830936  0.9819373
  0.3  1          0.6               0.50       150      0.9945230  1.0000000  0.9810752
  0.3  1          0.6               0.75        50      0.9927932  0.8499359  0.9896774
  0.3  1          0.6               0.75       100      0.9947927  1.0000000  0.9802168
  0.3  1          0.6               0.75       150      0.9952591  1.0000000  0.9785038
  0.3  1          0.6               1.00        50      0.9912284  0.8246831  0.9896811
  0.3  1          0.6               1.00       100      0.9916680  0.9629255  0.9784964
  0.3  1          0.6               1.00       150      0.9931402  1.0000000  0.9785001
  0.3  1          0.8               0.50        50      0.9907579  0.8194844  0.9870986
  0.3  1          0.8               0.50       100      0.9936334  0.9881356  0.9819373
  0.3  1          0.8               0.50       150      0.9945189  1.0000000  0.9785038
  0.3  1          0.8               0.75        50      0.9909578  0.8095570  0.9888264
  0.3  1          0.8               0.75       100      0.9930887  0.9830936  0.9827956
  0.3  1          0.8               0.75       150      0.9944515  1.0000000  0.9819446
  0.3  1          0.8               1.00        50      0.9896859  0.8162085  0.9845198
  0.3  1          0.8               1.00       100      0.9917779  0.9629255  0.9793547
  0.3  1          0.8               1.00       150      0.9932238  1.0000000  0.9776417
  0.3  2          0.6               0.50        50      0.9959556  0.9831933  0.9836614
  0.3  2          0.6               0.50       100      0.9965458  1.0000000  0.9862439
  0.3  2          0.6               0.50       150      0.9968138  1.0000000  0.9827993
  0.3  2          0.6               0.75        50      0.9938250  0.9763709  0.9810752
  0.3  2          0.6               0.75       100      0.9955210  1.0000000  0.9802168
  0.3  2          0.6               0.75       150      0.9968865  1.0000000  0.9827993
  0.3  2          0.6               1.00        50      0.9946040  0.9629255  0.9827993
  0.3  2          0.6               1.00       100      0.9955764  1.0000000  0.9793621
  0.3  2          0.6               1.00       150      0.9957488  1.0000000  0.9810826
  0.3  2          0.8               0.50        50      0.9947192  0.9678963  0.9827993
  0.3  2          0.8               0.50       100      0.9965821  1.0000000  0.9810826
  0.3  2          0.8               0.50       150      0.9965440  1.0000000  0.9810826
  0.3  2          0.8               0.75        50      0.9942848  0.9881356  0.9819336
  0.3  2          0.8               0.75       100      0.9956621  1.0000000  0.9802168
  0.3  2          0.8               0.75       150      0.9963353  1.0000000  0.9836577
  0.3  2          0.8               1.00        50      0.9923680  0.9881356  0.9810789
  0.3  2          0.8               1.00       100      0.9935304  1.0000000  0.9802205
  0.3  2          0.8               1.00       150      0.9945106  1.0000000  0.9810789
  0.3  3          0.6               0.50        50      0.9961883  1.0000000  0.9836614
  0.3  3          0.6               0.50       100      0.9969272  1.0000000  0.9870986
  0.3  3          0.6               0.50       150      0.9969041  1.0000000  0.9853781
  0.3  3          0.6               0.75        50      0.9963876  1.0000000  0.9862402
  0.3  3          0.6               0.75       100      0.9967720  1.0000000  0.9810826
  0.3  3          0.6               0.75       150      0.9972274  1.0000000  0.9836651
  0.3  3          0.6               1.00        50      0.9942127  1.0000000  0.9802205
  0.3  3          0.6               1.00       100      0.9955804  1.0000000  0.9819373
  0.3  3          0.6               1.00       150      0.9962587  1.0000000  0.9827993
  0.3  3          0.8               0.50        50      0.9970535  1.0000000  0.9845198
  0.3  3          0.8               0.50       100      0.9971875  1.0000000  0.9853744
  0.3  3          0.8               0.50       150      0.9966379  1.0000000  0.9862365
  0.3  3          0.8               0.75        50      0.9960998  1.0000000  0.9819373
  0.3  3          0.8               0.75       100      0.9973668  1.0000000  0.9810789
  0.3  3          0.8               0.75       150      0.9969822  1.0000000  0.9810826
  0.3  3          0.8               1.00        50      0.9940464  1.0000000  0.9802205
  0.3  3          0.8               1.00       100      0.9948144  1.0000000  0.9819410
  0.3  3          0.8               1.00       150      0.9952419  1.0000000  0.9819410
  0.4  1          0.6               0.50        50      0.9896943  0.9612021  0.9784964
  0.4  1          0.6               0.50       100      0.9938273  1.0000000  0.9802242
  0.4  1          0.6               0.50       150      0.9945802  1.0000000  0.9836651
  0.4  1          0.6               0.75        50      0.9910044  0.9258653  0.9819410
  0.4  1          0.6               0.75       100      0.9947940  1.0000000  0.9793695
  0.4  1          0.6               0.75       150      0.9950119  1.0000000  0.9828067
  0.4  1          0.6               1.00        50      0.9918253  0.9207378  0.9827993
  0.4  1          0.6               1.00       100      0.9925537  1.0000000  0.9785001
  0.4  1          0.6               1.00       150      0.9944426  1.0000000  0.9802242
  0.4  1          0.8               0.50        50      0.9922722  0.9391397  0.9845235
  0.4  1          0.8               0.50       100      0.9946071  1.0000000  0.9819373
  0.4  1          0.8               0.50       150      0.9952748  1.0000000  0.9819373
  0.4  1          0.8               0.75        50      0.9894259  0.9359066  0.9785038
  0.4  1          0.8               0.75       100      0.9930150  1.0000000  0.9785075
  0.4  1          0.8               0.75       150      0.9941002  1.0000000  0.9793658
  0.4  1          0.8               1.00        50      0.9912583  0.9157385  0.9836577
  0.4  1          0.8               1.00       100      0.9930608  1.0000000  0.9793584
  0.4  1          0.8               1.00       150      0.9944221  1.0000000  0.9802205
  0.4  2          0.6               0.50        50      0.9946000  1.0000000  0.9793658
  0.4  2          0.6               0.50       100      0.9960690  1.0000000  0.9819373
  0.4  2          0.6               0.50       150      0.9964600  1.0000000  0.9819410
  0.4  2          0.6               0.75        50      0.9956947  1.0000000  0.9819446
  0.4  2          0.6               0.75       100      0.9964081  1.0000000  0.9845235
  0.4  2          0.6               0.75       150      0.9966844  1.0000000  0.9836651
  0.4  2          0.6               1.00        50      0.9944676  1.0000000  0.9759250
  0.4  2          0.6               1.00       100      0.9956722  1.0000000  0.9802242
  0.4  2          0.6               1.00       150      0.9963212  1.0000000  0.9802242
  0.4  2          0.8               0.50        50      0.9939956  1.0000000  0.9810789
  0.4  2          0.8               0.50       100      0.9956101  1.0000000  0.9793547
  0.4  2          0.8               0.50       150      0.9960141  1.0000000  0.9802205
  0.4  2          0.8               0.75        50      0.9946413  1.0000000  0.9802205
  0.4  2          0.8               0.75       100      0.9957842  1.0000000  0.9810789
  0.4  2          0.8               0.75       150      0.9959878  1.0000000  0.9827993
  0.4  2          0.8               1.00        50      0.9934212  1.0000000  0.9785001
  0.4  2          0.8               1.00       100      0.9947669  1.0000000  0.9802205
  0.4  2          0.8               1.00       150      0.9951653  1.0000000  0.9810826
  0.4  3          0.6               0.50        50      0.9959099  1.0000000  0.9845198
  0.4  3          0.6               0.50       100      0.9963739  1.0000000  0.9879606
  0.4  3          0.6               0.50       150      0.9969505  1.0000000  0.9853855
  0.4  3          0.6               0.75        50      0.9966590  1.0000000  0.9853855
  0.4  3          0.6               0.75       100      0.9974174  1.0000000  0.9862439
  0.4  3          0.6               0.75       150      0.9971794  1.0000000  0.9853818
  0.4  3          0.6               1.00        50      0.9963990  1.0000000  0.9819446
  0.4  3          0.6               1.00       100      0.9970500  1.0000000  0.9810826
  0.4  3          0.6               1.00       150      0.9968328  1.0000000  0.9836614
  0.4  3          0.8               0.50        50      0.9958276  1.0000000  0.9802279
  0.4  3          0.8               0.50       100      0.9963560  1.0000000  0.9836614
  0.4  3          0.8               0.50       150      0.9975772  1.0000000  0.9828067
  0.4  3          0.8               0.75        50      0.9961161  1.0000000  0.9819373
  0.4  3          0.8               0.75       100      0.9978013  1.0000000  0.9819373
  0.4  3          0.8               0.75       150      0.9970167  1.0000000  0.9819410
  0.4  3          0.8               1.00        50      0.9947146  1.0000000  0.9802205
  0.4  3          0.8               1.00       100      0.9954167  1.0000000  0.9810826
  0.4  3          0.8               1.00       150      0.9964781  1.0000000  0.9836614

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 100, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 0.75.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.8      1.2
  positive      0.0     65.0
                           
 Accuracy (average) : 0.988

[1] "TRAIN accuracy: 0.988041002277904"
[1] "TRAIN +precision: 1"
[1] "TRAIN -precision: 0.965798045602606"
[1] "TRAIN specifity: 1"
[1] "TRAIN sensitivity: 0.981943250214961"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        2
            positive        6      388
[1] "TEST accuracy: 0.97979797979798"
[1] "TEST +precision: 0.984771573604061"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.994871794871795"
