[1] "DATASET NAME: HRM_Bi_IR_10"
[1] "TRAIN INSTANCES: 360"
[1] "TEST INSTANCES: 112"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.1906111240387"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

360 samples
964 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 288, 288, 287, 288, 289 
Resampling results:

  ROC        Sens       Spec     
  0.9124463  0.5580952  0.9652753

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     11.1      2.8
  positive      8.9     77.2
                            
 Accuracy (average) : 0.8833

[1] "TRAIN accuracy: 0.883333333333333"
[1] "TRAIN +precision: 0.896774193548387"
[1] "TRAIN -precision: 0.8"
[1] "TRAIN specifity: 0.555555555555556"
[1] "TRAIN sensitivity: 0.965277777777778"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        1
            positive       11       96
[1] "TEST accuracy: 0.892857142857143"
[1] "TEST +precision: 0.897196261682243"
[1] "TEST -precision: 0.8"
[1] "TEST specifity: 0.266666666666667"
[1] "TEST sensitivity: 0.989690721649485"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.35743816693624"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

360 samples
964 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 288, 287, 289, 289, 287 
Resampling results across tuning parameters:

  C      M  ROC        Sens        Spec     
  0.010  1  0.5071429  0.01428571  1.0000000
  0.010  2  0.5071429  0.01428571  1.0000000
  0.010  3  0.5071429  0.01428571  1.0000000
  0.255  1  0.6303033  0.20761905  0.9931034
  0.255  2  0.4994253  0.04190476  0.9964912
  0.255  3  0.5067704  0.04190476  0.9964912
  0.500  1  0.6651448  0.20761905  0.9931034
  0.500  2  0.5293544  0.05523810  0.9792498
  0.500  3  0.4981907  0.04190476  0.9861464

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      4.2      0.6
  positive     15.8     79.4
                            
 Accuracy (average) : 0.8361

[1] "TRAIN accuracy: 0.836111111111111"
[1] "TRAIN +precision: 0.833819241982507"
[1] "TRAIN -precision: 0.88235294117647"
[1] "TRAIN specifity: 0.208333333333333"
[1] "TRAIN sensitivity: 0.993055555555556"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        1
            positive       15       96
[1] "TEST accuracy: 0.857142857142857"
[1] "TEST +precision: 0.864864864864865"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.989690721649485"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 2.19122876326243"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

360 samples
964 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 288, 288, 288, 288, 288 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens        Spec     
  0.3  1          0.6               0.50        50      0.6164202  0.00000000  1.0000000
  0.3  1          0.6               0.50       100      0.6175884  0.00000000  0.9965517
  0.3  1          0.6               0.50       150      0.6416422  0.00000000  0.9930430
  0.3  1          0.6               0.75        50      0.6908906  0.01333333  0.9965517
  0.3  1          0.6               0.75       100      0.6721345  0.04190476  0.9861464
  0.3  1          0.6               0.75       150      0.6724537  0.04190476  0.9826981
  0.3  1          0.6               1.00        50      0.6791218  0.04190476  1.0000000
  0.3  1          0.6               1.00       100      0.6740004  0.04190476  0.9965517
  0.3  1          0.6               1.00       150      0.6604590  0.04190476  0.9861464
  0.3  1          0.8               0.50        50      0.6046140  0.00000000  0.9965517
  0.3  1          0.8               0.50       100      0.6366804  0.01428571  0.9965517
  0.3  1          0.8               0.50       150      0.6428242  0.01428571  0.9861464
  0.3  1          0.8               0.75        50      0.6684968  0.02761905  0.9965517
  0.3  1          0.8               0.75       100      0.6662010  0.04190476  0.9862069
  0.3  1          0.8               0.75       150      0.6657091  0.04190476  0.9827586
  0.3  1          0.8               1.00        50      0.6807228  0.04190476  1.0000000
  0.3  1          0.8               1.00       100      0.6744675  0.04190476  0.9965517
  0.3  1          0.8               1.00       150      0.6662472  0.04190476  0.9861464
  0.3  2          0.6               0.50        50      0.6339455  0.01428571  1.0000000
  0.3  2          0.6               0.50       100      0.6500392  0.01428571  0.9896552
  0.3  2          0.6               0.50       150      0.6489582  0.01428571  0.9931034
  0.3  2          0.6               0.75        50      0.6487803  0.02857143  0.9896552
  0.3  2          0.6               0.75       100      0.6484844  0.04285714  0.9826981
  0.3  2          0.6               0.75       150      0.6611105  0.07047619  0.9792498
  0.3  2          0.6               1.00        50      0.6907139  0.05523810  0.9931034
  0.3  2          0.6               1.00       100      0.6912615  0.06952381  0.9827586
  0.3  2          0.6               1.00       150      0.6870991  0.06952381  0.9826981
  0.3  2          0.8               0.50        50      0.6399085  0.00000000  0.9931034
  0.3  2          0.8               0.50       100      0.6516876  0.00000000  0.9965517
  0.3  2          0.8               0.50       150      0.6680566  0.00000000  0.9931034
  0.3  2          0.8               0.75        50      0.6639580  0.02761905  0.9861464
  0.3  2          0.8               0.75       100      0.6740070  0.04190476  0.9861464
  0.3  2          0.8               0.75       150      0.6640214  0.04190476  0.9826981
  0.3  2          0.8               1.00        50      0.6763465  0.05619048  0.9931034
  0.3  2          0.8               1.00       100      0.6768245  0.05619048  0.9792498
  0.3  2          0.8               1.00       150      0.6767867  0.05619048  0.9792498
  0.3  3          0.6               0.50        50      0.6486874  0.00000000  0.9931034
  0.3  3          0.6               0.50       100      0.6268350  0.00000000  0.9931034
  0.3  3          0.6               0.50       150      0.6266066  0.00000000  0.9896552
  0.3  3          0.6               0.75        50      0.6581822  0.02761905  0.9826981
  0.3  3          0.6               0.75       100      0.6675783  0.02761905  0.9861464
  0.3  3          0.6               0.75       150      0.6642772  0.04095238  0.9861464
  0.3  3          0.6               1.00        50      0.6966966  0.06952381  0.9826981
  0.3  3          0.6               1.00       100      0.6813171  0.05523810  0.9792498
  0.3  3          0.6               1.00       150      0.6762809  0.06952381  0.9826981
  0.3  3          0.8               0.50        50      0.6348910  0.00000000  0.9931034
  0.3  3          0.8               0.50       100      0.6367820  0.00000000  0.9931034
  0.3  3          0.8               0.50       150      0.6428930  0.00000000  0.9931034
  0.3  3          0.8               0.75        50      0.6513374  0.05523810  0.9792498
  0.3  3          0.8               0.75       100      0.6598575  0.06952381  0.9896552
  0.3  3          0.8               0.75       150      0.6514365  0.05523810  0.9896552
  0.3  3          0.8               1.00        50      0.6983045  0.08380952  0.9896552
  0.3  3          0.8               1.00       100      0.6803388  0.08380952  0.9861464
  0.3  3          0.8               1.00       150      0.6806332  0.08380952  0.9861464
  0.4  1          0.6               0.50        50      0.6021593  0.00000000  1.0000000
  0.4  1          0.6               0.50       100      0.6287858  0.00000000  1.0000000
  0.4  1          0.6               0.50       150      0.6378597  0.01428571  0.9931034
  0.4  1          0.6               0.75        50      0.6547652  0.01428571  0.9965517
  0.4  1          0.6               0.75       100      0.6509184  0.05523810  0.9826981
  0.4  1          0.6               0.75       150      0.6521306  0.05523810  0.9826981
  0.4  1          0.6               1.00        50      0.6681612  0.01428571  0.9965517
  0.4  1          0.6               1.00       100      0.6581811  0.02761905  0.9931034
  0.4  1          0.6               1.00       150      0.6712805  0.02761905  0.9862069
  0.4  1          0.8               0.50        50      0.6516380  0.01333333  1.0000000
  0.4  1          0.8               0.50       100      0.6719644  0.01333333  1.0000000
  0.4  1          0.8               0.50       150      0.6583979  0.01333333  0.9931034
  0.4  1          0.8               0.75        50      0.6564369  0.02857143  0.9965517
  0.4  1          0.8               0.75       100      0.6639037  0.05523810  0.9896552
  0.4  1          0.8               0.75       150      0.6611193  0.05523810  0.9862069
  0.4  1          0.8               1.00        50      0.6866451  0.04190476  0.9965517
  0.4  1          0.8               1.00       100      0.6742398  0.04190476  0.9862069
  0.4  1          0.8               1.00       150      0.6797292  0.04190476  0.9826981
  0.4  2          0.6               0.50        50      0.6389755  0.00000000  0.9931034
  0.4  2          0.6               0.50       100      0.6625581  0.00000000  0.9896552
  0.4  2          0.6               0.50       150      0.6425950  0.00000000  0.9862069
  0.4  2          0.6               0.75        50      0.6707624  0.04190476  0.9826981
  0.4  2          0.6               0.75       100      0.6653334  0.05619048  0.9826981
  0.4  2          0.6               0.75       150      0.6730425  0.05619048  0.9861464
  0.4  2          0.6               1.00        50      0.6879083  0.04190476  0.9896552
  0.4  2          0.6               1.00       100      0.6933063  0.05619048  0.9861464
  0.4  2          0.6               1.00       150      0.6891438  0.07047619  0.9861464
  0.4  2          0.8               0.50        50      0.6387292  0.00000000  0.9895947
  0.4  2          0.8               0.50       100      0.6528965  0.00000000  0.9931034
  0.4  2          0.8               0.50       150      0.6441307  0.01428571  0.9861464
  0.4  2          0.8               0.75        50      0.6648463  0.06952381  0.9862069
  0.4  2          0.8               0.75       100      0.6668827  0.05523810  0.9826981
  0.4  2          0.8               0.75       150      0.6671174  0.05523810  0.9861464
  0.4  2          0.8               1.00        50      0.6974749  0.06952381  0.9862069
  0.4  2          0.8               1.00       100      0.6961738  0.08380952  0.9862069
  0.4  2          0.8               1.00       150      0.6888823  0.08380952  0.9862069
  0.4  3          0.6               0.50        50      0.6322771  0.00000000  0.9861464
  0.4  3          0.6               0.50       100      0.6400831  0.00000000  0.9895947
  0.4  3          0.6               0.50       150      0.6393682  0.00000000  0.9792498
  0.4  3          0.6               0.75        50      0.6933176  0.06952381  0.9827586
  0.4  3          0.6               0.75       100      0.6659904  0.05523810  0.9723533
  0.4  3          0.6               0.75       150      0.6670747  0.06952381  0.9792498
  0.4  3          0.6               1.00        50      0.7008369  0.06952381  0.9862069
  0.4  3          0.6               1.00       100      0.6808781  0.06952381  0.9862069
  0.4  3          0.6               1.00       150      0.6779603  0.08285714  0.9862069
  0.4  3          0.8               0.50        50      0.6151796  0.00000000  0.9965517
  0.4  3          0.8               0.50       100      0.6201764  0.00000000  0.9896552
  0.4  3          0.8               0.50       150      0.6426260  0.00000000  0.9861464
  0.4  3          0.8               0.75        50      0.6669545  0.07047619  0.9931034
  0.4  3          0.8               0.75       100      0.6858144  0.07047619  0.9861464
  0.4  3          0.8               0.75       150      0.6656989  0.06952381  0.9861464
  0.4  3          0.8               1.00        50      0.6855903  0.06952381  0.9826981
  0.4  3          0.8               1.00       100      0.6817718  0.06952381  0.9861464
  0.4  3          0.8               1.00       150      0.6757257  0.09714286  0.9861464

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      1.4      1.1
  positive     18.6     78.9
                            
 Accuracy (average) : 0.8028

[1] "TRAIN accuracy: 0.802777777777778"
[1] "TRAIN +precision: 0.809116809116809"
[1] "TRAIN -precision: 0.555555555555556"
[1] "TRAIN specifity: 0.0694444444444444"
[1] "TRAIN sensitivity: 0.986111111111111"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       15       97
[1] "TEST accuracy: 0.866071428571429"
[1] "TEST +precision: 0.866071428571429"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
