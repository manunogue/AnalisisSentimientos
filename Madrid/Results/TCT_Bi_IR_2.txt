[1] "DATASET NAME: TCT_Bi_IR_2"
[1] "TRAIN INSTANCES: 967"
[1] "TEST INSTANCES: 225"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 3.68169403076172"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

967 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 774, 774, 774, 773, 773 
Resampling results:

  ROC        Sens       Spec     
  0.9973449  0.9615013  0.9968254

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     33.5      0.2
  positive      1.3     64.9
                            
 Accuracy (average) : 0.9845

[1] "TRAIN accuracy: 0.984488107549121"
[1] "TRAIN +precision: 0.979719188767551"
[1] "TRAIN -precision: 0.993865030674847"
[1] "TRAIN specifity: 0.961424332344214"
[1] "TRAIN sensitivity: 0.996825396825397"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        0
            positive       13      208
[1] "TEST accuracy: 0.942222222222222"
[1] "TEST +precision: 0.941176470588235"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.235294117647059"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 2.01834057966868"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

967 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 773, 774, 774, 774, 773 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.8304871  0.5815189  0.9603175
  0.010  2  0.8344426  0.5815189  0.9603175
  0.010  3  0.8360798  0.5815189  0.9650794
  0.255  1  0.8752400  0.6379280  0.9746032
  0.255  2  0.8810874  0.6379280  0.9761905
  0.255  3  0.8861174  0.6379280  0.9888889
  0.500  1  0.8764344  0.6379280  0.9761905
  0.500  2  0.8864287  0.6379280  0.9873016
  0.500  3  0.8881440  0.6379280  0.9920635

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.5 and M = 3.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     22.2      0.5
  positive     12.6     64.6
                            
 Accuracy (average) : 0.8687

[1] "TRAIN accuracy: 0.868665977249224"
[1] "TRAIN +precision: 0.836680053547523"
[1] "TRAIN -precision: 0.977272727272727"
[1] "TRAIN specifity: 0.637982195845697"
[1] "TRAIN sensitivity: 0.992063492063492"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive       17      208
[1] "TEST accuracy: 0.924444444444444"
[1] "TEST +precision: 0.924444444444444"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.31510701576869"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

967 samples
940 predictors
  2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 774, 773, 773, 774, 774 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.9385471  0.5784021  0.9777778
  0.3  1          0.6               0.50       100      0.9653199  0.8273924  0.9777778
  0.3  1          0.6               0.50       150      0.9733009  0.8809921  0.9761905
  0.3  1          0.6               0.75        50      0.9438929  0.6610184  0.9714286
  0.3  1          0.6               0.75       100      0.9692671  0.8215540  0.9777778
  0.3  1          0.6               0.75       150      0.9775038  0.8899473  0.9777778
  0.3  1          0.6               1.00        50      0.9417919  0.6700615  0.9730159
  0.3  1          0.6               1.00       100      0.9674046  0.8304653  0.9777778
  0.3  1          0.6               1.00       150      0.9797459  0.8839772  0.9825397
  0.3  1          0.8               0.50        50      0.9440356  0.6017998  0.9761905
  0.3  1          0.8               0.50       100      0.9647770  0.8127305  0.9746032
  0.3  1          0.8               0.50       150      0.9758591  0.8809921  0.9777778
  0.3  1          0.8               0.75        50      0.9413005  0.5991659  0.9730159
  0.3  1          0.8               0.75       100      0.9670724  0.8512730  0.9777778
  0.3  1          0.8               0.75       150      0.9781617  0.8899473  0.9777778
  0.3  1          0.8               1.00        50      0.9396872  0.6701054  0.9746032
  0.3  1          0.8               1.00       100      0.9706361  0.8543459  0.9793651
  0.3  1          0.8               1.00       150      0.9796612  0.8839772  0.9857143
  0.3  2          0.6               0.50        50      0.9665646  0.8127305  0.9793651
  0.3  2          0.6               0.50       100      0.9779708  0.8989025  0.9793651
  0.3  2          0.6               0.50       150      0.9792660  0.9107989  0.9761905
  0.3  2          0.6               0.75        50      0.9679211  0.8571993  0.9761905
  0.3  2          0.6               0.75       100      0.9785294  0.9137401  0.9761905
  0.3  2          0.6               0.75       150      0.9837737  0.9345040  0.9825397
  0.3  2          0.6               1.00        50      0.9731143  0.8393766  0.9793651
  0.3  2          0.6               1.00       100      0.9820866  0.9167252  0.9857143
  0.3  2          0.6               1.00       150      0.9853478  0.9345040  0.9904762
  0.3  2          0.8               0.50        50      0.9660389  0.8303775  0.9777778
  0.3  2          0.8               0.50       100      0.9763504  0.9078139  0.9809524
  0.3  2          0.8               0.50       150      0.9808944  0.9257243  0.9777778
  0.3  2          0.8               0.75        50      0.9719296  0.8186128  0.9777778
  0.3  2          0.8               0.75       100      0.9811400  0.9136962  0.9809524
  0.3  2          0.8               0.75       150      0.9845010  0.9316067  0.9841270
  0.3  2          0.8               1.00        50      0.9735859  0.8483758  0.9809524
  0.3  2          0.8               1.00       100      0.9823223  0.9077700  0.9888889
  0.3  2          0.8               1.00       150      0.9859251  0.9286216  0.9904762
  0.3  3          0.6               0.50        50      0.9757231  0.8660667  0.9809524
  0.3  3          0.6               0.50       100      0.9814506  0.9048727  0.9777778
  0.3  3          0.6               0.50       150      0.9817652  0.9257243  0.9793651
  0.3  3          0.6               0.75        50      0.9772085  0.8809921  0.9825397
  0.3  3          0.6               0.75       100      0.9839260  0.9226514  0.9857143
  0.3  3          0.6               0.75       150      0.9851445  0.9374890  0.9793651
  0.3  3          0.6               1.00        50      0.9792459  0.8869622  0.9841270
  0.3  3          0.6               1.00       100      0.9852055  0.9345040  0.9904762
  0.3  3          0.6               1.00       150      0.9867738  0.9434592  0.9825397
  0.3  3          0.8               0.50        50      0.9715502  0.8930641  0.9793651
  0.3  3          0.8               0.50       100      0.9783194  0.9078139  0.9793651
  0.3  3          0.8               0.50       150      0.9799490  0.9167691  0.9777778
  0.3  3          0.8               0.75        50      0.9761414  0.8780948  0.9761905
  0.3  3          0.8               0.75       100      0.9835814  0.9345040  0.9793651
  0.3  3          0.8               0.75       150      0.9845139  0.9374890  0.9793651
  0.3  3          0.8               1.00        50      0.9793116  0.8839772  0.9841270
  0.3  3          0.8               1.00       100      0.9853927  0.9286216  0.9920635
  0.3  3          0.8               1.00       150      0.9869366  0.9434592  0.9809524
  0.4  1          0.6               0.50        50      0.9481263  0.7416155  0.9698413
  0.4  1          0.6               0.50       100      0.9695023  0.8780948  0.9793651
  0.4  1          0.6               0.50       150      0.9753534  0.9078139  0.9761905
  0.4  1          0.6               0.75        50      0.9509593  0.7947761  0.9730159
  0.4  1          0.6               0.75       100      0.9755092  0.8780070  0.9761905
  0.4  1          0.6               0.75       150      0.9791343  0.9018437  0.9777778
  0.4  1          0.6               1.00        50      0.9562795  0.7976734  0.9777778
  0.4  1          0.6               1.00       100      0.9754501  0.8780070  0.9841270
  0.4  1          0.6               1.00       150      0.9815035  0.8988147  0.9888889
  0.4  1          0.8               0.50        50      0.9386985  0.7265145  0.9698413
  0.4  1          0.8               0.50       100      0.9670327  0.8602283  0.9714286
  0.4  1          0.8               0.50       150      0.9755085  0.8988586  0.9698413
  0.4  1          0.8               0.75        50      0.9466385  0.7889377  0.9730159
  0.4  1          0.8               0.75       100      0.9729418  0.8780948  0.9746032
  0.4  1          0.8               0.75       150      0.9773635  0.8988147  0.9746032
  0.4  1          0.8               1.00        50      0.9545835  0.8098332  0.9746032
  0.4  1          0.8               1.00       100      0.9777652  0.8750219  0.9825397
  0.4  1          0.8               1.00       150      0.9824258  0.8988147  0.9904762
  0.4  2          0.6               0.50        50      0.9694751  0.8721686  0.9746032
  0.4  2          0.6               0.50       100      0.9784228  0.9108428  0.9793651
  0.4  2          0.6               0.50       150      0.9801464  0.9137840  0.9793651
  0.4  2          0.6               0.75        50      0.9707236  0.8661545  0.9777778
  0.4  2          0.6               0.75       100      0.9808270  0.9375768  0.9761905
  0.4  2          0.6               0.75       150      0.9838627  0.9434592  0.9777778
  0.4  2          0.6               1.00        50      0.9779222  0.8809921  0.9825397
  0.4  2          0.6               1.00       100      0.9858728  0.9286216  0.9873016
  0.4  2          0.6               1.00       150      0.9868069  0.9434592  0.9857143
  0.4  2          0.8               0.50        50      0.9711371  0.8633011  0.9809524
  0.4  2          0.8               0.50       100      0.9801338  0.9196664  0.9793651
  0.4  2          0.8               0.50       150      0.9804028  0.9286216  0.9777778
  0.4  2          0.8               0.75        50      0.9762800  0.8780948  0.9777778
  0.4  2          0.8               0.75       100      0.9844036  0.9374890  0.9857143
  0.4  2          0.8               0.75       150      0.9852319  0.9434592  0.9761905
  0.4  2          0.8               1.00        50      0.9794630  0.8780948  0.9857143
  0.4  2          0.8               1.00       100      0.9859319  0.9286216  0.9873016
  0.4  2          0.8               1.00       150      0.9868776  0.9434592  0.9873016
  0.4  3          0.6               0.50        50      0.9743454  0.8749781  0.9809524
  0.4  3          0.6               0.50       100      0.9808259  0.9256365  0.9809524
  0.4  3          0.6               0.50       150      0.9817997  0.9286216  0.9793651
  0.4  3          0.6               0.75        50      0.9801316  0.9167691  0.9857143
  0.4  3          0.6               0.75       100      0.9846912  0.9434592  0.9793651
  0.4  3          0.6               0.75       150      0.9854704  0.9434592  0.9793651
  0.4  3          0.6               1.00        50      0.9838951  0.9078139  0.9841270
  0.4  3          0.6               1.00       100      0.9867732  0.9375768  0.9857143
  0.4  3          0.6               1.00       150      0.9863107  0.9434592  0.9793651
  0.4  3          0.8               0.50        50      0.9758703  0.9078139  0.9793651
  0.4  3          0.8               0.50       100      0.9799189  0.9227392  0.9761905
  0.4  3          0.8               0.50       150      0.9807501  0.9227392  0.9761905
  0.4  3          0.8               0.75        50      0.9800512  0.9226514  0.9746032
  0.4  3          0.8               0.75       100      0.9849173  0.9374890  0.9730159
  0.4  3          0.8               0.75       150      0.9851422  0.9374890  0.9746032
  0.4  3          0.8               1.00        50      0.9820589  0.9196664  0.9809524
  0.4  3          0.8               1.00       100      0.9869239  0.9434592  0.9793651
  0.4  3          0.8               1.00       150      0.9867933  0.9434592  0.9793651

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     32.9      1.2
  positive      2.0     63.9
                            
 Accuracy (average) : 0.9679

[1] "TRAIN accuracy: 0.96794208893485"
[1] "TRAIN +precision: 0.970172684458399"
[1] "TRAIN -precision: 0.963636363636364"
[1] "TRAIN specifity: 0.943620178041543"
[1] "TRAIN sensitivity: 0.980952380952381"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        4        0
            positive       13      208
[1] "TEST accuracy: 0.942222222222222"
[1] "TEST +precision: 0.941176470588235"
[1] "TEST -precision: 1"
[1] "TEST specifity: 0.235294117647059"
[1] "TEST sensitivity: 1"
