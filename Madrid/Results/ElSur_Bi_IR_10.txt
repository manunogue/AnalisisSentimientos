[1] "DATASET NAME: ElSur_Bi_IR_10"
[1] "TRAIN INSTANCES: 1300"
[1] "TEST INSTANCES: 396"
[1] "......................................................................................."
[1] "ALGORITHM: SVM"
[1] "TIME: 2.96322798728943"
[1] "MODEL SUMMARY: "
Support Vector Machines with Linear Kernel 

1300 samples
 617 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1039, 1039, 1041, 1040, 1041 
Resampling results:

  ROC        Sens       Spec     
  0.9913098  0.9925926  0.9931071

Tuning parameter 'C' was held constant at a value of 1
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative     10.5      0.6
  positive      0.1     88.8
                            
 Accuracy (average) : 0.9931

[1] "TRAIN accuracy: 0.993076923076923"
[1] "TRAIN +precision: 0.999134948096886"
[1] "TRAIN -precision: 0.944444444444444"
[1] "TRAIN specifity: 0.992700729927007"
[1] "TRAIN sensitivity: 0.993121238177128"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        1        1
            positive        5      389
[1] "TEST accuracy: 0.984848484848485"
[1] "TEST +precision: 0.987309644670051"
[1] "TEST -precision: 0.5"
[1] "TEST specifity: 0.166666666666667"
[1] "TEST sensitivity: 0.997435897435897"
[1] "......................................................................................."
[1] "ALGORITHM: J48"
[1] "TIME: 1.41615436474482"
[1] "MODEL SUMMARY: "
C4.5-like Trees 

1300 samples
 617 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1039, 1040, 1041, 1040, 1040 
Resampling results across tuning parameters:

  C      M  ROC        Sens       Spec     
  0.010  1  0.6748736  0.2835979  0.9982833
  0.010  2  0.6748736  0.2835979  0.9982833
  0.010  3  0.6748736  0.2835979  0.9982833
  0.255  1  0.6964065  0.3132275  0.9982833
  0.255  2  0.6964065  0.3132275  0.9982833
  0.255  3  0.6964065  0.3132275  0.9982833
  0.500  1  0.6964065  0.3132275  0.9982833
  0.500  2  0.6964065  0.3132275  0.9982833
  0.500  3  0.6964065  0.3132275  0.9982833

ROC was used to select the optimal model using the largest value.
The final values used for the model were C = 0.255 and M = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      3.3      0.2
  positive      7.2     89.3
                            
 Accuracy (average) : 0.9262

[1] "TRAIN accuracy: 0.926153846153846"
[1] "TRAIN +precision: 0.925099601593625"
[1] "TRAIN -precision: 0.955555555555556"
[1] "TRAIN specifity: 0.313868613138686"
[1] "TRAIN sensitivity: 0.998280309544282"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        0
            positive        6      390
[1] "TEST accuracy: 0.984848484848485"
[1] "TEST +precision: 0.984848484848485"
[1] "TEST -precision: NaN"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 1"
[1] "......................................................................................."
[1] "ALGORITHM: XGBoost"
[1] "TIME: 4.09374949932098"
[1] "MODEL SUMMARY: "
eXtreme Gradient Boosting 

1300 samples
 617 predictor
   2 classes: 'negative', 'positive' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 1039, 1041, 1039, 1041, 1040 
Resampling results across tuning parameters:

  eta  max_depth  colsample_bytree  subsample  nrounds  ROC        Sens       Spec     
  0.3  1          0.6               0.50        50      0.8689108  0.3579365  0.9991416
  0.3  1          0.6               0.50       100      0.9098956  0.5693122  0.9982833
  0.3  1          0.6               0.50       150      0.9268573  0.6211640  0.9982833
  0.3  1          0.6               0.75        50      0.8969562  0.4166667  0.9991416
  0.3  1          0.6               0.75       100      0.9233587  0.6941799  0.9982833
  0.3  1          0.6               0.75       150      0.9363688  0.7595238  0.9982833
  0.3  1          0.6               1.00        50      0.9016198  0.3134921  0.9991416
  0.3  1          0.6               1.00       100      0.9326576  0.6645503  0.9991416
  0.3  1          0.6               1.00       150      0.9427191  0.7447090  0.9974212
  0.3  1          0.8               0.50        50      0.8725989  0.3370370  0.9982796
  0.3  1          0.8               0.50       100      0.9055161  0.6063492  0.9957045
  0.3  1          0.8               0.50       150      0.9256281  0.6285714  0.9965665
  0.3  1          0.8               0.75        50      0.8916072  0.3582011  0.9991416
  0.3  1          0.8               0.75       100      0.9265786  0.6793651  0.9974249
  0.3  1          0.8               0.75       150      0.9392853  0.7669312  0.9957008
  0.3  1          0.8               1.00        50      0.9006787  0.3137566  0.9991416
  0.3  1          0.8               1.00       100      0.9327341  0.6796296  0.9982833
  0.3  1          0.8               1.00       150      0.9434502  0.7373016  0.9974212
  0.3  2          0.6               0.50        50      0.9032596  0.5470899  0.9991416
  0.3  2          0.6               0.50       100      0.9261616  0.7010582  0.9991416
  0.3  2          0.6               0.50       150      0.9304496  0.7010582  0.9991416
  0.3  2          0.6               0.75        50      0.9184831  0.6566138  0.9991416
  0.3  2          0.6               0.75       100      0.9391303  0.7447090  0.9982833
  0.3  2          0.6               0.75       150      0.9418349  0.7595238  0.9991416
  0.3  2          0.6               1.00        50      0.9359805  0.7018519  0.9974212
  0.3  2          0.6               1.00       100      0.9543612  0.7891534  0.9957008
  0.3  2          0.6               1.00       150      0.9566695  0.8039683  0.9939766
  0.3  2          0.8               0.50        50      0.9124655  0.5984127  0.9974249
  0.3  2          0.8               0.50       100      0.9341649  0.6642857  0.9965665
  0.3  2          0.8               0.50       150      0.9391148  0.7010582  0.9974249
  0.3  2          0.8               0.75        50      0.9390445  0.6571429  0.9982796
  0.3  2          0.8               0.75       100      0.9565116  0.7891534  0.9965628
  0.3  2          0.8               0.75       150      0.9565679  0.7962963  0.9965628
  0.3  2          0.8               1.00        50      0.9368676  0.6505291  0.9974249
  0.3  2          0.8               1.00       100      0.9531679  0.7751323  0.9931219
  0.3  2          0.8               1.00       150      0.9557018  0.8111111  0.9922599
  0.3  3          0.6               0.50        50      0.9314473  0.5912698  0.9991416
  0.3  3          0.6               0.50       100      0.9417133  0.6947090  0.9991416
  0.3  3          0.6               0.50       150      0.9448041  0.7018519  0.9991379
  0.3  3          0.6               0.75        50      0.9536102  0.7455026  0.9982796
  0.3  3          0.6               0.75       100      0.9585065  0.7965608  0.9974175
  0.3  3          0.6               0.75       150      0.9592697  0.8039683  0.9974175
  0.3  3          0.6               1.00        50      0.9515201  0.7600529  0.9957008
  0.3  3          0.6               1.00       100      0.9599974  0.8259259  0.9948424
  0.3  3          0.6               1.00       150      0.9608753  0.8404762  0.9957008
  0.3  3          0.8               0.50        50      0.9252510  0.6788360  0.9991416
  0.3  3          0.8               0.50       100      0.9349215  0.7298942  0.9991416
  0.3  3          0.8               0.50       150      0.9361624  0.7298942  0.9982833
  0.3  3          0.8               0.75        50      0.9415905  0.7380952  0.9965591
  0.3  3          0.8               0.75       100      0.9476621  0.8037037  0.9957008
  0.3  3          0.8               0.75       150      0.9490264  0.8037037  0.9957008
  0.3  3          0.8               1.00        50      0.9518009  0.7814815  0.9965628
  0.3  3          0.8               1.00       100      0.9591921  0.8330688  0.9957045
  0.3  3          0.8               1.00       150      0.9610141  0.8404762  0.9939803
  0.4  1          0.6               0.50        50      0.8790496  0.4600529  0.9982833
  0.4  1          0.6               0.50       100      0.9136595  0.6497354  0.9974212
  0.4  1          0.6               0.50       150      0.9274114  0.6788360  0.9974249
  0.4  1          0.6               0.75        50      0.8945193  0.4812169  0.9991416
  0.4  1          0.6               0.75       100      0.9218560  0.7373016  0.9965628
  0.4  1          0.6               0.75       150      0.9385988  0.7521164  0.9974212
  0.4  1          0.6               1.00        50      0.9115156  0.4962963  0.9982833
  0.4  1          0.6               1.00       100      0.9378004  0.7447090  0.9974212
  0.4  1          0.6               1.00       150      0.9471699  0.7743386  0.9948387
  0.4  1          0.8               0.50        50      0.8685740  0.4743386  0.9974249
  0.4  1          0.8               0.50       100      0.9116237  0.6722222  0.9957082
  0.4  1          0.8               0.50       150      0.9233170  0.7079365  0.9974249
  0.4  1          0.8               0.75        50      0.9000803  0.5034392  0.9965628
  0.4  1          0.8               0.75       100      0.9299949  0.7595238  0.9957008
  0.4  1          0.8               0.75       150      0.9402782  0.7595238  0.9957008
  0.4  1          0.8               1.00        50      0.9178410  0.4962963  0.9991416
  0.4  1          0.8               1.00       100      0.9400574  0.7373016  0.9965591
  0.4  1          0.8               1.00       150      0.9496373  0.7743386  0.9956971
  0.4  2          0.6               0.50        50      0.9164373  0.5989418  1.0000000
  0.4  2          0.6               0.50       100      0.9346896  0.6719577  0.9982833
  0.4  2          0.6               0.50       150      0.9373443  0.6719577  0.9965628
  0.4  2          0.6               0.75        50      0.9334873  0.6936508  0.9974249
  0.4  2          0.6               0.75       100      0.9467002  0.7666667  0.9957045
  0.4  2          0.6               0.75       150      0.9507536  0.7666667  0.9957045
  0.4  2          0.6               1.00        50      0.9431925  0.7669312  0.9965628
  0.4  2          0.6               1.00       100      0.9535590  0.7965608  0.9939840
  0.4  2          0.6               1.00       150      0.9550624  0.8111111  0.9939803
  0.4  2          0.8               0.50        50      0.9193606  0.6428571  0.9982833
  0.4  2          0.8               0.50       100      0.9383049  0.7079365  0.9965628
  0.4  2          0.8               0.50       150      0.9417099  0.7079365  0.9965665
  0.4  2          0.8               0.75        50      0.9336694  0.7380952  0.9965628
  0.4  2          0.8               0.75       100      0.9504022  0.7669312  0.9957045
  0.4  2          0.8               0.75       150      0.9515268  0.7669312  0.9965628
  0.4  2          0.8               1.00        50      0.9377568  0.7521164  0.9974212
  0.4  2          0.8               1.00       100      0.9528855  0.7817460  0.9957008
  0.4  2          0.8               1.00       150      0.9540792  0.7962963  0.9957008
  0.4  3          0.6               0.50        50      0.9288285  0.6730159  0.9948461
  0.4  3          0.6               0.50       100      0.9406680  0.6878307  0.9948461
  0.4  3          0.6               0.50       150      0.9427529  0.6878307  0.9957045
  0.4  3          0.6               0.75        50      0.9477641  0.7674603  0.9974249
  0.4  3          0.6               0.75       100      0.9524540  0.7894180  0.9965628
  0.4  3          0.6               0.75       150      0.9539893  0.7968254  0.9965628
  0.4  3          0.6               1.00        50      0.9512177  0.8111111  0.9965591
  0.4  3          0.6               1.00       100      0.9561501  0.8185185  0.9974212
  0.4  3          0.6               1.00       150      0.9562694  0.8185185  0.9974212
  0.4  3          0.8               0.50        50      0.9360838  0.6140212  0.9965665
  0.4  3          0.8               0.50       100      0.9406312  0.6798942  0.9957045
  0.4  3          0.8               0.50       150      0.9442744  0.7161376  0.9974212
  0.4  3          0.8               0.75        50      0.9516240  0.8037037  0.9974249
  0.4  3          0.8               0.75       100      0.9559872  0.8037037  0.9957045
  0.4  3          0.8               0.75       150      0.9563921  0.8037037  0.9965628
  0.4  3          0.8               1.00        50      0.9517218  0.8111111  0.9948387
  0.4  3          0.8               1.00       100      0.9570027  0.8256614  0.9939803
  0.4  3          0.8               1.00       150      0.9583176  0.8256614  0.9948424

Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter 'min_child_weight' was held constant at a value of 1
ROC was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 150, max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample = 1.
[1] "CONFUSION MATRIX: "
Cross-Validated (5 fold) Confusion Matrix 

(entries are percentual average cell counts across resamples)
 
          Reference
Prediction negative positive
  negative      8.8      0.5
  positive      1.7     88.9
                            
 Accuracy (average) : 0.9777

[1] "TRAIN accuracy: 0.977692307692308"
[1] "TRAIN +precision: 0.981324278438031"
[1] "TRAIN -precision: 0.942622950819672"
[1] "TRAIN specifity: 0.839416058394161"
[1] "TRAIN sensitivity: 0.993981083404987"
[1] "***************************************************************************************"
[1] "***************************************** TEST ****************************************"
[1] "***************************************************************************************"
[1] "TEST ConfMatrix : "
                    label
sentiment_prediction negative positive
            negative        0        1
            positive        6      389
[1] "TEST accuracy: 0.982323232323232"
[1] "TEST +precision: 0.984810126582279"
[1] "TEST -precision: 0"
[1] "TEST specifity: 0"
[1] "TEST sensitivity: 0.997435897435897"
